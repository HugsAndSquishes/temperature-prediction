{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from sklearn.model_selection import train_test_split, TimeSeriesSplit\n",
    "from sklearn.metrics import accuracy_score\n",
    "from sklearn.compose import ColumnTransformer\n",
    "from sklearn.preprocessing import StandardScaler, MinMaxScaler\n",
    "from sklearn.preprocessing import OneHotEncoder, OrdinalEncoder\n",
    "from sklearn.pipeline import Pipeline\n",
    "import joblib\n",
    "\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import LSTM, Dense\n",
    "from scikeras.wrappers import KerasRegressor\n",
    "\n",
    "import os"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 105,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv('../data/processed/preprocessed_data.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 106,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Entity</th>\n",
       "      <th>Year</th>\n",
       "      <th>Daily Average Temp</th>\n",
       "      <th>Monthly Average Temp</th>\n",
       "      <th>Month</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Afghanistan</td>\n",
       "      <td>1940</td>\n",
       "      <td>-2.032494</td>\n",
       "      <td>11.327695</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Afghanistan</td>\n",
       "      <td>1940</td>\n",
       "      <td>-0.733503</td>\n",
       "      <td>11.327695</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Afghanistan</td>\n",
       "      <td>1940</td>\n",
       "      <td>1.999134</td>\n",
       "      <td>11.327695</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Afghanistan</td>\n",
       "      <td>1940</td>\n",
       "      <td>10.199754</td>\n",
       "      <td>11.327695</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Afghanistan</td>\n",
       "      <td>1940</td>\n",
       "      <td>17.942135</td>\n",
       "      <td>11.327695</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "        Entity  Year  Daily Average Temp  Monthly Average Temp  Month\n",
       "0  Afghanistan  1940           -2.032494             11.327695      1\n",
       "1  Afghanistan  1940           -0.733503             11.327695      2\n",
       "2  Afghanistan  1940            1.999134             11.327695      3\n",
       "3  Afghanistan  1940           10.199754             11.327695      4\n",
       "4  Afghanistan  1940           17.942135             11.327695      5"
      ]
     },
     "execution_count": 106,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.head(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = df.drop('Daily Average Temp', axis=1)\n",
    "y = df['Daily Average Temp']\n",
    "# split data chronologically so that we train on older data and test with newer data\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Entity</th>\n",
       "      <th>Year</th>\n",
       "      <th>Monthly Average Temp</th>\n",
       "      <th>Month</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>6014</th>\n",
       "      <td>Angola</td>\n",
       "      <td>2016</td>\n",
       "      <td>22.886465</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>71221</th>\n",
       "      <td>Georgia</td>\n",
       "      <td>2010</td>\n",
       "      <td>10.112088</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>120599</th>\n",
       "      <td>Montenegro</td>\n",
       "      <td>1959</td>\n",
       "      <td>8.623334</td>\n",
       "      <td>12</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15706</th>\n",
       "      <td>Bangladesh</td>\n",
       "      <td>1973</td>\n",
       "      <td>25.110266</td>\n",
       "      <td>11</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>119862</th>\n",
       "      <td>Mongolia</td>\n",
       "      <td>1983</td>\n",
       "      <td>0.719259</td>\n",
       "      <td>7</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "            Entity  Year  Monthly Average Temp  Month\n",
       "6014        Angola  2016             22.886465      3\n",
       "71221      Georgia  2010             10.112088      2\n",
       "120599  Montenegro  1959              8.623334     12\n",
       "15706   Bangladesh  1973             25.110266     11\n",
       "119862    Mongolia  1983              0.719259      7"
      ]
     },
     "execution_count": 85,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Entity</th>\n",
       "      <th>Year</th>\n",
       "      <th>Monthly Average Temp</th>\n",
       "      <th>Month</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>50398</th>\n",
       "      <td>Denmark</td>\n",
       "      <td>1974</td>\n",
       "      <td>8.713705</td>\n",
       "      <td>11</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>115782</th>\n",
       "      <td>Mauritania</td>\n",
       "      <td>1983</td>\n",
       "      <td>27.948732</td>\n",
       "      <td>7</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>112125</th>\n",
       "      <td>Madagascar</td>\n",
       "      <td>2018</td>\n",
       "      <td>22.812632</td>\n",
       "      <td>10</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>56427</th>\n",
       "      <td>El Salvador</td>\n",
       "      <td>1967</td>\n",
       "      <td>25.615232</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>97929</th>\n",
       "      <td>Kenya</td>\n",
       "      <td>1940</td>\n",
       "      <td>23.996480</td>\n",
       "      <td>10</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "             Entity  Year  Monthly Average Temp  Month\n",
       "50398       Denmark  1974              8.713705     11\n",
       "115782   Mauritania  1983             27.948732      7\n",
       "112125   Madagascar  2018             22.812632     10\n",
       "56427   El Salvador  1967             25.615232      4\n",
       "97929         Kenya  1940             23.996480     10"
      ]
     },
     "execution_count": 71,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_test.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Scale and Encode"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {},
   "outputs": [],
   "source": [
    "categorical_cols = [\"Entity\"]\n",
    "numerical_cols = [\"Monthly Average Temp\"]\n",
    "#date_cols = [\"Day\"]\n",
    "\n",
    "preprocessor = ColumnTransformer([\n",
    "    (\"onehot\", OneHotEncoder(handle_unknown=\"ignore\"), categorical_cols),\n",
    "    (\"scale\", StandardScaler(), numerical_cols)\n",
    "])\n",
    "\n",
    "preprocessor_with_date = ColumnTransformer([\n",
    "    (\"onehot\", OneHotEncoder(handle_unknown=\"ignore\"), categorical_cols),\n",
    "    (\"scale\", StandardScaler(), numerical_cols),\n",
    "    (\"ordinal\", OrdinalEncoder(), date_cols)\n",
    "])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Linear Regression"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Linear Regression: Training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.linear_model import LinearRegression\n",
    "from sklearn.metrics import mean_squared_error, r2_score, root_mean_squared_error\n",
    "from sklearn.model_selection import train_test_split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['../models/global/linear_regression_global_pipeline.pkl']"
      ]
     },
     "execution_count": 79,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pipeline = Pipeline([\n",
    "    (\"preprocessor\", preprocessor),\n",
    "    (\"model\", LinearRegression())\n",
    "])\n",
    "\n",
    "pipeline.fit(X_train, y_train)\n",
    "linear_regression_y_pred = pipeline.predict(X_test)\n",
    "joblib.dump(pipeline, '../models/global/linear_regression_global_pipeline.pkl')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Linear Regression: Evaluation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Mean Squared Error: 28.85676379780414\n",
      "R-squared: 0.7270881906378455\n"
     ]
    }
   ],
   "source": [
    "# Mean Squared Error\n",
    "mse = mean_squared_error(y_test, linear_regression_y_pred)\n",
    "print(f\"Mean Squared Error: {mse}\")\n",
    "\n",
    "rmse = root_mean_squared_error(y_test, linear_regression_y_pred)\n",
    "\n",
    "# R-squared\n",
    "r2 = r2_score(y_test, linear_regression_y_pred)\n",
    "print(f\"R-squared: {r2}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Linear Regression: Hypertuning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import GridSearchCV\n",
    "\n",
    "def hypertune_model(model_or_pipeline, param_grid, X_train, y_train, cv=5, scoring=None, verbose=1):\n",
    "    grid_search = GridSearchCV(\n",
    "        estimator=model_or_pipeline,\n",
    "        param_grid=param_grid,\n",
    "        cv=cv,\n",
    "        scoring=scoring,\n",
    "        verbose=verbose,\n",
    "        n_jobs=-1\n",
    "    )\n",
    "    \n",
    "    grid_search.fit(X_train, y_train)\n",
    "    \n",
    "    print(\"Best Parameters:\", grid_search.best_params_)\n",
    "    return grid_search.best_estimator_, grid_search.best_params_, grid_search"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'preprocessor' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mNameError\u001b[39m                                 Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[20]\u001b[39m\u001b[32m, line 2\u001b[39m\n\u001b[32m      1\u001b[39m pipeline = Pipeline([\n\u001b[32m----> \u001b[39m\u001b[32m2\u001b[39m     (\u001b[33m\"\u001b[39m\u001b[33mpreprocessor\u001b[39m\u001b[33m\"\u001b[39m, \u001b[43mpreprocessor\u001b[49m),\n\u001b[32m      3\u001b[39m     (\u001b[33m'\u001b[39m\u001b[33mregressor\u001b[39m\u001b[33m'\u001b[39m, LinearRegression())\n\u001b[32m      4\u001b[39m ])\n\u001b[32m      6\u001b[39m param_grid = {\n\u001b[32m      7\u001b[39m     \u001b[33m'\u001b[39m\u001b[33mregressor__fit_intercept\u001b[39m\u001b[33m'\u001b[39m: [\u001b[38;5;28;01mTrue\u001b[39;00m, \u001b[38;5;28;01mFalse\u001b[39;00m],\n\u001b[32m      8\u001b[39m     \u001b[33m'\u001b[39m\u001b[33mregressor__positive\u001b[39m\u001b[33m'\u001b[39m: [\u001b[38;5;28;01mTrue\u001b[39;00m, \u001b[38;5;28;01mFalse\u001b[39;00m],\n\u001b[32m      9\u001b[39m }\n\u001b[32m     11\u001b[39m best_model, best_params, grid = hypertune_model(\n\u001b[32m     12\u001b[39m     pipeline, param_grid, X_train, y_train, scoring=\u001b[33m'\u001b[39m\u001b[33mneg_mean_squared_error\u001b[39m\u001b[33m'\u001b[39m\n\u001b[32m     13\u001b[39m )\n",
      "\u001b[31mNameError\u001b[39m: name 'preprocessor' is not defined"
     ]
    }
   ],
   "source": [
    "pipeline = Pipeline([\n",
    "    (\"preprocessor\", preprocessor),\n",
    "    ('regressor', LinearRegression())\n",
    "])\n",
    "\n",
    "param_grid = {\n",
    "    'regressor__fit_intercept': [True, False],\n",
    "    'regressor__positive': [True, False],\n",
    "}\n",
    "\n",
    "best_model, best_params, grid = hypertune_model(\n",
    "    pipeline, param_grid, X_train, y_train, scoring='neg_mean_squared_error'\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE: 3.7132\n",
      "MSE: 28.8568\n",
      "RMSE: 5.3718\n",
      "R²: 0.7271\n"
     ]
    }
   ],
   "source": [
    "# Predict on test data\n",
    "y_pred = best_model.predict(X_test)\n",
    "\n",
    "# Evaluate\n",
    "from sklearn.metrics import mean_squared_error, r2_score, root_mean_squared_error\n",
    "\n",
    "mae = mean_absolute_error(y_test, y_pred)\n",
    "mse = mean_squared_error(y_test, y_pred)\n",
    "rmse = root_mean_squared_error(y_test, y_pred)\n",
    "r2 = r2_score(y_test, y_pred)\n",
    "\n",
    "print(f\"MAE: {mae:.4f}\")\n",
    "print(f\"MSE: {mse:.4f}\")\n",
    "print(f\"RMSE: {rmse:.4f}\")\n",
    "print(f\"R²: {r2:.4f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Text(0.5, 1.0, 'Actual vs Predicted Temperature')"
      ]
     },
     "execution_count": 51,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 1000x600 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "\n",
    "plt.figure(figsize=(10, 6))\n",
    "plt.scatter(y_test, y_pred, alpha=0.5)\n",
    "plt.plot([y_test.min(), y_test.max()], [y_test.min(), y_test.max()], 'r--')\n",
    "plt.xlabel('Actual Temperature')\n",
    "plt.ylabel('Predicted Temperature')\n",
    "plt.title('Actual vs Predicted Temperature')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Long short-term memory LSTM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from LSTM_pipeline import LSTMPipeline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# focus on one country, and sort by Day\n",
    "df_country = df[df[\"Entity\"] == \"Afghanistan\"].copy()\n",
    "df_country[\"Day\"] = pd.to_datetime(df_country[\"Day\"])\n",
    "df_country = df_country.sort_values(by=\"Day\")\n",
    "monthly_temp = df_country[[\"Monthly Average Temp\"]].values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/dejauhnaebeadle/School/MachineLearning/machine-learning-project/code/rain-prediction/.venv/lib/python3.11/site-packages/keras/src/layers/rnn/rnn.py:200: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
      "  super().__init__(**kwargs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/30\n",
      "\u001b[1m46/46\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 11ms/step - loss: 0.0861 - val_loss: 0.0128\n",
      "Epoch 2/30\n",
      "\u001b[1m46/46\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - loss: 0.0159 - val_loss: 0.0198\n",
      "Epoch 3/30\n",
      "\u001b[1m46/46\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - loss: 0.0129 - val_loss: 0.0110\n",
      "Epoch 4/30\n",
      "\u001b[1m46/46\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 0.0116 - val_loss: 0.0101\n",
      "Epoch 5/30\n",
      "\u001b[1m46/46\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 0.0086 - val_loss: 0.0072\n",
      "Epoch 6/30\n",
      "\u001b[1m46/46\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 0.0084 - val_loss: 0.0068\n",
      "Epoch 7/30\n",
      "\u001b[1m46/46\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 0.0079 - val_loss: 0.0071\n",
      "Epoch 8/30\n",
      "\u001b[1m46/46\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 0.0080 - val_loss: 0.0070\n",
      "Epoch 9/30\n",
      "\u001b[1m46/46\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 0.0067 - val_loss: 0.0065\n",
      "Epoch 10/30\n",
      "\u001b[1m46/46\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 0.0074 - val_loss: 0.0062\n",
      "Epoch 11/30\n",
      "\u001b[1m46/46\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 0.0067 - val_loss: 0.0113\n",
      "Epoch 12/30\n",
      "\u001b[1m46/46\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - loss: 0.0065 - val_loss: 0.0064\n",
      "Epoch 13/30\n",
      "\u001b[1m46/46\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - loss: 0.0062 - val_loss: 0.0095\n",
      "Epoch 14/30\n",
      "\u001b[1m46/46\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 13ms/step - loss: 0.0061 - val_loss: 0.0068\n",
      "Epoch 15/30\n",
      "\u001b[1m46/46\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 12ms/step - loss: 0.0047 - val_loss: 0.0171\n",
      "Epoch 16/30\n",
      "\u001b[1m46/46\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 14ms/step - loss: 0.0070 - val_loss: 0.0048\n",
      "Epoch 17/30\n",
      "\u001b[1m46/46\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 18ms/step - loss: 0.0049 - val_loss: 0.0062\n",
      "Epoch 18/30\n",
      "\u001b[1m46/46\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 14ms/step - loss: 0.0056 - val_loss: 0.0047\n",
      "Epoch 19/30\n",
      "\u001b[1m46/46\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 12ms/step - loss: 0.0051 - val_loss: 0.0051\n",
      "Epoch 20/30\n",
      "\u001b[1m46/46\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 11ms/step - loss: 0.0048 - val_loss: 0.0063\n",
      "Epoch 21/30\n",
      "\u001b[1m46/46\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 11ms/step - loss: 0.0043 - val_loss: 0.0062\n",
      "Epoch 22/30\n",
      "\u001b[1m46/46\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - loss: 0.0057 - val_loss: 0.0042\n",
      "Epoch 23/30\n",
      "\u001b[1m46/46\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 0.0043 - val_loss: 0.0048\n",
      "Epoch 24/30\n",
      "\u001b[1m46/46\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 0.0054 - val_loss: 0.0044\n",
      "Epoch 25/30\n",
      "\u001b[1m46/46\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 0.0042 - val_loss: 0.0041\n",
      "Epoch 26/30\n",
      "\u001b[1m46/46\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 0.0045 - val_loss: 0.0059\n",
      "Epoch 27/30\n",
      "\u001b[1m46/46\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 0.0035 - val_loss: 0.0050\n",
      "Epoch 28/30\n",
      "\u001b[1m46/46\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 0.0048 - val_loss: 0.0050\n",
      "Epoch 29/30\n",
      "\u001b[1m46/46\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - loss: 0.0043 - val_loss: 0.0075\n",
      "Epoch 30/30\n",
      "\u001b[1m46/46\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 0.0044 - val_loss: 0.0051\n"
     ]
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAA0MAAAHDCAYAAADm78EeAAAAOnRFWHRTb2Z0d2FyZQBNYXRwbG90bGliIHZlcnNpb24zLjEwLjEsIGh0dHBzOi8vbWF0cGxvdGxpYi5vcmcvc2/+5QAAAAlwSFlzAAAPYQAAD2EBqD+naQAAkJpJREFUeJzt3Qd4VGX6NvA7yaSTQif0DoJSRERcCwgLsq4Fe++4dnddXWXX3thm2VX/lv1sa3d30XXtYENXUYFFsICA9N6SkDqZyXzX857znsxMEkhmJjPvmbl/13WYZDJJDpMp5zlPedMCgUAAREREREREKSY90TtARERERESUCAyGiIiIiIgoJTEYIiIiIiKilMRgiIiIiIiIUhKDISIiIiIiSkkMhoiIiIiIKCUxGCIiIiIiopTEYIiIiIiIiFISgyEiIiIiIkpJDIaIiMg4H330EdLS0tSldv7556Nv374x+x1PP/20+h1r1qyJ2c8kIiJ3YTBERBRD+gB7wYIFe73d9u3bcc0112Do0KHIzc1Fly5dcPDBB+OGG25ARUWFEwy0ZAv+vbJ9+umnjX5fIBBAr1691Nd//vOf7/P/MWHChJDf0aFDB4wdOxZPPvkk6uvr4Sb33HMPXnvtNaQCCRhb8piR2xEREeBJ9A4QEaWaXbt24aCDDkJ5eTkuvPBCFRDt3LkTS5YswSOPPILLLrsM++23H5599tmQ75s5cybatWuH3/3ud83+7JycHLzwwgs47LDDQq7/+OOPsWHDBmRnZ7d4P3v27IlZs2Y5wdvf//53XHTRRfjhhx/w+9//HvH2t7/9LaJATIKhk08+GSeccELI9eeccw5OP/30Vt0npvvFL36ByZMnO5+vXr0at9xyCy655BIcfvjhzvUDBgxI0B4SEZmFwRARUZw98cQTWLduHf773//i0EMPDfmaBEhZWVkqqDn77LNDviYBSKdOnRpdH+xnP/sZ/vGPf+Cvf/0rPJ6Gl3gJkMaMGYMdO3a0eD+LiopCfpccaA8ZMgQPPfQQ7rzzTmRmZjb6HglWvF6v2v9Ya+r3RSMjI0NtyWT8+PFq0yRDKcGQXLe3x01lZSXy8/PjtJdEROZgmRwRUZytWrVKHYQfcsghjb5WWFgYVSBxxhlnqCzTnDlznOskOPnnP/+JM888E9HIy8tT+ywHzpIpElJydeWVV+L555/H8OHDVZblnXfeUV/buHGjynx17dpVXS9flzK7cJKxkqyNHIxLueCvfvUr1NbWNrpdUz1DEnz95S9/wQEHHKDut86dO+Poo492yhRl/2R/n3nmmUYlYs31DP3f//2f83/p3r07rrjiCpSWljYqI9x///3x3XffYeLEieq+6dGjB/74xz/u836U75PvCSf/F/kZksXSXnrpJRXEFhQUqMeG/D/l/xsN/f+WbOHll1+u7nPJAu6tL+u2225zSjKDPffcc2r/pNRTSikl07Z+/fqo9o+IKJ4YDBERxVmfPn3g9/sblcHFghzIShbgxRdfdK57++23UVZWpg5Uo/Xjjz+qQK64uNi57oMPPlABzGmnnaYO1GUftm7dqgKnuXPnqmBJrh84cKAqs3vggQec762ursakSZPw7rvvqttJCeAnn3yC3/zmNy3aH/l5v/zlL1U/1B/+8AfceOONKiiaP3+++rrcxxLUSImYfCybZLiaIwf9EvxIEHTvvffipJNOwmOPPYYpU6agrq4u5La7d+9WgdfIkSPVbaXcUXq+5P7eG7mf5s2bhy1btoRcL71emzZtcv5OEtBKcNu+fXv1f5PMoARhklGMBQmEJJiTzJHcb611991349xzz8WgQYNw3333qb/D+++/jyOOOKJR8EhEZKwAERHFzFNPPRWQl9avvvqq2dts2bIl0LlzZ3W7oUOHBi699NLACy+8ECgtLd3rzx4+fHjgyCOP3OfvfeihhwIFBQWBqqoq9bVTTjklMHHiRPVxnz59Asccc8w+/x/ye2Tftm/frrbvv/8+cPXVV6vfceyxxzq3k8/T09MD3377bcj3X3TRRYGSkpLAjh07Qq4//fTTA0VFRc6+PfDAA+pnvPLKK85tKisrAwMHDlTXf/jhh8715513ntp/7YMPPlC3kf0KV19f73ycn5+vvre5+2z16tXq823btgWysrICU6ZMCfj9fud2cn/K7Z588smQ+0eu+/vf/+5cV1tbG+jWrVvgpJNO2ut9u3z5cvW9Dz74YMj1l19+eaBdu3bOfXPNNdcECgsLAz6fLxApeTzI75L/a/j/+7DDDmv0s8PvY+3WW29V36OtWbMmkJGREbj77rtDbrd06dKAx+NpdD0RkamYGSIiijMpG/v6669x6aWXquzCo48+qkrYpFxJenGsGCNyp556qsq4vPHGG9izZ4+6jKREbtmyZarsTDYZ6PDggw/imGOOaVTqduSRR2LYsGHO57L///rXv3Dssceqj6VPSW9Tp05VWapFixap27711lsoKSkJKQ2TkjNp+N8X+R1SunXrrbc2+lpTJV37IlksKSmUDEd6esPb44wZM1SJ2ptvvhlyexlmEdyHI71eMhFQsmd7M3jwYIwaNQovv/yyc51kCqWUUe4zKTkTkn2TEr/gksdYkv9XpD1Ts2fPVmV98lgL/vt269ZNZYo+/PDDmO8vEVFb4AAFIqIEkABAJsdJf8qKFStUmZiUQknJknzt4osvjvhnS/AiE8VkaEJVVZU60A4ONlpKyt1kgpsEFlJ6Jge5ErCF69evX8jn0k8kZVKPP/642pqybds2dbl27VpVPhcevMighpb0Xkk5m/SqxILsS1O/W4Kc/v37O1/XpM8mfL+lpE2mAu6LlMr99re/VX1V0icko9TlPpHrg8vYXnnlFUybNk3dRkr1JPiQ0rxYCP+7tYY8ZiXQlcdEPIZdEBG1FQZDREQJJAfTkimQTbIucnApwwiiCYaEZILkzL/0pcjBdHCPT0vJQIPgMc3N0ZkMTY+/lqzJeeed1+T3jBgxAm7XXFalJZk9CXpkVLpM/pNMlAQ9Mr0vONCRwHPx4sUqUJY+JNmeeuop1acjAyGiFf5321tGTQLq8L+x3Fb2qan7QbJmRERuwGCIiMgQkn2QzMLmzZuj/lnTp09XgwJkkEBwOVY8SGZKpp/JAfS+gikZJvHNN9+oACL4QHz58uX7/D2yVo4ECrJu096yQy0tmZN90b9b/haalM7Jej0tCQxbk5WRkjr528jgCCk7k4l64WseSVZKSudkkwBEskUy0OHmm29WGbVYk8dfU8MPwrNict/L30z+HxLIExG5FXuGiIji7IsvvlC9IOG+/PJLNRa7JSVi+yJn5qUMT6ajyYF0PEmmQKawSU+PBDrh9FhuvS6STFCTfhlNSvuaK68LJr9DDshvv/32vWZnJMPVkulmEuxI8CFrNAV/v6wLJX1OkrmLJckOSbAqPVjSbxNcIifksRBM+ph0Rq2p0eOxIEGO/F+DS/0kOH/11VdDbnfiiSeqv7Pc9+GZMPk8fN+JiEzFzBARURuQA1y93k6wa665Ro13llI4yd7IGi1yAP7999+r75HeHOkliYXmStTiQcZASxP9uHHjVLmeDFiQDI4MTpBBBfKxkK/JIq5S+rVw4ULVLyX3jwxR2BdZq+ecc85RwYv0sEiJmWRPZDS3fE0yLkLuY/mdMv5ZeowkmyH71VRGS0rX5ABfftZxxx2nskTS1zV27Ni9LloaCen/ue6669Qmma3wzJOUSsr9dNRRR6n+JMnOyBALGb4gAy3agoz1lvHg8ti8+uqrVWAqQbVkf/TQCx003XXXXer+knWaJKsl2UDJoEngJAMw5P9FRGQ6BkNERG1ADiCbIotaSvmaHOzLmiz//ve/UV5erg7EpUFeDi5Hjx6NZJiYJ5muO+64Q5WASUDRsWNHtZipDIrQ9P1w1VVXqQN9+fyss85SfU4tGRQgPTSSLZHszfXXX6/6bg466CAceuihzm0kCJKD85tuuklN2ZMgsalgSEgmTf4WEqDJ2kkSpMj33nPPPTEfCiABjuynrBskgU/4z5fgSzJkct9JZksmtUn2SPYxeNpdLMnfSIKZa6+9Vq31JIHjrFmzVLAZHAwJWZtIgqT777/fyc7Jek/yOJZAkojIDdJkvnaid4KIiIiIiCje2DNEREREREQpicEQERERERGlJAZDRERERESUkhgMERERERFRSmIwREREREREKYnBEBERERERpaSkWWdIFtqTVcxl0be0tLRE7w4RERERESWIrB60Z88etdj23tZmS5pgSAIhWeyNiIiIiIhIrF+/Xi1ynfTBkGSE9H+4sLAw0btDREREREQJUl5erhIlOkZI+mBIl8ZJIMRgiIiIiIiI0vbRPsMBCkRERERElJIYDBERERERUUpiMERERERERCkpaXqGWjp+2+v1Jno3KEKZmZnIyMhI9G4QERERUZJImWBIgqDVq1ergIjcq7i4GN26deNaUkREREQUNU+qLLq0efNmlVWQEXt7W3iJzP0bVlVVYdu2berzkpKSRO8SEREREblcSgRDPp9PHUjLCrR5eXmJ3h2KUG5urrqUgKhLly4smSMiIiKiqKREisTv96vLrKysRO8KRUkHs3V1dYneFSIiIiJKtWBo3rx5OPbYY1WWRfo2XnvttWZve+mll6rbPPDAA/v8uQ8//DD69u2LnJwcjBs3Dl9++SVijX0m7se/IRERERElLBiqrKzEyJEjVfCyN6+++irmz5+vgqZ9efnll3Httdfi1ltvxaJFi9TPnzp1qtMfQkRERERElPBgaNq0abjrrrswffr0Zm+zceNGXHXVVXj++efVOOR9ue+++zBjxgxccMEFGDZsGB599FFVDvXkk0+2dveIiIiIiIgS0zMko6vPOeccXH/99Rg+fHiLRl4vXLgQkydPbtip9HT1+eeff97s99XW1qK8vDxkS7ZysL1tt912W6J3kYiIiIjI1WI+Te4Pf/gDPB4Prr766hbdfseOHWrAQdeuXUOul8+XLVvW7PfNmjULt99+O5KVjAIPLiO85ZZbsHz5cue6du3ahYydlvtQ7nciIiIiImqZmB49S4bnL3/5i+r7aetG95kzZ6o+I00yQ7KGULKQhUW1oqIidX/q6z766CNMnDgRb731Fm666SYsXboU7733Hp5++mmUlpaGDLX45S9/icWLF6vv0Zk7CVgff/xxbNmyBYMHD8bNN9+Mk08+OQH/SyIiIoqEnAj9bnM5dleaOV21Z/tc9O2Un+jdIIpvMPTJJ5+ooQe9e/d2rpOMxa9//Ws1UW7NmjWNvqdTp05qvZitW7eGXC+fBwcE4bKzs9UW6QtIdZ01bjvecjMzYhYo3njjjfjzn/+M/v37o3379i36HsmoPffcc6ova9CgQWo64Nlnn43OnTvjyCOPjMl+ERERUdv6cPk2XPj0ApgqPQ34+PqJ6NWB6ztSCgVD0isU3PsjZCqcXC/DEZoia/+MGTMG77//Pk444QQneyGfX3nllWgLEggNu+VdJMJ3d0xFXlZs7vY77rgDP/3pT1t8e+mzuueeezB37lyMHz9eXSeB1KefforHHnuMwRAREZFLrNlRpS4LcjzoUWwtSq61q6/AL6r/hreyp+F7z9C479u6XVWo8vpV5orBEJmu1UflFRUVWLlypfP56tWrVRlWhw4dVEaoY8eOIbeXaXKS4RkyZIhz3aRJk9Q0Oh3sSLnbeeedh4MOOggHH3ywyiLJCO/mAiiyyP3VGvJ3q6qqahRAyRCL0aNHx3jviIiIqK346wPqctLQLnjg9LD38C//Brz1AX7aYTtw2adx37fLnluIt7/Zgs2l1XH/3URtHgwtWLBA9atoum9HghnpWWmJVatWqcEJ2mmnnYbt27erIQHSxzJq1Ci88847jYYqxLJUTTI0iSC/O1by80NrcWUKn5QABqurqwsJZMWbb76JHj16hNwu0pJDIiIiij+fHQxlpDcxGLhyu3W5dSmw9Tug67C47ltJkZWp2lxWE9ffSxSXYGjChAmNDrj3pqk+oaaukyxRW5XFhZOenViVqplE+n6++eabkOska6fXepI1nCToWbduHUviiIiIXMxfX68uPdKcE65qZ8PHS18BusZ3OY7uxTnqchODIUrFdYYocY466iiVufv73/+OFStW4NZbbw0JjgoKCnDdddfhV7/6FZ555hmVoZPJfw8++KD6nIiIiNyVGfJk7CsY+qc0YycmM8QyOXIBBkNJRIZVyJjs3/zmNxg7diz27NmDc889N+Q2d955p7qNTJXbb7/9cPTRR6uyuX79+iVsv4mIiCiynqF9ZobK1gPr58dxz4ASOzPEMjlyg+SrFUtC559/vtpaUqooC9HubTFaKRG85ppr1EZERERJ2DNUtdu6LOwJlG8AlrwM9Dk0bvtWUmQFQ1vKa1TQltFUwEZkCGaGiIiIiNyaGdpbmdzBM6zLb18DfN647VuXghwVAMk+bt9TG7ffSxQJBkNERERELuPz68xQWDAklSM6GBp2PNCuG1BTCqycE7d9k33qWmBNqd1Uxr4hMhuDISIiIqJkmSbnrQT8djamXRfggJOtj5e8Etf9K7EXgt1cyr4hMhuDISIiIiKXqXN6hsKCIZ0V8uQAmXnAAadYny9/G6gpi3vf0GZmhshwDIaIiIiIXMZvl8l5mguGcjvI1CSgZCTQeaiVLfrmX3Hbv+52ZmgTM0NkOAZDRERERMkyTa56l3WZ19G6lIBo9DnWxwvjt6YgM0PkFgyGiIiIiJKlZ6hKB0MdGq4beTqQnglsXgxs/jquC69u4lpDZDgGQ0REREQuzQw1Gq2ty+R0ZkjkdwL2+7n18aJn47J/3fXCq6XMDJHZGAwRERERuXWdofQWBEPiwHMbpsp5q+KWGdpeUYs6v5XFIjIRgyHC+eefjxNOOMH5fMKECfjlL38Z9/346KOPkJaWhtLS0rj/biIioqToGWouGOo3ASjuDdSWAd+/3ub71zE/C1kZ6WrZo63lLJUjczEYMjxIkeBAtqysLAwcOBB33HEHfD5fm/7e2bNn484772zRbRnAEBERmZgZCuoZEhI0jT43boMU0tPT0M0ZosBgiMzlSfQO0N4dffTReOqpp1BbW4u33noLV1xxBTIzMzFz5syQ23m9XhUwxUKHDmEvoERERGRoZqi5AQphmSEx6kzgo3uAdZ8BO1YAnQa1+US5dbuqsMkFfUP19QE8/8VabNtjL1hrmE7tsnHmuN7IzGAeI9YYDBkuOzsb3bp1Ux9fdtllePXVV/H6669j+fLlKhszduxYPPzww+p2q1evxvr16/HrX/8a7733HtLT03H44YfjL3/5C/r27at+ht/vx/XXX48nn3wSGRkZuOiiixCQHHYQKZMbNWoUHnjgAfW5BGK33HILXnjhBWzbtg29evVSwdikSZMwceJEdZv27dury/POOw9PP/006uvr8Yc//AGPP/44tmzZgsGDB+Pmm2/GySfbK2EDKriTcjzZ50MOOUR9LxEREbVimlxGC6bJaUU9gEFTgB/eAf59BTDhRqD/RGv8dhuuNeSGzNC7327Bzf/+FiaTTNvU4dYxIcVOagZDcvBf1/bNg02S1aCjeNHJzc3Fzp1WCvz9999HYWEh5syZoz6vq6vD1KlTMX78eHzyySfweDy46667VHZpyZIlKnN07733qmBFgqH99ttPfS4B1lFHHdXs7zz33HPx+eef469//StGjhypgq4dO3aooOhf//oXTjrpJBWcyb7I/olZs2bhueeew6OPPopBgwZh3rx5OPvss9G5c2cceeSRKgA68cQTVabrkksuwYIFC1QQR0RERPtW528uM9RMz5B26NXAyrnA+i+AZ6cDnQYDg4+2vq98E1CxDcjKBwq6Au26Ah36W1/vOCDytYZckBl659st6vKgPu2xf48imGTeD9vx445KV9yPbpSawZAEQvd0T8zv/u0m60WmlSR7I8HPu+++i6uuugrbt29Hfn4+/t//+39OeZwEH5KRkeukj0dIiV1xcbHq7ZkyZYrK9khWRwIRIcGK/Mzm/PDDD3jllVdUwDV58mR1Xf/+/RuV1HXp0kX9Hp1JuueeezB37lwVmOnv+fTTT/HYY4+pYOiRRx7BgAEDVDAmhgwZgqVLl6psEhEREUXQMyQne/cVDPX9CXD5F8CXjwOLnwd2/GBte/Pub4HOQ4GhxwAjz2hxeV1JsTvWGvL66vHBsm3q45k/2w9j+ljVLqb43atLVTC0q6ou0buSlFIzGHKRN954A+3atVNZHwl0zjzzTNx2220qo3LAAQeE9Al9/fXXWLlyJQoKCkJ+Rk1NDVatWoWysjJs3rwZ48aNc74m2aODDjqoUamctnjxYlVOJwFMS8k+VFVV4ac//WmjvqbRo0erj7///vuQ/RA6cCIiIqIIpsnV7gHq7QPm3L30/3YaCPzsj8BRNwFLXraCIckCFXYH2nUBvJVWhmjPFmDjQmDNJ8D2Zdb2yb3AgEnAuEuBgZOtwQzN6O4MUDA7o/HF6p3YU+NTfTmje1kndk3SId861iut8iZ6V5JSagZDUqomGZpE/e5WkJ4cyaJI0NO9e3cVvGiSGQpWUVGBMWPG4Pnnn2/0c6Q8LRK67K01ZD/Em2++iR49eoR8TXqbiIiIqA16hqrtfiFPLpDVguONnELg4Bn7vl11KbBiDvDNv6x+o1XvW1uHAcC4X1jZIvlZzaw1tLnU7MzQe99uVZc/HdZVTcEzTXGeFQztZmaoTaRmMCQlZBGUqiWCBDwyUrslDjzwQLz88suqZE36d5pSUlKCL774AkcccYT6XMZ0L1y4UH1vUyT7JBmpjz/+2CmTC6YzUzKYQRs2bJgKetatW9dsRkn6lWQQRLD58+e36P9JRESU6nz+Jsrk9lUiF6ncYmDEKda2azXw1f8DFj0L7FoFvP0b4P07gdFnAQdfEtJb1L3YygztrPSips6PnMwMmDhFbs53VjA0ZXhXmKh9Xqa63F3JzFBb4Hy+JHLWWWehU6dOOP7449UABRl0IL1CV199NTZs2KBuc8011+D3v/89XnvtNSxbtgyXX375XtcIkil0MuXtwgsvVN+jf6b0EYk+ffqo/iQp55M+JskKSZneddddh1/96ld45plnVIneokWL8OCDD6rPxaWXXooVK1aoyXYyfEEm1clgByIiImp5z1DIAIW9TZKLlQ79gKl3A9d+BxxzrzWAwbsH+OJR4MEDgWdPBJa/A9T7UZSbiVw7ANpiaN/Q0o1l2FJeg/ysDBw6IMZBZIy0t8vkdrNMrk0wGEoieXl5ampb79691YAEyb7I6GzpGdKZIpnYds4556gAR3p0JHCZPn36Xn+ulOnJSGwJnIYOHYoZM2agsrJSfU3K4G6//XbceOON6Nq1K6688kp1vSzaKqO0Zaqc7IdMtJOyuX79+qmvyz7KJDoJsGRCnQxykKELRERE1JoBCultnxlqSnY7YOzFwBVfAue8ak2cQ5pVPvfiaSowSvv8IQwutEq7NhnaN/Ted9YUuQlDuiDbY17mSrTXZXLMDLWJtEBznfMuU15ejqKiIjUkILxETIIByWjIgXhOjpWyJXfi35LI/Z75bA1+//Yy+OyeB9OcclAv3DP9gETvBtFeHfHHD9WCpv+67NCG6WefP2xNftv/ZODkJ+K/U1JCt+AJq4Suxqo6qU3Lxqt141E49Xf42eEHwzRT7v8YP2ytwF9OH4XjR4X2OZti3c4qHPGnD1WW7fs7JeikaGODYMwMERFRXL39zWZU1/nVOikmbv9auKHZCZtERo/WjmdmqLkSuil3Add+Dxz3INDtAGQHanG65yMMXXwnTLN6R6UKhOQ+lMyQqYrzrZ4hed2U3iuKrdQcoEBERAlT67MyQn88eQSOGBTZpMu2UOevx+F//FDtX2lVnVOnT2QinVmNe89QS8gkuwPPBUafg3efuxdTV92JnPI1+HC5tZaPKT601xYaP6Cj6m8yVUG2RwVsMk5d+ob0lD6KDQZDREQUV7V11kFct8IcdLPXITFFx/wsNflqc1kNgyFyxzS5DIMyQ+HS0lDXcxywCijybsUFT31p9RUZZsowM6fIaTKoSsZr76ioxe7KOgZDMcZgiIiI4qrGZ5V5ZHvMq9SW4EyCoa3lNRjWvfkacyJTFl31mJgZCnLo6BHAx0B+Wi3Gl2SgIj10YfhE61qYjeNHm9krFD5eWwVDnCgXcwyGiIgoIZkhE9ccKSnKwbebylVmyC3e+WYzbpy91NheAimFfOycMersNrXFaO0ETZNroQ7FRUBeJ6BqB148tQdQMiLRu+RKHK/ddlIqGGJDrPvJArBElBw9Q9mZZmaGxBZDxwA35fWvN6keJ1O9991WVHr9aJedUocccesZMmqAQnOKeqpgCOUbGQxFiAuvtp2UeGXKzMxUZ6RkUdDOnTvz7JRLA1mv16v+hunp6cjKYi0/kVvV2hkME9f00LX4bsoMrd9lBW5/PGkEDh1ozkGwnH+UgRT6b85gqI2myemeIbnDq3WZnDmPAycY2rwYKLMWgKfW6+Bkhsw98eFWKfHKlJGRgZ49e2LDhg1Ys2ZNoneHolxYVhZslYCIiNydGcoxMTNUaGeGyl0UDO2uUpcjehWhZ/s8mCTLkw6vrx419t+cYt8z5EyTqy0H6n3Wx7nm9Aw5wZAoW5/oPXEtGaAgWCYXeykRDIl27dph0KBBqKtjRO3moNbj8TCzR+Tys9lef72xmSFdJueWzNCemjqnRK6XYYGQyLGDIZ0NpNiorw+oRJDw6JODukQuMx/IzDE0GNqY6D1xLZbJtZ2UCYb0wbRsRESUGHJgrBmZGbKDoa0uCYZ0iZyU0OQbWIaWLUMyanyosYdmUGyzQiGZoSpDS+RCgiGWyUWqvZMZ4kn9WDPvnYiIiJJWrT1WW2RlmFsmt6fWp7IubimR69XezHVHdMAb/Hen2PULhQxQcIYnGFYiJwrtYEgGKFCUwRAzQ7Fm3jsRERElLZ0hkAM4j4HBkGRXCnOsDIusNWS69busYKhnB/NK5IJLIZkZaptJcqGZIUMnyQVnhso3AX67r4lahaO1245570RERJS0dIag2TWG5CCvejcSyU0T5Tbsrja2X0gwM9Q2fP69ZYYMDIbadQXSM4GAH6jYkui9cXXPUGml+Rlrt2EwRERE8V9jyNPM2897NwF/Ggis+gCJ4qYhCuvszFCvDmaWyTEzlIieIQPL5GTIQ2GJ9TGHKEQ1WltKeIN7Lyl6DIaIiChuapw1hpp5+1n+pjUeeM6t1ropiRyvXeaeMjlmhlKzZ0gCIWfCqsmZIVHUy7rkeO2IFOZkQse9pdUslYslBkNERJSANYaaKJOrLgV222vBbVkCLHsTieCWzJAsRu2UyRneM1TLzFCb9Aw5JXKmD1AQnCgXlfT0NBTl6vHaLJWLJQZDREQUN/qgWBbjbGTL0tDPP5pl9RDFWYker234AIUdFV5U1/khiYHuxYatKxOWGaphZqhNMkOhwZDBo7VFYQ/rkhPlIsYhCm2DwRAREcW/TK6pzJBkg0Sfw4DsQmDrN8Cy/8R5D92TGdJjtaWsz8QFbAUzQ23bM+T0C7miTM6lmSFvJbDgKeDpnwMvnw189QSwa3VCx2uXMhiKKfNWaCMiouQvk2sqM7T5a+uy/5FA358AH/8B+Oj3wNBjrQbsOE+T21JmlaCZyvR+oZDMkB0EU4wzQ8Hj6fUUxtz2MLtnyCXBUMU24JN7gcUvALXlDdd/b5+gKegOFHS1gs/cDkB6BuCvA+rrrPHhfm/Dx5K+la/LRL10j/2xJ2yzr8vIAjIy7S0r6LosTPdtwoCMKhT+sAbocxJQ0C1hd08yYTBERERmZIY225mhbiOA3ocA8x8Ftn0HfPcasP+Jcc8MyUrvsr/NjgFPMN0v1NPQSXIhmSFOv2qT0dohmSF/rXWZkQ0jFfVwVzD0jwuAtZ9aH3foD4y5APDVWpMuN3wJ7NlkbXF0tvwjbUPyUrn738BF78X19ycrBkNERJT4zJC3Ctix3Pq4ZCSQWwyMvwL46B7gvZuBXgc3lNm0MVl0NS8rA1Vev5oo17dTPkzkhsxQNjND8esZqrfv4wxDD+3087d6l/V8zzL3cYvS9XYglAac+QowcHJDdvrI64HaPcD25UDlDqs8UbZAvZXNkeyPzuyojz0Nfx+ZlOls4Z9LNqkuKLskmzfkumUbd2LXjm04NOM7YOfKhN5FycTQZwwRESUjPWK5UWZIMkByMJHfuaH045DLgCUvA7tWAc8cC1zwdlzKQmRUsfTh/LijUvUNGRsM2T1Dpk6SEznMDLXpNLnQzJA9YUwOwE2UUwRkFQDePdYQhU6DYKxlb1iXvccDg6c0/np2AdDzoLjv1ocfrcKT78zHVxmXW2WRElBJeR1FhQMUiIgobvTim43WGdq8uCErpNdNySkEznsdKO4N7PoReOY4oGJ7XEvltpSb2ze0fpc9Vru9wWVyzAy16QCF0MyQHQxJRsJUzhAFw9ca+u5163LYcTBJ+7xM7EY76xM5eVRTluhdSgrMDBERUdwzQ7qxvsl+ofCDp/P+Azz1M6uM7umfAb3GNXxdDgak0blyG1BTbp2xlTPQUmYnDdudhwJdZBsGFJQ0BFotDYbK7D4MA8ukNpWavcaQYGYoTj1DkimSg2MhDfemkufz9u/N7hvasxVY97n18X7HwrTR2j54UJmWj/xApVWeZ+q6Ui5i8DOGiIiSjT4objQKWk+Sk8xQuPZ9gXNftwKhHT9YW3OqdjT/tXbdrNKWHgcCPQ4Cuo+2sk97WWvI1Ilym8uqVXYgMyMNXQvNXGNIMDPUtj1DmXqanPSbaEYHQ3qIwkbDS+QCQI8xcetTbPVobRQgH3YwBIPLDV3C4GcMEREl7TS54DI56XWQnqHmgiHRaSAw4wPg21etpmIRCFjrEbXrYm3ysbcCqC616ul3rwa2fQ9sXwbsXAVUbLEOdHQ/gDRHdx5iBUYSIEmg1GW4anjuZo/XNnWtIV0i16M4N7RvxDDMDMWpZ0iXyLmmTM7gzND3rxuZFdJlcmJHoAA9sKVhbSmKCoMhIiKK/zS54AEKMpVJApzsIisLtLcDqUOviuwXy/QqyT5tXABsXAhsWAiUrbMCJdkWP2fdzpOrArIjcvfDMekFqNo9BkD8G6WTYXiCYGYoTtPk9PAEkwcoBK81VG5oMFS1C1j9ifXxfmb1C+kyObHD3w6Ql1CZZkdRYzBERERxU9vUAAWnRG5Ei3t6Wk3G+PYZb22a9BqpwMgOkDYuAmrLgPXz0Qfz8XAW4N+dDqzuAPQ7AibZYI/V7mnwWG3BzFDbDlBoyAy5pEyu0PC1hpa/DQT8QNf9gY4DYJriXCvQ3RUosK5gZigmDH7GEBFRsqnRo7WDg6EtzQxPaGtSWjdkmrUJKT2SMd4bFqB6zZfY9b9/o0faTvjXfI4Mw4Kh9faCq732teDqkn8A//0LMPosYOyMuK9Bw8xQW2eGwnqG0tIb1sMxvUxOylzb6uRH1CVy5mWFhCcjXa2DtsvHYCiWGAwREVHcM0MhZXJ7G54QT3IQKWufdBqE7BGn418Ly3F1xj9Rs3Md8t244Or3bwCvXmJNGXvnRmDx88Ax9wO9xsZtP/XfmZmhNs4Mmb7GkFbY3erV89VYJWn5HeP3uyX4kt8rUydlCqVskgnWH8v1qz4wtl8ouFRud6kOhnYleneSAoMhIiJKwKKr+ox2PbBlaUOZnCHS09NQmdsV8AK+3evd1zO0eh7wzwutQKj/RGDT/6z7+YmfAkOPAXofYg2O6HaAdfu6aqCuyjpYlEv53FcLZGQBnhzAkx16mSlb/j6zEDoDWMvMUEz57QEKnoywAQomD08Q8viRjGzFVmD1x8D+J4Z+va4GWPeZdYJk02JrsIo8BvM7AfldrDHSmXlAVr51KRkx5zFbA/jkcWxvteUNgY/6uKxh+MredBwEdNkPppKJcrucYIiZoVhgMERERPHPDOnR2jLxTSbAyeACOQgxiC+/hwqGdm1ejQv+778wydby2uYXXJXA58UzAX8tMPTnwCnPWNP15twCfP1C2ES9KGUVWGs7ZbezL/VWqC571GXhFxnbUe9tByzZBbTrDPQ9HEgPG61O0a0z5LfL5Nxwvw47HvjyceC1y6zAqO9h1vUSrL98jvWa0JaklFAenzJWX9Ykyym2P5ePi4CRp5tXvhe+8Cp7hhIbDM2bNw9/+tOfsHDhQmzevBmvvvoqTjjhBOfrt912G1566SWsX78eWVlZGDNmDO6++26MGxe0SF4Y+Z7bb7895LohQ4Zg2bJlrd09IiJyU2Zoz+aGXoI497PsS/tufYHdQEf/DixaVwrTyFjtDvZ0KYecHX/hdMC7xwo6TnrCul8lCJn+CDDuF1YpkB4cIePGNQlIVcYnD8jMBTKyrTPpkiGSs+/6UoIsTX6PbHua3kcpgpopyQo5dp/9N+vKqbOA8Ze3xV2ScmVyzjQ53TNkepmcmHoPULoe+OFt4IXTrDXEdq4E/nONldnJl4D5MKBkFNBtf+t7ZGpa5XarLEyyQN5KK/sjmTCVqZTHbm7DY1iuk8DGCXKCgp2sdkYHOy3JDK1lMBRTrX7nqaysxMiRI3HhhRfixBPD0psABg8ejIceegj9+/dHdXU17r//fkyZMgUrV65E586dm/25w4cPx9y5cxt2zGPWmyIREUWvxpkml9Fw8C7kQMYwF//8MOB7oDCtCk+cPgT+zHYwyYiexUgLP6iTBWklwJEx5ae/YB0YBus+yto0KR2SA2g5eGxp472UaElQJAekUn5Uu8faJMOnPm64rmpPKd5auAIFadWY2nE7sHuNtVGMp8m5pExO7+MpTwMvnGKVc8piyvJ4EgMnAyf+zSqHo2Z7hhaDPUOx1OqIY9q0aWprzplnnhny+X333YcnnngCS5YswaRJk5rfEY8H3bp1a+3uEBGRCzNDOTozJGeCDQ2GcvLtM8k1ZZjU3Qd0ccF7lA40ZJFaORu+L/L/ay0JmmRUuWyScdoLb5UX182foz5eNfJbZHx0d8PfnCLm9+ueofSwMjkXBENCgvTTXwSePQHY8JV13ZE3Akf+xh2lfgkuk3NGa8sACBme4YYg2GBtOn/R6/Xi8ccfR1FRkcom7c2KFSvQvXt3lVE666yzsG7durbcNSIiSgA9VaxRZkgyEyYq7Gn2IpHhdL9F+34wQfDUQF96dujfnGJYJqenybkokJA+s7P+ARx+HXDOa8DEme7a/wRmhsqRj3p9CM/sUNTapBbtjTfewOmnn46qqiqUlJRgzpw56NSpU7O3l36ip59+WvUJSR+S9A8dfvjh+Oabb1BQYEe/YWpra9WmlZeXt8V/hYiIYkivN+OsM2RwZkgp6gFs+xYo2whX2KWDob4wQfB6UnVpWVDhkC6JoqjXGWq06KrbMgS57YFJNyd6L1zXMySBUHlaOxQHyvHpkmWoKDJrdP2wkiL07mj2gtBtHgxNnDgRixcvxo4dO/C3v/0Np556Kr744gt06dKlydsHl92NGDFCBUd9+vTBK6+8gosuuqjJ75k1a1ajoQtEROSOzJCTMZAmaKMzQz2sy/JNcAVdJtfBjMyQ9DRledLh9dWjLt0e9sBgKPaZIbesM0RR62gPTdnhb4fi9HI89OaXmF9fAZPcecL+OKdjH6R0MJSfn4+BAweq7ZBDDsGgQYNU39DMmTNb9P3FxcVqEIMMXWiO/Kxrr702JDPUq1evmOw/ERG1dZlcemgwZGpmyAmGWCYXqRw7GPJaeaGGvznFIDOUHpYZ4vCpZHdgn/Y46cCeqFvRHqjbhLFd6uHPaQ+TdCmwn+suEZdnTX19fUhJ275UVFRg1apVOOecc5q9TXZ2ttqIiMgd6vz1zkGc0zOkswQml8kJN5TJSXZARhYbVCYnsiULWOODN42ZobbPDDEYSnaZGem499SRwEv9gGXf4tc/6QSMPTTRu5VaAxQkUJESONnE6tWr1ccy8EDGbv/2t7/F/PnzsXbtWrUWkYzg3rhxI0455RTnZ8hUORm/rV133XX4+OOPsWbNGnz22WeYPn06MjIycMYZZ8Tq/0lERIZkhULWGXLK5EzPDLkgGCrbAAT81vpABSUwhZ4cWAs7GOIAhaj5Zbx5Uz1DLJNLHXr8OAcoRK3VpxAWLFigeoI0Xap23nnn4dFHH1ULpT7zzDOqX6hjx44YO3YsPvnkE7WOkCZZH/m6tmHDBhX47Ny5U61FdNhhh6mAam/rEhERkTuHJ4QOUNCZIUN7hmQxWJ0ZCgTMXqzRKZHr2/I1g+JAZwFrdJkcR2u33TQ5tw1QoMjlyZLGXHg1IcHQhAkTEJA3hGbMnj17nz9DMkDBXnrppdbuBhERubhfyFks1PjMUHfrsq4SqCm1pl+ZyrBJco0zQ/aBOjNDUfP57Z6hDF0mpzNDLJNLGQyGYsacU0dERJTUasPHarshMyS9TPqgw/SJcoZNkgvPDFUH2DMUK/5m1xliMJQyGAzFDIMhIiKKi5o6OzMUtBAn6qrMHq0dnB0yfYiCgZPkgjNDNQH7QJ3BUNR8ds+Qp9E0OZbJpQwGQzHDYIiIiOKi1ucPOTgOKZkydZqcKOzpjvHau9YYWSbXKDPE0dqxzwxxmlwKB0McoBAtBkNERBTnnqGgzJDpo7XdMl5benkNLZPTwW9lvZ21kIl3+uCdYtMzxMxQCk+TY2YoWjyFQAknAzlu/NdS/G/9bpgoL8uDu07YH/v3KEr0rhAlxTS5kJ4h0wcouGW8thwQefdYHxebtfK7Dn6rdDCk/+48cI8YM0PkZIZkuIs8n0w+oWQ4Pmso4baW1+LlBfZCgYZ69X8bGQwRxSgzlBPcM2T6AIWQ8doGl8nprFBBd+PuSycz5PeE/d0LE7dTSTJaOyO8Z4jrDKWO7EIr+JW/vZTK6Qw2tRqDITKqj+DJ88fCJP/5ejNe/HIdyqtZ0kEUy9Ha7swMbTJ/rLZhJXLBmaFaKe2SQRkSCHGIQoynyekyOR7WpQxZnkCyQxVbrcwwg6GI8VlDCVfnbzhbfOiATjDJj9sr1WV5DYMhojYpk3NDZkhPkys3eOFVQyfJiWw9TU7+/p5s62/OtYZiMk0uo1GZHDNDKSU4GKKIcYACJZzXZ53hysww7+FYmGu9sZRX22fdiCi2ZXLOaO1c84MhOYg3dXLTbjMnyYkcnRmSv7/+O/s4US4aXGeIFI7Xjgnzjj4pZTNDWQYGQ0U6GGJmiKhtFl2tc0FmSLIZ+V3MHq9tcplccGZI/52ZGYpRzxDL5FKaM1HO0JM0LmHe0SelHK8OhoIPkAxRmGO9sTAYImqDzJCUnOkMgcmZITeM1za4TI6ZobYbre1UVPg5QCEl5dmtBcwMRcW8o09KOXX2AVKmXi8hnBww1VtnlBNVJldWxWCIKOaZIV9twxdNHwtr8nhtGUKxZ7OxZXLMDMWhZ0iXyXFceWphmVxMMBgiYzJDTfYM+bzA/x0CPPHThLx5FuZYbyx7an2ot8sSiCgyNXqanM4MBWcHTA+G9HhtE4Oh3WsbRu3qshmDMDMUe1xniBQGQzHBYIgSri483R9s1ypg+zJg40Lgk3vjvm8FdpmcJKcqvByiQBSLzFCOzgzpExxpGeaf0dZDFEwsk3NK5PoaOemuycxQcFaQYtAzZFdPMBhKLQyGYoLBECWc17eXnqHSoMVYP70f2L48jntm9Tbokh6uNUQUo3WGwjNDpmeFTC2TkwNgaZze/LWxwxOCM0MqMyjrDAWvL0XRZYZ0eTnL5FITByjEBE8hkNnT5MrWNXwsL/Zv/Ao4/824nv2UvqHte2qt8drt4/ZriZJ/nSFnwVWDJ8mFl8ntXGVlNWTCXHMByrbvgR0/WEFeVj6Q1Q7ILrAu5fPMPHutnSp7q2649FYBNaVAdSlQUxb0sf158Me15aG/28B+oeDMkMoM6r81F12NyQCFjHQ9QIHrDKUkZoZigsEQGdQzlNZ8ZmjIz4AfPwLW/hdY/Dww+uy47Z9MlFPBECfKEcU2M+SM1XZBZqjLMCCnCKjYArx+FTD9sYaTMnIg+uXjwIr3gA0LAe+e+O5bZr5Vxrf/STCRnh6o/v76b83MUButMxS0hhelVjBk6oLQLsBgiIzJDDXZM1RmB0N9DgV6jwfm3Ay8dxMw+Ggg3x4pGbeFVxkMEcUkGHKmybkoM5RTCJzyNPDcycCSl4EO/YEJNwLlm4B/Xgis+7zhtpIB6jrcWvultgLw2pt8HAibjClZIgkQnMtcK+jKKQZyi61L+Vx/7FynPy4yvjRK/72ZGWrLaXL248rwxwK1UTDkrwW8lUB2u0TvkSsxGCJjRmvvtWeoqBcw9BjrIGTrN8B7NwPTH4nrRLnyGg5QIIptmZyLMkNiwFHAz+8D/nMN8NEs6+Bj8QtA1Q5rktuEmUC/I4Au+zV9hl6tqyTlcdXW/1kCgxQ4k6szQ6pniJmhNp4mx2AopWTlWRMa5cSSZIcYDEWEAxTInEVX95YZKu5lnfH6+QMyegr4+gVg9by47B8zQ0RttOiqmwYoaGPOB35yjfXxZ3+1AqFuBwCXfASMvxzotn/zpUoS+Mj/VZqe5TIFAiHBzFA8pslxgELKYt9Q1JgZInNHa8saQ3u2WB8X9bYue40FDroQWPCENUzhss+ab2SOYc+QYM8QURtlhtxQJhds0m1W1vrb2cCB5wHT/uCugC6hmSEGQ7EcoOC8b/rtygX2DKUeOblSviG+E+X8PqByu9VDuWerdVmxzTpmq9gKjPuFlSV3CQZDZMxo7UxP2FlSeXIjYB0oBfcHTboFWPYGsHOlNW5b6vbjkhlimRwRUj0zJGSC18lPAtP+CLTrnOi9MZ4erS2lXf70bKjPErCIdnJnhnQwxMxQyinoBmxZAvz4ITBoctO3kd7GZW8CK+ZYWcR23YCCrkB+Z6vEV8rrsgqsYy413VImW1ZY2SYJetS2o+FjFXjtZSF6CYQYDBFFMlo7o5l+oZ6h5STSNHz0LKtpWRZilQlKnQbFoWeImSGiaNT6XDxaO5y8JjEQatVobVGngyEdCFNE/PYAhUbT5Fgml3rGzrAmWX7xKDDqLKDrsIavrfoA+OAua+H6WEvLANp1sTc7uJJL+bzvYXATBkNkbmaoLGh4QrjhJ1qNyyvnAv8438oODZoKeLJivn+FuXaZHHuGiKJSU6enyenR2i7NDFGrOMGvxEBpdlkzM0OxzQxxgELqGjwFGPpzq2LmzV8DF7xlnaxZ81/ghdOtSXPSa93rYGuZEskGSSmbbJLlqZVJl3vsJQHsvka15QP5Ha3bO1snIL+LdSm9SklSlslgiMxddLU0aHhCOHmiH3Mv8Mhh1nS5l88G8joBB5xsBU96scPcDlZmSTYZjRsBZoaIYkM10KsyOT1a26U9Q9QqaWlpalqonPjyptvBEHuGYjRNLj2sTC45Dk6plY7+vZUFWveZdaK4ZCTw4hlWICQBkAyfkswNNYnBECWct7kBCmUbQocnhJPV1i/7FFjwFPD1i9ZZDkkTN0fW5ehxINDrEKD3OKDnWCtg2gf2DBG11aKrOjOUl8C9onjI0cEQ7Ow9R2vHJjOkFyvXwRDL5FKTnDSWCpk5t1jrMUqGsLbMWp9R+huZfd8rBkNk7qKrZeuazwwFB0Q/vR046iarMVDK5iTdW1dlbZIClqCqejdQU2qdOZFNZGQD/Q63FnAdPBUobjro4jQ5ougFAoEmFl3V6wwxM5TsVABc40Ntmh0M+aR0hyLFdYaokUMuBxa/CGz/3vq8yzDgjBcZCLUAgyEypmeo0aKrwQuu7oucDRv6M2trigRIO1cBG74C1s23NplWJ8GTbG9dB3QZbgVFEhz1PMgpN+A6Q0TR04FQyDQ5Z4AC36yTnS6NrNWZIQ5QiOrEgr+5aXIZPKxLWWotxvuBvx9nTZg7ezaQ2z7Re+UKfNaQQT1DQQMUZFJO+cZ9Z4ZaKrsA6D7K2g6eYa0Ev+MHYPnbwA/vAuvnA9u+tbZP77N6jQZNUcFRUbfD1Y/YU+tDfX0A6frNh4giCoaYGUo9emhGTcDOXHCAQsR0INR0ZoiHdSmtz3jgqkXWgANmhFqMzxoys0xO+n/8Xmt0Y0H32P9SGcDQeYi1HfZLa2b+yveBH94BVs4BqncBS15SW8d0D57PHIIP6kejassAtOs+NPb7Q5QiwxPk2M05gJNSVsEBCimTGaphZihm/UKC6wxRI7E4gZxiGAyRmQMU9Fjtwu7xSfvLCs4jTrE2WVl5/RdWYPTDO0jb8QN+kvGt2vD4c8CAo6z0c/DaR0TU4gVXZbpYSHaAZzBTJjNUHdADFJgZikUw5Lxvcp0hooiFNWkQxV9dUz1Dpeta3i8UaxJ89f0JMOVO4MqvVMr53vQL8Il/f+vrMoBBBjIQUYvV2Jmh4DVnOFo7BTNDukxOMkNSrkyt5rdPIIauM6QzQzzHTdRaDIYo4bxNlcnpzJAJ6d6OA/BW/gk4p+638HvsEcAymY6IIsoMObjoasplhqp0MBSob+hzoVbxSU+tLUNnWXVmiMEQUasxGCJzBih40iKbJBcHeqKcN9NeuLWawRBRa9T69pIZYjCUMpmhyvqgMi4uvBrVAAVJCjkDfbjOEFHEGAyRMaO1jc0MqbWGrDeYWk+BdQUzQ0StUlOn1xhqIjPE0dpJL0f3DPmDMhcMhqLqGfKk636heivTJjhAgajVGAyRmdPkDM0MVWcwM0QUTWZIZwgUjtZOGdm6Z0hOfukeMR0MU6s0XmMoqNyQ6wwRtRqDITKmZ8gZoCBNtWWGBUM51htMZXo76wpmhohapbbJzJAerc3MULLTf/fa4GCImaEoM0NhawwJ9gwRtRqDIUq4Op/1wp6lM0Myqc1bYX1c1BMmZYb2pOVbVzAzRNQqNbpnKDgz5IzWZmYoZTJDMlVQ94gxMxQRvz1AISMjrF9IsEyOqNUYDJF5ZXJlG6zLvE5Alj29zZCeofIAM0NEMckMSQZYL7zJzFDK9AwxM9QGmaHgYIgDFIhajcEQGTRaO83I4QmiyM4M7Q7YwRkzQ0QRjdZ2MkO+2oYvMjOU9JgZih2fP2yAgi6TS8vgYuBEEWAwRAaN1k43cniCKMy16rB3+bnOEFFMFl3VWSGRaUYGmOKdGQoKiKnVmaFGAxTYL0QUEQZDZMxobadnyMkM9YYpdJncDp99RpOZIaLoFl3V/UJyNpulPamZGQoOiKnVPUOe8J4hPo+IIsJgiBI+ItQ+ydXQM6QDjbwOMIUeoLCtzn4TZ2aIKDaZIS64mlKZIWu0dnZoQEwRlck5mSG/HQwxM0QUEQZDZESJnMjUB0l+u3RCl1IYNFp7S529T8wMEcUmM2TQ85zaPjNUK0GxHpjBzFBU6wx5wsvkmBkiigiDITJieELIAAVdR56RBdMyQ5u99hlNZoaIIlp01ckM6eZ5ZoZSLzOkB2YwMxRlz1DYAAVmhogiwmCIjOgXCukZ0sGQLqUwQIGdGSqr16O1ywG7bpuI9q0mfLS2M1abmaFUwMxQW2aGrBMNXGOIKDIMhsiQNYbSkKZHguoyuQxzgiE5gMvJTEcZ7EVXEQBqyxK8V0RuLJPTmSEuuJpKdHmkehzovzmnycV2mlwGM0NEkWAwRAlV5wuEDk8QPq9xmSE9Ua4OHtTrs5rsGyJqMZURaCozxLHaqTVaW2WGdJkcM0NRTZNzBijoMjlmhogiwWCIDFlwNeih6AxQMCwYsvuG6rKKrCvYN0TUYqpXJKRniAMUUnK0dsg6Q+wZigTXGSKKLQZDZNaCq4YOUAieKOf1FFpXMDNE1OrMkDNNjqO1Uzcz5AxQYGYomp4h5ySi7hlimRxRRBgMkVkLrho6QCE4M1TjKbCuYGaIqNU9Q8wMpabQzJAeoMDMUCTqGq0zxDI5omgwGCJjBig4DFxnSPcMiap0e6IcM0NErV901RmgUGVdMjOUUpkhyWr49XAcZoZi0zPEdYaIosJgiMzrGdIDFEwrk8u1ShAqdDDEzBBRq7PADWVyzAylEicIlhgo3Q6GmBmKTc8Q1xkiigqDITIi3R8aDNWYWSZnZ4bKwcwQUcSZIS66mpKcv7v86dN0MMTR2lGtM5QRvs4QgyGiSDAYIjN6hoIHKPhNzQxZwVBZwB4FzMwQUQTrDDEzlIpkHTn9Ou/VwRDL5CLic3qG9AAFlskRRYPBEJkxTa7JAQo5RmaGdvnthVeZGSKKYoAC1xlKNTn2374W9kE7y+SiywxxgAJRTDAYIjMGKHj0i7oPCPjNLJOze4Z2+u2yHmaGiCIokwvLDOkxy5T0su2soBd21p+ZoRitM+SzLtPt5xYRtW0wNG/ePBx77LHo3r27Snu/9tprIV+/7bbbMHToUOTn56N9+/aYPHkyvvjii33+3Icffhh9+/ZFTk4Oxo0bhy+//LK1u0YuLpNzeob0JDkTy+TszNB2nx0MMTNE1CI+f71zAJfjTJOrNjIDTG1H/+1r0uzXdmaGYjRNzg6GWCZHFJ9gqLKyEiNHjlTBS1MGDx6Mhx56CEuXLsWnn36qApwpU6Zg+/btzf7Ml19+Gddeey1uvfVWLFq0SP38qVOnYtu2ba3dPXLpAAWnTC64oda4zJD1RrO1jpkhokimRoZkhjhAIeXov31NgJmhtpkmx2CIKC7B0LRp03DXXXdh+vTpTX79zDPPVNmg/v37Y/jw4bjvvvtQXl6OJUuWNPsz5TYzZszABRdcgGHDhuHRRx9FXl4ennzyydbuHrmM12eVzmTqPgI9PAFpxk3GKcyx9mdzrR2kMTNE1CI1dcHBkD7xwQEKqZoZqmbPUEx6hpyKCmeAglnvmURu0abPHK/Xi8cffxxFRUUq29PcbRYuXIiZM2c616Wnp6uA6vPPP2/2Z9fW1qpNk4CLkigzJAdIaUELsRqUGdpcmwPkAPU1ZTjkrvcQSEs35kDj7hMOwBGDOyd6V4hC1NonPeR5nq7PZjMzlLqZofqgMrlAwLjXere8bzZkhnTPEIMhoki0yTPnjTfewOmnn46qqiqUlJRgzpw56NSpU5O33bFjB/x+P7p27RpyvXy+bNmyZn/HrFmzcPvtt8d83ylRi66mhWaGPGb1C4n2eVno2T4X23ZbZ+HSEUBNRSnKYU+XM8CbSzYzGCLj1NqZoeC1ZpgZSt3MUFXAzgwF6q0SLwNf713ZM8QyOSJzgqGJEydi8eLFKtD529/+hlNPPVUNUejSpUvMfodkkqTPKDgz1KtXr5j9fIrzaO3w0pkMs/qF9Fm49351BNburEL9EzlI99Vg9gXDUFfYO9G7hn8s2IAn/7sadfabJJFJauzMULYeniA4Wjvl5NiZoer6oIN2XzWDoainyXGdISLjgiGZJDdw4EC1HXLIIRg0aBCeeOKJkFI4TTJGGRkZ2Lp1a8j18nm3bt2a/R3Z2dlqoySbJufTmSEz/7Z5WR7sV1II5LYH9mzGwAIfIJ8nWPfinJBackpNn67YgRe+XGvc46Csui50eILgaO2Uo4Phqnp5HMiBfACoqwFyihK9a0myzhDL5IgiEZdnTn19fUh/T7CsrCyMGTMG77//Pk444QTn9vL5lVdeGY/dI5MWXdWjtQ0Nhhw5xSoYMmWinH5T1CuTU2q6d85y/G+dGY/JpnQrCgp8nNHa7BlKtcxQrS9glUdKVkg2ijAzpAcosGeIKBqtfuZUVFRg5cqVzuerV69WJXEdOnRAx44dcffdd+O4445TvUJSJicjuDdu3IhTTjnF+Z5JkyapaXQ62JFyt/POOw8HHXQQDj74YDzwwANqhLdMl6PUaARtyAzVGlsmFyK32KiJch77/tPBJaWmPTXWQdHFh/VD307m9LKJ9LQ0HDG4UxNlcswMpVpmSC3AK393CYQkM0St4rffNz2615brDBHFNxhasGCB6gnSdN+OBDMyEluGHjzzzDMqEJLgaOzYsfjkk0/UmG1t1apV6uvaaaedptYhuuWWW7BlyxaMGjUK77zzTqOhCpTMAxTCp8llmZ8ZEoZkhvQACn3GkFJTtdfqzfn5yO4Y1ct+jJpIJojpjAAzQylDl0k+8/lanOFPh4TGVz37OVZ5ml+HMJ4O7FOMO4/fXy0obzKuM0SU4GBowoQJCMgbWTNmz569z5+xZs2aRtdJlohlcamnzhc2QEGXyTEz1Coeu1yCmaHUps64y8MzM6g3x0TBiyszM5Qy+tnZyh0VtdiT5UGndGDTjt34LmDG0hjfbS7HlRMHhZZzummaHNcZIooInzlk1mhtwwcomJoZ0uUS7BlKbe4JhoL6RJgZShnnHNIH+/coQmWtD53fKgZKt+LWaf1R2u3gRO8aLn9+ESpqfWoznc4McYACUWzwmUNmjdZ2ywAFwzJDuszQx9HaKUsy9tV2MKTXczGW7hNJy2CfQwqRBXfH9GlvffJRPlAKjOiaDRiwNlpBjkcFQrrU1A3T5DJ0eTnXGSKKiuHvmJTsvDJVKKRnSK8zxJ6h1tC14+wZSu0sq/7z52S5JDOUmQsY3p9BbUT+9sGDNBIs137OVHl9rhk85Gm0zhDPbxNFgsEQmTVa2y1lcsZlhlgml+pqvA1ZQePL5HRmSMYrU2rSf3t9AizB8nQwZGdX3dAz1DBAgZkhomgwGCIzFl1tVCZn+EGSYZkhDlAgXSInZ4udTKupnLHa7BdKWYZlhvIyrayKG8rkGvUMOZkhBkNEkTD8HZNSJzMUNkDB9DI5wzJDzgAFlsmlLNcMTxDOWG3DT3pQHDJDTS/InrgyORf1DIVPk+MABaKIMBgiI4KhRj1DppfJGZYZcgYoMDOEVM8MZTcXDO1YAfzvuYYTDiaUyXGsdurSf/vgyYIJlJ9tPW+qXdAz1JAZ0hUVDIaIosFgiBLKa/e4OMGQ32WZoZoywIAJbrpcQjfWUuoGQ7lZzbys//sKa3vhFKAmweu6cMFV0n97HRgnWK5dJlfpyswQy+SIosFgiBLK6/OHjtbWJROml8/ozFCgHvDuSfTecLQ2oca7lzI5WYdk02Lr4x8/Ap6aBpRvQsIwM0Q6+29IZsgZoOCCYKj5dYYYDBFFgsEQJVRdo8yQDoYMzwzJQZwO2AzoG9JnCPUZQ0o9Nb69BEPbl1vPrcw8IL8LsPUb4P9NBrZ+h8SO1s5LzO8ngwYo1BgVDLmhTM6ZJqd7bdkzRBQVBkNk2GhtOxjKMLxnyLC+IT1am2VyqavaHq3dZM/QliXWZffRwMVzgY6DgPKNVoZo48I47ylHa1PwAAUzMkNuGqCgl1DI1D1DOhjiOkNEEWEwRGYMUPDoaXI6M+SCYMigiXK6kZYDFFKX0zPUVDC02Q6Guo0A2vcBLnoP6DnWCuSfOR5Y+3l8d7auyrrkaO3UZWxmyIU9QyyTI4oKgyEyYp2hLLcNUDAsM6RHa9exTC5l7TUY0pmhkhHWZV4H4JxXgb6HWz1vz04HVn0Yv511pkYyM5SyDFt0NTfL476eIadMjgMUiKLBnCollLfRaG2XDFAwLDPk1tHaHyzbireXboGJPBnpOGtcb+zfowiuGqBgn+F2SH/BlqUNmSEtuwA46x/Ay2cDK+cCz59sBUdDfgYMORoo7t12O8tFV0n/7Q0JhvLt502lC3qG9KCchmlydgCX7oI1xogMxGCIEkr3uDSeJsfMUGvoqUJywrC+PoB0/SZpuN+9+g02l5lxMNSUbeU1eOL8sXDToqs54Zmh0jVAbbnVh9d5SOMD0tNfAF69FPh2NvDjh9b29vVAbgegoAQo6GpdtrMvC7oBHfpZfUeRToNjZoh0KTTL5FrNb79vcpocUWwwGKKE1j3r2udG0+TcMEBBZ4YqtiXm98tBhDTBl65D7vY1+JXnY/RM2wE8/TBQvh7oMtw60NVNtgaqqLHOwl5yRH8U55nzRr5yWwVmL9qI3VUGLFDayjK5nMz0pvuFuuzXdBmNHJSe8hQw8XfAD28Dy94C1s8HqndZ27Zvm/6FaelA+37Wzy0ZaQ1nKBkFtOu8751lZoj0OkPGDFBwX5kc1xkiig0GQ5Tw4QnB09BcNUBBDvzEN/8CJt0a22yWlD1IkCVrwZRvAMo2WoGPCn7WA2XrgYqtzs1lQPE1+tm8zr4sXQfs2QQU9YSp6uxyj3PH90HP9nlNB3zyWEiLb6brvyt3qGDIDQdG++wZcvqFRu79B3QaCHS6Cjj0Kmsx4bINwJ4t1lZhX6ptM7BjhZUR3bXK2pa90fBzCns0BEbdRzUdIOnMEIOh1KWziqZlhuznkcn0SUQ9OAd+PVqbwRBRJBgMUcL7hULK5PQABTcEQ/ufCMy91To4lBKjkac3vk0gAKz9DPjyceugUd6s5OyduvQ0fC6jUWv3WJv0IMnBpx6XujeyTktRL9QX9cSLy4GNgU648sSJyHv7l9YBpy6fcMs6U8H+cYF1v8owjZwiq2zryN8AB5wctwOjilrz+wfCy+QaBUObvw4dntAScn/L1nV401+Xx7UE69uXAVu/BTYvBjb9zwqSdNAeEiD1bAiM5LJyh3U9y+RSl2mZIft5U+WKnqHwzJAOhtgzRBQJBkOUMHX2JLmQ9RLctM6QBGwHXwJ8cCfw2UPAiNMaMhiS2Vn6T2D+ww0Ho60lZUjSoyFn2gu7WxkeddkLKO4FFPW2poLJ76wP4He/fUt920VDJiNvzo3GB0P1TZVJBh9sL3+7IUCu3G5tb1wL9DuyZaVYUcjPdk/JjFZTV9/0AAVnrPY+MkOtIY851UvUFeh/ZMP1EszL71PBkR0g7VxpZTdlCw6QBDNDqUtnhvRrfoLpEyBueM43ZIZYJkcUCwyGKOFZAXlBdxr+3TRAQRx0IfDJvcDWpcDqj4H+E6wD+dcuB5a81HD2W7JGg6fJUb4VoMibl5Q2yBk9+TgtA8gptCZ8ZRdZTerSsN7CRfTk/pO7UN4j1VlD/aao3yQNLpELGRGreSsazhhfucAKiKTJX0q+PrgDOO7BuBwYVbooM6Qbv0MWXZWytsptVmDdXJYnluTx2/cn1hYeIElgpIOknSusr3U7oO33iczODOn+sQTTJ0DkeRQIBJAW59LcqKbJcYACUVQYDFHiF1wNzgq4aYCCkMzMqLOAr/5mZYckGHr/disQkgBnwo3AQRcB+R3jMgpa1m1S96t+UzQ4M6RXUQ9ZZ0rTQyky84FOg6yPf/Yn4MmpwKJnrSBU+lLaSDv7wKjWV6/Glct968qeIZ0VkslvWU30ZMVDUwFSTbn12IzD84JMzwyZ0TOkM6pyMsnrrUF2zU4rK29gUBSSUVdjte3XUmaGiCJi/js8JX3PkNMvJHwu6hnSDrlM6oaAlXOAt28EPr3fuv64v1o9LnE64Mu0zxKqICPD/GAoeICGU+4RHgwFl8P1PgQ44BTrjf/tG6wMXBvJsydLiSoXNFQ3GwxtiaBfKB4kC8pAKLXpfjHJDLXhc7lFqnYhf/V7+I3nJbycdQey/tQXuH84MP//YHzPUHBvKXuGiCLCzBAljGQxms0MuSkY6jgA2O/nwPf/Ab54xLpu4k3A6LPjuhtW9sLvnjI5OzMkJ16dcg9NSruElAoGm3w7sOxNYP0XwNJ/ACNObZN9kwBdJhzKPkqpXGFOpnsGKGSlN84M7WuSHFG8OcMzpHTYG7/XfAm8ZNCHjI+X15F1X6iyTQkjLtdHRDq+iLTfs42zQjp2VCeR9NAhwTI5oogwGKKEZwaydL+I1EHrF3a3lMlp46+ygiEhJVxHXBf3XdDZFVVP7oIyOadMMj29cX2+zgzlhw1KKOoBHP5ra2jFezdbwxSkib+NskNl1XWorPW7d9FVPVa7m2GZISIpn5Qy2LpKYPvytsteequsfjUV/HxpBUDVuxvfrtNgzN7RE5/XDcTMcdnosOhBoLYCpvYLiQx57ww+4cUyOaKIMBiixB8Mh4/VdtMABa33OGDCTMBbCUy+LSF15noIgVvK5HTPkLPGVJNlcl0af238lcDi54FdPwJPHQ2c+7o1XS/G8rMyVDDkhlG7oYuu2sGQjGjfvcb6mIMKyDRS0tX3MGDFu8CPH+09GJLH8eIXremDMlWzuLf12pBdaI2Al58lfWiyzIGszbbjByurI5uMfw9fpkCyUj3GAL3G2dvBqv/zT7Pex+aaGlxduB0d9CAXQ/uFnBNgwa9P6TykI4oEnzmUMF5f2FhlXSLn1vVHZFhCAukF+FSQ6YIyOd0z1uRwAl0ml9+l6cbrs/8FPHO8HRBNA879t1WuGEN59hAFt2SGqr32aG0dDMn6P0KPYCcyjQycUcHQh8BPrm76NrKo9X9+CdSWN/9zpJIg+P0jXLtu1gmrXodYwY+cHGjihJseolAN+/1HTm4Z2i/UqGdIBvYYOOyByA0YDFHiByjog2E9PEHIQpvUKjrDot4sXVAmp8s9mlxwtWJ785kh0aE/cOE7wN+Pt8Y0P3k0cOLj1sFVjA4IGtYa8rlz0dWqndalrE1FZKIBE61LWZi6rqZhwpwORGRQyv+etT6XTE6HAUDZBqBsvbVwrx6/rwMhWZagsARo38/KNEmvnJSISjapBa8L+fbglMq0XGODIX/QFE51AoxrDBFFjcEQJXzRVadMTo9YlUCIZ7haTWdYQjJDwaWHhqlzMoNN/K2dAQrNBEO6f+iCt4Fnp1vrPD17AtBxIDDmfGDkmVFPK5MyObUrLliEMWSanF50VR/IJWqkNtG+dB5qZW0qtli9PHoBX1mD7eljrF4fmdQpPZhH3th43TU5gSbrWEnfUV5HICs/qt3Rz53KgM4MVRidGVJtolxjiChqHK1N5gxQcOvwBEM4AxSCe4bCa+UNXHS16czQ1ubL5ILJ6O3z/2MNrchqB+xcCbx3E/DngcD/mwx8eA+wbr51cBXheG03LLwqzyXdS+D0DMkBoojyAJGozchJL8nmCimV05a/ZQVCkuk573XgqJuaXoBaSt3kpIf0EMXgca4XW64IZBsbDOnnubzeq8Ez+jW+hQt0E1FjDIYo4WVyzsGwz4VjtQ2i70e/S8rkdGZQD35wyNxYp0wubJpcU3LbAz+/H/j1MuDYv1iLsQbqgQ1fAR//wVqoVYKjVy+1Jv61sPQlPzvDNcGQzgqJnEz7+aT/nzKxi8j0UrlVQcHQF49ZlwdfDPQ7Im67ooOhSicYqjS2vNh53dTBEIcnEEWMzx5K+DozzqKrblxjyCB6rR63lMnpcg+nZ0yTs7G6F2BfmaHwUb1SIieb9BXIwdWqD6wzzjJK9+sXrS0zDxh6DDDydKDfhGbPqOrMUJULyuRq7H2Uh4Bzf8pIYcHMEJlMZ4Zk8lvVLuu5u/ZTayDA2Ivjuiu5mdZzvqw+p+H1U0rxDJpu2pAZ0u+bLJMjihaDoRhbs6MSD8z9IaH7UJyXhV/9dDCKcjPdteiqzgxxeEL0AxRcUCbXME2umTWGJKOR3S6yHy4N0weeY21SIif9CLJY6/I3rTG9smCrbLKo6/4nAyNPsxqtg3rVGnqGzL0PG/ULZWY0rNmkS3zYM0QmK+gGdN4P2P49sPpjYOVc6/phx8d9+IfODJX7g96D5Hnk6WDcSSRnoWqWyRFFjc+eGNtV5cVrizclejcwqGs7nDWuD9zRM8QyuZiP1k53QWbIWWcovZk1hlpQItcScpDQ9yfWNvVuYOMiYMlL1she6U2a/7C1dRkGjDgNOOAUNZzBmSbngtHaNXX1ocMTRJ3ODEUYUBLFs1ROgqGl/wRWzLGuG3dp3HcjT5fG+tKsk3Ly+imlcgaNptevm7pHlJkhougxGIqxnsW5uOmY/RL2+9/5ZgsWrN2NHXvMPQhutOhqowEKzAxFv+hqlvE9Qz7999flHo0myXWN/S+VrEnPMdY29R7rLLSUzi1/B9j2HTD3VmDubapPYVTOUchHT1f1DGV7goIhXSYnZYFEJus/EZj/f8CyN6zPS0ZZC6HGWZ5dJqcmSMpJhOpdxvUN6Z6hRpkh9gwRRYzPnhjrUpiDiw/vn7Dfv6vSq4Kh0mqve9YZ8oRnhly44KoBdIZFvVnqkgk3l8nlxygz1BwpJRwyzdqqS4HvXgO+fhlY95kq15mIj7EgOwtL1h8OrLjc6m0wtBSl2u4ZCskMsUyO3KLPoVZmQ6+ZI1mhBCyvoMvkqg0OhoKnySlcZ4goapwml2SK86wXxNIqczMCzfcM2esMsUwuutHaIdPk3Fwm14rhCdHKLbYGL1z4NnDN18DEm7Anvy9y07wYV/E+8PxJwENjrAZvNyy4KlgmR24hvYE6EyQnQfY/MSG7oU8mqIWW9eAR7x6YxOkZcioqmBkiihaDoSRTnGuVR5VWmXsQ3LhMTk/FYZlcTDJDLimTa1QmGV4m15pJcrHUvi9w5PX4bNo7OL72DryVeyzgybUGL2xZCtMHKDic0drMDJELHHCydXno1Qk7IaYzQ2qCpBMMmZoZst83mRkiihpPJSRrZqja3IPgZkdrc4BCDEdrm18mV1ffXGZIrzGUoGDIlp+dia8DA/HX7NH4WYdNwMaFRi7CGJwZygkpk+NobXKRMRcAAyZZC6gmSEiZXH47I4MhnVFnzxBR7DAzlGRkrLb7yuTCBigwGIpugEJ9cGbI64JFV5sboJDoYChotLasYSRqK4zODOXoEwshPUMMhsgFpEeofZ+E9AppucFri+ny0to9ZvcMOdPkGAwRRYrBUNL2DJl7ENx4tHZGaM9QBoOhSOipbGpKm9MzZG5QrKciNSqTk3HXiSyTs+nR2pW1wQdG5XDNAAWnZ4jBEFFL5DfZM1Rp5OumM3jGWWeIZXJEkWIwlKTBUFl1HertM0jGZ4Y89ou6rPQtDFrt2030m6MqP3TK5OqML5MMGa0dCASVybXxNLkWlsyo0drZhdaVhpfJsWeIKBYDFMzvGcrQr5tcZ4goagyGkkxRrvWCKK+Xe2rM7RdpctFVv90zxMxQDEZru2iAgg6GdbDhqzYjM2SXzNT66lFvaMlM+KKrOToYkqBSH8RxmhxRi+TZz3lntLaBJ0B8jUZrs2eIKFoMhpKMLLqoz2ibvtaQkxlwRmtzgELsR2ubHww5U5GCx2pn5lvjdhNIr0Yv6jz57ugZ0sFQnQSUdmaY6wwRtW6aXJ0fASczVGFoZii8TI7BEFGkGAwlofb2EIXdhg9RaLToKgcoRMUTMlrb/DI5PRXJ+fuHrDGU2BI5nbHUAaY3I9/ozFCj0dq6X0iwTI6oVWVyEnD4PXlGlsk1nEQKH6DAMjmiSDEYSuJSOdOHKDS76CrL5KLLDPndUSbnDX9TD5kk1xWJlpaW5gxRqEnPNXIBRq3GGaCQHno2W9ZHSg/qIyKiZuUF9dw5J0AMC4YaZ4a4zhBRtBgMJfkQBZM1WnSTAxRiM0DBJWVyOjMUss6QzgzJKvQGTZeqTstzV2bIWWOIWSGi1mTXdaa6Ni3XZT1DPOlBFCkGQ0kcDO2u9LpzgIInJ4F7lQQDFFRmKNP4MrlGwXBImVxihydoeXZmqMoJhsw6MGq06Gp4mRzHahNFtvBqeo6Rz/nG0+R0MMTMEFGkGAwl88KrhmeGvM0NUNAlXhRhmZz0DJmfGWo0QCO4TC7Bk+QarTuCXFdkhpxgSJ/NlkEURNTqUrlq5BhZJtc4M8QyOaJoMRhqC2qSU+IUOz1D5h4IB/cMOQ30nCYXkwEKbimTcxqBQ8rk9BpDXYwatbsHZpbMaNX2aO3GZXIMhogiWmvIec6bFQz5nddNDlAgihXOYoy1PVuA+4cD3UcDfQ4F+hwG9B4H5BTFvUzO9AEKDWVSXGcoFnS5mb/eHWVyeiX1rIymBiiYEQzl2+O1K+pzjM4MNQxQ0MGQXmOIPUNEkZwAqXIyQ2adAGHPEFHsMRiKtQ1fWS9Ocinbf/8ic6mAjgOAklFA91FAUS8gu8AKkGRhN8mEyCZBgP5YFlBLCzpITMIyOadnyBM+QIHBUCT0ej11LimT8/oCTWSGtppVJmf3DJXWZzcEQ7KgaYTPzbZS4wvvGeKCq0SR0CcUnBMgEgwZ9Jxv1DPkrDPEzBBRpBgMxdrQnwPXfA2s/QxY+1/rctePwM6V1vbNP1v2c9LS7eAoyxooIB/LWV4pe1Fbu6Y/zszDftv9mJq+GSWlnYB1AaBkBJBpp/wNUhc+WtsZoMBgKOrR2i4ok9OZIefvLwccTplcZ6POEpfV6+dPwMq6JHhB2HDVdmYoJ1OP1raDIa4xRBTRAIXyQHZDsCFr4BnyvtQoM8QyOaKoMRiKNTl71L6vtY0607pODvA2fw1sXmxdVm63zjDXlluXkhGRQECf4RGBesBXbW0oa9UuHADgsSz7254E0HMscPFcmDpAoVHPEAcoRETXkKs3SzdOk5MzsOrxblBmyD4wKvNJpjbdel7KfpoWDDU7Wps9Q0Stka/7BP1B70NycsGQYMjJDGWED1Dg4RxRpPjsiQc5yz1osrXtTb3fCggkMPIFbfpzGZcrL8pqq2j248qKcny/djPap1dhADZYAZhBaX7Na5f2NJomZ8ibjmsHKKjR2jnumyanx2rLBDRDgg1ntLa3HsgqAGrLrBMYBd1g4mjthp4hu8+BwRBRq+jnUKUvzarKkMXA5fmU1wEmUJn/kJ4h67mvSuuJKCJ89phEGiBVw3N0pS2Ve2pw8t3vIzetFt9nX2Cl+OUALqcQJh4MN6wzZPcMcYBCRDKDR2u7aZqcflN31hgyo0QuODNU6fVZAZoKhsphEjk40s+l3PB1hlgmRxTZOkPynJeTCRIMGbTWkC6Ty2CZHFHMcLR2EirOtdL71YFsBPTBUNVOGD9NjpmhmGSG3FImp4I2+fvrMklnklxXmMLJDNX6raEnwqADI1Fj996FrjOkBygwM0QU0Wht6cPTA0gMGq+ty+S4zhBRAoOhefPm4dhjj0X37t2RlpaG1157zflaXV0dbrjhBhxwwAHIz89Xtzn33HOxadOmvf7M2267Tf2s4G3o0KGR/Y9I9eDoM9r+nPZGBkP19QHnDJfTM8JgKEY9Q0GjtV2QGcrUU5Eqd1iXeZ1ginbZQZkhfWBk2HhtPTxBqmCzdWDJYIgoInmZ9gmQuuBgyMTMUHpYZoiFPkRxC4YqKysxcuRIPPzww42+VlVVhUWLFuHmm29Wl7Nnz8by5ctx3HHH7fPnDh8+HJs3b3a2Tz/9tLW7Rk2M1/Zmdwg90DSE1z4QDhmg4KwzxAEK0U2Tc1mZnBMM11iXBk0+1NPkKmt9DZkhgw6MgvuFcjwZ6kSSwmCIKMoyOX/D88eg53zjzBB7hoii1epnz7Rp09TWlKKiIsyZMyfkuoceeggHH3ww1q1bh969eze/Ix4PunUzqynZzYpyM7GxtBrVnmKrA8mwzJA+EHbK5GTAAzNDMVpnyB2LrjYaoGDg3z9fL8DoDS6TMywzFD48QbBniCgieXY2uEr3DBlWJqeXJHBOIrFMjsj8nqGysjJ1trK4uHivt1uxYoUqq+vfvz/OOussFTxR5NrnWy+MVR77fq/aYeSBsHMwrMaKB4w7GHYTXW5o9QzZ2TUZBa3PHBpGT0VyyiSdARpZxh0YWQMUzAyGnElyul8oJDNkxlQ+IrdlhqwTIO3MzwxxgAJR1No0r1pTU6N6iM444wwUFjY/yWzcuHF4+umnMWTIEFUid/vtt+Pwww/HN998g4IC+wAkTG1trdq08nKzJjyZMkShPL3IyDI5nRmSiThqKk6tXSKlrmQwFNUABVUmF/TUljdLmVRo6DpTrsgMhQxQMLNnKFsvuBoSDDEzRNQaubpnyNABCnrwjNMzpNcn5DpDRBFrs2ePDFM49dRTEQgE8Mgjj+z1tsFldyNGjFDBUZ8+ffDKK6/goosuavJ7Zs2apYImalpRnnWWaDfsILRqF0zitSdgOWO1ZeFZzaCDYTfRZwpDyuScMgp73SGD6HIPozND9lniCukZMrCZuskFV4PL5NgzRBR5Zkg/f2pN7hmygyH2DBGZVSanA6G1a9eqHqK9ZYWaIiV1gwcPxsqVK5u9zcyZM1UJnt7Wr18fgz1PHsW51sHwLhQYWSanByg0HAjbWYG0DCOzGG6gMyzqzTI4oDB0iEKdHRA3zgyZE7i1s0dr1/rq4Td0mlzTZXIVDQvYElGE6wwZmBniOkNE5gdDOhCSHqC5c+eiY8eOrf4ZFRUVWLVqFUpKSpq9TXZ2tgqygjdq0N6eJrfd387oMjlnkpyBB8Juoxtq1X2rAsqwN0vD1OkznM6iu/oxYF7PkPBm5LlngIJXZ4ZYJkcU/TpDFS4YoMDMEFHcgiEJVBYvXqw2sXr1avWxDDyQQOjkk0/GggUL8Pzzz8Pv92PLli1q83obyqAmTZqkpsxp1113HT7++GOsWbMGn332GaZPn46MjAzVa0TRlcltrrNfzE2bJudrrl/EnANh147WtoMM0yfKNRqgoEslDeoZkzJOfb/WpucbGQzV1NWHLrgq96P+m7NMjiiicfqho7VN7BnSJ7t0mRwzQ0SRavWpBAl0Jk6c6Hx+7bXXqsvzzjtPLZ76+uuvq89HjRoV8n0ffvghJkyYoD6WrM+OHQ2Zig0bNqjAZ+fOnejcuTMOO+wwzJ8/X31M0ZXJbarLNzIYaiiTC19jyJwDYVcPUBBSKid9OLoXxyBSyqdjNmfRVSczZM5jQCZhStlMeY0P1el5KDbsLHHwAAUnGKoLOnBjmRxRq+gFy2WCZCAr38qvG/ScZ88QUey1+tkjAY0MRWjO3r6mSQYo2EsvvdTa3aB9aJ9vZVjW19oLWNaWW2eMDcm8OAMUnDI5+4DdkP1zo0w9QMEuo3DeHPWZQ1PXmQp/DBg0QEHkZ3usYMhascu4zFDDAIX00LPYcqaYzyeiiMrkJOao8+Qhy9ieIT1NjusMERm/zhAlNjO0virLGkpgWHaorrnMEHuGos4MyfkIa4iC/eZoYGYoOBhyznD6aozLDIVMlNMT+QyaLNXkAAX2CxFFXSYnatPsk4kmZ4acMjlmhogixWAoyXuGymr9COR1MG6inDNAISPsQJhlchFzGmp1k63OsBjYM+SU8oUExGZmhvREuQrkGpkZ0sFQjh6goA/cuOAqUatJL46uWKhJ18FQpQsGKDAzRBQpBkNJvuiqZAnqczuanxlimVzUnN6b8IVXDS6Tk5ObTiOwgYuuBp8p3hPIaQg2dCmiiesM6TWGMpkZIoomG1xjYDaYPUNEscdgKEnJmS3dCOrNam/ceG2vnRlweoY4QCG2mSG/4WVy9hu6Ewwb/BjIt8drl9frEk5pJjDnTHG1N2yanD6LzUlyRBHJs59LlU6ZnME9Q5wmRxQ1BkNJrNhea6hGB0MGZYb0AIXGmSGzDoTdxDlTqIcoGFwm12jBVYOzgzozVO7LBNLSjTtT3LhniMEQUTTy7NLYyuBscAuGQyUmM8R1hoiixWAoiRXbfUNVniIXDVBgMBTNGGhdcmZ6mZyue3fWGHJBZqhSRlhnFxjXN9RsmRyDIaLohqYE7NeigL+hjNe4dYbsYIiZIaKIMRhKgWBoT3qRcWVyzgAFT1i/iGHN826jzxaq+9fgMjmvveiunoDnhsyQrDuC7ELrSu8egwco2Jkh9gwRRUSfWNhTH/RaZMhEOWeAAnuGiGKGwVAKDFEoTdOZoR0Gl8kxMxQL+v5UdeUGl8npN/QsV/QMWQcZVbX+hgltBmaGcnT/HcvkiGKSGaqqCzqpYEwwFJQZqpfnvl5km5khokgxGEqBzNCugF3aU7ULpvA6o7VZJtcWQxT8Emw4ZXLmBUM6Mxg89MHUvrHgFekbyuTMODAS1VK+F7RYJIMhothkg9VzSz+PDBmi4PQMyWtn8Gs7M0NEEWMwlALB0HZ/O/PK5OwyqUx9NlsfCBuWFXAbjz1hqM4flBkyMhja2zQ5w8rkgjND2eZlhhoNUOBobaKo6BMLVQYGQw09Q+mhWX9mhogixmAoBcrktuhgyMABCk5mSC+6alhWwG30QIKQ0dr1BmeGdN27TGoytFSy6cyQgWVyzjQ5LrpKFIsyuWp5zmeZ9ZwPmSan+4UEM0NEEeOzJ4kV2Zmhzd78hmBIlU+lGzRNTk/E8RqZFXAbPWGozvAyOV/4OlPqTT1g5GPAGaBQ6wM6Fhg4QKE+rExOT5NjZogomuf84g1l2O71oDOA/36/FhtL1yd616zXIadMjsEQUSzw2ZPE2tvrDK2vzW0YD1pTCuR1MKdnyCmTMzMr4NoBCoaXyXnDM0PBY2s9Zo7WViUzrsgMsWeIKBqFudah0bwftuO7TD+OzAD+9flyzK7vClNkezIasv4SCKUF9V8SUaswGEqBnqFl22tR7clHbn0lbnlxHrZl9Ur0ruG7zeXqkusMxZYOLnzBo7Xrzc0MOaO1g8d/GzpNziqTa2fUAAUpmdGTGRt6hvRobQZDRJGYProHftiyB+U1PuRvKwKqgAO7ZaK0sAtMMKRbAfp2zANK7T5grjFEFBUGQ0msZ/tcdbJIFovchnz0Sa/Etyt/xMKAOS+cXQpywtYZMutA2G10cFEndeX6DdLAzFDjnjH775+WbtxK6vlZwQMUzMoM6eEJIcEQM0NEUSkpysUDp4+2PnmtN7AYOPvAjjj7sLEwCtcYIooJPoOS/AX9xRmHYMW2CuR93hUo24arDmmP9V33hwkKczw4ev9u1icsk4uJzODR2hmZ7hmtbegaQ8HN1CozpIcSGLLmSHAwlO2sM8SeIaKYMWyaXJPBkGEnkIjchs+gJHdI/45qw489gLKlmNAzHRjTB8bhAIWYlslZo7XNLZNrNFrbWWPIvL+/LpOTQQX1WQXWCM5aq8zTlH4hCYTSdf+VLpPjNDmi5A6G9IkulskRRSXxY8UoPvI6WpdV5qw1FMLJDNllcxRVmZzqyTG4TM5XHz5N0PzMkKhJzzWqZ8hZYyhoH52DNq4zRBQ9fVLBkNLYEPpEF9cYIooKg6GUC4Z2wexgyLzMgCsHKBheJqeb/htnhswLhiTrokeWV6fnG3VgVO0NG54gWCZHFDtOaayBmaF6u0w2Pej5T0StxmAo1YKhSkMzQwZnBlw5QMHwMjmfs3Bg2DRBA8sk09LSnIVXq9JyjeoZ0mVyTjAkB0e+autjlskRRY9lckRJjz1DqSK/k+Flcub2jLhJZvBobYPL5OrszFCWJ2ydIQMzQ7pvSMbsXj17JV6Vp9Ge3fjp7z9I9G6h1he2xlCdnRUSLJMjSu5giGVyRDHBYChV5OlgaCeM5KwzxJ6haOjpbCrzYnCZXF2jzJDZAzSGdivA5rIarK/IAHKAPNRgU2klAoYk12XdkdADtjQg085iEVHk9Dh9rxmlsSGYGSKKCQZDKVcmZ2gw5KuxLlkmF6MBCmYvuqpHazf0DJmdGXrsnIOwfMseqwTtaeu6/1wySk2XS7T0tDQVrDVaY4gr0hMleWaIPUNEscBgKFXkmz5NjmVyMS2Tk8xLprmZIRWshUyTMzszlOVJxwE9i4BAobXAYb0P+3fKAAqLYRQuuEqUQsEQy+SIYsGMGg+KX5mc9BToaVMm4QCFthugoAMNo9cZMjsz5JBsi8mjdnXPEPuFiJJ/mhzL5IhigsFQKtU96xdME/uGDB6t7MrR2iFlcvYq5QaWyekeJ1f1jGUXGrXWUAg95Y6T5IhiHAxVAAHrJI4x9Gt7Bot8iKLBYChVyBltkyfK6Z4hBkNR0cGFGlBg8jS5Rj1DZpfJhcjWmaFyGIdrDBG1TZlcoB6os8fWmxYMSekuEUWMwVAqMXWinDSBBuxGUJbJRUVPZwvJDBlYJudzyuTCM0PZLpouZWJmyC7lYZkcUWwEP5dMK41lmRxRTDAYSiV5HcycKKf7RQQHKERFBxf+4NHaBpbJed2cGTK6Z4gDFIhiSk4wdehvfbxpEYwgi6evfB/48UPrcw5QIIoKc6uppKiXdbn+C2DkaTCGzgq4pWfELQMUDC6T05khvb+uzAwZ2TOky+QYDBHFzIBJwK4fgZVzgSHT4vd7pUepbAOwZQmw+Wtg8xLr4/KNTS+dQUQRYTCUSkacCix+Dvj6JWDyrUBOUXx+b12N9eItL+p6K5dL+zrnhT2Ntc8xG61d35BlMbFMTvZPjtl1mZyzzpQLMkNG9wwxM0QUcwMnA1/9DVgxxwpQ2mINLzlptX05sPVbYOvShsCnenfTt+84EOg2AigZCRx4buz3hyiF8MgzlfQ7Aui8H7D9e+B/zwPjL4/+Z0p5k/QgqWBnfUOAoz62A53K7S37WcOO50KRMR2t7TG4TC4Q0uPkqmmCepqciT1DukyOPUNEsdP3MCvTXrrWyhB1HBDdCYvS9UDpOmDHD8DWb4At3wDblzW9QLacIJT37RI78JEAqNv+DRlqIooag6FUIoHGwTOAN6+1znKNu9Sqh26KnI3a/oP14i+bBDlyXfjW0gNCOTgr6gkU9rAu9aY/l0tOwIpaRvBobadMzsDMkO4Z8oSVyblhgIbJPUNOZoijtYlimg3uMx5YPc8qldtbMLR7DbBtGbBzpbXt2Wy9V1btsk4cVu/ay+8pBLrubwU7cikBUJdh7jhJRORiDIZSzYjTgLm3N9Q/D54S+vVNi4EvHgW++VfLD6LT0oGC7naAo4OdXqGBT257Zn3iOEDBpwYoZJk/WtsO3hoyQ24ok3NDzxBPLBDFvFROBUPvA+N+0fjr1aXA2zcAS17a98+SoKe4D9ChL9D1gIbgp7g33yeJEoDBUCqe4Rp9NjD/YeDLxxqCodWfAB/NAtb+t+G2hT2B9n2B9n2sgEaaNHM7WIGN2oqtS+k9Ss9I2H+JGuiyMxVsGFwmp8r4gqfJuSkzlG1yZkgvusqeIaKYB0NzbgHWfGL1wWYGDfuRAOnfVwJ7NlknB7sMt7JH0tdT3KvhfVMmuspJQnnvJCJjMBhKRQdfDMz/PysztPYzYMFTwNJXGuqTh08Hxl0G9ByT6D2laEZrp5s7QEFnhvQisc54dTdkhvTkJikfNU2dnRnKZDBEFFNSrlZQYpW9rfscGDDRGqbw3k3A5w9Zt5ER3Cc8CvQel+i9JaJWYDCUiuQFe9AUYMW7wFN6TGgacNCFwBHXAYXdE7yDFJsBCuaWyfkaZYa87skM9TnMer5I47P00klpaKJUbLf2Q02g+hbYuNC6npkhotiS8jUZsS0TWeVEogRDn97XEAgdfAkw+TY+94hciMFQqpKaZwmGRPfRwDH3AT0OTPReUZQ8IaO1TS6TC1901UXrDOV3BHqOBTZ8aT2H5CRCW5OyHJk2JQHPtu8aAqCmJjXK4IzOQ9t+n4hSzUA7GFr1AfDd68D7d1jX/+zP1nAiInIlBkOpasBRwM8fsBY5lfWH2POTFHRwoTIvBk+Tq6sPK5NzMkMuKJMTg6dawdAP78U2GJIs3s5VVsAjwY9cbvveGngSsO6zUGlWb4KU8EgDdtfhQI8xQGFJ7PaJiCz9J1g9QfK8nD2jISPEQIjI1RgMpXLK/6ALEr0X1Eajta0BCuaWydX5rDK5LDdmhsTgo4EP7gR+/AioqwYyc/f9PdJfsGcLULEFqNxhbfKxrDlSZq87IoFQU2uNCGnClmBHBT0S/Ay31h/h5Dii+JABCHKyYcNX1kLRUjY3dVai94qIosRgiChpR2vbmSEEgHq/Udk/n9szQxKIyLTF8g3WJMbwEfWa9BZ8+6q1srxsteX7/tmyRpCUuXXZz8r4qMv9gHZdOXaXyIis8FfWc/SUpxrKkYnItfgsJkrC0doqGJLJgJoEG+ktyF7Eidfn4p4hIUGJHBQteAL44Z3GwdCercA7N1iBUMj3ZQDtugB5nYD8TtbHel0uGcHbabAVZDW3GDIRJdYhV1jP36HHWMtKEJHrMRgiSiI60+ILLpPTpXItKeWKExWsqUVXXbjOkOYEQ+9aJXASIMnl/561xu3WlFnBj5Sj9j3MOpPcYYA7xocTUdOkLJUl5kRJhcEQUbIOUHDK5MybKOdMk/PodYbsMjk3BQr9jgA8uVapnEx2k9K54DVHSkYBx/0VKBmZ6D0lIiKiZjAYIkrC0dpqWpvqEZLPA0ZNlAsEAtY6SEFlfa7MDEmmrf+RVpmcbF+/2BAITboVOPRq9hMQEREZju/UREm46Kpe1FSVykmgYdBEOV0iFzpNzoWZIV0qJ4HQvD8Dvmrrup/fH5+1h4iIiChq7NIlSsZFV+0yNKdUrrlxzQngBGoh0+RcmBkSg6ZalwyEiIiIXInBEFES0cFFnc6+6GDIoMyQVwdqusdJSvp0T5NbpslpRT2A3uOtj4+5j4EQERGRy7BMjigJByj4dTCUbl4w5GSt9LpIsnih5pZ1hoKd+bK1gGrHAYneEyIiImolBkNEyThAweAyuYbhCWlIk3HUeo0hN2aGhKw1wvVGiIiIXIllckTJOlrb0DI5Hag19At53Z0ZIiIiItdiMESUjIuuSh+OoWVyzhpDziQ5PTwhy1q4lIiIiChOGAwRJZEMp0wuoNbzMbFMTo/WdoIhnRly2yQ5IiIicj0GQ0RJJFMvYqqHKBhYJuf16cxQWmhmyG1rDBEREZHrMRgiSiJOH47OwBhYJqczQx4duLl1jSEiIiJyPQZDREnEKT3TQYeBZXK6ZyjLo3uGvO6dJEdERESuxmCIKAlHazvr+Zg8TU7vq84MMRgiIiIi04OhefPm4dhjj0X37t3VGiGvvfaa87W6ujrccMMNOOCAA5Cfn69uc+6552LTpk37/LkPP/ww+vbti5ycHIwbNw5ffvll6/83RClOD1Bw1vMxsExOrzPUME1OD1BgzxAREREZHgxVVlZi5MiRKngJV1VVhUWLFuHmm29Wl7Nnz8by5ctx3HHH7fVnvvzyy7j22mtx6623qu+Tnz916lRs27attbtHlNLkBEVm8HhtA8vkVMYqeIACM0NERESUIJ7WfsO0adPU1pSioiLMmTMn5LqHHnoIBx98MNatW4fevXs3+X333XcfZsyYgQsuuEB9/uijj+LNN9/Ek08+iRtvvLG1u0iEVM8OSfZFLbzqlMkFLWxqzKKr4esMMRgiIiKiJOsZKisrU2eri4uLm/y61+vFwoULMXny5IadSk9Xn3/++efN/tza2lqUl5eHbETUMF5bBR1OmZwP5pXJcbQ2ERERJXEwVFNTo3qIzjjjDBQWFjZ5mx07dsDv96Nr164h18vnW7ZsafZnz5o1S2Wi9NarV6+Y7z+Rm8drh6wzZFKZnJTvhSy6yswQERERJVkwJMMUTj31VAQCATzyyCMx//kzZ85UWSe9rV+/Pua/g8iNdPlZnallcr5mBigwM0RERESm9wy1JhBau3YtPvjgg2azQqJTp07IyMjA1q1bQ66Xz7t169bs92VnZ6uNiEJl2hPlVAbGxDK5+mZGazMzRERERG7PDOlAaMWKFZg7dy46duy419tnZWVhzJgxeP/9953r6uvr1efjx4+P9e4RpWZmyKAyuTqfXSbnLLrKniEiIiJySWaooqICK1eudD5fvXo1Fi9ejA4dOqCkpAQnn3yyGo/9xhtvqF4g3fcjX5fAR0yaNAnTp0/HlVdeqT6XsdrnnXceDjroIDV57oEHHlAjvPV0OSJqfc+QtehqlnFlcj7pZQrKYDn7xswQERERmR4MLViwABMnTnQ+l0BGSDBz22234fXXX1efjxo1KuT7PvzwQ0yYMEF9vGrVKjU4QTvttNOwfft23HLLLSp4ku995513Gg1VIKJ90+VnKuhI9xhXJud11hkKzwwxGCIiIiLDgyEJaGQoQnP29jVtzZo1ja6TLJHOFBFR5DzBo7UNHKCg1j8KXmfIyQyxTI6IiIiSbJ0hIoqvzJDR2lnm9QzZmaGsRusMMTNERERE8cVgiCiZBygYWCZX1ygzpKfJMTNERERE8cVgiChpe4bMLJPTmaHG6wwxM0RERETxxWCIKMnoIEP15hhYJqem3AWV83GdISIiIkoUBkNESTpaW2VgnDI5c4Ihr10m1zgzxDI5IiIiii8GQ0TJPFrbKZMzLzOkgzZmhoiIiChRGAwRJelo7ZBFV42cJsfMEBERESUWgyGiJKMzLqGLrhoUDMl+BWWwmBkiIiKiRGEwRJTUAxTMK5Or89kDFDw6M8R1hoiIiCgxGAwRJRmdcamrN7NMTmWsJBiyy/mcsd9cZ4iIiIjijMEQUZLxBGeG0g3MDOnR2h67TI6ZISIiIkoQBkNESUav32MNUDCwZ0hPk2NmiIiIiBKMwRBRkslwyuTMXHS1zllniJkhIiIiSiwGQ0RJOkDBX29mmZxeZ8hZdNXJDDEYIiIiovhiMESUrAMUVJmcecGQ184M6d6mhswQy+SIiIgovhgMESXzAAUdDNWbmBlKAwIBrjNERERECcNgiCjJZNqZIZ+M1jZ5mpwEbcH7xcwQERERxRmDIaIkzQypQQUGlsk1DFBIb8gKCU9O4naKiIiIUhKDIaKkHq1tXplcw2jtNMBnD08QLJMjIiKiOGMwRJTMo7WDy+SkP8cAPtkvAFmeoMxQugfQ6w4RERERxQmPPoiStEzOH1wmhwBQ74cJ6nzBmSEOTyAiIqLEYTBElMwDFJxgyJxSuTrZL6dnyC6T4/AEIiIiSgAGQ0TJPEBBl8kZNEQhZICCr8a6kpkhIiIiSgAGQ0TJOkAhPDNkQDAUCATgt3uG1H7qAQrMDBEREVECMBgiSjKe9ODMUAaQlm5MmZzOCjkZLC64SkRERAnEYIgoyXiCR2sLgxZe1WO1RZYqk7ODIQ+DISIiIoo/BkNESUZNaZPYxy5HQ4ZdgqaHFSSQLyQzlNawT3ofiYiIiOKIwRBRMg9QEBke67Leh0TzBmWGQkZrMzNERERECcBgiCiZR2sbVian90mGJ6SlMTNEREREicVgiChJM0NOSZpBZXJ1vqCx2oKZISIiIkogBkNESTpAQS9ualKZnN4n3dfUME2OmSEiIiKKPwZDREkmMz0sM+SUyRmQGbJ7hrI8OjOk1xliZoiIiIjij8EQUbJmhhqVyRnQM2Tvk14LiesMERERUSIxGCJK2tHa9cZOk8v0pIVlhlgmR0RERPHHYIgo2QcoGFQmp/dJl/IxM0RERESJxGCIKEkzQw0DFMwpk9M9Q7qUr2GaHDNDREREFH8MhoiSTGaj0drmlMnpYMgZre2sM8TMEBEREcUfgyGiJKOzLr76AAKBgFFlcnqogy7l4zpDRERElEgMhoiSjNOPYwdEJpXJ+fRobV0m52SGWCZHRERE8cdgiCjJOP04ulTOKZOrM2aanDNam5khIiIiSiAGQ0RJJsMeoCB8MkTBKZOrM2eanF50lZkhIiIiSiAGQ0RJxhlO4GSGzCmTcwYo6ICNmSEiIiJKILt+hoiSKTOUlgbI7ISf/OED3JW2FSemAQ+89x3+33vvmrHoqjNNjusMERERUeIwGCJKQiN6FuPr9aWo8vpRLSVpHiDg86LCn/jx2uKAnkXWBz67TI7rDBEREVECMBgiSkL/vHQ8Nu6uVh93mDcXWAJcML4nph8yIdG7hixPOroX51qfMDNERERECcRgiCgJSRla30751if5eeqiOBso1teZgpkhIiIiSiAOUCBKdukeYwYoNMLMEBERESUQgyGiZGfQNLnmM0M5id4TIiIiSkEskyNKdhl6nSE78DCBjLpb9T5QtdP6nGVyRERElAAMhoiSXY49uU0HHokki8Au+w/wyb3A5q+t67ILgcIeid4zIiIiSkEMhoiSXfu+1mXp2sRmgn54F/jgTmDrN9Z1mXnAmPOB8VcCeR0St29ERESUshgMESW74j7W5e61VlAiK7LG0+pPgPfvADZ82ZAJGnepteV3jO++EBEREQVhMESU7Ip7W5e15UD17vhlYTYuBN6/E/jxQ+tzTy4w7hfAT65hJoiIiIiMwGCIKNll5QHtugIVW4Hda9o+ENn2PfDBXcCyN6zP0zOtcrgjrgMKurXt7yYiIiJqBQZDRKnSNyTBkPQN9TiwbX7HrtXAR78HlrwsTUJAWjow4nRgwg0NfUtEREREBmEwRJQKJBhZ/4WVGYq10nXAp/cDi/4O1Pus6/Y7Dpj4O6DL0Nj/PiIiIqJELbo6b948HHvssejevTvS0tLw2muvhXx99uzZmDJlCjp27Ki+vnjx4n3+zKefflrdNnjLyeEijESxH6IQw2Bo14/Av68A/joaWPCkFQgNmATM+BA47VkGQkRERJR8maHKykqMHDkSF154IU488cQmv37YYYfh1FNPxYwZM1r8cwsLC7F8+XLncwmIiChGdJmaTJSLdp0gGYggwc/yt4BAvXV9/wnAEb8B+v4k+n0lIiIiMjUYmjZtmtqac84556jLNWtadwZagp9u3dhcTdQm2keZGZJ+oG9fBf73rJUR0gb+FDjyN0Cvg2Ozn0RERESp2DNUUVGBPn36oL6+HgceeCDuueceDB8+vNnb19bWqk0rLy+P054SuTgzVLYeqPcD6Rn7/p7KnVbwI0HQ5qByV1knaOQZwEEXshSOiIiIXM2IYGjIkCF48sknMWLECJSVleHPf/4zDj30UHz77bfo2bNnk98za9Ys3H777XHfVyJXKigBMrIAvxco39iw9lBTpJTu84eARc8CvmrrOpkM1/dwYP+TgANOBrLy47brREREREkdDI0fP15tmgRC++23Hx577DHceeedTX7PzJkzce2114Zkhnr16hWX/SVyHckEFfUCdq2ygp2mgqFAAHjvJmD+I0DAb11XMspaI2i/Y4H8TnHfbSIiIqKkD4bCZWZmYvTo0Vi5cmWzt8nOzlYbEbWiVE4FQ2uAfoc3/vr/nrMyQmLAUcBPfgn0O0Ia+uK+q0RERERGjtaOB7/fj6VLl6KkpCTRu0KUfEMUZOHVcDtXAW/fYH08+TbgnFeB/kcyECIiIqKk5olk0EFwxmb16tVqLaEOHTqgd+/e2LVrF9atW4dNmzapr+tx2TIpTk+LO/fcc9GjRw/V9yPuuOMOHHLIIRg4cCBKS0vxpz/9CWvXrsXFF18cq/8nETnjtcMmyvnrgNkzgLpKqy/o0KsTsntERERExgdDCxYswMSJE53Pdd/OeeedpxZPff3113HBBRc4Xz/99NPV5a233orbbrtNfSzBUnp6Q1Jq9+7dak2iLVu2oH379hgzZgw+++wzDBs2LLr/HRE1sfBqWGbo4z8AGxcCOUXA9EdbNmmOiIiIKAmkBQLSNe1+MkChqKhITaOTBVyJKMymxcDjRwL5XYDrV1jXbVgAPPFTa/HUk58C9m+8kDIRERFRssYGRvYMEVEblslVbgO8ldbHn95vBUIHnMJAiIiIiFIOgyGiVJFbbJXCidJ1QPkmYPnb1ueH/zqhu0ZERESUCAyGiFJ1iMKiv1vrCfU+FOiyX6L3jIiIiCjuGAwRpeIQBRmlvfAZ6+ODLkzoLhERERElCoMholTMDC14AtizCcjrCAw7LtF7RURERJQQDIaIUjEY2vWjdTn6bMCTndBdIiIiIkoUBkNEqaS9XSanjTk/UXtCRERElHAMhohSSft+DR8PmAR06J/IvSEiIiJKKAZDRKmkqBeQZj/tOTiBiIiIUpwn0TtARHHkyQKOugko2wAMPjrRe0NERESUUAyGiFINF1glIiIiUlgmR0REREREKYnBEBERERERpSQGQ0RERERElJIYDBERERERUUpiMERERERERCmJwRAREREREaUkBkNERERERJSSGAwREREREVFKYjBEREREREQpicEQERERERGlJAZDRERERESUkhgMERERERFRSmIwREREREREKYnBEBERERERpSQPkkQgEFCX5eXlid4VIiIiIiJKIB0T6Bgh6YOhPXv2qMtevXoleleIiIiIiMiQGKGoqKjZr6cF9hUuuUR9fT02bdqEgoICpKWlJTwSlaBs/fr1KCwsTOi+JBvet22L92/b4v3bdnjfti3ev22L92/b4X2buvdvIBBQgVD37t2Rnp6e/Jkh+U/27NkTJpEHhWkPjGTB+7Zt8f5tW7x/2w7v27bF+7dt8f5tO7xvU/P+LdpLRkjjAAUiIiIiIkpJDIaIiIiIiCglMRhqA9nZ2bj11lvVJcUW79u2xfu3bfH+bTu8b9sW79+2xfu37fC+bVvZSXD/Js0ABSIiIiIiotZgZoiIiIiIiFISgyEiIiIiIkpJDIaIiIiIiCglMRgiIiIiIqKUxGAoxh5++GH07dsXOTk5GDduHL788stE75IrzZo1C2PHjkVBQQG6dOmCE044AcuXLw+5zYQJE5CWlhayXXrppQnbZ7e47bbbGt1vQ4cOdb5eU1ODK664Ah07dkS7du1w0kknYevWrQndZzeR53/4/Sub3KeCj9vWmTdvHo499li1grjcV6+99lrI12UG0C233IKSkhLk5uZi8uTJWLFiRchtdu3ahbPOOkstCFhcXIyLLroIFRUVSHV7u2/r6upwww034IADDkB+fr66zbnnnotNmzbt8/H++9//PgH/G/c9ds8///xG993RRx8dchs+diO/f5t6HZbtT3/6k3MbPn6b1pJjsJYcK6xbtw7HHHMM8vLy1M+5/vrr4fP5YBoGQzH08ssv49prr1UjBhctWoSRI0di6tSp2LZtW6J3zXU+/vhj9SSbP38+5syZo96Yp0yZgsrKypDbzZgxA5s3b3a2P/7xjwnbZzcZPnx4yP326aefOl/71a9+hf/85z/4xz/+of4OcvBz4oknJnR/3eSrr74KuW/l8StOOeUU5zZ83LacPOfltVRONDVF7ru//vWvePTRR/HFF1+oA3d53ZU3ak0OJr/99lv1t3jjjTfUQdQll1yCVLe3+7aqqkq9j918883qcvbs2epg6Ljjjmt02zvuuCPk8XzVVVfF6X/g7seukOAn+L578cUXQ77Ox27k92/w/Srbk08+qYIdOWgPxsdvZMdg+zpW8Pv9KhDyer347LPP8Mwzz+Dpp59WJ6+MI6O1KTYOPvjgwBVXXOF87vf7A927dw/MmjUrofuVDLZt2yYj4AMff/yxc92RRx4ZuOaaaxK6X2506623BkaOHNnk10pLSwOZmZmBf/zjH85133//vbrvP//88zjuZfKQx+iAAQMC9fX16nM+biMnj8NXX33V+Vzu027dugX+9Kc/hTyGs7OzAy+++KL6/LvvvlPf99VXXzm3efvttwNpaWmBjRs3xvl/4J77tilffvmlut3atWud6/r06RO4//7747CHyXf/nnfeeYHjjz++2e/hYze2j1+5r4866qiQ6/j4bZnwY7CWHCu89dZbgfT09MCWLVuc2zzyyCOBwsLCQG1tbcAkzAzFiES+CxcuVCUaWnp6uvr8888/T+i+JYOysjJ12aFDh5Drn3/+eXTq1An7778/Zs6cqc5m0r5JGZGUFvTv31+deZRUtpDHsJwBCn4cSwld7969+TiO8HXhueeew4UXXqjOSGp83MbG6tWrsWXLlpDHa1FRkSpR1o9XuZTyooMOOsi5jdxeXp8lk0Stex2Wx7Hcn8GkrEhKZUaPHq1KkEwsgzHVRx99pMqHhgwZgssuuww7d+50vsbHbuxI+dabb76pygzD8fHb+mOwlhwryKWU2Xbt2tW5jWTty8vLVbbTJJ5E70Cy2LFjh0oJBv/RhXy+bNmyhO1XMqivr8cvf/lL/OQnP1EHj9qZZ56JPn36qIP6JUuWqPp2KeOQcg5qnhwoSqpa3nylJOD222/H4Ycfjm+++UYdWGZlZTU62JHHsXyNWkdq2EtLS1VvgMbHbezox2RTr7v6a3IpB5vBPB6PelPnY7rlpOxQHqtnnHGG6l/Rrr76ahx44IHq/pRSGAnu5XXlvvvuS+j+uoGUyElZUb9+/bBq1Sr89re/xbRp09RBZEZGBh+7MSQlWtL/El7yzcfvvjV1DNaSYwW5bOq1WX/NJAyGyHhStyoH6sF9LSK4blrOPkgD9aRJk9SbyoABAxKwp+4gb7baiBEjVHAkB+evvPKKakCn2HniiSfU/S2Bj8bHLbmNnAE+9dRT1bCKRx55JORr0icb/HoiB0i/+MUvVAN2dnZ2AvbWPU4//fSQ1wK5/+Q1QLJF8ppAsSP9QlIFIcOtgvHxu2/NHYMlE5bJxYiUvMiZnPBJGvJ5t27dErZfbnfllVeqptEPP/wQPXv23Ott5aBerFy5Mk57lxzkzM7gwYPV/SaPVSntkmxGMD6OW2/t2rWYO3cuLr744r3ejo/byOnH5N5ed+UyfIiNlMHIlC4+plseCMnjWRqpg7NCzT2e5f5ds2ZN3PYxWUjZshxL6NcCPnZj45NPPlHZ9329Fgs+flt2DNaSYwW5bOq1WX/NJAyGYkTOJowZMwbvv/9+SGpRPh8/fnxC982N5AykPAlfffVVfPDBB6qMYF8WL16sLuVMO7WcjGmVrITcb/IYzszMDHkcy5uI9BTxcdw6Tz31lCpxkWk6e8PHbeTkdUHeVIMfr1KPLv0U+vEql/KGLTXumrymyOuzDkRp74GQ9BhKYC99Ffsij2fpaQkv76J927Bhg+oZ0q8FfOzGLkMv720yeW5f+Pht2TFYS44V5HLp0qUhAb0+oTJs2DAYJdETHJLJSy+9pKYYPf3002oKzCWXXBIoLi4OmaRBLXPZZZcFioqKAh999FFg8+bNzlZVVaW+vnLlysAdd9wRWLBgQWD16tWBf//734H+/fsHjjjiiETvuvF+/etfq/tV7rf//ve/gcmTJwc6deqkpsWISy+9NNC7d+/ABx98oO7f8ePHq41aTiZJyn14ww03hFzPx23r7dmzJ/C///1PbfKWdd9996mP9USz3//+9+p1Vu7LJUuWqIlR/fr1C1RXVzs/4+ijjw6MHj068MUXXwQ+/fTTwKBBgwJnnHFGINXt7b71er2B4447LtCzZ8/A4sWLQ16H9SSozz77TE3ikq+vWrUq8NxzzwU6d+4cOPfccxP9XzP+/pWvXXfddWrylrwWzJ07N3DggQeqx2ZNTY3zM/jYjfy1QZSVlQXy8vLUFLNwfPxGfgzWkmMFn88X2H///QNTpkxR9/E777yj7t+ZM2cGTMNgKMYefPBB9eDIyspSo7bnz5+f6F1yJXlha2p76qmn1NfXrVunDiA7dOigAtCBAwcGrr/+evXCR3t32mmnBUpKStRjtEePHupzOUjX5CDy8ssvD7Rv3169iUyfPl29CFLLvfvuu+rxunz58pDr+bhtvQ8//LDJ1wIZS6zHa998882Brl27qvt00qRJje73nTt3qgPIdu3aqbGuF1xwgTqQSnV7u2/lAL2512H5PrFw4cLAuHHj1EFTTk5OYL/99gvcc889IQfzqWxv968cVMpBohwcyohiGfE8Y8aMRidP+diN/LVBPPbYY4Hc3Fw1CjocH7+RH4O19FhhzZo1gWnTpqm/gZx0lZOxdXV1AdOkyT+Jzk4RERERERHFG3uGiIiIiIgoJTEYIiIiIiKilMRgiIiIiIiIUhKDISIiIiIiSkkMhoiIiIiIKCUxGCIiIiIiopTEYIiIiIiIiFISgyEiIiIiIkpJDIaIiIiIiCglMRgiIiIiIqKUxGCIiIiIiIhSEoMhIiIiIiJCKvr/xBvX9mWz/FwAAAAASUVORK5CYII=",
      "text/plain": [
       "<Figure size 1000x500 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "pipeline = LSTMPipeline(seq_len=12)\n",
    "pipeline.fit(monthly_temp)\n",
    "pipeline.plot_results()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def run_LSTM(countries, countries_to_plot=[], model_dir=\"models\", scaler_dir=\"scalers\"):\n",
    "    os.makedirs(model_dir, exist_ok=True)\n",
    "    os.makedirs(scaler_dir, exist_ok=True)\n",
    "\n",
    "    results = []\n",
    "\n",
    "    for country in countries:\n",
    "        country_df = df[df[\"Entity\"] == country].copy()\n",
    "        country_df[\"Day\"] = pd.to_datetime(country_df[\"Day\"])\n",
    "        country_df = country_df.sort_values(by=\"Day\")\n",
    "\n",
    "        temps = country_df[\"Monthly Average Temp\"].values\n",
    "        pipeline = LSTMPipeline(seq_len=12)\n",
    "        \n",
    "        try:\n",
    "            pipeline.fit(temps)\n",
    "            pipeline.save(\n",
    "                model_path=f\"{model_dir}/{country}.keras\",\n",
    "                scaler_path=f\"{scaler_dir}/{country}_scaler.pkl\"\n",
    "            )\n",
    "            metrics = pipeline.evaluate()\n",
    "            results.append({\n",
    "                \"Country\": country,\n",
    "                \"MAE\": metrics[\"MAE\"],\n",
    "                \"RMSE\": metrics[\"RMSE\"],\n",
    "                \"R2\": metrics[\"R2\"]\n",
    "            })\n",
    "            print(f\"Finished: {country} | MAE: {metrics['MAE']:.2f} | RMSE: {metrics['RMSE']:.2f} | R²: {metrics['R2']:.2f}\")\n",
    "\n",
    "            if country in countries_to_plot:\n",
    "                pipeline.plot_results()\n",
    "                \n",
    "        except Exception as e:\n",
    "            print(f\"Error with {country}: {e}\")\n",
    "    return pd.DataFrame(results)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/30\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/dejauhnaebeadle/School/MachineLearning/machine-learning-project/code/rain-prediction/.venv/lib/python3.11/site-packages/keras/src/layers/rnn/rnn.py:200: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
      "  super().__init__(**kwargs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m46/46\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 11ms/step - loss: 0.0677 - val_loss: 0.0150\n",
      "Epoch 2/30\n",
      "\u001b[1m46/46\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 0.0164 - val_loss: 0.0122\n",
      "Epoch 3/30\n",
      "\u001b[1m46/46\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 0.0132 - val_loss: 0.0111\n",
      "Epoch 4/30\n",
      "\u001b[1m46/46\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 0.0110 - val_loss: 0.0120\n",
      "Epoch 5/30\n",
      "\u001b[1m46/46\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 0.0096 - val_loss: 0.0104\n",
      "Epoch 6/30\n",
      "\u001b[1m46/46\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - loss: 0.0076 - val_loss: 0.0152\n",
      "Epoch 7/30\n",
      "\u001b[1m46/46\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 0.0079 - val_loss: 0.0134\n",
      "Epoch 8/30\n",
      "\u001b[1m46/46\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 0.0075 - val_loss: 0.0070\n",
      "Epoch 9/30\n",
      "\u001b[1m46/46\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 0.0070 - val_loss: 0.0066\n",
      "Epoch 10/30\n",
      "\u001b[1m46/46\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 0.0066 - val_loss: 0.0057\n",
      "Epoch 11/30\n",
      "\u001b[1m46/46\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 0.0093 - val_loss: 0.0067\n",
      "Epoch 12/30\n",
      "\u001b[1m46/46\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - loss: 0.0059 - val_loss: 0.0080\n",
      "Epoch 13/30\n",
      "\u001b[1m46/46\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 0.0072 - val_loss: 0.0080\n",
      "Epoch 14/30\n",
      "\u001b[1m46/46\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 0.0041 - val_loss: 0.0100\n",
      "Epoch 15/30\n",
      "\u001b[1m46/46\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 0.0078 - val_loss: 0.0049\n",
      "Epoch 16/30\n",
      "\u001b[1m46/46\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - loss: 0.0049 - val_loss: 0.0052\n",
      "Epoch 17/30\n",
      "\u001b[1m46/46\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - loss: 0.0060 - val_loss: 0.0056\n",
      "Epoch 18/30\n",
      "\u001b[1m46/46\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 0.0062 - val_loss: 0.0049\n",
      "Epoch 19/30\n",
      "\u001b[1m46/46\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 0.0071 - val_loss: 0.0043\n",
      "Epoch 20/30\n",
      "\u001b[1m46/46\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - loss: 0.0056 - val_loss: 0.0042\n",
      "Epoch 21/30\n",
      "\u001b[1m46/46\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 0.0063 - val_loss: 0.0042\n",
      "Epoch 22/30\n",
      "\u001b[1m46/46\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - loss: 0.0038 - val_loss: 0.0046\n",
      "Epoch 23/30\n",
      "\u001b[1m46/46\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 0.0061 - val_loss: 0.0053\n",
      "Epoch 24/30\n",
      "\u001b[1m46/46\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - loss: 0.0038 - val_loss: 0.0058\n",
      "Epoch 25/30\n",
      "\u001b[1m46/46\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 0.0066 - val_loss: 0.0040\n",
      "Epoch 26/30\n",
      "\u001b[1m46/46\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 0.0048 - val_loss: 0.0067\n",
      "Epoch 27/30\n",
      "\u001b[1m46/46\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 0.0044 - val_loss: 0.0052\n",
      "Epoch 28/30\n",
      "\u001b[1m46/46\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 0.0045 - val_loss: 0.0042\n",
      "Epoch 29/30\n",
      "\u001b[1m46/46\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - loss: 0.0042 - val_loss: 0.0053\n",
      "Epoch 30/30\n",
      "\u001b[1m46/46\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - loss: 0.0041 - val_loss: 0.0041\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:The `save_format` argument is deprecated in Keras 3. We recommend removing this argument as it can be inferred from the file path. Received: save_format=keras\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Finished: Afghanistan | MAE: 0.13 | RMSE: 0.24 | R²: 0.87\n",
      "Epoch 1/30\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/dejauhnaebeadle/School/MachineLearning/machine-learning-project/code/rain-prediction/.venv/lib/python3.11/site-packages/keras/src/layers/rnn/rnn.py:200: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
      "  super().__init__(**kwargs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m46/46\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 11ms/step - loss: 0.0492 - val_loss: 0.0065\n",
      "Epoch 2/30\n",
      "\u001b[1m46/46\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 0.0087 - val_loss: 0.0063\n",
      "Epoch 3/30\n",
      "\u001b[1m46/46\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - loss: 0.0071 - val_loss: 0.0052\n",
      "Epoch 4/30\n",
      "\u001b[1m46/46\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 0.0064 - val_loss: 0.0053\n",
      "Epoch 5/30\n",
      "\u001b[1m46/46\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 0.0048 - val_loss: 0.0043\n",
      "Epoch 6/30\n",
      "\u001b[1m46/46\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 0.0049 - val_loss: 0.0038\n",
      "Epoch 7/30\n",
      "\u001b[1m46/46\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 0.0036 - val_loss: 0.0032\n",
      "Epoch 8/30\n",
      "\u001b[1m46/46\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 0.0040 - val_loss: 0.0038\n",
      "Epoch 9/30\n",
      "\u001b[1m46/46\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 0.0034 - val_loss: 0.0031\n",
      "Epoch 10/30\n",
      "\u001b[1m46/46\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 0.0036 - val_loss: 0.0029\n",
      "Epoch 11/30\n",
      "\u001b[1m46/46\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - loss: 0.0036 - val_loss: 0.0028\n",
      "Epoch 12/30\n",
      "\u001b[1m46/46\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 0.0032 - val_loss: 0.0034\n",
      "Epoch 13/30\n",
      "\u001b[1m46/46\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 0.0037 - val_loss: 0.0027\n",
      "Epoch 14/30\n",
      "\u001b[1m46/46\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 0.0032 - val_loss: 0.0027\n",
      "Epoch 15/30\n",
      "\u001b[1m46/46\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 0.0029 - val_loss: 0.0024\n",
      "Epoch 16/30\n",
      "\u001b[1m46/46\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 0.0034 - val_loss: 0.0023\n",
      "Epoch 17/30\n",
      "\u001b[1m46/46\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 0.0036 - val_loss: 0.0025\n",
      "Epoch 18/30\n",
      "\u001b[1m46/46\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 0.0040 - val_loss: 0.0027\n",
      "Epoch 19/30\n",
      "\u001b[1m46/46\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 0.0032 - val_loss: 0.0032\n",
      "Epoch 20/30\n",
      "\u001b[1m46/46\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 0.0029 - val_loss: 0.0023\n",
      "Epoch 21/30\n",
      "\u001b[1m46/46\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - loss: 0.0032 - val_loss: 0.0027\n",
      "Epoch 22/30\n",
      "\u001b[1m46/46\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 0.0018 - val_loss: 0.0020\n",
      "Epoch 23/30\n",
      "\u001b[1m46/46\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 0.0025 - val_loss: 0.0022\n",
      "Epoch 24/30\n",
      "\u001b[1m46/46\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - loss: 0.0028 - val_loss: 0.0023\n",
      "Epoch 25/30\n",
      "\u001b[1m46/46\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - loss: 0.0026 - val_loss: 0.0021\n",
      "Epoch 26/30\n",
      "\u001b[1m46/46\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 0.0023 - val_loss: 0.0022\n",
      "Epoch 27/30\n",
      "\u001b[1m46/46\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 14ms/step - loss: 0.0024 - val_loss: 0.0019\n",
      "Epoch 28/30\n",
      "\u001b[1m46/46\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 10ms/step - loss: 0.0024 - val_loss: 0.0026\n",
      "Epoch 29/30\n",
      "\u001b[1m46/46\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 18ms/step - loss: 0.0032 - val_loss: 0.0018\n",
      "Epoch 30/30\n",
      "\u001b[1m46/46\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 14ms/step - loss: 0.0023 - val_loss: 0.0020\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:The `save_format` argument is deprecated in Keras 3. We recommend removing this argument as it can be inferred from the file path. Received: save_format=keras\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:5 out of the last 15 calls to <function TensorFlowTrainer.make_predict_function.<locals>.one_step_on_data_distributed at 0x1352a0fe0> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has reduce_retracing=True option that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/guide/function#controlling_retracing and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:5 out of the last 15 calls to <function TensorFlowTrainer.make_predict_function.<locals>.one_step_on_data_distributed at 0x1352a0fe0> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has reduce_retracing=True option that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/guide/function#controlling_retracing and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Finished: Albania | MAE: 0.17 | RMSE: 0.20 | R²: 0.79\n",
      "Epoch 1/30\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/dejauhnaebeadle/School/MachineLearning/machine-learning-project/code/rain-prediction/.venv/lib/python3.11/site-packages/keras/src/layers/rnn/rnn.py:200: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
      "  super().__init__(**kwargs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m46/46\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 11ms/step - loss: 0.0358 - val_loss: 0.0016\n",
      "Epoch 2/30\n",
      "\u001b[1m46/46\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 0.0048 - val_loss: 0.0017\n",
      "Epoch 3/30\n",
      "\u001b[1m46/46\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 0.0043 - val_loss: 0.0025\n",
      "Epoch 4/30\n",
      "\u001b[1m46/46\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - loss: 0.0046 - val_loss: 8.5910e-04\n",
      "Epoch 5/30\n",
      "\u001b[1m46/46\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - loss: 0.0040 - val_loss: 0.0012\n",
      "Epoch 6/30\n",
      "\u001b[1m46/46\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - loss: 0.0037 - val_loss: 5.8448e-04\n",
      "Epoch 7/30\n",
      "\u001b[1m46/46\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - loss: 0.0035 - val_loss: 0.0015\n",
      "Epoch 8/30\n",
      "\u001b[1m46/46\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 0.0026 - val_loss: 5.6047e-04\n",
      "Epoch 9/30\n",
      "\u001b[1m46/46\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - loss: 0.0027 - val_loss: 6.2892e-04\n",
      "Epoch 10/30\n",
      "\u001b[1m46/46\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - loss: 0.0030 - val_loss: 9.4374e-04\n",
      "Epoch 11/30\n",
      "\u001b[1m46/46\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - loss: 0.0030 - val_loss: 9.7370e-04\n",
      "Epoch 12/30\n",
      "\u001b[1m46/46\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 0.0024 - val_loss: 0.0017\n",
      "Epoch 13/30\n",
      "\u001b[1m46/46\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 0.0023 - val_loss: 8.4264e-04\n",
      "Epoch 14/30\n",
      "\u001b[1m46/46\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 0.0022 - val_loss: 0.0011\n",
      "Epoch 15/30\n",
      "\u001b[1m46/46\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 0.0026 - val_loss: 4.5508e-04\n",
      "Epoch 16/30\n",
      "\u001b[1m46/46\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 0.0022 - val_loss: 4.2773e-04\n",
      "Epoch 17/30\n",
      "\u001b[1m46/46\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 0.0022 - val_loss: 5.7462e-04\n",
      "Epoch 18/30\n",
      "\u001b[1m46/46\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 11ms/step - loss: 0.0018 - val_loss: 4.1249e-04\n",
      "Epoch 19/30\n",
      "\u001b[1m46/46\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 11ms/step - loss: 0.0020 - val_loss: 5.6951e-04\n",
      "Epoch 20/30\n",
      "\u001b[1m46/46\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 14ms/step - loss: 0.0022 - val_loss: 3.9831e-04\n",
      "Epoch 21/30\n",
      "\u001b[1m46/46\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 17ms/step - loss: 0.0026 - val_loss: 9.6281e-04\n",
      "Epoch 22/30\n",
      "\u001b[1m46/46\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 19ms/step - loss: 0.0020 - val_loss: 8.9258e-04\n",
      "Epoch 23/30\n",
      "\u001b[1m46/46\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 17ms/step - loss: 0.0021 - val_loss: 5.9772e-04\n",
      "Epoch 24/30\n",
      "\u001b[1m46/46\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 17ms/step - loss: 0.0015 - val_loss: 4.6052e-04\n",
      "Epoch 25/30\n",
      "\u001b[1m46/46\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 18ms/step - loss: 0.0016 - val_loss: 3.4281e-04\n",
      "Epoch 26/30\n",
      "\u001b[1m46/46\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - loss: 0.0022 - val_loss: 4.4995e-04\n",
      "Epoch 27/30\n",
      "\u001b[1m46/46\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - loss: 0.0016 - val_loss: 4.4832e-04\n",
      "Epoch 28/30\n",
      "\u001b[1m46/46\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - loss: 0.0017 - val_loss: 5.4587e-04\n",
      "Epoch 29/30\n",
      "\u001b[1m46/46\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 0.0018 - val_loss: 3.2883e-04\n",
      "Epoch 30/30\n",
      "\u001b[1m46/46\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 0.0016 - val_loss: 8.0777e-04\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:The `save_format` argument is deprecated in Keras 3. We recommend removing this argument as it can be inferred from the file path. Received: save_format=keras\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:5 out of the last 15 calls to <function TensorFlowTrainer.make_predict_function.<locals>.one_step_on_data_distributed at 0x1358cbe20> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has reduce_retracing=True option that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/guide/function#controlling_retracing and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:5 out of the last 15 calls to <function TensorFlowTrainer.make_predict_function.<locals>.one_step_on_data_distributed at 0x1358cbe20> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has reduce_retracing=True option that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/guide/function#controlling_retracing and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Finished: Algeria | MAE: 0.13 | RMSE: 0.21 | R²: 0.86\n",
      "Epoch 1/30\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/dejauhnaebeadle/School/MachineLearning/machine-learning-project/code/rain-prediction/.venv/lib/python3.11/site-packages/keras/src/layers/rnn/rnn.py:200: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
      "  super().__init__(**kwargs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m46/46\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 11ms/step - loss: 0.0380 - val_loss: 0.0142\n",
      "Epoch 2/30\n",
      "\u001b[1m46/46\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 0.0069 - val_loss: 0.0190\n",
      "Epoch 3/30\n",
      "\u001b[1m46/46\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 0.0058 - val_loss: 0.0116\n",
      "Epoch 4/30\n",
      "\u001b[1m46/46\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 0.0049 - val_loss: 0.0089\n",
      "Epoch 5/30\n",
      "\u001b[1m46/46\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - loss: 0.0048 - val_loss: 0.0081\n",
      "Epoch 6/30\n",
      "\u001b[1m46/46\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 0.0039 - val_loss: 0.0066\n",
      "Epoch 7/30\n",
      "\u001b[1m46/46\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - loss: 0.0039 - val_loss: 0.0093\n",
      "Epoch 8/30\n",
      "\u001b[1m46/46\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 0.0035 - val_loss: 0.0060\n",
      "Epoch 9/30\n",
      "\u001b[1m46/46\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 0.0032 - val_loss: 0.0073\n",
      "Epoch 10/30\n",
      "\u001b[1m46/46\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 0.0032 - val_loss: 0.0053\n",
      "Epoch 11/30\n",
      "\u001b[1m46/46\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 0.0031 - val_loss: 0.0053\n",
      "Epoch 12/30\n",
      "\u001b[1m46/46\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 0.0029 - val_loss: 0.0070\n",
      "Epoch 13/30\n",
      "\u001b[1m46/46\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 0.0027 - val_loss: 0.0053\n",
      "Epoch 14/30\n",
      "\u001b[1m46/46\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 0.0028 - val_loss: 0.0070\n",
      "Epoch 15/30\n",
      "\u001b[1m46/46\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 0.0027 - val_loss: 0.0046\n",
      "Epoch 16/30\n",
      "\u001b[1m46/46\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 0.0025 - val_loss: 0.0065\n",
      "Epoch 17/30\n",
      "\u001b[1m46/46\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - loss: 0.0030 - val_loss: 0.0045\n",
      "Epoch 18/30\n",
      "\u001b[1m46/46\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - loss: 0.0025 - val_loss: 0.0043\n",
      "Epoch 19/30\n",
      "\u001b[1m46/46\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 10ms/step - loss: 0.0025 - val_loss: 0.0045\n",
      "Epoch 20/30\n",
      "\u001b[1m46/46\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 10ms/step - loss: 0.0031 - val_loss: 0.0042\n",
      "Epoch 21/30\n",
      "\u001b[1m46/46\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 12ms/step - loss: 0.0022 - val_loss: 0.0041\n",
      "Epoch 22/30\n",
      "\u001b[1m46/46\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - loss: 0.0021 - val_loss: 0.0039\n",
      "Epoch 23/30\n",
      "\u001b[1m46/46\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - loss: 0.0026 - val_loss: 0.0047\n",
      "Epoch 24/30\n",
      "\u001b[1m46/46\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - loss: 0.0025 - val_loss: 0.0043\n",
      "Epoch 25/30\n",
      "\u001b[1m46/46\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 12ms/step - loss: 0.0020 - val_loss: 0.0037\n",
      "Epoch 26/30\n",
      "\u001b[1m46/46\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 11ms/step - loss: 0.0023 - val_loss: 0.0036\n",
      "Epoch 27/30\n",
      "\u001b[1m46/46\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 0.0018 - val_loss: 0.0038\n",
      "Epoch 28/30\n",
      "\u001b[1m46/46\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - loss: 0.0022 - val_loss: 0.0038\n",
      "Epoch 29/30\n",
      "\u001b[1m46/46\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 8ms/step - loss: 0.0028 - val_loss: 0.0039\n",
      "Epoch 30/30\n",
      "\u001b[1m46/46\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - loss: 0.0020 - val_loss: 0.0041\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:The `save_format` argument is deprecated in Keras 3. We recommend removing this argument as it can be inferred from the file path. Received: save_format=keras\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Finished: American Samoa | MAE: 0.06 | RMSE: 0.09 | R²: 0.86\n",
      "Epoch 1/30\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/dejauhnaebeadle/School/MachineLearning/machine-learning-project/code/rain-prediction/.venv/lib/python3.11/site-packages/keras/src/layers/rnn/rnn.py:200: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
      "  super().__init__(**kwargs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m46/46\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 11ms/step - loss: 0.0397 - val_loss: 0.0101\n",
      "Epoch 2/30\n",
      "\u001b[1m46/46\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 0.0094 - val_loss: 0.0097\n",
      "Epoch 3/30\n",
      "\u001b[1m46/46\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 0.0072 - val_loss: 0.0083\n",
      "Epoch 4/30\n",
      "\u001b[1m46/46\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 0.0060 - val_loss: 0.0075\n",
      "Epoch 5/30\n",
      "\u001b[1m46/46\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 0.0061 - val_loss: 0.0087\n",
      "Epoch 6/30\n",
      "\u001b[1m46/46\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 0.0057 - val_loss: 0.0073\n",
      "Epoch 7/30\n",
      "\u001b[1m46/46\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 0.0047 - val_loss: 0.0075\n",
      "Epoch 8/30\n",
      "\u001b[1m46/46\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - loss: 0.0043 - val_loss: 0.0052\n",
      "Epoch 9/30\n",
      "\u001b[1m46/46\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - loss: 0.0045 - val_loss: 0.0058\n",
      "Epoch 10/30\n",
      "\u001b[1m46/46\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - loss: 0.0046 - val_loss: 0.0044\n",
      "Epoch 11/30\n",
      "\u001b[1m46/46\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 0.0043 - val_loss: 0.0044\n",
      "Epoch 12/30\n",
      "\u001b[1m46/46\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - loss: 0.0040 - val_loss: 0.0045\n",
      "Epoch 13/30\n",
      "\u001b[1m46/46\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - loss: 0.0031 - val_loss: 0.0042\n",
      "Epoch 14/30\n",
      "\u001b[1m46/46\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 0.0032 - val_loss: 0.0064\n",
      "Epoch 15/30\n",
      "\u001b[1m46/46\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 0.0029 - val_loss: 0.0038\n",
      "Epoch 16/30\n",
      "\u001b[1m46/46\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - loss: 0.0031 - val_loss: 0.0039\n",
      "Epoch 17/30\n",
      "\u001b[1m46/46\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - loss: 0.0036 - val_loss: 0.0039\n",
      "Epoch 18/30\n",
      "\u001b[1m46/46\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - loss: 0.0046 - val_loss: 0.0044\n",
      "Epoch 19/30\n",
      "\u001b[1m46/46\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - loss: 0.0028 - val_loss: 0.0037\n",
      "Epoch 20/30\n",
      "\u001b[1m46/46\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - loss: 0.0038 - val_loss: 0.0034\n",
      "Epoch 21/30\n",
      "\u001b[1m46/46\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - loss: 0.0027 - val_loss: 0.0033\n",
      "Epoch 22/30\n",
      "\u001b[1m46/46\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - loss: 0.0034 - val_loss: 0.0035\n",
      "Epoch 23/30\n",
      "\u001b[1m46/46\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - loss: 0.0039 - val_loss: 0.0033\n",
      "Epoch 24/30\n",
      "\u001b[1m46/46\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - loss: 0.0032 - val_loss: 0.0034\n",
      "Epoch 25/30\n",
      "\u001b[1m46/46\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 0.0026 - val_loss: 0.0039\n",
      "Epoch 26/30\n",
      "\u001b[1m46/46\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - loss: 0.0019 - val_loss: 0.0030\n",
      "Epoch 27/30\n",
      "\u001b[1m46/46\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - loss: 0.0024 - val_loss: 0.0031\n",
      "Epoch 28/30\n",
      "\u001b[1m46/46\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - loss: 0.0035 - val_loss: 0.0030\n",
      "Epoch 29/30\n",
      "\u001b[1m46/46\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - loss: 0.0026 - val_loss: 0.0030\n",
      "Epoch 30/30\n",
      "\u001b[1m46/46\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 13ms/step - loss: 0.0034 - val_loss: 0.0030\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:The `save_format` argument is deprecated in Keras 3. We recommend removing this argument as it can be inferred from the file path. Received: save_format=keras\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Finished: Andorra | MAE: 0.09 | RMSE: 0.28 | R²: 0.86\n",
      "Epoch 1/30\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/dejauhnaebeadle/School/MachineLearning/machine-learning-project/code/rain-prediction/.venv/lib/python3.11/site-packages/keras/src/layers/rnn/rnn.py:200: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
      "  super().__init__(**kwargs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m46/46\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 15ms/step - loss: 0.0488 - val_loss: 0.0075\n",
      "Epoch 2/30\n",
      "\u001b[1m46/46\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 0.0087 - val_loss: 0.0086\n",
      "Epoch 3/30\n",
      "\u001b[1m46/46\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - loss: 0.0080 - val_loss: 0.0074\n",
      "Epoch 4/30\n",
      "\u001b[1m46/46\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - loss: 0.0064 - val_loss: 0.0053\n",
      "Epoch 5/30\n",
      "\u001b[1m46/46\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 0.0048 - val_loss: 0.0064\n",
      "Epoch 6/30\n",
      "\u001b[1m46/46\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 11ms/step - loss: 0.0058 - val_loss: 0.0039\n",
      "Epoch 7/30\n",
      "\u001b[1m46/46\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - loss: 0.0044 - val_loss: 0.0046\n",
      "Epoch 8/30\n",
      "\u001b[1m46/46\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - loss: 0.0040 - val_loss: 0.0046\n",
      "Epoch 9/30\n",
      "\u001b[1m46/46\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - loss: 0.0053 - val_loss: 0.0040\n",
      "Epoch 10/30\n",
      "\u001b[1m46/46\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 0.0043 - val_loss: 0.0041\n",
      "Epoch 11/30\n",
      "\u001b[1m46/46\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - loss: 0.0033 - val_loss: 0.0037\n",
      "Epoch 12/30\n",
      "\u001b[1m46/46\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - loss: 0.0043 - val_loss: 0.0039\n",
      "Epoch 13/30\n",
      "\u001b[1m46/46\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - loss: 0.0026 - val_loss: 0.0038\n",
      "Epoch 14/30\n",
      "\u001b[1m46/46\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 0.0037 - val_loss: 0.0053\n",
      "Epoch 15/30\n",
      "\u001b[1m46/46\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 0.0039 - val_loss: 0.0030\n",
      "Epoch 16/30\n",
      "\u001b[1m46/46\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 0.0032 - val_loss: 0.0031\n",
      "Epoch 17/30\n",
      "\u001b[1m46/46\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 0.0024 - val_loss: 0.0037\n",
      "Epoch 18/30\n",
      "\u001b[1m46/46\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 0.0039 - val_loss: 0.0028\n",
      "Epoch 19/30\n",
      "\u001b[1m46/46\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 0.0028 - val_loss: 0.0029\n",
      "Epoch 20/30\n",
      "\u001b[1m46/46\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 0.0027 - val_loss: 0.0034\n",
      "Epoch 21/30\n",
      "\u001b[1m46/46\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 0.0031 - val_loss: 0.0028\n",
      "Epoch 22/30\n",
      "\u001b[1m46/46\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 0.0026 - val_loss: 0.0028\n",
      "Epoch 23/30\n",
      "\u001b[1m46/46\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 0.0034 - val_loss: 0.0025\n",
      "Epoch 24/30\n",
      "\u001b[1m46/46\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 0.0020 - val_loss: 0.0024\n",
      "Epoch 25/30\n",
      "\u001b[1m46/46\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 0.0021 - val_loss: 0.0025\n",
      "Epoch 26/30\n",
      "\u001b[1m46/46\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - loss: 0.0034 - val_loss: 0.0024\n",
      "Epoch 27/30\n",
      "\u001b[1m46/46\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 0.0021 - val_loss: 0.0028\n",
      "Epoch 28/30\n",
      "\u001b[1m46/46\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 0.0025 - val_loss: 0.0024\n",
      "Epoch 29/30\n",
      "\u001b[1m46/46\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 0.0017 - val_loss: 0.0023\n",
      "Epoch 30/30\n",
      "\u001b[1m46/46\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 0.0015 - val_loss: 0.0048\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:The `save_format` argument is deprecated in Keras 3. We recommend removing this argument as it can be inferred from the file path. Received: save_format=keras\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Finished: Angola | MAE: 0.20 | RMSE: 0.22 | R²: 0.63\n",
      "Epoch 1/30\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/dejauhnaebeadle/School/MachineLearning/machine-learning-project/code/rain-prediction/.venv/lib/python3.11/site-packages/keras/src/layers/rnn/rnn.py:200: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
      "  super().__init__(**kwargs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m46/46\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 11ms/step - loss: 0.0283 - val_loss: 0.0048\n",
      "Epoch 2/30\n",
      "\u001b[1m46/46\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 0.0067 - val_loss: 0.0073\n",
      "Epoch 3/30\n",
      "\u001b[1m46/46\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - loss: 0.0052 - val_loss: 0.0042\n",
      "Epoch 4/30\n",
      "\u001b[1m46/46\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 0.0045 - val_loss: 0.0046\n",
      "Epoch 5/30\n",
      "\u001b[1m46/46\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 0.0043 - val_loss: 0.0024\n",
      "Epoch 6/30\n",
      "\u001b[1m46/46\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - loss: 0.0042 - val_loss: 0.0038\n",
      "Epoch 7/30\n",
      "\u001b[1m46/46\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 0.0032 - val_loss: 0.0031\n",
      "Epoch 8/30\n",
      "\u001b[1m46/46\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - loss: 0.0033 - val_loss: 0.0035\n",
      "Epoch 9/30\n",
      "\u001b[1m46/46\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - loss: 0.0029 - val_loss: 0.0032\n",
      "Epoch 10/30\n",
      "\u001b[1m46/46\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 11ms/step - loss: 0.0030 - val_loss: 0.0024\n",
      "Epoch 11/30\n",
      "\u001b[1m46/46\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - loss: 0.0029 - val_loss: 0.0031\n",
      "Epoch 12/30\n",
      "\u001b[1m46/46\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - loss: 0.0028 - val_loss: 0.0023\n",
      "Epoch 13/30\n",
      "\u001b[1m46/46\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 20ms/step - loss: 0.0031 - val_loss: 0.0023\n",
      "Epoch 14/30\n",
      "\u001b[1m46/46\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 12ms/step - loss: 0.0030 - val_loss: 0.0024\n",
      "Epoch 15/30\n",
      "\u001b[1m46/46\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 11ms/step - loss: 0.0028 - val_loss: 0.0021\n",
      "Epoch 16/30\n",
      "\u001b[1m46/46\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 13ms/step - loss: 0.0024 - val_loss: 0.0024\n",
      "Epoch 17/30\n",
      "\u001b[1m46/46\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 16ms/step - loss: 0.0023 - val_loss: 0.0024\n",
      "Epoch 18/30\n",
      "\u001b[1m46/46\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 18ms/step - loss: 0.0023 - val_loss: 0.0016\n",
      "Epoch 19/30\n",
      "\u001b[1m46/46\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 11ms/step - loss: 0.0019 - val_loss: 0.0021\n",
      "Epoch 20/30\n",
      "\u001b[1m46/46\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 11ms/step - loss: 0.0025 - val_loss: 0.0016\n",
      "Epoch 21/30\n",
      "\u001b[1m46/46\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 22ms/step - loss: 0.0022 - val_loss: 0.0020\n",
      "Epoch 22/30\n",
      "\u001b[1m46/46\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 21ms/step - loss: 0.0021 - val_loss: 0.0017\n",
      "Epoch 23/30\n",
      "\u001b[1m46/46\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 12ms/step - loss: 0.0022 - val_loss: 0.0025\n",
      "Epoch 24/30\n",
      "\u001b[1m46/46\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 17ms/step - loss: 0.0025 - val_loss: 0.0015\n",
      "Epoch 25/30\n",
      "\u001b[1m46/46\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 15ms/step - loss: 0.0020 - val_loss: 0.0016\n",
      "Epoch 26/30\n",
      "\u001b[1m46/46\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 9ms/step - loss: 0.0026 - val_loss: 0.0015\n",
      "Epoch 27/30\n",
      "\u001b[1m46/46\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - loss: 0.0020 - val_loss: 0.0016\n",
      "Epoch 28/30\n",
      "\u001b[1m46/46\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - loss: 0.0019 - val_loss: 0.0014\n",
      "Epoch 29/30\n",
      "\u001b[1m46/46\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 0.0023 - val_loss: 0.0018\n",
      "Epoch 30/30\n",
      "\u001b[1m46/46\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - loss: 0.0022 - val_loss: 0.0018\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:The `save_format` argument is deprecated in Keras 3. We recommend removing this argument as it can be inferred from the file path. Received: save_format=keras\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Finished: Anguilla | MAE: 0.07 | RMSE: 0.10 | R²: 0.88\n",
      "Epoch 1/30\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/dejauhnaebeadle/School/MachineLearning/machine-learning-project/code/rain-prediction/.venv/lib/python3.11/site-packages/keras/src/layers/rnn/rnn.py:200: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
      "  super().__init__(**kwargs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m46/46\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 11ms/step - loss: 0.0303 - val_loss: 0.0053\n",
      "Epoch 2/30\n",
      "\u001b[1m46/46\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - loss: 0.0067 - val_loss: 0.0063\n",
      "Epoch 3/30\n",
      "\u001b[1m46/46\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 0.0047 - val_loss: 0.0050\n",
      "Epoch 4/30\n",
      "\u001b[1m46/46\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - loss: 0.0043 - val_loss: 0.0070\n",
      "Epoch 5/30\n",
      "\u001b[1m46/46\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - loss: 0.0041 - val_loss: 0.0090\n",
      "Epoch 6/30\n",
      "\u001b[1m46/46\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 0.0042 - val_loss: 0.0039\n",
      "Epoch 7/30\n",
      "\u001b[1m46/46\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - loss: 0.0034 - val_loss: 0.0032\n",
      "Epoch 8/30\n",
      "\u001b[1m46/46\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - loss: 0.0036 - val_loss: 0.0028\n",
      "Epoch 9/30\n",
      "\u001b[1m46/46\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - loss: 0.0027 - val_loss: 0.0045\n",
      "Epoch 10/30\n",
      "\u001b[1m46/46\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 0.0035 - val_loss: 0.0029\n",
      "Epoch 11/30\n",
      "\u001b[1m46/46\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - loss: 0.0028 - val_loss: 0.0029\n",
      "Epoch 12/30\n",
      "\u001b[1m46/46\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - loss: 0.0032 - val_loss: 0.0024\n",
      "Epoch 13/30\n",
      "\u001b[1m46/46\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - loss: 0.0025 - val_loss: 0.0025\n",
      "Epoch 14/30\n",
      "\u001b[1m46/46\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 0.0035 - val_loss: 0.0030\n",
      "Epoch 15/30\n",
      "\u001b[1m46/46\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 0.0028 - val_loss: 0.0027\n",
      "Epoch 16/30\n",
      "\u001b[1m46/46\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 0.0027 - val_loss: 0.0027\n",
      "Epoch 17/30\n",
      "\u001b[1m46/46\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - loss: 0.0026 - val_loss: 0.0026\n",
      "Epoch 18/30\n",
      "\u001b[1m46/46\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 0.0025 - val_loss: 0.0031\n",
      "Epoch 19/30\n",
      "\u001b[1m46/46\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 0.0027 - val_loss: 0.0024\n",
      "Epoch 20/30\n",
      "\u001b[1m46/46\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 0.0025 - val_loss: 0.0023\n",
      "Epoch 21/30\n",
      "\u001b[1m46/46\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - loss: 0.0021 - val_loss: 0.0036\n",
      "Epoch 22/30\n",
      "\u001b[1m46/46\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 0.0021 - val_loss: 0.0021\n",
      "Epoch 23/30\n",
      "\u001b[1m46/46\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 0.0022 - val_loss: 0.0020\n",
      "Epoch 24/30\n",
      "\u001b[1m46/46\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 0.0023 - val_loss: 0.0018\n",
      "Epoch 25/30\n",
      "\u001b[1m46/46\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 0.0021 - val_loss: 0.0042\n",
      "Epoch 26/30\n",
      "\u001b[1m46/46\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 0.0020 - val_loss: 0.0019\n",
      "Epoch 27/30\n",
      "\u001b[1m46/46\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 0.0020 - val_loss: 0.0019\n",
      "Epoch 28/30\n",
      "\u001b[1m46/46\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 0.0021 - val_loss: 0.0018\n",
      "Epoch 29/30\n",
      "\u001b[1m46/46\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 0.0017 - val_loss: 0.0017\n",
      "Epoch 30/30\n",
      "\u001b[1m46/46\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - loss: 0.0021 - val_loss: 0.0019\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:The `save_format` argument is deprecated in Keras 3. We recommend removing this argument as it can be inferred from the file path. Received: save_format=keras\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Finished: Antigua and Barbuda | MAE: 0.05 | RMSE: 0.10 | R²: 0.90\n",
      "Epoch 1/30\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/dejauhnaebeadle/School/MachineLearning/machine-learning-project/code/rain-prediction/.venv/lib/python3.11/site-packages/keras/src/layers/rnn/rnn.py:200: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
      "  super().__init__(**kwargs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m46/46\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 9ms/step - loss: 0.0681 - val_loss: 0.0156\n",
      "Epoch 2/30\n",
      "\u001b[1m46/46\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 0.0075 - val_loss: 0.0149\n",
      "Epoch 3/30\n",
      "\u001b[1m46/46\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 0.0077 - val_loss: 0.0129\n",
      "Epoch 4/30\n",
      "\u001b[1m46/46\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 0.0073 - val_loss: 0.0110\n",
      "Epoch 5/30\n",
      "\u001b[1m46/46\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 0.0055 - val_loss: 0.0097\n",
      "Epoch 6/30\n",
      "\u001b[1m46/46\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 0.0057 - val_loss: 0.0088\n",
      "Epoch 7/30\n",
      "\u001b[1m46/46\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 0.0050 - val_loss: 0.0105\n",
      "Epoch 8/30\n",
      "\u001b[1m46/46\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 0.0044 - val_loss: 0.0091\n",
      "Epoch 9/30\n",
      "\u001b[1m46/46\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 0.0039 - val_loss: 0.0093\n",
      "Epoch 10/30\n",
      "\u001b[1m46/46\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 0.0043 - val_loss: 0.0079\n",
      "Epoch 11/30\n",
      "\u001b[1m46/46\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 0.0043 - val_loss: 0.0079\n",
      "Epoch 12/30\n",
      "\u001b[1m46/46\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 0.0040 - val_loss: 0.0085\n",
      "Epoch 13/30\n",
      "\u001b[1m46/46\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 0.0047 - val_loss: 0.0074\n",
      "Epoch 14/30\n",
      "\u001b[1m46/46\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 0.0034 - val_loss: 0.0075\n",
      "Epoch 15/30\n",
      "\u001b[1m46/46\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 0.0042 - val_loss: 0.0073\n",
      "Epoch 16/30\n",
      "\u001b[1m46/46\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - loss: 0.0037 - val_loss: 0.0075\n",
      "Epoch 17/30\n",
      "\u001b[1m46/46\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 0.0032 - val_loss: 0.0069\n",
      "Epoch 18/30\n",
      "\u001b[1m46/46\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 0.0029 - val_loss: 0.0069\n",
      "Epoch 19/30\n",
      "\u001b[1m46/46\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 0.0029 - val_loss: 0.0069\n",
      "Epoch 20/30\n",
      "\u001b[1m46/46\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 0.0036 - val_loss: 0.0067\n",
      "Epoch 21/30\n",
      "\u001b[1m46/46\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 0.0031 - val_loss: 0.0064\n",
      "Epoch 22/30\n",
      "\u001b[1m46/46\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 0.0023 - val_loss: 0.0064\n",
      "Epoch 23/30\n",
      "\u001b[1m46/46\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 0.0032 - val_loss: 0.0066\n",
      "Epoch 24/30\n",
      "\u001b[1m46/46\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 0.0037 - val_loss: 0.0061\n",
      "Epoch 25/30\n",
      "\u001b[1m46/46\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 0.0042 - val_loss: 0.0068\n",
      "Epoch 26/30\n",
      "\u001b[1m46/46\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 0.0038 - val_loss: 0.0060\n",
      "Epoch 27/30\n",
      "\u001b[1m46/46\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 0.0027 - val_loss: 0.0058\n",
      "Epoch 28/30\n",
      "\u001b[1m46/46\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 0.0027 - val_loss: 0.0059\n",
      "Epoch 29/30\n",
      "\u001b[1m46/46\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 0.0027 - val_loss: 0.0060\n",
      "Epoch 30/30\n",
      "\u001b[1m46/46\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 0.0028 - val_loss: 0.0056\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:The `save_format` argument is deprecated in Keras 3. We recommend removing this argument as it can be inferred from the file path. Received: save_format=keras\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Finished: Argentina | MAE: 0.04 | RMSE: 0.12 | R²: 0.81\n",
      "Epoch 1/30\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/dejauhnaebeadle/School/MachineLearning/machine-learning-project/code/rain-prediction/.venv/lib/python3.11/site-packages/keras/src/layers/rnn/rnn.py:200: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
      "  super().__init__(**kwargs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m46/46\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 11ms/step - loss: 0.0672 - val_loss: 0.0049\n",
      "Epoch 2/30\n",
      "\u001b[1m46/46\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 0.0137 - val_loss: 0.0035\n",
      "Epoch 3/30\n",
      "\u001b[1m46/46\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 0.0111 - val_loss: 0.0041\n",
      "Epoch 4/30\n",
      "\u001b[1m46/46\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 0.0098 - val_loss: 0.0047\n",
      "Epoch 5/30\n",
      "\u001b[1m46/46\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 0.0091 - val_loss: 0.0045\n",
      "Epoch 6/30\n",
      "\u001b[1m46/46\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 0.0066 - val_loss: 0.0063\n",
      "Epoch 7/30\n",
      "\u001b[1m46/46\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 0.0060 - val_loss: 0.0058\n",
      "Epoch 8/30\n",
      "\u001b[1m46/46\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 0.0070 - val_loss: 0.0032\n",
      "Epoch 9/30\n",
      "\u001b[1m46/46\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 0.0072 - val_loss: 0.0017\n",
      "Epoch 10/30\n",
      "\u001b[1m46/46\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 0.0051 - val_loss: 0.0039\n",
      "Epoch 11/30\n",
      "\u001b[1m46/46\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 0.0064 - val_loss: 0.0024\n",
      "Epoch 12/30\n",
      "\u001b[1m46/46\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 0.0054 - val_loss: 0.0021\n",
      "Epoch 13/30\n",
      "\u001b[1m46/46\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 0.0058 - val_loss: 0.0014\n",
      "Epoch 14/30\n",
      "\u001b[1m46/46\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 0.0067 - val_loss: 0.0015\n",
      "Epoch 15/30\n",
      "\u001b[1m46/46\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 0.0049 - val_loss: 0.0016\n",
      "Epoch 16/30\n",
      "\u001b[1m46/46\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 0.0045 - val_loss: 0.0012\n",
      "Epoch 17/30\n",
      "\u001b[1m46/46\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 0.0056 - val_loss: 0.0015\n",
      "Epoch 18/30\n",
      "\u001b[1m46/46\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 0.0042 - val_loss: 0.0022\n",
      "Epoch 19/30\n",
      "\u001b[1m46/46\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 0.0057 - val_loss: 0.0019\n",
      "Epoch 20/30\n",
      "\u001b[1m46/46\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 0.0031 - val_loss: 0.0017\n",
      "Epoch 21/30\n",
      "\u001b[1m46/46\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 0.0037 - val_loss: 0.0011\n",
      "Epoch 22/30\n",
      "\u001b[1m46/46\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 0.0056 - val_loss: 0.0024\n",
      "Epoch 23/30\n",
      "\u001b[1m46/46\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 0.0047 - val_loss: 0.0012\n",
      "Epoch 24/30\n",
      "\u001b[1m46/46\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 0.0036 - val_loss: 0.0014\n",
      "Epoch 25/30\n",
      "\u001b[1m46/46\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 0.0038 - val_loss: 0.0012\n",
      "Epoch 26/30\n",
      "\u001b[1m46/46\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 0.0035 - val_loss: 0.0015\n",
      "Epoch 27/30\n",
      "\u001b[1m46/46\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 0.0051 - val_loss: 0.0021\n",
      "Epoch 28/30\n",
      "\u001b[1m46/46\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 0.0034 - val_loss: 0.0017\n",
      "Epoch 29/30\n",
      "\u001b[1m46/46\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 0.0041 - val_loss: 0.0028\n",
      "Epoch 30/30\n",
      "\u001b[1m46/46\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 0.0050 - val_loss: 0.0011\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:The `save_format` argument is deprecated in Keras 3. We recommend removing this argument as it can be inferred from the file path. Received: save_format=keras\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Finished: Armenia | MAE: 0.14 | RMSE: 0.31 | R²: 0.82\n",
      "Epoch 1/30\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/dejauhnaebeadle/School/MachineLearning/machine-learning-project/code/rain-prediction/.venv/lib/python3.11/site-packages/keras/src/layers/rnn/rnn.py:200: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
      "  super().__init__(**kwargs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m46/46\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 10ms/step - loss: 0.0441 - val_loss: 0.0110\n",
      "Epoch 2/30\n",
      "\u001b[1m46/46\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 0.0096 - val_loss: 0.0094\n",
      "Epoch 3/30\n",
      "\u001b[1m46/46\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 0.0089 - val_loss: 0.0096\n",
      "Epoch 4/30\n",
      "\u001b[1m46/46\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 0.0078 - val_loss: 0.0062\n",
      "Epoch 5/30\n",
      "\u001b[1m46/46\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 0.0081 - val_loss: 0.0059\n",
      "Epoch 6/30\n",
      "\u001b[1m46/46\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 0.0059 - val_loss: 0.0056\n",
      "Epoch 7/30\n",
      "\u001b[1m46/46\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 0.0051 - val_loss: 0.0051\n",
      "Epoch 8/30\n",
      "\u001b[1m46/46\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 0.0062 - val_loss: 0.0072\n",
      "Epoch 9/30\n",
      "\u001b[1m46/46\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 0.0049 - val_loss: 0.0064\n",
      "Epoch 10/30\n",
      "\u001b[1m46/46\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 0.0053 - val_loss: 0.0061\n",
      "Epoch 11/30\n",
      "\u001b[1m46/46\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - loss: 0.0044 - val_loss: 0.0053\n",
      "Epoch 12/30\n",
      "\u001b[1m46/46\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 0.0043 - val_loss: 0.0056\n",
      "Epoch 13/30\n",
      "\u001b[1m46/46\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 0.0058 - val_loss: 0.0049\n",
      "Epoch 14/30\n",
      "\u001b[1m46/46\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 0.0035 - val_loss: 0.0074\n",
      "Epoch 15/30\n",
      "\u001b[1m46/46\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 0.0046 - val_loss: 0.0040\n",
      "Epoch 16/30\n",
      "\u001b[1m46/46\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 0.0035 - val_loss: 0.0040\n",
      "Epoch 17/30\n",
      "\u001b[1m46/46\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 0.0039 - val_loss: 0.0047\n",
      "Epoch 18/30\n",
      "\u001b[1m46/46\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 0.0039 - val_loss: 0.0049\n",
      "Epoch 19/30\n",
      "\u001b[1m46/46\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 0.0034 - val_loss: 0.0043\n",
      "Epoch 20/30\n",
      "\u001b[1m46/46\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 0.0033 - val_loss: 0.0044\n",
      "Epoch 21/30\n",
      "\u001b[1m46/46\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 0.0038 - val_loss: 0.0051\n",
      "Epoch 22/30\n",
      "\u001b[1m46/46\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 0.0039 - val_loss: 0.0065\n",
      "Epoch 23/30\n",
      "\u001b[1m46/46\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 0.0034 - val_loss: 0.0036\n",
      "Epoch 24/30\n",
      "\u001b[1m46/46\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 0.0029 - val_loss: 0.0037\n",
      "Epoch 25/30\n",
      "\u001b[1m46/46\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 0.0033 - val_loss: 0.0040\n",
      "Epoch 26/30\n",
      "\u001b[1m46/46\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 0.0034 - val_loss: 0.0046\n",
      "Epoch 27/30\n",
      "\u001b[1m46/46\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 0.0032 - val_loss: 0.0033\n",
      "Epoch 28/30\n",
      "\u001b[1m46/46\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 0.0032 - val_loss: 0.0039\n",
      "Epoch 29/30\n",
      "\u001b[1m46/46\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 0.0028 - val_loss: 0.0041\n",
      "Epoch 30/30\n",
      "\u001b[1m46/46\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - loss: 0.0025 - val_loss: 0.0033\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:The `save_format` argument is deprecated in Keras 3. We recommend removing this argument as it can be inferred from the file path. Received: save_format=keras\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Finished: Australia | MAE: 0.09 | RMSE: 0.15 | R²: 0.89\n"
     ]
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 1000x500 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/30\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/dejauhnaebeadle/School/MachineLearning/machine-learning-project/code/rain-prediction/.venv/lib/python3.11/site-packages/keras/src/layers/rnn/rnn.py:200: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
      "  super().__init__(**kwargs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m46/46\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 9ms/step - loss: 0.1344 - val_loss: 0.0273\n",
      "Epoch 2/30\n",
      "\u001b[1m46/46\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 0.0081 - val_loss: 0.0122\n",
      "Epoch 3/30\n",
      "\u001b[1m46/46\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 0.0076 - val_loss: 0.0102\n",
      "Epoch 4/30\n",
      "\u001b[1m46/46\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 0.0068 - val_loss: 0.0058\n",
      "Epoch 5/30\n",
      "\u001b[1m46/46\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 0.0066 - val_loss: 0.0081\n",
      "Epoch 6/30\n",
      "\u001b[1m46/46\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 0.0053 - val_loss: 0.0081\n",
      "Epoch 7/30\n",
      "\u001b[1m46/46\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 0.0050 - val_loss: 0.0046\n",
      "Epoch 8/30\n",
      "\u001b[1m46/46\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 0.0043 - val_loss: 0.0097\n",
      "Epoch 9/30\n",
      "\u001b[1m46/46\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 0.0043 - val_loss: 0.0067\n",
      "Epoch 10/30\n",
      "\u001b[1m46/46\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 0.0035 - val_loss: 0.0034\n",
      "Epoch 11/30\n",
      "\u001b[1m46/46\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 0.0039 - val_loss: 0.0036\n",
      "Epoch 12/30\n",
      "\u001b[1m46/46\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 0.0043 - val_loss: 0.0041\n",
      "Epoch 13/30\n",
      "\u001b[1m46/46\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 0.0033 - val_loss: 0.0044\n",
      "Epoch 14/30\n",
      "\u001b[1m46/46\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 0.0038 - val_loss: 0.0040\n",
      "Epoch 15/30\n",
      "\u001b[1m46/46\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 0.0037 - val_loss: 0.0073\n",
      "Epoch 16/30\n",
      "\u001b[1m46/46\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 0.0035 - val_loss: 0.0029\n",
      "Epoch 17/30\n",
      "\u001b[1m46/46\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 0.0030 - val_loss: 0.0056\n",
      "Epoch 18/30\n",
      "\u001b[1m46/46\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 0.0034 - val_loss: 0.0056\n",
      "Epoch 19/30\n",
      "\u001b[1m46/46\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 0.0036 - val_loss: 0.0027\n",
      "Epoch 20/30\n",
      "\u001b[1m46/46\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 0.0033 - val_loss: 0.0035\n",
      "Epoch 21/30\n",
      "\u001b[1m46/46\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 0.0032 - val_loss: 0.0027\n",
      "Epoch 22/30\n",
      "\u001b[1m46/46\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 0.0026 - val_loss: 0.0026\n",
      "Epoch 23/30\n",
      "\u001b[1m46/46\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 0.0035 - val_loss: 0.0028\n",
      "Epoch 24/30\n",
      "\u001b[1m46/46\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 0.0028 - val_loss: 0.0037\n",
      "Epoch 25/30\n",
      "\u001b[1m46/46\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 0.0029 - val_loss: 0.0040\n",
      "Epoch 26/30\n",
      "\u001b[1m46/46\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 0.0033 - val_loss: 0.0024\n",
      "Epoch 27/30\n",
      "\u001b[1m46/46\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 0.0027 - val_loss: 0.0017\n",
      "Epoch 28/30\n",
      "\u001b[1m46/46\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 0.0018 - val_loss: 0.0063\n",
      "Epoch 29/30\n",
      "\u001b[1m46/46\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 0.0030 - val_loss: 0.0038\n",
      "Epoch 30/30\n",
      "\u001b[1m46/46\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 0.0026 - val_loss: 0.0016\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:The `save_format` argument is deprecated in Keras 3. We recommend removing this argument as it can be inferred from the file path. Received: save_format=keras\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Finished: Austria | MAE: 0.15 | RMSE: 0.24 | R²: 0.87\n",
      "Epoch 1/30\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/dejauhnaebeadle/School/MachineLearning/machine-learning-project/code/rain-prediction/.venv/lib/python3.11/site-packages/keras/src/layers/rnn/rnn.py:200: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
      "  super().__init__(**kwargs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m46/46\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 10ms/step - loss: 0.0614 - val_loss: 0.0087\n",
      "Epoch 2/30\n",
      "\u001b[1m46/46\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 0.0167 - val_loss: 0.0084\n",
      "Epoch 3/30\n",
      "\u001b[1m46/46\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 0.0137 - val_loss: 0.0070\n",
      "Epoch 4/30\n",
      "\u001b[1m46/46\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 0.0090 - val_loss: 0.0023\n",
      "Epoch 5/30\n",
      "\u001b[1m46/46\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 0.0085 - val_loss: 0.0040\n",
      "Epoch 6/30\n",
      "\u001b[1m46/46\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 0.0087 - val_loss: 0.0102\n",
      "Epoch 7/30\n",
      "\u001b[1m46/46\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 0.0079 - val_loss: 0.0032\n",
      "Epoch 8/30\n",
      "\u001b[1m46/46\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 0.0086 - val_loss: 0.0050\n",
      "Epoch 9/30\n",
      "\u001b[1m46/46\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 0.0079 - val_loss: 0.0024\n",
      "Epoch 10/30\n",
      "\u001b[1m46/46\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 0.0091 - val_loss: 0.0030\n",
      "Epoch 11/30\n",
      "\u001b[1m46/46\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 0.0073 - val_loss: 0.0040\n",
      "Epoch 12/30\n",
      "\u001b[1m46/46\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 0.0070 - val_loss: 0.0017\n",
      "Epoch 13/30\n",
      "\u001b[1m46/46\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - loss: 0.0075 - val_loss: 0.0016\n",
      "Epoch 14/30\n",
      "\u001b[1m46/46\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 0.0066 - val_loss: 0.0018\n",
      "Epoch 15/30\n",
      "\u001b[1m46/46\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 0.0060 - val_loss: 0.0018\n",
      "Epoch 16/30\n",
      "\u001b[1m46/46\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 0.0065 - val_loss: 0.0026\n",
      "Epoch 17/30\n",
      "\u001b[1m46/46\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 0.0063 - val_loss: 0.0014\n",
      "Epoch 18/30\n",
      "\u001b[1m46/46\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - loss: 0.0054 - val_loss: 0.0013\n",
      "Epoch 19/30\n",
      "\u001b[1m46/46\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 0.0046 - val_loss: 0.0023\n",
      "Epoch 20/30\n",
      "\u001b[1m46/46\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - loss: 0.0043 - val_loss: 0.0013\n",
      "Epoch 21/30\n",
      "\u001b[1m46/46\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 0.0057 - val_loss: 0.0021\n",
      "Epoch 22/30\n",
      "\u001b[1m46/46\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 0.0047 - val_loss: 0.0033\n",
      "Epoch 23/30\n",
      "\u001b[1m46/46\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 0.0056 - val_loss: 0.0013\n",
      "Epoch 24/30\n",
      "\u001b[1m46/46\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 0.0055 - val_loss: 0.0030\n",
      "Epoch 25/30\n",
      "\u001b[1m46/46\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 0.0042 - val_loss: 0.0032\n",
      "Epoch 26/30\n",
      "\u001b[1m46/46\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 0.0062 - val_loss: 0.0013\n",
      "Epoch 27/30\n",
      "\u001b[1m46/46\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 0.0048 - val_loss: 0.0019\n",
      "Epoch 28/30\n",
      "\u001b[1m46/46\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 0.0032 - val_loss: 0.0025\n",
      "Epoch 29/30\n",
      "\u001b[1m46/46\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 0.0045 - val_loss: 0.0024\n",
      "Epoch 30/30\n",
      "\u001b[1m46/46\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 0.0055 - val_loss: 0.0014\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:The `save_format` argument is deprecated in Keras 3. We recommend removing this argument as it can be inferred from the file path. Received: save_format=keras\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Finished: Azerbaijan | MAE: 0.14 | RMSE: 0.26 | R²: 0.79\n",
      "Epoch 1/30\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/dejauhnaebeadle/School/MachineLearning/machine-learning-project/code/rain-prediction/.venv/lib/python3.11/site-packages/keras/src/layers/rnn/rnn.py:200: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
      "  super().__init__(**kwargs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m46/46\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 10ms/step - loss: 0.0526 - val_loss: 0.0077\n",
      "Epoch 2/30\n",
      "\u001b[1m46/46\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 0.0087 - val_loss: 0.0083\n",
      "Epoch 3/30\n",
      "\u001b[1m46/46\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 0.0075 - val_loss: 0.0069\n",
      "Epoch 4/30\n",
      "\u001b[1m46/46\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - loss: 0.0063 - val_loss: 0.0059\n",
      "Epoch 5/30\n",
      "\u001b[1m46/46\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 0.0055 - val_loss: 0.0038\n",
      "Epoch 6/30\n",
      "\u001b[1m46/46\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - loss: 0.0045 - val_loss: 0.0037\n",
      "Epoch 7/30\n",
      "\u001b[1m46/46\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 0.0047 - val_loss: 0.0037\n",
      "Epoch 8/30\n",
      "\u001b[1m46/46\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - loss: 0.0045 - val_loss: 0.0048\n",
      "Epoch 9/30\n",
      "\u001b[1m46/46\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - loss: 0.0041 - val_loss: 0.0032\n",
      "Epoch 10/30\n",
      "\u001b[1m46/46\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 13ms/step - loss: 0.0036 - val_loss: 0.0030\n",
      "Epoch 11/30\n",
      "\u001b[1m46/46\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - loss: 0.0038 - val_loss: 0.0036\n",
      "Epoch 12/30\n",
      "\u001b[1m46/46\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - loss: 0.0042 - val_loss: 0.0030\n",
      "Epoch 13/30\n",
      "\u001b[1m46/46\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 0.0029 - val_loss: 0.0026\n",
      "Epoch 14/30\n",
      "\u001b[1m46/46\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - loss: 0.0036 - val_loss: 0.0029\n",
      "Epoch 15/30\n",
      "\u001b[1m46/46\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - loss: 0.0032 - val_loss: 0.0028\n",
      "Epoch 16/30\n",
      "\u001b[1m46/46\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - loss: 0.0030 - val_loss: 0.0025\n",
      "Epoch 17/30\n",
      "\u001b[1m46/46\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 0.0040 - val_loss: 0.0025\n",
      "Epoch 18/30\n",
      "\u001b[1m46/46\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - loss: 0.0023 - val_loss: 0.0023\n",
      "Epoch 19/30\n",
      "\u001b[1m46/46\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - loss: 0.0036 - val_loss: 0.0029\n",
      "Epoch 20/30\n",
      "\u001b[1m46/46\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 14ms/step - loss: 0.0025 - val_loss: 0.0030\n",
      "Epoch 21/30\n",
      "\u001b[1m46/46\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 15ms/step - loss: 0.0028 - val_loss: 0.0021\n",
      "Epoch 22/30\n",
      "\u001b[1m46/46\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 24ms/step - loss: 0.0024 - val_loss: 0.0021\n",
      "Epoch 23/30\n",
      "\u001b[1m46/46\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 14ms/step - loss: 0.0024 - val_loss: 0.0019\n",
      "Epoch 24/30\n",
      "\u001b[1m46/46\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 13ms/step - loss: 0.0023 - val_loss: 0.0019\n",
      "Epoch 25/30\n",
      "\u001b[1m46/46\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 13ms/step - loss: 0.0022 - val_loss: 0.0019\n",
      "Epoch 26/30\n",
      "\u001b[1m46/46\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 11ms/step - loss: 0.0035 - val_loss: 0.0027\n",
      "Epoch 27/30\n",
      "\u001b[1m46/46\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 12ms/step - loss: 0.0032 - val_loss: 0.0019\n",
      "Epoch 28/30\n",
      "\u001b[1m46/46\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 17ms/step - loss: 0.0031 - val_loss: 0.0022\n",
      "Epoch 29/30\n",
      "\u001b[1m46/46\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 14ms/step - loss: 0.0030 - val_loss: 0.0027\n",
      "Epoch 30/30\n",
      "\u001b[1m46/46\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 14ms/step - loss: 0.0023 - val_loss: 0.0020\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:The `save_format` argument is deprecated in Keras 3. We recommend removing this argument as it can be inferred from the file path. Received: save_format=keras\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Finished: Bahamas | MAE: 0.06 | RMSE: 0.09 | R²: 0.94\n",
      "Epoch 1/30\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/dejauhnaebeadle/School/MachineLearning/machine-learning-project/code/rain-prediction/.venv/lib/python3.11/site-packages/keras/src/layers/rnn/rnn.py:200: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
      "  super().__init__(**kwargs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m46/46\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 18ms/step - loss: 0.1048 - val_loss: 0.0077\n",
      "Epoch 2/30\n",
      "\u001b[1m46/46\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - loss: 0.0148 - val_loss: 0.0095\n",
      "Epoch 3/30\n",
      "\u001b[1m46/46\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - loss: 0.0144 - val_loss: 0.0049\n",
      "Epoch 4/30\n",
      "\u001b[1m46/46\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - loss: 0.0108 - val_loss: 0.0047\n",
      "Epoch 5/30\n",
      "\u001b[1m46/46\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 0.0098 - val_loss: 0.0051\n",
      "Epoch 6/30\n",
      "\u001b[1m46/46\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 0.0084 - val_loss: 0.0071\n",
      "Epoch 7/30\n",
      "\u001b[1m46/46\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 0.0072 - val_loss: 0.0089\n",
      "Epoch 8/30\n",
      "\u001b[1m46/46\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 0.0080 - val_loss: 0.0027\n",
      "Epoch 9/30\n",
      "\u001b[1m46/46\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 0.0068 - val_loss: 0.0027\n",
      "Epoch 10/30\n",
      "\u001b[1m46/46\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 0.0070 - val_loss: 0.0026\n",
      "Epoch 11/30\n",
      "\u001b[1m46/46\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - loss: 0.0061 - val_loss: 0.0032\n",
      "Epoch 12/30\n",
      "\u001b[1m46/46\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 0.0056 - val_loss: 0.0029\n",
      "Epoch 13/30\n",
      "\u001b[1m46/46\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 0.0067 - val_loss: 0.0032\n",
      "Epoch 14/30\n",
      "\u001b[1m46/46\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - loss: 0.0051 - val_loss: 0.0048\n",
      "Epoch 15/30\n",
      "\u001b[1m46/46\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - loss: 0.0067 - val_loss: 0.0035\n",
      "Epoch 16/30\n",
      "\u001b[1m46/46\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 0.0059 - val_loss: 0.0024\n",
      "Epoch 17/30\n",
      "\u001b[1m46/46\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - loss: 0.0052 - val_loss: 0.0021\n",
      "Epoch 18/30\n",
      "\u001b[1m46/46\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - loss: 0.0062 - val_loss: 0.0022\n",
      "Epoch 19/30\n",
      "\u001b[1m46/46\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - loss: 0.0062 - val_loss: 0.0021\n",
      "Epoch 20/30\n",
      "\u001b[1m46/46\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - loss: 0.0063 - val_loss: 0.0019\n",
      "Epoch 21/30\n",
      "\u001b[1m46/46\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 0.0048 - val_loss: 0.0019\n",
      "Epoch 22/30\n",
      "\u001b[1m46/46\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 0.0057 - val_loss: 0.0018\n",
      "Epoch 23/30\n",
      "\u001b[1m46/46\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - loss: 0.0042 - val_loss: 0.0019\n",
      "Epoch 24/30\n",
      "\u001b[1m46/46\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 0.0051 - val_loss: 0.0023\n",
      "Epoch 25/30\n",
      "\u001b[1m46/46\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - loss: 0.0038 - val_loss: 0.0018\n",
      "Epoch 26/30\n",
      "\u001b[1m46/46\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - loss: 0.0047 - val_loss: 0.0019\n",
      "Epoch 27/30\n",
      "\u001b[1m46/46\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - loss: 0.0033 - val_loss: 0.0034\n",
      "Epoch 28/30\n",
      "\u001b[1m46/46\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - loss: 0.0038 - val_loss: 0.0017\n",
      "Epoch 29/30\n",
      "\u001b[1m46/46\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 0.0041 - val_loss: 0.0020\n",
      "Epoch 30/30\n",
      "\u001b[1m46/46\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 0.0052 - val_loss: 0.0017\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:The `save_format` argument is deprecated in Keras 3. We recommend removing this argument as it can be inferred from the file path. Received: save_format=keras\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Finished: Bahrain | MAE: 0.04 | RMSE: 0.13 | R²: 0.92\n",
      "Epoch 1/30\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/dejauhnaebeadle/School/MachineLearning/machine-learning-project/code/rain-prediction/.venv/lib/python3.11/site-packages/keras/src/layers/rnn/rnn.py:200: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
      "  super().__init__(**kwargs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m46/46\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 10ms/step - loss: 0.0816 - val_loss: 0.0053\n",
      "Epoch 2/30\n",
      "\u001b[1m46/46\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - loss: 0.0117 - val_loss: 0.0066\n",
      "Epoch 3/30\n",
      "\u001b[1m46/46\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 0.0105 - val_loss: 0.0065\n",
      "Epoch 4/30\n",
      "\u001b[1m46/46\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 0.0091 - val_loss: 0.0047\n",
      "Epoch 5/30\n",
      "\u001b[1m46/46\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - loss: 0.0084 - val_loss: 0.0056\n",
      "Epoch 6/30\n",
      "\u001b[1m46/46\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - loss: 0.0080 - val_loss: 0.0046\n",
      "Epoch 7/30\n",
      "\u001b[1m46/46\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 0.0058 - val_loss: 0.0064\n",
      "Epoch 8/30\n",
      "\u001b[1m46/46\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 0.0068 - val_loss: 0.0048\n",
      "Epoch 9/30\n",
      "\u001b[1m46/46\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 0.0073 - val_loss: 0.0045\n",
      "Epoch 10/30\n",
      "\u001b[1m46/46\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 0.0056 - val_loss: 0.0028\n",
      "Epoch 11/30\n",
      "\u001b[1m46/46\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - loss: 0.0050 - val_loss: 0.0027\n",
      "Epoch 12/30\n",
      "\u001b[1m46/46\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 12ms/step - loss: 0.0060 - val_loss: 0.0063\n",
      "Epoch 13/30\n",
      "\u001b[1m46/46\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 13ms/step - loss: 0.0056 - val_loss: 0.0024\n",
      "Epoch 14/30\n",
      "\u001b[1m46/46\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 20ms/step - loss: 0.0061 - val_loss: 0.0055\n",
      "Epoch 15/30\n",
      "\u001b[1m46/46\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 16ms/step - loss: 0.0059 - val_loss: 0.0026\n",
      "Epoch 16/30\n",
      "\u001b[1m46/46\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 13ms/step - loss: 0.0048 - val_loss: 0.0020\n",
      "Epoch 17/30\n",
      "\u001b[1m46/46\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 11ms/step - loss: 0.0068 - val_loss: 0.0051\n",
      "Epoch 18/30\n",
      "\u001b[1m46/46\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 12ms/step - loss: 0.0052 - val_loss: 0.0030\n",
      "Epoch 19/30\n",
      "\u001b[1m46/46\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 11ms/step - loss: 0.0050 - val_loss: 0.0022\n",
      "Epoch 20/30\n",
      "\u001b[1m46/46\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - loss: 0.0036 - val_loss: 0.0027\n",
      "Epoch 21/30\n",
      "\u001b[1m46/46\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 0.0054 - val_loss: 0.0047\n",
      "Epoch 22/30\n",
      "\u001b[1m46/46\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 0.0043 - val_loss: 0.0016\n",
      "Epoch 23/30\n",
      "\u001b[1m46/46\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 0.0050 - val_loss: 0.0020\n",
      "Epoch 24/30\n",
      "\u001b[1m46/46\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - loss: 0.0044 - val_loss: 0.0015\n",
      "Epoch 25/30\n",
      "\u001b[1m46/46\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 0.0043 - val_loss: 0.0017\n",
      "Epoch 26/30\n",
      "\u001b[1m46/46\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 0.0035 - val_loss: 0.0040\n",
      "Epoch 27/30\n",
      "\u001b[1m46/46\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 0.0050 - val_loss: 0.0017\n",
      "Epoch 28/30\n",
      "\u001b[1m46/46\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 0.0032 - val_loss: 0.0044\n",
      "Epoch 29/30\n",
      "\u001b[1m46/46\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 0.0056 - val_loss: 0.0022\n",
      "Epoch 30/30\n",
      "\u001b[1m46/46\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 0.0036 - val_loss: 0.0020\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:The `save_format` argument is deprecated in Keras 3. We recommend removing this argument as it can be inferred from the file path. Received: save_format=keras\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Finished: Bangladesh | MAE: 0.09 | RMSE: 0.12 | R²: 0.82\n",
      "Epoch 1/30\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/dejauhnaebeadle/School/MachineLearning/machine-learning-project/code/rain-prediction/.venv/lib/python3.11/site-packages/keras/src/layers/rnn/rnn.py:200: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
      "  super().__init__(**kwargs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m46/46\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 9ms/step - loss: 0.1363 - val_loss: 0.0106\n",
      "Epoch 2/30\n",
      "\u001b[1m46/46\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 0.0137 - val_loss: 0.0082\n",
      "Epoch 3/30\n",
      "\u001b[1m46/46\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 0.0120 - val_loss: 0.0048\n",
      "Epoch 4/30\n",
      "\u001b[1m46/46\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 0.0093 - val_loss: 0.0028\n",
      "Epoch 5/30\n",
      "\u001b[1m46/46\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 0.0091 - val_loss: 0.0041\n",
      "Epoch 6/30\n",
      "\u001b[1m46/46\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 0.0071 - val_loss: 0.0026\n",
      "Epoch 7/30\n",
      "\u001b[1m46/46\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 0.0069 - val_loss: 0.0095\n",
      "Epoch 8/30\n",
      "\u001b[1m46/46\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 0.0076 - val_loss: 0.0022\n",
      "Epoch 9/30\n",
      "\u001b[1m46/46\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 0.0057 - val_loss: 0.0052\n",
      "Epoch 10/30\n",
      "\u001b[1m46/46\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 0.0060 - val_loss: 0.0026\n",
      "Epoch 11/30\n",
      "\u001b[1m46/46\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 0.0054 - val_loss: 0.0045\n",
      "Epoch 12/30\n",
      "\u001b[1m46/46\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 0.0049 - val_loss: 0.0031\n",
      "Epoch 13/30\n",
      "\u001b[1m46/46\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 0.0050 - val_loss: 0.0027\n",
      "Epoch 14/30\n",
      "\u001b[1m46/46\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 0.0053 - val_loss: 0.0017\n",
      "Epoch 15/30\n",
      "\u001b[1m46/46\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 0.0048 - val_loss: 0.0027\n",
      "Epoch 16/30\n",
      "\u001b[1m46/46\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 0.0047 - val_loss: 0.0035\n",
      "Epoch 17/30\n",
      "\u001b[1m46/46\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 0.0037 - val_loss: 0.0014\n",
      "Epoch 18/30\n",
      "\u001b[1m46/46\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 0.0045 - val_loss: 0.0026\n",
      "Epoch 19/30\n",
      "\u001b[1m46/46\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 0.0051 - val_loss: 0.0012\n",
      "Epoch 20/30\n",
      "\u001b[1m46/46\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 0.0037 - val_loss: 0.0012\n",
      "Epoch 21/30\n",
      "\u001b[1m46/46\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 0.0045 - val_loss: 0.0019\n",
      "Epoch 22/30\n",
      "\u001b[1m46/46\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 0.0044 - val_loss: 0.0017\n",
      "Epoch 23/30\n",
      "\u001b[1m46/46\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 0.0035 - val_loss: 0.0041\n",
      "Epoch 24/30\n",
      "\u001b[1m46/46\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 0.0042 - val_loss: 0.0032\n",
      "Epoch 25/30\n",
      "\u001b[1m46/46\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 0.0034 - val_loss: 0.0017\n",
      "Epoch 26/30\n",
      "\u001b[1m46/46\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 0.0048 - val_loss: 0.0014\n",
      "Epoch 27/30\n",
      "\u001b[1m46/46\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 0.0044 - val_loss: 0.0011\n",
      "Epoch 28/30\n",
      "\u001b[1m46/46\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 0.0041 - val_loss: 0.0023\n",
      "Epoch 29/30\n",
      "\u001b[1m46/46\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 0.0031 - val_loss: 9.6232e-04\n",
      "Epoch 30/30\n",
      "\u001b[1m46/46\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 0.0023 - val_loss: 0.0011\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:The `save_format` argument is deprecated in Keras 3. We recommend removing this argument as it can be inferred from the file path. Received: save_format=keras\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Finished: Belarus | MAE: 0.14 | RMSE: 0.24 | R²: 0.89\n",
      "Epoch 1/30\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/dejauhnaebeadle/School/MachineLearning/machine-learning-project/code/rain-prediction/.venv/lib/python3.11/site-packages/keras/src/layers/rnn/rnn.py:200: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
      "  super().__init__(**kwargs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m46/46\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 15ms/step - loss: 0.0499 - val_loss: 0.0036\n",
      "Epoch 2/30\n",
      "\u001b[1m46/46\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 0.0126 - val_loss: 0.0078\n",
      "Epoch 3/30\n",
      "\u001b[1m46/46\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 0.0110 - val_loss: 0.0037\n",
      "Epoch 4/30\n",
      "\u001b[1m46/46\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 0.0082 - val_loss: 0.0056\n",
      "Epoch 5/30\n",
      "\u001b[1m46/46\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 0.0081 - val_loss: 0.0031\n",
      "Epoch 6/30\n",
      "\u001b[1m46/46\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 0.0070 - val_loss: 0.0032\n",
      "Epoch 7/30\n",
      "\u001b[1m46/46\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 0.0056 - val_loss: 0.0100\n",
      "Epoch 8/30\n",
      "\u001b[1m46/46\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 0.0061 - val_loss: 0.0021\n",
      "Epoch 9/30\n",
      "\u001b[1m46/46\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 0.0058 - val_loss: 0.0018\n",
      "Epoch 10/30\n",
      "\u001b[1m46/46\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 0.0065 - val_loss: 0.0017\n",
      "Epoch 11/30\n",
      "\u001b[1m46/46\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 0.0065 - val_loss: 0.0017\n",
      "Epoch 12/30\n",
      "\u001b[1m46/46\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 0.0047 - val_loss: 0.0025\n",
      "Epoch 13/30\n",
      "\u001b[1m46/46\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 0.0050 - val_loss: 0.0025\n",
      "Epoch 14/30\n",
      "\u001b[1m46/46\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 0.0051 - val_loss: 0.0034\n",
      "Epoch 15/30\n",
      "\u001b[1m46/46\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 0.0046 - val_loss: 0.0043\n",
      "Epoch 16/30\n",
      "\u001b[1m46/46\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 0.0042 - val_loss: 0.0014\n",
      "Epoch 17/30\n",
      "\u001b[1m46/46\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 0.0033 - val_loss: 0.0014\n",
      "Epoch 18/30\n",
      "\u001b[1m46/46\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 0.0035 - val_loss: 0.0017\n",
      "Epoch 19/30\n",
      "\u001b[1m46/46\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 0.0039 - val_loss: 0.0021\n",
      "Epoch 20/30\n",
      "\u001b[1m46/46\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 0.0040 - val_loss: 0.0036\n",
      "Epoch 21/30\n",
      "\u001b[1m46/46\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 0.0054 - val_loss: 0.0015\n",
      "Epoch 22/30\n",
      "\u001b[1m46/46\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 0.0035 - val_loss: 0.0014\n",
      "Epoch 23/30\n",
      "\u001b[1m46/46\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 0.0034 - val_loss: 0.0016\n",
      "Epoch 24/30\n",
      "\u001b[1m46/46\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 0.0037 - val_loss: 0.0023\n",
      "Epoch 25/30\n",
      "\u001b[1m46/46\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 0.0042 - val_loss: 0.0013\n",
      "Epoch 26/30\n",
      "\u001b[1m46/46\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 0.0037 - val_loss: 0.0022\n",
      "Epoch 27/30\n",
      "\u001b[1m46/46\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 0.0040 - val_loss: 0.0012\n",
      "Epoch 28/30\n",
      "\u001b[1m46/46\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 0.0041 - val_loss: 0.0012\n",
      "Epoch 29/30\n",
      "\u001b[1m46/46\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 0.0046 - val_loss: 0.0014\n",
      "Epoch 30/30\n",
      "\u001b[1m46/46\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 0.0040 - val_loss: 0.0012\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:The `save_format` argument is deprecated in Keras 3. We recommend removing this argument as it can be inferred from the file path. Received: save_format=keras\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Finished: Belgium | MAE: 0.08 | RMSE: 0.27 | R²: 0.86\n",
      "Epoch 1/30\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/dejauhnaebeadle/School/MachineLearning/machine-learning-project/code/rain-prediction/.venv/lib/python3.11/site-packages/keras/src/layers/rnn/rnn.py:200: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
      "  super().__init__(**kwargs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m46/46\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 10ms/step - loss: 0.0334 - val_loss: 0.0040\n",
      "Epoch 2/30\n",
      "\u001b[1m46/46\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 0.0054 - val_loss: 0.0042\n",
      "Epoch 3/30\n",
      "\u001b[1m46/46\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - loss: 0.0038 - val_loss: 0.0047\n",
      "Epoch 4/30\n",
      "\u001b[1m46/46\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 0.0036 - val_loss: 0.0024\n",
      "Epoch 5/30\n",
      "\u001b[1m46/46\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - loss: 0.0039 - val_loss: 0.0030\n",
      "Epoch 6/30\n",
      "\u001b[1m46/46\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - loss: 0.0040 - val_loss: 0.0018\n",
      "Epoch 7/30\n",
      "\u001b[1m46/46\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 0.0024 - val_loss: 0.0017\n",
      "Epoch 8/30\n",
      "\u001b[1m46/46\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 0.0026 - val_loss: 0.0021\n",
      "Epoch 9/30\n",
      "\u001b[1m46/46\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 0.0030 - val_loss: 0.0016\n",
      "Epoch 10/30\n",
      "\u001b[1m46/46\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - loss: 0.0026 - val_loss: 0.0017\n",
      "Epoch 11/30\n",
      "\u001b[1m46/46\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - loss: 0.0023 - val_loss: 0.0015\n",
      "Epoch 12/30\n",
      "\u001b[1m46/46\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 0.0020 - val_loss: 0.0016\n",
      "Epoch 13/30\n",
      "\u001b[1m46/46\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 0.0023 - val_loss: 0.0014\n",
      "Epoch 14/30\n",
      "\u001b[1m46/46\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - loss: 0.0023 - val_loss: 0.0013\n",
      "Epoch 15/30\n",
      "\u001b[1m46/46\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - loss: 0.0022 - val_loss: 0.0013\n",
      "Epoch 16/30\n",
      "\u001b[1m46/46\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - loss: 0.0018 - val_loss: 0.0016\n",
      "Epoch 17/30\n",
      "\u001b[1m46/46\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 0.0019 - val_loss: 0.0012\n",
      "Epoch 18/30\n",
      "\u001b[1m46/46\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 0.0024 - val_loss: 0.0013\n",
      "Epoch 19/30\n",
      "\u001b[1m46/46\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - loss: 0.0020 - val_loss: 0.0020\n",
      "Epoch 20/30\n",
      "\u001b[1m46/46\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - loss: 0.0016 - val_loss: 0.0012\n",
      "Epoch 21/30\n",
      "\u001b[1m46/46\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 0.0018 - val_loss: 0.0014\n",
      "Epoch 22/30\n",
      "\u001b[1m46/46\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 0.0019 - val_loss: 0.0012\n",
      "Epoch 23/30\n",
      "\u001b[1m46/46\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 0.0016 - val_loss: 0.0012\n",
      "Epoch 24/30\n",
      "\u001b[1m46/46\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - loss: 0.0018 - val_loss: 0.0011\n",
      "Epoch 25/30\n",
      "\u001b[1m46/46\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 0.0017 - val_loss: 0.0011\n",
      "Epoch 26/30\n",
      "\u001b[1m46/46\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 0.0019 - val_loss: 0.0011\n",
      "Epoch 27/30\n",
      "\u001b[1m46/46\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - loss: 0.0019 - val_loss: 0.0010\n",
      "Epoch 28/30\n",
      "\u001b[1m46/46\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - loss: 0.0020 - val_loss: 0.0010\n",
      "Epoch 29/30\n",
      "\u001b[1m46/46\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - loss: 0.0013 - val_loss: 0.0012\n",
      "Epoch 30/30\n",
      "\u001b[1m46/46\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - loss: 0.0019 - val_loss: 0.0011\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:The `save_format` argument is deprecated in Keras 3. We recommend removing this argument as it can be inferred from the file path. Received: save_format=keras\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Finished: Belize | MAE: 0.05 | RMSE: 0.10 | R²: 0.92\n",
      "Epoch 1/30\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/dejauhnaebeadle/School/MachineLearning/machine-learning-project/code/rain-prediction/.venv/lib/python3.11/site-packages/keras/src/layers/rnn/rnn.py:200: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
      "  super().__init__(**kwargs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m46/46\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 10ms/step - loss: 0.0957 - val_loss: 0.0048\n",
      "Epoch 2/30\n",
      "\u001b[1m46/46\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 0.0091 - val_loss: 0.0034\n",
      "Epoch 3/30\n",
      "\u001b[1m46/46\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 0.0067 - val_loss: 0.0017\n",
      "Epoch 4/30\n",
      "\u001b[1m46/46\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 0.0064 - val_loss: 0.0015\n",
      "Epoch 5/30\n",
      "\u001b[1m46/46\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 0.0058 - val_loss: 0.0013\n",
      "Epoch 6/30\n",
      "\u001b[1m46/46\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 0.0069 - val_loss: 9.6195e-04\n",
      "Epoch 7/30\n",
      "\u001b[1m46/46\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 0.0050 - val_loss: 0.0019\n",
      "Epoch 8/30\n",
      "\u001b[1m46/46\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 0.0045 - val_loss: 0.0046\n",
      "Epoch 9/30\n",
      "\u001b[1m46/46\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 0.0045 - val_loss: 7.8477e-04\n",
      "Epoch 10/30\n",
      "\u001b[1m46/46\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 0.0041 - val_loss: 0.0021\n",
      "Epoch 11/30\n",
      "\u001b[1m46/46\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - loss: 0.0048 - val_loss: 0.0013\n",
      "Epoch 12/30\n",
      "\u001b[1m46/46\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 0.0040 - val_loss: 8.4127e-04\n",
      "Epoch 13/30\n",
      "\u001b[1m46/46\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 0.0037 - val_loss: 8.0266e-04\n",
      "Epoch 14/30\n",
      "\u001b[1m46/46\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 0.0036 - val_loss: 7.3370e-04\n",
      "Epoch 15/30\n",
      "\u001b[1m46/46\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 0.0029 - val_loss: 7.7046e-04\n",
      "Epoch 16/30\n",
      "\u001b[1m46/46\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 0.0039 - val_loss: 6.1887e-04\n",
      "Epoch 17/30\n",
      "\u001b[1m46/46\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 0.0042 - val_loss: 0.0012\n",
      "Epoch 18/30\n",
      "\u001b[1m46/46\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 0.0028 - val_loss: 7.5041e-04\n",
      "Epoch 19/30\n",
      "\u001b[1m46/46\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 0.0030 - val_loss: 6.2984e-04\n",
      "Epoch 20/30\n",
      "\u001b[1m46/46\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 0.0026 - val_loss: 5.5061e-04\n",
      "Epoch 21/30\n",
      "\u001b[1m46/46\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 0.0024 - val_loss: 0.0014\n",
      "Epoch 22/30\n",
      "\u001b[1m46/46\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 0.0029 - val_loss: 0.0015\n",
      "Epoch 23/30\n",
      "\u001b[1m46/46\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 0.0027 - val_loss: 7.3439e-04\n",
      "Epoch 24/30\n",
      "\u001b[1m46/46\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - loss: 0.0028 - val_loss: 8.4323e-04\n",
      "Epoch 25/30\n",
      "\u001b[1m46/46\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 0.0027 - val_loss: 7.1941e-04\n",
      "Epoch 26/30\n",
      "\u001b[1m46/46\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 0.0027 - val_loss: 0.0013\n",
      "Epoch 27/30\n",
      "\u001b[1m46/46\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 0.0020 - val_loss: 5.1498e-04\n",
      "Epoch 28/30\n",
      "\u001b[1m46/46\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 0.0023 - val_loss: 4.8445e-04\n",
      "Epoch 29/30\n",
      "\u001b[1m46/46\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - loss: 0.0024 - val_loss: 0.0015\n",
      "Epoch 30/30\n",
      "\u001b[1m46/46\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - loss: 0.0021 - val_loss: 0.0014\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:The `save_format` argument is deprecated in Keras 3. We recommend removing this argument as it can be inferred from the file path. Received: save_format=keras\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Finished: Benin | MAE: 0.10 | RMSE: 0.13 | R²: 0.76\n",
      "Epoch 1/30\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/dejauhnaebeadle/School/MachineLearning/machine-learning-project/code/rain-prediction/.venv/lib/python3.11/site-packages/keras/src/layers/rnn/rnn.py:200: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
      "  super().__init__(**kwargs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m46/46\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 10ms/step - loss: 0.0522 - val_loss: 0.0022\n",
      "Epoch 2/30\n",
      "\u001b[1m46/46\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 0.0094 - val_loss: 0.0027\n",
      "Epoch 3/30\n",
      "\u001b[1m46/46\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 0.0078 - val_loss: 0.0022\n",
      "Epoch 4/30\n",
      "\u001b[1m46/46\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 0.0063 - val_loss: 0.0016\n",
      "Epoch 5/30\n",
      "\u001b[1m46/46\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 0.0069 - val_loss: 0.0020\n",
      "Epoch 6/30\n",
      "\u001b[1m46/46\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 0.0055 - val_loss: 0.0018\n",
      "Epoch 7/30\n",
      "\u001b[1m46/46\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 0.0048 - val_loss: 0.0017\n",
      "Epoch 8/30\n",
      "\u001b[1m46/46\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 0.0059 - val_loss: 0.0012\n",
      "Epoch 9/30\n",
      "\u001b[1m46/46\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - loss: 0.0047 - val_loss: 0.0013\n",
      "Epoch 10/30\n",
      "\u001b[1m46/46\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 0.0039 - val_loss: 9.3075e-04\n",
      "Epoch 11/30\n",
      "\u001b[1m46/46\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - loss: 0.0044 - val_loss: 0.0028\n",
      "Epoch 12/30\n",
      "\u001b[1m46/46\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 0.0040 - val_loss: 0.0010\n",
      "Epoch 13/30\n",
      "\u001b[1m46/46\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 0.0036 - val_loss: 7.5030e-04\n",
      "Epoch 14/30\n",
      "\u001b[1m46/46\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 0.0035 - val_loss: 0.0026\n",
      "Epoch 15/30\n",
      "\u001b[1m46/46\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 0.0040 - val_loss: 0.0013\n",
      "Epoch 16/30\n",
      "\u001b[1m46/46\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 0.0031 - val_loss: 7.4363e-04\n",
      "Epoch 17/30\n",
      "\u001b[1m46/46\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - loss: 0.0036 - val_loss: 0.0014\n",
      "Epoch 18/30\n",
      "\u001b[1m46/46\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 0.0032 - val_loss: 0.0022\n",
      "Epoch 19/30\n",
      "\u001b[1m46/46\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 0.0031 - val_loss: 7.9582e-04\n",
      "Epoch 20/30\n",
      "\u001b[1m46/46\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 0.0034 - val_loss: 9.6229e-04\n",
      "Epoch 21/30\n",
      "\u001b[1m46/46\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 0.0036 - val_loss: 0.0015\n",
      "Epoch 22/30\n",
      "\u001b[1m46/46\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 0.0036 - val_loss: 0.0016\n",
      "Epoch 23/30\n",
      "\u001b[1m46/46\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 0.0027 - val_loss: 0.0015\n",
      "Epoch 24/30\n",
      "\u001b[1m46/46\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 0.0036 - val_loss: 5.7640e-04\n",
      "Epoch 25/30\n",
      "\u001b[1m46/46\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 0.0028 - val_loss: 7.6700e-04\n",
      "Epoch 26/30\n",
      "\u001b[1m46/46\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - loss: 0.0025 - val_loss: 5.5027e-04\n",
      "Epoch 27/30\n",
      "\u001b[1m46/46\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 0.0030 - val_loss: 0.0021\n",
      "Epoch 28/30\n",
      "\u001b[1m46/46\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 0.0030 - val_loss: 6.3433e-04\n",
      "Epoch 29/30\n",
      "\u001b[1m46/46\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - loss: 0.0025 - val_loss: 8.7320e-04\n",
      "Epoch 30/30\n",
      "\u001b[1m46/46\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 0.0022 - val_loss: 9.1991e-04\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:The `save_format` argument is deprecated in Keras 3. We recommend removing this argument as it can be inferred from the file path. Received: save_format=keras\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Finished: Bhutan | MAE: 0.11 | RMSE: 0.14 | R²: 0.81\n",
      "Epoch 1/30\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/dejauhnaebeadle/School/MachineLearning/machine-learning-project/code/rain-prediction/.venv/lib/python3.11/site-packages/keras/src/layers/rnn/rnn.py:200: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
      "  super().__init__(**kwargs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m46/46\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 11ms/step - loss: 0.0460 - val_loss: 0.0031\n",
      "Epoch 2/30\n",
      "\u001b[1m46/46\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 0.0069 - val_loss: 0.0042\n",
      "Epoch 3/30\n",
      "\u001b[1m46/46\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - loss: 0.0064 - val_loss: 0.0024\n",
      "Epoch 4/30\n",
      "\u001b[1m46/46\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 0.0056 - val_loss: 0.0034\n",
      "Epoch 5/30\n",
      "\u001b[1m46/46\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 0.0044 - val_loss: 0.0051\n",
      "Epoch 6/30\n",
      "\u001b[1m46/46\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - loss: 0.0048 - val_loss: 0.0057\n",
      "Epoch 7/30\n",
      "\u001b[1m46/46\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 0.0040 - val_loss: 0.0011\n",
      "Epoch 8/30\n",
      "\u001b[1m46/46\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - loss: 0.0042 - val_loss: 0.0062\n",
      "Epoch 9/30\n",
      "\u001b[1m46/46\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - loss: 0.0044 - val_loss: 0.0023\n",
      "Epoch 10/30\n",
      "\u001b[1m46/46\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 0.0037 - val_loss: 0.0035\n",
      "Epoch 11/30\n",
      "\u001b[1m46/46\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - loss: 0.0046 - val_loss: 0.0027\n",
      "Epoch 12/30\n",
      "\u001b[1m46/46\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - loss: 0.0036 - val_loss: 0.0031\n",
      "Epoch 13/30\n",
      "\u001b[1m46/46\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - loss: 0.0033 - val_loss: 0.0036\n",
      "Epoch 14/30\n",
      "\u001b[1m46/46\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 0.0035 - val_loss: 0.0040\n",
      "Epoch 15/30\n",
      "\u001b[1m46/46\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 0.0032 - val_loss: 0.0020\n",
      "Epoch 16/30\n",
      "\u001b[1m46/46\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 0.0030 - val_loss: 0.0025\n",
      "Epoch 17/30\n",
      "\u001b[1m46/46\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 0.0025 - val_loss: 0.0026\n",
      "Epoch 18/30\n",
      "\u001b[1m46/46\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 0.0032 - val_loss: 0.0025\n",
      "Epoch 19/30\n",
      "\u001b[1m46/46\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 0.0025 - val_loss: 0.0018\n",
      "Epoch 20/30\n",
      "\u001b[1m46/46\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 0.0026 - val_loss: 0.0011\n",
      "Epoch 21/30\n",
      "\u001b[1m46/46\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 0.0029 - val_loss: 8.5824e-04\n",
      "Epoch 22/30\n",
      "\u001b[1m46/46\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 0.0032 - val_loss: 0.0020\n",
      "Epoch 23/30\n",
      "\u001b[1m46/46\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 0.0026 - val_loss: 0.0014\n",
      "Epoch 24/30\n",
      "\u001b[1m46/46\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 0.0020 - val_loss: 0.0050\n",
      "Epoch 25/30\n",
      "\u001b[1m46/46\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 0.0027 - val_loss: 0.0022\n",
      "Epoch 26/30\n",
      "\u001b[1m46/46\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 0.0023 - val_loss: 9.6032e-04\n",
      "Epoch 27/30\n",
      "\u001b[1m46/46\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - loss: 0.0022 - val_loss: 5.8938e-04\n",
      "Epoch 28/30\n",
      "\u001b[1m46/46\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 0.0030 - val_loss: 0.0021\n",
      "Epoch 29/30\n",
      "\u001b[1m46/46\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 0.0018 - val_loss: 8.1542e-04\n",
      "Epoch 30/30\n",
      "\u001b[1m46/46\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 0.0021 - val_loss: 0.0016\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:The `save_format` argument is deprecated in Keras 3. We recommend removing this argument as it can be inferred from the file path. Received: save_format=keras\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Finished: Bolivia | MAE: 0.18 | RMSE: 0.21 | R²: 0.72\n",
      "Epoch 1/30\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/dejauhnaebeadle/School/MachineLearning/machine-learning-project/code/rain-prediction/.venv/lib/python3.11/site-packages/keras/src/layers/rnn/rnn.py:200: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
      "  super().__init__(**kwargs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m46/46\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 10ms/step - loss: 0.0707 - val_loss: 0.0042\n",
      "Epoch 2/30\n",
      "\u001b[1m46/46\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 0.0041 - val_loss: 0.0055\n",
      "Epoch 3/30\n",
      "\u001b[1m46/46\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 0.0041 - val_loss: 0.0048\n",
      "Epoch 4/30\n",
      "\u001b[1m46/46\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 0.0038 - val_loss: 0.0045\n",
      "Epoch 5/30\n",
      "\u001b[1m46/46\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 0.0039 - val_loss: 0.0046\n",
      "Epoch 6/30\n",
      "\u001b[1m46/46\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - loss: 0.0035 - val_loss: 0.0037\n",
      "Epoch 7/30\n",
      "\u001b[1m46/46\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 0.0030 - val_loss: 0.0026\n",
      "Epoch 8/30\n",
      "\u001b[1m46/46\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 0.0031 - val_loss: 0.0037\n",
      "Epoch 9/30\n",
      "\u001b[1m46/46\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 0.0028 - val_loss: 0.0025\n",
      "Epoch 10/30\n",
      "\u001b[1m46/46\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 0.0024 - val_loss: 0.0022\n",
      "Epoch 11/30\n",
      "\u001b[1m46/46\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 0.0026 - val_loss: 0.0036\n",
      "Epoch 12/30\n",
      "\u001b[1m46/46\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 0.0023 - val_loss: 0.0018\n",
      "Epoch 13/30\n",
      "\u001b[1m46/46\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 0.0025 - val_loss: 0.0041\n",
      "Epoch 14/30\n",
      "\u001b[1m46/46\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 0.0024 - val_loss: 0.0023\n",
      "Epoch 15/30\n",
      "\u001b[1m46/46\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 0.0020 - val_loss: 0.0062\n",
      "Epoch 16/30\n",
      "\u001b[1m46/46\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 0.0023 - val_loss: 0.0030\n",
      "Epoch 17/30\n",
      "\u001b[1m46/46\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 0.0023 - val_loss: 0.0026\n",
      "Epoch 18/30\n",
      "\u001b[1m46/46\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 0.0019 - val_loss: 0.0036\n",
      "Epoch 19/30\n",
      "\u001b[1m46/46\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 0.0017 - val_loss: 0.0021\n",
      "Epoch 20/30\n",
      "\u001b[1m46/46\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 0.0021 - val_loss: 0.0028\n",
      "Epoch 21/30\n",
      "\u001b[1m46/46\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 0.0019 - val_loss: 0.0016\n",
      "Epoch 22/30\n",
      "\u001b[1m46/46\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 0.0019 - val_loss: 0.0020\n",
      "Epoch 23/30\n",
      "\u001b[1m46/46\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - loss: 0.0018 - val_loss: 0.0035\n",
      "Epoch 24/30\n",
      "\u001b[1m46/46\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 0.0014 - val_loss: 0.0017\n",
      "Epoch 25/30\n",
      "\u001b[1m46/46\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 0.0017 - val_loss: 0.0019\n",
      "Epoch 26/30\n",
      "\u001b[1m46/46\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - loss: 0.0014 - val_loss: 0.0024\n",
      "Epoch 27/30\n",
      "\u001b[1m46/46\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 0.0017 - val_loss: 0.0013\n",
      "Epoch 28/30\n",
      "\u001b[1m46/46\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 0.0015 - val_loss: 0.0018\n",
      "Epoch 29/30\n",
      "\u001b[1m46/46\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 0.0015 - val_loss: 0.0013\n",
      "Epoch 30/30\n",
      "\u001b[1m46/46\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 0.0016 - val_loss: 0.0015\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:The `save_format` argument is deprecated in Keras 3. We recommend removing this argument as it can be inferred from the file path. Received: save_format=keras\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Finished: Bosnia and Herzegovina | MAE: 0.16 | RMSE: 0.20 | R²: 0.88\n",
      "Epoch 1/30\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/dejauhnaebeadle/School/MachineLearning/machine-learning-project/code/rain-prediction/.venv/lib/python3.11/site-packages/keras/src/layers/rnn/rnn.py:200: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
      "  super().__init__(**kwargs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m46/46\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 10ms/step - loss: 0.0723 - val_loss: 0.0258\n",
      "Epoch 2/30\n",
      "\u001b[1m46/46\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 0.0136 - val_loss: 0.0242\n",
      "Epoch 3/30\n",
      "\u001b[1m46/46\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 0.0120 - val_loss: 0.0188\n",
      "Epoch 4/30\n",
      "\u001b[1m46/46\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 0.0096 - val_loss: 0.0237\n",
      "Epoch 5/30\n",
      "\u001b[1m46/46\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 0.0092 - val_loss: 0.0175\n",
      "Epoch 6/30\n",
      "\u001b[1m46/46\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 0.0075 - val_loss: 0.0135\n",
      "Epoch 7/30\n",
      "\u001b[1m46/46\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 0.0080 - val_loss: 0.0134\n",
      "Epoch 8/30\n",
      "\u001b[1m46/46\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 0.0069 - val_loss: 0.0128\n",
      "Epoch 9/30\n",
      "\u001b[1m46/46\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 0.0065 - val_loss: 0.0143\n",
      "Epoch 10/30\n",
      "\u001b[1m46/46\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 0.0075 - val_loss: 0.0121\n",
      "Epoch 11/30\n",
      "\u001b[1m46/46\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - loss: 0.0060 - val_loss: 0.0114\n",
      "Epoch 12/30\n",
      "\u001b[1m46/46\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - loss: 0.0067 - val_loss: 0.0118\n",
      "Epoch 13/30\n",
      "\u001b[1m46/46\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - loss: 0.0052 - val_loss: 0.0110\n",
      "Epoch 14/30\n",
      "\u001b[1m46/46\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 0.0054 - val_loss: 0.0120\n",
      "Epoch 15/30\n",
      "\u001b[1m46/46\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - loss: 0.0066 - val_loss: 0.0104\n",
      "Epoch 16/30\n",
      "\u001b[1m46/46\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - loss: 0.0050 - val_loss: 0.0110\n",
      "Epoch 17/30\n",
      "\u001b[1m46/46\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - loss: 0.0043 - val_loss: 0.0127\n",
      "Epoch 18/30\n",
      "\u001b[1m46/46\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - loss: 0.0052 - val_loss: 0.0099\n",
      "Epoch 19/30\n",
      "\u001b[1m46/46\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 9ms/step - loss: 0.0044 - val_loss: 0.0097\n",
      "Epoch 20/30\n",
      "\u001b[1m46/46\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - loss: 0.0054 - val_loss: 0.0102\n",
      "Epoch 21/30\n",
      "\u001b[1m46/46\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - loss: 0.0070 - val_loss: 0.0096\n",
      "Epoch 22/30\n",
      "\u001b[1m46/46\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - loss: 0.0049 - val_loss: 0.0103\n",
      "Epoch 23/30\n",
      "\u001b[1m46/46\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - loss: 0.0038 - val_loss: 0.0091\n",
      "Epoch 24/30\n",
      "\u001b[1m46/46\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - loss: 0.0045 - val_loss: 0.0095\n",
      "Epoch 25/30\n",
      "\u001b[1m46/46\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - loss: 0.0056 - val_loss: 0.0095\n",
      "Epoch 26/30\n",
      "\u001b[1m46/46\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 0.0053 - val_loss: 0.0089\n",
      "Epoch 27/30\n",
      "\u001b[1m46/46\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - loss: 0.0041 - val_loss: 0.0098\n",
      "Epoch 28/30\n",
      "\u001b[1m46/46\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - loss: 0.0046 - val_loss: 0.0088\n",
      "Epoch 29/30\n",
      "\u001b[1m46/46\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - loss: 0.0041 - val_loss: 0.0087\n",
      "Epoch 30/30\n",
      "\u001b[1m46/46\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 0.0040 - val_loss: 0.0109\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:The `save_format` argument is deprecated in Keras 3. We recommend removing this argument as it can be inferred from the file path. Received: save_format=keras\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Finished: Botswana | MAE: 0.24 | RMSE: 0.32 | R²: 0.79\n",
      "Epoch 1/30\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/dejauhnaebeadle/School/MachineLearning/machine-learning-project/code/rain-prediction/.venv/lib/python3.11/site-packages/keras/src/layers/rnn/rnn.py:200: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
      "  super().__init__(**kwargs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m46/46\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 11ms/step - loss: 0.0581 - val_loss: 0.0089\n",
      "Epoch 2/30\n",
      "\u001b[1m46/46\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 0.0089 - val_loss: 0.0098\n",
      "Epoch 3/30\n",
      "\u001b[1m46/46\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 0.0082 - val_loss: 0.0081\n",
      "Epoch 4/30\n",
      "\u001b[1m46/46\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 0.0067 - val_loss: 0.0032\n",
      "Epoch 5/30\n",
      "\u001b[1m46/46\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 0.0061 - val_loss: 0.0071\n",
      "Epoch 6/30\n",
      "\u001b[1m46/46\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 0.0057 - val_loss: 0.0047\n",
      "Epoch 7/30\n",
      "\u001b[1m46/46\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - loss: 0.0048 - val_loss: 0.0045\n",
      "Epoch 8/30\n",
      "\u001b[1m46/46\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - loss: 0.0044 - val_loss: 0.0090\n",
      "Epoch 9/30\n",
      "\u001b[1m46/46\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - loss: 0.0047 - val_loss: 0.0022\n",
      "Epoch 10/30\n",
      "\u001b[1m46/46\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - loss: 0.0047 - val_loss: 0.0022\n",
      "Epoch 11/30\n",
      "\u001b[1m46/46\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - loss: 0.0042 - val_loss: 0.0032\n",
      "Epoch 12/30\n",
      "\u001b[1m46/46\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - loss: 0.0037 - val_loss: 0.0041\n",
      "Epoch 13/30\n",
      "\u001b[1m46/46\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - loss: 0.0048 - val_loss: 0.0029\n",
      "Epoch 14/30\n",
      "\u001b[1m46/46\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - loss: 0.0036 - val_loss: 0.0042\n",
      "Epoch 15/30\n",
      "\u001b[1m46/46\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - loss: 0.0043 - val_loss: 0.0018\n",
      "Epoch 16/30\n",
      "\u001b[1m46/46\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - loss: 0.0049 - val_loss: 0.0027\n",
      "Epoch 17/30\n",
      "\u001b[1m46/46\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - loss: 0.0041 - val_loss: 0.0028\n",
      "Epoch 18/30\n",
      "\u001b[1m46/46\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 12ms/step - loss: 0.0050 - val_loss: 0.0029\n",
      "Epoch 19/30\n",
      "\u001b[1m46/46\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - loss: 0.0038 - val_loss: 0.0027\n",
      "Epoch 20/30\n",
      "\u001b[1m46/46\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - loss: 0.0038 - val_loss: 0.0020\n",
      "Epoch 21/30\n",
      "\u001b[1m46/46\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 10ms/step - loss: 0.0030 - val_loss: 0.0016\n",
      "Epoch 22/30\n",
      "\u001b[1m46/46\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 13ms/step - loss: 0.0033 - val_loss: 0.0018\n",
      "Epoch 23/30\n",
      "\u001b[1m46/46\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - loss: 0.0033 - val_loss: 0.0015\n",
      "Epoch 24/30\n",
      "\u001b[1m46/46\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - loss: 0.0027 - val_loss: 0.0070\n",
      "Epoch 25/30\n",
      "\u001b[1m46/46\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - loss: 0.0028 - val_loss: 0.0021\n",
      "Epoch 26/30\n",
      "\u001b[1m46/46\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - loss: 0.0027 - val_loss: 0.0020\n",
      "Epoch 27/30\n",
      "\u001b[1m46/46\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - loss: 0.0022 - val_loss: 0.0017\n",
      "Epoch 28/30\n",
      "\u001b[1m46/46\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - loss: 0.0030 - val_loss: 0.0028\n",
      "Epoch 29/30\n",
      "\u001b[1m46/46\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - loss: 0.0036 - val_loss: 0.0029\n",
      "Epoch 30/30\n",
      "\u001b[1m46/46\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - loss: 0.0032 - val_loss: 0.0024\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:The `save_format` argument is deprecated in Keras 3. We recommend removing this argument as it can be inferred from the file path. Received: save_format=keras\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Finished: Brazil | MAE: 0.11 | RMSE: 0.14 | R²: 0.78\n",
      "Epoch 1/30\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/dejauhnaebeadle/School/MachineLearning/machine-learning-project/code/rain-prediction/.venv/lib/python3.11/site-packages/keras/src/layers/rnn/rnn.py:200: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
      "  super().__init__(**kwargs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m46/46\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 12ms/step - loss: 0.0762 - val_loss: 0.0010\n",
      "Epoch 2/30\n",
      "\u001b[1m46/46\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - loss: 0.0045 - val_loss: 5.7266e-04\n",
      "Epoch 3/30\n",
      "\u001b[1m46/46\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - loss: 0.0032 - val_loss: 0.0026\n",
      "Epoch 4/30\n",
      "\u001b[1m46/46\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 0.0031 - val_loss: 0.0023\n",
      "Epoch 5/30\n",
      "\u001b[1m46/46\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 0.0027 - val_loss: 4.6790e-04\n",
      "Epoch 6/30\n",
      "\u001b[1m46/46\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - loss: 0.0029 - val_loss: 0.0010\n",
      "Epoch 7/30\n",
      "\u001b[1m46/46\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - loss: 0.0024 - val_loss: 4.1087e-04\n",
      "Epoch 8/30\n",
      "\u001b[1m46/46\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 0.0028 - val_loss: 4.8710e-04\n",
      "Epoch 9/30\n",
      "\u001b[1m46/46\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 0.0021 - val_loss: 3.9084e-04\n",
      "Epoch 10/30\n",
      "\u001b[1m46/46\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - loss: 0.0022 - val_loss: 3.4097e-04\n",
      "Epoch 11/30\n",
      "\u001b[1m46/46\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - loss: 0.0022 - val_loss: 7.1897e-04\n",
      "Epoch 12/30\n",
      "\u001b[1m46/46\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 0.0022 - val_loss: 6.3793e-04\n",
      "Epoch 13/30\n",
      "\u001b[1m46/46\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 0.0018 - val_loss: 5.1429e-04\n",
      "Epoch 14/30\n",
      "\u001b[1m46/46\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 0.0017 - val_loss: 2.9929e-04\n",
      "Epoch 15/30\n",
      "\u001b[1m46/46\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - loss: 0.0017 - val_loss: 4.4050e-04\n",
      "Epoch 16/30\n",
      "\u001b[1m46/46\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 0.0016 - val_loss: 4.7076e-04\n",
      "Epoch 17/30\n",
      "\u001b[1m46/46\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 0.0014 - val_loss: 0.0011\n",
      "Epoch 18/30\n",
      "\u001b[1m46/46\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - loss: 0.0015 - val_loss: 4.1067e-04\n",
      "Epoch 19/30\n",
      "\u001b[1m46/46\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - loss: 0.0016 - val_loss: 3.9658e-04\n",
      "Epoch 20/30\n",
      "\u001b[1m46/46\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - loss: 0.0017 - val_loss: 8.2200e-04\n",
      "Epoch 21/30\n",
      "\u001b[1m46/46\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - loss: 0.0015 - val_loss: 3.1280e-04\n",
      "Epoch 22/30\n",
      "\u001b[1m46/46\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - loss: 0.0016 - val_loss: 4.9169e-04\n",
      "Epoch 23/30\n",
      "\u001b[1m46/46\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - loss: 0.0013 - val_loss: 2.9203e-04\n",
      "Epoch 24/30\n",
      "\u001b[1m46/46\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - loss: 0.0011 - val_loss: 4.8257e-04\n",
      "Epoch 25/30\n",
      "\u001b[1m46/46\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - loss: 0.0016 - val_loss: 2.8415e-04\n",
      "Epoch 26/30\n",
      "\u001b[1m46/46\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - loss: 0.0012 - val_loss: 2.7998e-04\n",
      "Epoch 27/30\n",
      "\u001b[1m46/46\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - loss: 0.0015 - val_loss: 2.5803e-04\n",
      "Epoch 28/30\n",
      "\u001b[1m46/46\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - loss: 0.0010 - val_loss: 6.5831e-04\n",
      "Epoch 29/30\n",
      "\u001b[1m46/46\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 0.0010 - val_loss: 3.7789e-04\n",
      "Epoch 30/30\n",
      "\u001b[1m46/46\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 0.0012 - val_loss: 3.9200e-04\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:The `save_format` argument is deprecated in Keras 3. We recommend removing this argument as it can be inferred from the file path. Received: save_format=keras\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Finished: Brunei | MAE: 0.08 | RMSE: 0.11 | R²: 0.86\n",
      "Epoch 1/30\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/dejauhnaebeadle/School/MachineLearning/machine-learning-project/code/rain-prediction/.venv/lib/python3.11/site-packages/keras/src/layers/rnn/rnn.py:200: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
      "  super().__init__(**kwargs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m46/46\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 10ms/step - loss: 0.0730 - val_loss: 0.0075\n",
      "Epoch 2/30\n",
      "\u001b[1m46/46\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - loss: 0.0076 - val_loss: 0.0097\n",
      "Epoch 3/30\n",
      "\u001b[1m46/46\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 0.0073 - val_loss: 0.0070\n",
      "Epoch 4/30\n",
      "\u001b[1m46/46\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - loss: 0.0064 - val_loss: 0.0069\n",
      "Epoch 5/30\n",
      "\u001b[1m46/46\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - loss: 0.0052 - val_loss: 0.0055\n",
      "Epoch 6/30\n",
      "\u001b[1m46/46\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 0.0044 - val_loss: 0.0044\n",
      "Epoch 7/30\n",
      "\u001b[1m46/46\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - loss: 0.0040 - val_loss: 0.0066\n",
      "Epoch 8/30\n",
      "\u001b[1m46/46\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - loss: 0.0043 - val_loss: 0.0041\n",
      "Epoch 9/30\n",
      "\u001b[1m46/46\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - loss: 0.0040 - val_loss: 0.0032\n",
      "Epoch 10/30\n",
      "\u001b[1m46/46\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - loss: 0.0036 - val_loss: 0.0035\n",
      "Epoch 11/30\n",
      "\u001b[1m46/46\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - loss: 0.0040 - val_loss: 0.0034\n",
      "Epoch 12/30\n",
      "\u001b[1m46/46\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 0.0040 - val_loss: 0.0044\n",
      "Epoch 13/30\n",
      "\u001b[1m46/46\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 0.0039 - val_loss: 0.0029\n",
      "Epoch 14/30\n",
      "\u001b[1m46/46\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - loss: 0.0032 - val_loss: 0.0049\n",
      "Epoch 15/30\n",
      "\u001b[1m46/46\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 0.0029 - val_loss: 0.0038\n",
      "Epoch 16/30\n",
      "\u001b[1m46/46\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 0.0027 - val_loss: 0.0024\n",
      "Epoch 17/30\n",
      "\u001b[1m46/46\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 0.0034 - val_loss: 0.0030\n",
      "Epoch 18/30\n",
      "\u001b[1m46/46\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 0.0031 - val_loss: 0.0026\n",
      "Epoch 19/30\n",
      "\u001b[1m46/46\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 0.0031 - val_loss: 0.0023\n",
      "Epoch 20/30\n",
      "\u001b[1m46/46\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - loss: 0.0026 - val_loss: 0.0033\n",
      "Epoch 21/30\n",
      "\u001b[1m46/46\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 0.0026 - val_loss: 0.0026\n",
      "Epoch 22/30\n",
      "\u001b[1m46/46\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 0.0035 - val_loss: 0.0030\n",
      "Epoch 23/30\n",
      "\u001b[1m46/46\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 0.0020 - val_loss: 0.0030\n",
      "Epoch 24/30\n",
      "\u001b[1m46/46\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - loss: 0.0023 - val_loss: 0.0019\n",
      "Epoch 25/30\n",
      "\u001b[1m46/46\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 0.0029 - val_loss: 0.0042\n",
      "Epoch 26/30\n",
      "\u001b[1m46/46\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - loss: 0.0023 - val_loss: 0.0031\n",
      "Epoch 27/30\n",
      "\u001b[1m46/46\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - loss: 0.0023 - val_loss: 0.0024\n",
      "Epoch 28/30\n",
      "\u001b[1m46/46\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 0.0031 - val_loss: 0.0021\n",
      "Epoch 29/30\n",
      "\u001b[1m46/46\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 0.0023 - val_loss: 0.0041\n",
      "Epoch 30/30\n",
      "\u001b[1m46/46\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 0.0027 - val_loss: 0.0024\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:The `save_format` argument is deprecated in Keras 3. We recommend removing this argument as it can be inferred from the file path. Received: save_format=keras\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Finished: Bulgaria | MAE: 0.23 | RMSE: 0.26 | R²: 0.76\n",
      "Epoch 1/30\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/dejauhnaebeadle/School/MachineLearning/machine-learning-project/code/rain-prediction/.venv/lib/python3.11/site-packages/keras/src/layers/rnn/rnn.py:200: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
      "  super().__init__(**kwargs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m46/46\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 11ms/step - loss: 0.0759 - val_loss: 0.0037\n",
      "Epoch 2/30\n",
      "\u001b[1m46/46\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 0.0097 - val_loss: 0.0013\n",
      "Epoch 3/30\n",
      "\u001b[1m46/46\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 0.0102 - val_loss: 0.0015\n",
      "Epoch 4/30\n",
      "\u001b[1m46/46\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - loss: 0.0100 - val_loss: 0.0011\n",
      "Epoch 5/30\n",
      "\u001b[1m46/46\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 0.0066 - val_loss: 0.0015\n",
      "Epoch 6/30\n",
      "\u001b[1m46/46\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 0.0077 - val_loss: 0.0051\n",
      "Epoch 7/30\n",
      "\u001b[1m46/46\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - loss: 0.0062 - val_loss: 0.0017\n",
      "Epoch 8/30\n",
      "\u001b[1m46/46\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - loss: 0.0059 - val_loss: 0.0034\n",
      "Epoch 9/30\n",
      "\u001b[1m46/46\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - loss: 0.0052 - val_loss: 0.0016\n",
      "Epoch 10/30\n",
      "\u001b[1m46/46\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - loss: 0.0052 - val_loss: 0.0012\n",
      "Epoch 11/30\n",
      "\u001b[1m46/46\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 0.0046 - val_loss: 0.0020\n",
      "Epoch 12/30\n",
      "\u001b[1m46/46\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 0.0054 - val_loss: 0.0010\n",
      "Epoch 13/30\n",
      "\u001b[1m46/46\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - loss: 0.0056 - val_loss: 0.0016\n",
      "Epoch 14/30\n",
      "\u001b[1m46/46\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - loss: 0.0052 - val_loss: 6.8250e-04\n",
      "Epoch 15/30\n",
      "\u001b[1m46/46\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - loss: 0.0043 - val_loss: 0.0021\n",
      "Epoch 16/30\n",
      "\u001b[1m46/46\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - loss: 0.0045 - val_loss: 0.0011\n",
      "Epoch 17/30\n",
      "\u001b[1m46/46\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - loss: 0.0040 - val_loss: 0.0016\n",
      "Epoch 18/30\n",
      "\u001b[1m46/46\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - loss: 0.0042 - val_loss: 0.0020\n",
      "Epoch 19/30\n",
      "\u001b[1m46/46\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - loss: 0.0050 - val_loss: 8.0962e-04\n",
      "Epoch 20/30\n",
      "\u001b[1m46/46\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - loss: 0.0051 - val_loss: 8.9511e-04\n",
      "Epoch 21/30\n",
      "\u001b[1m46/46\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 0.0029 - val_loss: 0.0010\n",
      "Epoch 22/30\n",
      "\u001b[1m46/46\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 0.0032 - val_loss: 5.7116e-04\n",
      "Epoch 23/30\n",
      "\u001b[1m46/46\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - loss: 0.0032 - val_loss: 8.5490e-04\n",
      "Epoch 24/30\n",
      "\u001b[1m46/46\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - loss: 0.0041 - val_loss: 5.5182e-04\n",
      "Epoch 25/30\n",
      "\u001b[1m46/46\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 0.0036 - val_loss: 0.0014\n",
      "Epoch 26/30\n",
      "\u001b[1m46/46\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 0.0034 - val_loss: 6.3643e-04\n",
      "Epoch 27/30\n",
      "\u001b[1m46/46\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 0.0035 - val_loss: 7.1033e-04\n",
      "Epoch 28/30\n",
      "\u001b[1m46/46\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 0.0035 - val_loss: 5.1604e-04\n",
      "Epoch 29/30\n",
      "\u001b[1m46/46\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 0.0030 - val_loss: 5.6310e-04\n",
      "Epoch 30/30\n",
      "\u001b[1m46/46\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - loss: 0.0030 - val_loss: 0.0033\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:The `save_format` argument is deprecated in Keras 3. We recommend removing this argument as it can be inferred from the file path. Received: save_format=keras\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Finished: Burkina Faso | MAE: 0.19 | RMSE: 0.21 | R²: 0.35\n",
      "Epoch 1/30\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/dejauhnaebeadle/School/MachineLearning/machine-learning-project/code/rain-prediction/.venv/lib/python3.11/site-packages/keras/src/layers/rnn/rnn.py:200: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
      "  super().__init__(**kwargs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m46/46\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 11ms/step - loss: 0.0295 - val_loss: 0.0051\n",
      "Epoch 2/30\n",
      "\u001b[1m46/46\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - loss: 0.0057 - val_loss: 0.0045\n",
      "Epoch 3/30\n",
      "\u001b[1m46/46\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 0.0053 - val_loss: 0.0043\n",
      "Epoch 4/30\n",
      "\u001b[1m46/46\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 0.0043 - val_loss: 0.0030\n",
      "Epoch 5/30\n",
      "\u001b[1m46/46\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - loss: 0.0045 - val_loss: 0.0030\n",
      "Epoch 6/30\n",
      "\u001b[1m46/46\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 0.0030 - val_loss: 0.0037\n",
      "Epoch 7/30\n",
      "\u001b[1m46/46\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - loss: 0.0030 - val_loss: 0.0045\n",
      "Epoch 8/30\n",
      "\u001b[1m46/46\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 0.0034 - val_loss: 0.0030\n",
      "Epoch 9/30\n",
      "\u001b[1m46/46\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 0.0028 - val_loss: 0.0022\n",
      "Epoch 10/30\n",
      "\u001b[1m46/46\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 0.0029 - val_loss: 0.0020\n",
      "Epoch 11/30\n",
      "\u001b[1m46/46\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - loss: 0.0029 - val_loss: 0.0029\n",
      "Epoch 12/30\n",
      "\u001b[1m46/46\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 0.0030 - val_loss: 0.0023\n",
      "Epoch 13/30\n",
      "\u001b[1m46/46\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 0.0023 - val_loss: 0.0036\n",
      "Epoch 14/30\n",
      "\u001b[1m46/46\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - loss: 0.0024 - val_loss: 0.0018\n",
      "Epoch 15/30\n",
      "\u001b[1m46/46\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 0.0024 - val_loss: 0.0018\n",
      "Epoch 16/30\n",
      "\u001b[1m46/46\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 0.0027 - val_loss: 0.0031\n",
      "Epoch 17/30\n",
      "\u001b[1m46/46\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 0.0021 - val_loss: 0.0028\n",
      "Epoch 18/30\n",
      "\u001b[1m46/46\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 0.0019 - val_loss: 0.0016\n",
      "Epoch 19/30\n",
      "\u001b[1m46/46\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 0.0021 - val_loss: 0.0016\n",
      "Epoch 20/30\n",
      "\u001b[1m46/46\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 0.0024 - val_loss: 0.0021\n",
      "Epoch 21/30\n",
      "\u001b[1m46/46\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 0.0019 - val_loss: 0.0016\n",
      "Epoch 22/30\n",
      "\u001b[1m46/46\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - loss: 0.0024 - val_loss: 0.0022\n",
      "Epoch 23/30\n",
      "\u001b[1m46/46\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - loss: 0.0018 - val_loss: 0.0014\n",
      "Epoch 24/30\n",
      "\u001b[1m46/46\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 0.0019 - val_loss: 0.0018\n",
      "Epoch 25/30\n",
      "\u001b[1m46/46\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 0.0023 - val_loss: 0.0017\n",
      "Epoch 26/30\n",
      "\u001b[1m46/46\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 0.0016 - val_loss: 0.0025\n",
      "Epoch 27/30\n",
      "\u001b[1m46/46\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - loss: 0.0017 - val_loss: 0.0014\n",
      "Epoch 28/30\n",
      "\u001b[1m46/46\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - loss: 0.0021 - val_loss: 0.0018\n",
      "Epoch 29/30\n",
      "\u001b[1m46/46\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 0.0018 - val_loss: 0.0016\n",
      "Epoch 30/30\n",
      "\u001b[1m46/46\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 0.0024 - val_loss: 0.0019\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:The `save_format` argument is deprecated in Keras 3. We recommend removing this argument as it can be inferred from the file path. Received: save_format=keras\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Finished: Burundi | MAE: 0.10 | RMSE: 0.13 | R²: 0.88\n",
      "Epoch 1/30\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/dejauhnaebeadle/School/MachineLearning/machine-learning-project/code/rain-prediction/.venv/lib/python3.11/site-packages/keras/src/layers/rnn/rnn.py:200: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
      "  super().__init__(**kwargs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m46/46\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 10ms/step - loss: 0.0478 - val_loss: 0.0024\n",
      "Epoch 2/30\n",
      "\u001b[1m46/46\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 0.0048 - val_loss: 0.0024\n",
      "Epoch 3/30\n",
      "\u001b[1m46/46\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - loss: 0.0051 - val_loss: 0.0014\n",
      "Epoch 4/30\n",
      "\u001b[1m46/46\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 0.0046 - val_loss: 0.0012\n",
      "Epoch 5/30\n",
      "\u001b[1m46/46\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 0.0039 - val_loss: 0.0012\n",
      "Epoch 6/30\n",
      "\u001b[1m46/46\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 0.0032 - val_loss: 0.0010\n",
      "Epoch 7/30\n",
      "\u001b[1m46/46\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - loss: 0.0036 - val_loss: 9.0110e-04\n",
      "Epoch 8/30\n",
      "\u001b[1m46/46\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 0.0027 - val_loss: 0.0011\n",
      "Epoch 9/30\n",
      "\u001b[1m46/46\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 0.0024 - val_loss: 0.0012\n",
      "Epoch 10/30\n",
      "\u001b[1m46/46\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 0.0025 - val_loss: 0.0018\n",
      "Epoch 11/30\n",
      "\u001b[1m46/46\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 0.0027 - val_loss: 0.0023\n",
      "Epoch 12/30\n",
      "\u001b[1m46/46\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 0.0031 - val_loss: 9.7218e-04\n",
      "Epoch 13/30\n",
      "\u001b[1m46/46\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 0.0023 - val_loss: 0.0031\n",
      "Epoch 14/30\n",
      "\u001b[1m46/46\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 0.0031 - val_loss: 6.8730e-04\n",
      "Epoch 15/30\n",
      "\u001b[1m46/46\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 0.0022 - val_loss: 6.7986e-04\n",
      "Epoch 16/30\n",
      "\u001b[1m46/46\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 0.0026 - val_loss: 6.6114e-04\n",
      "Epoch 17/30\n",
      "\u001b[1m46/46\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 0.0022 - val_loss: 9.4505e-04\n",
      "Epoch 18/30\n",
      "\u001b[1m46/46\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 0.0023 - val_loss: 6.3467e-04\n",
      "Epoch 19/30\n",
      "\u001b[1m46/46\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 0.0025 - val_loss: 0.0012\n",
      "Epoch 20/30\n",
      "\u001b[1m46/46\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 0.0021 - val_loss: 0.0022\n",
      "Epoch 21/30\n",
      "\u001b[1m46/46\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 0.0024 - val_loss: 6.0793e-04\n",
      "Epoch 22/30\n",
      "\u001b[1m46/46\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 0.0018 - val_loss: 0.0017\n",
      "Epoch 23/30\n",
      "\u001b[1m46/46\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 0.0021 - val_loss: 7.4206e-04\n",
      "Epoch 24/30\n",
      "\u001b[1m46/46\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 0.0030 - val_loss: 6.6701e-04\n",
      "Epoch 25/30\n",
      "\u001b[1m46/46\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 0.0023 - val_loss: 7.4667e-04\n",
      "Epoch 26/30\n",
      "\u001b[1m46/46\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 0.0018 - val_loss: 5.7472e-04\n",
      "Epoch 27/30\n",
      "\u001b[1m46/46\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 0.0018 - val_loss: 6.2562e-04\n",
      "Epoch 28/30\n",
      "\u001b[1m46/46\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 0.0018 - val_loss: 5.7652e-04\n",
      "Epoch 29/30\n",
      "\u001b[1m46/46\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 0.0018 - val_loss: 5.7735e-04\n",
      "Epoch 30/30\n",
      "\u001b[1m46/46\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 0.0019 - val_loss: 5.4002e-04\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:The `save_format` argument is deprecated in Keras 3. We recommend removing this argument as it can be inferred from the file path. Received: save_format=keras\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Finished: Cambodia | MAE: 0.07 | RMSE: 0.15 | R²: 0.85\n",
      "Epoch 1/30\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/dejauhnaebeadle/School/MachineLearning/machine-learning-project/code/rain-prediction/.venv/lib/python3.11/site-packages/keras/src/layers/rnn/rnn.py:200: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
      "  super().__init__(**kwargs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m46/46\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 12ms/step - loss: 0.0332 - val_loss: 0.0067\n",
      "Epoch 2/30\n",
      "\u001b[1m46/46\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 0.0066 - val_loss: 0.0065\n",
      "Epoch 3/30\n",
      "\u001b[1m46/46\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 0.0059 - val_loss: 0.0086\n",
      "Epoch 4/30\n",
      "\u001b[1m46/46\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 0.0049 - val_loss: 0.0034\n",
      "Epoch 5/30\n",
      "\u001b[1m46/46\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 0.0041 - val_loss: 0.0025\n",
      "Epoch 6/30\n",
      "\u001b[1m46/46\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 0.0049 - val_loss: 0.0045\n",
      "Epoch 7/30\n",
      "\u001b[1m46/46\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 0.0041 - val_loss: 9.7164e-04\n",
      "Epoch 8/30\n",
      "\u001b[1m46/46\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 0.0036 - val_loss: 0.0040\n",
      "Epoch 9/30\n",
      "\u001b[1m46/46\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 0.0031 - val_loss: 0.0012\n",
      "Epoch 10/30\n",
      "\u001b[1m46/46\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 0.0047 - val_loss: 8.3695e-04\n",
      "Epoch 11/30\n",
      "\u001b[1m46/46\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 0.0025 - val_loss: 0.0017\n",
      "Epoch 12/30\n",
      "\u001b[1m46/46\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 0.0035 - val_loss: 0.0021\n",
      "Epoch 13/30\n",
      "\u001b[1m46/46\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 0.0024 - val_loss: 0.0062\n",
      "Epoch 14/30\n",
      "\u001b[1m46/46\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 0.0029 - val_loss: 0.0010\n",
      "Epoch 15/30\n",
      "\u001b[1m46/46\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 0.0032 - val_loss: 0.0011\n",
      "Epoch 16/30\n",
      "\u001b[1m46/46\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 0.0026 - val_loss: 0.0027\n",
      "Epoch 17/30\n",
      "\u001b[1m46/46\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 0.0028 - val_loss: 9.3384e-04\n",
      "Epoch 18/30\n",
      "\u001b[1m46/46\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - loss: 0.0018 - val_loss: 0.0024\n",
      "Epoch 19/30\n",
      "\u001b[1m46/46\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 0.0023 - val_loss: 7.3501e-04\n",
      "Epoch 20/30\n",
      "\u001b[1m46/46\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 0.0027 - val_loss: 0.0012\n",
      "Epoch 21/30\n",
      "\u001b[1m46/46\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 0.0026 - val_loss: 7.6846e-04\n",
      "Epoch 22/30\n",
      "\u001b[1m46/46\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 0.0017 - val_loss: 8.4113e-04\n",
      "Epoch 23/30\n",
      "\u001b[1m46/46\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 0.0028 - val_loss: 0.0020\n",
      "Epoch 24/30\n",
      "\u001b[1m46/46\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - loss: 0.0020 - val_loss: 0.0015\n",
      "Epoch 25/30\n",
      "\u001b[1m46/46\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 0.0021 - val_loss: 0.0032\n",
      "Epoch 26/30\n",
      "\u001b[1m46/46\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 0.0020 - val_loss: 0.0014\n",
      "Epoch 27/30\n",
      "\u001b[1m46/46\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 0.0036 - val_loss: 5.7807e-04\n",
      "Epoch 28/30\n",
      "\u001b[1m46/46\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 0.0020 - val_loss: 0.0020\n",
      "Epoch 29/30\n",
      "\u001b[1m46/46\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 0.0024 - val_loss: 0.0010\n",
      "Epoch 30/30\n",
      "\u001b[1m46/46\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 0.0023 - val_loss: 0.0012\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:The `save_format` argument is deprecated in Keras 3. We recommend removing this argument as it can be inferred from the file path. Received: save_format=keras\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Finished: Cameroon | MAE: 0.11 | RMSE: 0.13 | R²: 0.78\n",
      "Epoch 1/30\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/dejauhnaebeadle/School/MachineLearning/machine-learning-project/code/rain-prediction/.venv/lib/python3.11/site-packages/keras/src/layers/rnn/rnn.py:200: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
      "  super().__init__(**kwargs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m46/46\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 10ms/step - loss: 0.0365 - val_loss: 0.0140\n",
      "Epoch 2/30\n",
      "\u001b[1m46/46\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 0.0091 - val_loss: 0.0127\n",
      "Epoch 3/30\n",
      "\u001b[1m46/46\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 0.0083 - val_loss: 0.0129\n",
      "Epoch 4/30\n",
      "\u001b[1m46/46\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 0.0085 - val_loss: 0.0090\n",
      "Epoch 5/30\n",
      "\u001b[1m46/46\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 0.0059 - val_loss: 0.0099\n",
      "Epoch 6/30\n",
      "\u001b[1m46/46\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 0.0049 - val_loss: 0.0079\n",
      "Epoch 7/30\n",
      "\u001b[1m46/46\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 0.0051 - val_loss: 0.0087\n",
      "Epoch 8/30\n",
      "\u001b[1m46/46\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 0.0066 - val_loss: 0.0077\n",
      "Epoch 9/30\n",
      "\u001b[1m46/46\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 0.0058 - val_loss: 0.0062\n",
      "Epoch 10/30\n",
      "\u001b[1m46/46\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 0.0055 - val_loss: 0.0061\n",
      "Epoch 11/30\n",
      "\u001b[1m46/46\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 0.0044 - val_loss: 0.0077\n",
      "Epoch 12/30\n",
      "\u001b[1m46/46\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - loss: 0.0042 - val_loss: 0.0060\n",
      "Epoch 13/30\n",
      "\u001b[1m46/46\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 0.0049 - val_loss: 0.0082\n",
      "Epoch 14/30\n",
      "\u001b[1m46/46\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 0.0046 - val_loss: 0.0054\n",
      "Epoch 15/30\n",
      "\u001b[1m46/46\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 0.0031 - val_loss: 0.0055\n",
      "Epoch 16/30\n",
      "\u001b[1m46/46\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 0.0033 - val_loss: 0.0060\n",
      "Epoch 17/30\n",
      "\u001b[1m46/46\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 0.0039 - val_loss: 0.0058\n",
      "Epoch 18/30\n",
      "\u001b[1m46/46\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 0.0028 - val_loss: 0.0051\n",
      "Epoch 19/30\n",
      "\u001b[1m46/46\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - loss: 0.0034 - val_loss: 0.0093\n",
      "Epoch 20/30\n",
      "\u001b[1m46/46\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 0.0042 - val_loss: 0.0066\n",
      "Epoch 21/30\n",
      "\u001b[1m46/46\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 0.0034 - val_loss: 0.0060\n",
      "Epoch 22/30\n",
      "\u001b[1m46/46\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 0.0034 - val_loss: 0.0047\n",
      "Epoch 23/30\n",
      "\u001b[1m46/46\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 0.0041 - val_loss: 0.0047\n",
      "Epoch 24/30\n",
      "\u001b[1m46/46\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 0.0047 - val_loss: 0.0048\n",
      "Epoch 25/30\n",
      "\u001b[1m46/46\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - loss: 0.0037 - val_loss: 0.0049\n",
      "Epoch 26/30\n",
      "\u001b[1m46/46\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - loss: 0.0028 - val_loss: 0.0065\n",
      "Epoch 27/30\n",
      "\u001b[1m46/46\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 0.0029 - val_loss: 0.0049\n",
      "Epoch 28/30\n",
      "\u001b[1m46/46\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 0.0034 - val_loss: 0.0044\n",
      "Epoch 29/30\n",
      "\u001b[1m46/46\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 0.0027 - val_loss: 0.0049\n",
      "Epoch 30/30\n",
      "\u001b[1m46/46\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 0.0028 - val_loss: 0.0047\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:The `save_format` argument is deprecated in Keras 3. We recommend removing this argument as it can be inferred from the file path. Received: save_format=keras\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Finished: Canada | MAE: 0.22 | RMSE: 0.34 | R²: 0.83\n",
      "Epoch 1/30\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/dejauhnaebeadle/School/MachineLearning/machine-learning-project/code/rain-prediction/.venv/lib/python3.11/site-packages/keras/src/layers/rnn/rnn.py:200: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
      "  super().__init__(**kwargs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m46/46\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 12ms/step - loss: 0.0455 - val_loss: 0.0076\n",
      "Epoch 2/30\n",
      "\u001b[1m46/46\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 0.0126 - val_loss: 0.0073\n",
      "Epoch 3/30\n",
      "\u001b[1m46/46\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 0.0122 - val_loss: 0.0035\n",
      "Epoch 4/30\n",
      "\u001b[1m46/46\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - loss: 0.0087 - val_loss: 0.0075\n",
      "Epoch 5/30\n",
      "\u001b[1m46/46\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - loss: 0.0091 - val_loss: 0.0076\n",
      "Epoch 6/30\n",
      "\u001b[1m46/46\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - loss: 0.0070 - val_loss: 0.0036\n",
      "Epoch 7/30\n",
      "\u001b[1m46/46\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 0.0063 - val_loss: 0.0060\n",
      "Epoch 8/30\n",
      "\u001b[1m46/46\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 0.0068 - val_loss: 0.0050\n",
      "Epoch 9/30\n",
      "\u001b[1m46/46\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 0.0067 - val_loss: 0.0027\n",
      "Epoch 10/30\n",
      "\u001b[1m46/46\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 0.0072 - val_loss: 0.0060\n",
      "Epoch 11/30\n",
      "\u001b[1m46/46\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - loss: 0.0077 - val_loss: 0.0020\n",
      "Epoch 12/30\n",
      "\u001b[1m46/46\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - loss: 0.0044 - val_loss: 0.0032\n",
      "Epoch 13/30\n",
      "\u001b[1m46/46\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 0.0048 - val_loss: 0.0017\n",
      "Epoch 14/30\n",
      "\u001b[1m46/46\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 0.0052 - val_loss: 0.0020\n",
      "Epoch 15/30\n",
      "\u001b[1m46/46\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 0.0043 - val_loss: 0.0027\n",
      "Epoch 16/30\n",
      "\u001b[1m46/46\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - loss: 0.0047 - val_loss: 0.0029\n",
      "Epoch 17/30\n",
      "\u001b[1m46/46\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 0.0049 - val_loss: 0.0016\n",
      "Epoch 18/30\n",
      "\u001b[1m46/46\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - loss: 0.0041 - val_loss: 0.0015\n",
      "Epoch 19/30\n",
      "\u001b[1m46/46\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - loss: 0.0049 - val_loss: 0.0022\n",
      "Epoch 20/30\n",
      "\u001b[1m46/46\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - loss: 0.0048 - val_loss: 0.0027\n",
      "Epoch 21/30\n",
      "\u001b[1m46/46\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - loss: 0.0040 - val_loss: 0.0017\n",
      "Epoch 22/30\n",
      "\u001b[1m46/46\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 0.0043 - val_loss: 0.0035\n",
      "Epoch 23/30\n",
      "\u001b[1m46/46\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - loss: 0.0050 - val_loss: 0.0014\n",
      "Epoch 24/30\n",
      "\u001b[1m46/46\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - loss: 0.0043 - val_loss: 0.0014\n",
      "Epoch 25/30\n",
      "\u001b[1m46/46\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 0.0040 - val_loss: 0.0023\n",
      "Epoch 26/30\n",
      "\u001b[1m46/46\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - loss: 0.0050 - val_loss: 0.0016\n",
      "Epoch 27/30\n",
      "\u001b[1m46/46\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 0.0034 - val_loss: 0.0014\n",
      "Epoch 28/30\n",
      "\u001b[1m46/46\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - loss: 0.0034 - val_loss: 0.0016\n",
      "Epoch 29/30\n",
      "\u001b[1m46/46\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 0.0040 - val_loss: 0.0025\n",
      "Epoch 30/30\n",
      "\u001b[1m46/46\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - loss: 0.0042 - val_loss: 0.0018\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:The `save_format` argument is deprecated in Keras 3. We recommend removing this argument as it can be inferred from the file path. Received: save_format=keras\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Finished: Cape Verde | MAE: 0.07 | RMSE: 0.16 | R²: 0.88\n",
      "Epoch 1/30\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/dejauhnaebeadle/School/MachineLearning/machine-learning-project/code/rain-prediction/.venv/lib/python3.11/site-packages/keras/src/layers/rnn/rnn.py:200: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
      "  super().__init__(**kwargs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m46/46\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 13ms/step - loss: 0.0727 - val_loss: 0.0068\n",
      "Epoch 2/30\n",
      "\u001b[1m46/46\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - loss: 0.0067 - val_loss: 0.0053\n",
      "Epoch 3/30\n",
      "\u001b[1m46/46\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - loss: 0.0059 - val_loss: 0.0038\n",
      "Epoch 4/30\n",
      "\u001b[1m46/46\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - loss: 0.0051 - val_loss: 0.0021\n",
      "Epoch 5/30\n",
      "\u001b[1m46/46\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - loss: 0.0046 - val_loss: 0.0041\n",
      "Epoch 6/30\n",
      "\u001b[1m46/46\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - loss: 0.0044 - val_loss: 0.0054\n",
      "Epoch 7/30\n",
      "\u001b[1m46/46\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - loss: 0.0039 - val_loss: 0.0022\n",
      "Epoch 8/30\n",
      "\u001b[1m46/46\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - loss: 0.0034 - val_loss: 0.0029\n",
      "Epoch 9/30\n",
      "\u001b[1m46/46\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - loss: 0.0033 - val_loss: 0.0013\n",
      "Epoch 10/30\n",
      "\u001b[1m46/46\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - loss: 0.0028 - val_loss: 0.0021\n",
      "Epoch 11/30\n",
      "\u001b[1m46/46\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - loss: 0.0032 - val_loss: 0.0028\n",
      "Epoch 12/30\n",
      "\u001b[1m46/46\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - loss: 0.0035 - val_loss: 0.0015\n",
      "Epoch 13/30\n",
      "\u001b[1m46/46\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 0.0031 - val_loss: 0.0026\n",
      "Epoch 14/30\n",
      "\u001b[1m46/46\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 0.0025 - val_loss: 0.0014\n",
      "Epoch 15/30\n",
      "\u001b[1m46/46\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - loss: 0.0027 - val_loss: 0.0023\n",
      "Epoch 16/30\n",
      "\u001b[1m46/46\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - loss: 0.0030 - val_loss: 0.0012\n",
      "Epoch 17/30\n",
      "\u001b[1m46/46\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 0.0031 - val_loss: 0.0022\n",
      "Epoch 18/30\n",
      "\u001b[1m46/46\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 0.0024 - val_loss: 0.0011\n",
      "Epoch 19/30\n",
      "\u001b[1m46/46\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - loss: 0.0031 - val_loss: 0.0012\n",
      "Epoch 20/30\n",
      "\u001b[1m46/46\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - loss: 0.0024 - val_loss: 0.0018\n",
      "Epoch 21/30\n",
      "\u001b[1m46/46\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 0.0025 - val_loss: 0.0010\n",
      "Epoch 22/30\n",
      "\u001b[1m46/46\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - loss: 0.0021 - val_loss: 9.1648e-04\n",
      "Epoch 23/30\n",
      "\u001b[1m46/46\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 0.0029 - val_loss: 8.6180e-04\n",
      "Epoch 24/30\n",
      "\u001b[1m46/46\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - loss: 0.0030 - val_loss: 0.0017\n",
      "Epoch 25/30\n",
      "\u001b[1m46/46\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 0.0021 - val_loss: 0.0011\n",
      "Epoch 26/30\n",
      "\u001b[1m46/46\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 0.0021 - val_loss: 8.6660e-04\n",
      "Epoch 27/30\n",
      "\u001b[1m46/46\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - loss: 0.0023 - val_loss: 0.0018\n",
      "Epoch 28/30\n",
      "\u001b[1m46/46\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - loss: 0.0015 - val_loss: 0.0014\n",
      "Epoch 29/30\n",
      "\u001b[1m46/46\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - loss: 0.0019 - val_loss: 0.0011\n",
      "Epoch 30/30\n",
      "\u001b[1m46/46\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - loss: 0.0014 - val_loss: 0.0018\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:The `save_format` argument is deprecated in Keras 3. We recommend removing this argument as it can be inferred from the file path. Received: save_format=keras\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Finished: Cayman Islands | MAE: 0.09 | RMSE: 0.11 | R²: 0.86\n",
      "Epoch 1/30\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/dejauhnaebeadle/School/MachineLearning/machine-learning-project/code/rain-prediction/.venv/lib/python3.11/site-packages/keras/src/layers/rnn/rnn.py:200: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
      "  super().__init__(**kwargs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m46/46\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 11ms/step - loss: 0.0251 - val_loss: 0.0054\n",
      "Epoch 2/30\n",
      "\u001b[1m46/46\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 0.0087 - val_loss: 0.0027\n",
      "Epoch 3/30\n",
      "\u001b[1m46/46\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 0.0062 - val_loss: 0.0035\n",
      "Epoch 4/30\n",
      "\u001b[1m46/46\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - loss: 0.0051 - val_loss: 0.0021\n",
      "Epoch 5/30\n",
      "\u001b[1m46/46\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 0.0047 - val_loss: 0.0059\n",
      "Epoch 6/30\n",
      "\u001b[1m46/46\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 0.0042 - val_loss: 0.0011\n",
      "Epoch 7/30\n",
      "\u001b[1m46/46\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - loss: 0.0038 - val_loss: 0.0030\n",
      "Epoch 8/30\n",
      "\u001b[1m46/46\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - loss: 0.0038 - val_loss: 0.0029\n",
      "Epoch 9/30\n",
      "\u001b[1m46/46\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 0.0037 - val_loss: 0.0016\n",
      "Epoch 10/30\n",
      "\u001b[1m46/46\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 0.0035 - val_loss: 0.0013\n",
      "Epoch 11/30\n",
      "\u001b[1m46/46\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 0.0033 - val_loss: 0.0022\n",
      "Epoch 12/30\n",
      "\u001b[1m46/46\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 0.0041 - val_loss: 0.0018\n",
      "Epoch 13/30\n",
      "\u001b[1m46/46\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 0.0024 - val_loss: 7.5691e-04\n",
      "Epoch 14/30\n",
      "\u001b[1m46/46\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 0.0040 - val_loss: 0.0029\n",
      "Epoch 15/30\n",
      "\u001b[1m46/46\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - loss: 0.0034 - val_loss: 8.3220e-04\n",
      "Epoch 16/30\n",
      "\u001b[1m46/46\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 0.0028 - val_loss: 7.3674e-04\n",
      "Epoch 17/30\n",
      "\u001b[1m46/46\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 0.0030 - val_loss: 0.0012\n",
      "Epoch 18/30\n",
      "\u001b[1m46/46\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 0.0026 - val_loss: 7.0531e-04\n",
      "Epoch 19/30\n",
      "\u001b[1m46/46\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 0.0034 - val_loss: 6.4804e-04\n",
      "Epoch 20/30\n",
      "\u001b[1m46/46\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 11ms/step - loss: 0.0023 - val_loss: 0.0011\n",
      "Epoch 21/30\n",
      "\u001b[1m46/46\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - loss: 0.0027 - val_loss: 9.4991e-04\n",
      "Epoch 22/30\n",
      "\u001b[1m46/46\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - loss: 0.0028 - val_loss: 6.1747e-04\n",
      "Epoch 23/30\n",
      "\u001b[1m46/46\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 0.0023 - val_loss: 0.0016\n",
      "Epoch 24/30\n",
      "\u001b[1m46/46\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 0.0029 - val_loss: 7.8550e-04\n",
      "Epoch 25/30\n",
      "\u001b[1m46/46\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - loss: 0.0022 - val_loss: 6.0766e-04\n",
      "Epoch 26/30\n",
      "\u001b[1m46/46\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - loss: 0.0023 - val_loss: 6.8936e-04\n",
      "Epoch 27/30\n",
      "\u001b[1m46/46\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 0.0026 - val_loss: 6.7549e-04\n",
      "Epoch 28/30\n",
      "\u001b[1m46/46\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 0.0023 - val_loss: 9.8772e-04\n",
      "Epoch 29/30\n",
      "\u001b[1m46/46\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - loss: 0.0025 - val_loss: 7.2079e-04\n",
      "Epoch 30/30\n",
      "\u001b[1m46/46\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 0.0024 - val_loss: 0.0011\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:The `save_format` argument is deprecated in Keras 3. We recommend removing this argument as it can be inferred from the file path. Received: save_format=keras\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Finished: Central African Republic | MAE: 0.12 | RMSE: 0.15 | R²: 0.88\n",
      "Epoch 1/30\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/dejauhnaebeadle/School/MachineLearning/machine-learning-project/code/rain-prediction/.venv/lib/python3.11/site-packages/keras/src/layers/rnn/rnn.py:200: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
      "  super().__init__(**kwargs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m46/46\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 10ms/step - loss: 0.0582 - val_loss: 0.0026\n",
      "Epoch 2/30\n",
      "\u001b[1m46/46\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 0.0065 - val_loss: 0.0036\n",
      "Epoch 3/30\n",
      "\u001b[1m46/46\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 0.0068 - val_loss: 0.0012\n",
      "Epoch 4/30\n",
      "\u001b[1m46/46\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 0.0059 - val_loss: 0.0015\n",
      "Epoch 5/30\n",
      "\u001b[1m46/46\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 0.0051 - val_loss: 0.0049\n",
      "Epoch 6/30\n",
      "\u001b[1m46/46\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 0.0042 - val_loss: 0.0037\n",
      "Epoch 7/30\n",
      "\u001b[1m46/46\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 0.0037 - val_loss: 0.0037\n",
      "Epoch 8/30\n",
      "\u001b[1m46/46\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 0.0042 - val_loss: 0.0030\n",
      "Epoch 9/30\n",
      "\u001b[1m46/46\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 0.0040 - val_loss: 0.0024\n",
      "Epoch 10/30\n",
      "\u001b[1m46/46\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - loss: 0.0036 - val_loss: 0.0031\n",
      "Epoch 11/30\n",
      "\u001b[1m46/46\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 0.0043 - val_loss: 0.0026\n",
      "Epoch 12/30\n",
      "\u001b[1m46/46\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 0.0032 - val_loss: 0.0059\n",
      "Epoch 13/30\n",
      "\u001b[1m46/46\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 0.0042 - val_loss: 0.0016\n",
      "Epoch 14/30\n",
      "\u001b[1m46/46\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - loss: 0.0026 - val_loss: 0.0031\n",
      "Epoch 15/30\n",
      "\u001b[1m46/46\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - loss: 0.0028 - val_loss: 0.0040\n",
      "Epoch 16/30\n",
      "\u001b[1m46/46\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - loss: 0.0032 - val_loss: 0.0016\n",
      "Epoch 17/30\n",
      "\u001b[1m46/46\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 0.0028 - val_loss: 0.0012\n",
      "Epoch 18/30\n",
      "\u001b[1m46/46\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 0.0030 - val_loss: 0.0014\n",
      "Epoch 19/30\n",
      "\u001b[1m46/46\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - loss: 0.0027 - val_loss: 0.0019\n",
      "Epoch 20/30\n",
      "\u001b[1m46/46\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 0.0022 - val_loss: 8.4251e-04\n",
      "Epoch 21/30\n",
      "\u001b[1m46/46\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 0.0027 - val_loss: 5.5806e-04\n",
      "Epoch 22/30\n",
      "\u001b[1m46/46\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - loss: 0.0026 - val_loss: 4.8560e-04\n",
      "Epoch 23/30\n",
      "\u001b[1m46/46\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - loss: 0.0026 - val_loss: 0.0022\n",
      "Epoch 24/30\n",
      "\u001b[1m46/46\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - loss: 0.0039 - val_loss: 7.6031e-04\n",
      "Epoch 25/30\n",
      "\u001b[1m46/46\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - loss: 0.0026 - val_loss: 7.9876e-04\n",
      "Epoch 26/30\n",
      "\u001b[1m46/46\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - loss: 0.0020 - val_loss: 0.0014\n",
      "Epoch 27/30\n",
      "\u001b[1m46/46\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 13ms/step - loss: 0.0022 - val_loss: 0.0030\n",
      "Epoch 28/30\n",
      "\u001b[1m46/46\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - loss: 0.0021 - val_loss: 0.0030\n",
      "Epoch 29/30\n",
      "\u001b[1m46/46\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - loss: 0.0021 - val_loss: 9.9776e-04\n",
      "Epoch 30/30\n",
      "\u001b[1m46/46\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - loss: 0.0021 - val_loss: 0.0038\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:The `save_format` argument is deprecated in Keras 3. We recommend removing this argument as it can be inferred from the file path. Received: save_format=keras\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Finished: Chad | MAE: 0.30 | RMSE: 0.33 | R²: 0.11\n",
      "Epoch 1/30\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/dejauhnaebeadle/School/MachineLearning/machine-learning-project/code/rain-prediction/.venv/lib/python3.11/site-packages/keras/src/layers/rnn/rnn.py:200: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
      "  super().__init__(**kwargs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m46/46\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 13ms/step - loss: 0.0556 - val_loss: 0.0147\n",
      "Epoch 2/30\n",
      "\u001b[1m46/46\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - loss: 0.0080 - val_loss: 0.0142\n",
      "Epoch 3/30\n",
      "\u001b[1m46/46\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - loss: 0.0069 - val_loss: 0.0136\n",
      "Epoch 4/30\n",
      "\u001b[1m46/46\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - loss: 0.0064 - val_loss: 0.0124\n",
      "Epoch 5/30\n",
      "\u001b[1m46/46\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - loss: 0.0060 - val_loss: 0.0107\n",
      "Epoch 6/30\n",
      "\u001b[1m46/46\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - loss: 0.0047 - val_loss: 0.0111\n",
      "Epoch 7/30\n",
      "\u001b[1m46/46\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - loss: 0.0047 - val_loss: 0.0094\n",
      "Epoch 8/30\n",
      "\u001b[1m46/46\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - loss: 0.0041 - val_loss: 0.0091\n",
      "Epoch 9/30\n",
      "\u001b[1m46/46\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - loss: 0.0045 - val_loss: 0.0084\n",
      "Epoch 10/30\n",
      "\u001b[1m46/46\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - loss: 0.0035 - val_loss: 0.0078\n",
      "Epoch 11/30\n",
      "\u001b[1m46/46\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - loss: 0.0036 - val_loss: 0.0101\n",
      "Epoch 12/30\n",
      "\u001b[1m46/46\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - loss: 0.0039 - val_loss: 0.0079\n",
      "Epoch 13/30\n",
      "\u001b[1m46/46\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - loss: 0.0042 - val_loss: 0.0079\n",
      "Epoch 14/30\n",
      "\u001b[1m46/46\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 7ms/step - loss: 0.0036 - val_loss: 0.0071\n",
      "Epoch 15/30\n",
      "\u001b[1m46/46\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - loss: 0.0034 - val_loss: 0.0068\n",
      "Epoch 16/30\n",
      "\u001b[1m46/46\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - loss: 0.0030 - val_loss: 0.0068\n",
      "Epoch 17/30\n",
      "\u001b[1m46/46\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - loss: 0.0033 - val_loss: 0.0065\n",
      "Epoch 18/30\n",
      "\u001b[1m46/46\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - loss: 0.0031 - val_loss: 0.0069\n",
      "Epoch 19/30\n",
      "\u001b[1m46/46\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - loss: 0.0029 - val_loss: 0.0062\n",
      "Epoch 20/30\n",
      "\u001b[1m46/46\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - loss: 0.0031 - val_loss: 0.0065\n",
      "Epoch 21/30\n",
      "\u001b[1m46/46\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - loss: 0.0027 - val_loss: 0.0063\n",
      "Epoch 22/30\n",
      "\u001b[1m46/46\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - loss: 0.0031 - val_loss: 0.0058\n",
      "Epoch 23/30\n",
      "\u001b[1m46/46\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - loss: 0.0039 - val_loss: 0.0057\n",
      "Epoch 24/30\n",
      "\u001b[1m46/46\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - loss: 0.0023 - val_loss: 0.0056\n",
      "Epoch 25/30\n",
      "\u001b[1m46/46\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - loss: 0.0021 - val_loss: 0.0074\n",
      "Epoch 26/30\n",
      "\u001b[1m46/46\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - loss: 0.0043 - val_loss: 0.0056\n",
      "Epoch 27/30\n",
      "\u001b[1m46/46\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - loss: 0.0028 - val_loss: 0.0054\n",
      "Epoch 28/30\n",
      "\u001b[1m46/46\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - loss: 0.0025 - val_loss: 0.0052\n",
      "Epoch 29/30\n",
      "\u001b[1m46/46\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - loss: 0.0025 - val_loss: 0.0051\n",
      "Epoch 30/30\n",
      "\u001b[1m46/46\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - loss: 0.0025 - val_loss: 0.0051\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:The `save_format` argument is deprecated in Keras 3. We recommend removing this argument as it can be inferred from the file path. Received: save_format=keras\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Finished: Chile | MAE: 0.05 | RMSE: 0.10 | R²: 0.86\n",
      "Epoch 1/30\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/dejauhnaebeadle/School/MachineLearning/machine-learning-project/code/rain-prediction/.venv/lib/python3.11/site-packages/keras/src/layers/rnn/rnn.py:200: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
      "  super().__init__(**kwargs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m46/46\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 15ms/step - loss: 0.0390 - val_loss: 0.0070\n",
      "Epoch 2/30\n",
      "\u001b[1m46/46\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 0.0050 - val_loss: 0.0066\n",
      "Epoch 3/30\n",
      "\u001b[1m46/46\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - loss: 0.0053 - val_loss: 0.0040\n",
      "Epoch 4/30\n",
      "\u001b[1m46/46\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - loss: 0.0046 - val_loss: 0.0044\n",
      "Epoch 5/30\n",
      "\u001b[1m46/46\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - loss: 0.0043 - val_loss: 0.0039\n",
      "Epoch 6/30\n",
      "\u001b[1m46/46\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - loss: 0.0036 - val_loss: 0.0044\n",
      "Epoch 7/30\n",
      "\u001b[1m46/46\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 0.0032 - val_loss: 0.0028\n",
      "Epoch 8/30\n",
      "\u001b[1m46/46\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 0.0030 - val_loss: 0.0033\n",
      "Epoch 9/30\n",
      "\u001b[1m46/46\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - loss: 0.0034 - val_loss: 0.0025\n",
      "Epoch 10/30\n",
      "\u001b[1m46/46\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - loss: 0.0025 - val_loss: 0.0110\n",
      "Epoch 11/30\n",
      "\u001b[1m46/46\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 0.0036 - val_loss: 0.0022\n",
      "Epoch 12/30\n",
      "\u001b[1m46/46\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 0.0027 - val_loss: 0.0024\n",
      "Epoch 13/30\n",
      "\u001b[1m46/46\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 0.0023 - val_loss: 0.0023\n",
      "Epoch 14/30\n",
      "\u001b[1m46/46\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - loss: 0.0025 - val_loss: 0.0025\n",
      "Epoch 15/30\n",
      "\u001b[1m46/46\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - loss: 0.0019 - val_loss: 0.0021\n",
      "Epoch 16/30\n",
      "\u001b[1m46/46\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - loss: 0.0022 - val_loss: 0.0022\n",
      "Epoch 17/30\n",
      "\u001b[1m46/46\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - loss: 0.0022 - val_loss: 0.0020\n",
      "Epoch 18/30\n",
      "\u001b[1m46/46\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - loss: 0.0024 - val_loss: 0.0025\n",
      "Epoch 19/30\n",
      "\u001b[1m46/46\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - loss: 0.0021 - val_loss: 0.0018\n",
      "Epoch 20/30\n",
      "\u001b[1m46/46\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - loss: 0.0022 - val_loss: 0.0019\n",
      "Epoch 21/30\n",
      "\u001b[1m46/46\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - loss: 0.0020 - val_loss: 0.0017\n",
      "Epoch 22/30\n",
      "\u001b[1m46/46\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - loss: 0.0021 - val_loss: 0.0019\n",
      "Epoch 23/30\n",
      "\u001b[1m46/46\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - loss: 0.0027 - val_loss: 0.0025\n",
      "Epoch 24/30\n",
      "\u001b[1m46/46\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - loss: 0.0022 - val_loss: 0.0019\n",
      "Epoch 25/30\n",
      "\u001b[1m46/46\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - loss: 0.0019 - val_loss: 0.0032\n",
      "Epoch 26/30\n",
      "\u001b[1m46/46\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 11ms/step - loss: 0.0019 - val_loss: 0.0017\n",
      "Epoch 27/30\n",
      "\u001b[1m46/46\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - loss: 0.0019 - val_loss: 0.0016\n",
      "Epoch 28/30\n",
      "\u001b[1m46/46\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - loss: 0.0026 - val_loss: 0.0016\n",
      "Epoch 29/30\n",
      "\u001b[1m46/46\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - loss: 0.0018 - val_loss: 0.0016\n",
      "Epoch 30/30\n",
      "\u001b[1m46/46\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - loss: 0.0018 - val_loss: 0.0023\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:The `save_format` argument is deprecated in Keras 3. We recommend removing this argument as it can be inferred from the file path. Received: save_format=keras\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Finished: China | MAE: 0.10 | RMSE: 0.12 | R²: 0.90\n",
      "Epoch 1/30\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/dejauhnaebeadle/School/MachineLearning/machine-learning-project/code/rain-prediction/.venv/lib/python3.11/site-packages/keras/src/layers/rnn/rnn.py:200: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
      "  super().__init__(**kwargs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m46/46\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 12ms/step - loss: 0.0881 - val_loss: 0.0044\n",
      "Epoch 2/30\n",
      "\u001b[1m46/46\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - loss: 0.0074 - val_loss: 0.0041\n",
      "Epoch 3/30\n",
      "\u001b[1m46/46\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - loss: 0.0063 - val_loss: 0.0013\n",
      "Epoch 4/30\n",
      "\u001b[1m46/46\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 0.0049 - val_loss: 0.0015\n",
      "Epoch 5/30\n",
      "\u001b[1m46/46\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 0.0040 - val_loss: 0.0015\n",
      "Epoch 6/30\n",
      "\u001b[1m46/46\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - loss: 0.0051 - val_loss: 0.0021\n",
      "Epoch 7/30\n",
      "\u001b[1m46/46\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 0.0032 - val_loss: 6.2963e-04\n",
      "Epoch 8/30\n",
      "\u001b[1m46/46\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 0.0041 - val_loss: 0.0012\n",
      "Epoch 9/30\n",
      "\u001b[1m46/46\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - loss: 0.0032 - val_loss: 0.0011\n",
      "Epoch 10/30\n",
      "\u001b[1m46/46\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - loss: 0.0026 - val_loss: 0.0014\n",
      "Epoch 11/30\n",
      "\u001b[1m46/46\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 0.0030 - val_loss: 0.0020\n",
      "Epoch 12/30\n",
      "\u001b[1m46/46\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 0.0027 - val_loss: 9.6399e-04\n",
      "Epoch 13/30\n",
      "\u001b[1m46/46\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 0.0029 - val_loss: 9.6583e-04\n",
      "Epoch 14/30\n",
      "\u001b[1m46/46\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - loss: 0.0024 - val_loss: 0.0014\n",
      "Epoch 15/30\n",
      "\u001b[1m46/46\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 0.0024 - val_loss: 8.7461e-04\n",
      "Epoch 16/30\n",
      "\u001b[1m46/46\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 0.0024 - val_loss: 5.8778e-04\n",
      "Epoch 17/30\n",
      "\u001b[1m46/46\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 0.0026 - val_loss: 8.5555e-04\n",
      "Epoch 18/30\n",
      "\u001b[1m46/46\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - loss: 0.0023 - val_loss: 4.6900e-04\n",
      "Epoch 19/30\n",
      "\u001b[1m46/46\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 0.0027 - val_loss: 4.9674e-04\n",
      "Epoch 20/30\n",
      "\u001b[1m46/46\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 0.0024 - val_loss: 4.0974e-04\n",
      "Epoch 21/30\n",
      "\u001b[1m46/46\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 0.0022 - val_loss: 6.1742e-04\n",
      "Epoch 22/30\n",
      "\u001b[1m46/46\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 0.0021 - val_loss: 8.3784e-04\n",
      "Epoch 23/30\n",
      "\u001b[1m46/46\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 0.0018 - val_loss: 7.3034e-04\n",
      "Epoch 24/30\n",
      "\u001b[1m46/46\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - loss: 0.0017 - val_loss: 3.6717e-04\n",
      "Epoch 25/30\n",
      "\u001b[1m46/46\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - loss: 0.0024 - val_loss: 3.5597e-04\n",
      "Epoch 26/30\n",
      "\u001b[1m46/46\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - loss: 0.0020 - val_loss: 3.6102e-04\n",
      "Epoch 27/30\n",
      "\u001b[1m46/46\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 13ms/step - loss: 0.0018 - val_loss: 8.7130e-04\n",
      "Epoch 28/30\n",
      "\u001b[1m46/46\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 9ms/step - loss: 0.0024 - val_loss: 3.8123e-04\n",
      "Epoch 29/30\n",
      "\u001b[1m46/46\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - loss: 0.0018 - val_loss: 3.8641e-04\n",
      "Epoch 30/30\n",
      "\u001b[1m46/46\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 0.0017 - val_loss: 3.2232e-04\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:The `save_format` argument is deprecated in Keras 3. We recommend removing this argument as it can be inferred from the file path. Received: save_format=keras\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Finished: Colombia | MAE: 0.06 | RMSE: 0.11 | R²: 0.89\n",
      "Epoch 1/30\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/dejauhnaebeadle/School/MachineLearning/machine-learning-project/code/rain-prediction/.venv/lib/python3.11/site-packages/keras/src/layers/rnn/rnn.py:200: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
      "  super().__init__(**kwargs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m46/46\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 12ms/step - loss: 0.0566 - val_loss: 0.0124\n",
      "Epoch 2/30\n",
      "\u001b[1m46/46\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - loss: 0.0101 - val_loss: 0.0068\n",
      "Epoch 3/30\n",
      "\u001b[1m46/46\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - loss: 0.0092 - val_loss: 0.0127\n",
      "Epoch 4/30\n",
      "\u001b[1m46/46\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - loss: 0.0084 - val_loss: 0.0046\n",
      "Epoch 5/30\n",
      "\u001b[1m46/46\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 0.0070 - val_loss: 0.0081\n",
      "Epoch 6/30\n",
      "\u001b[1m46/46\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - loss: 0.0062 - val_loss: 0.0067\n",
      "Epoch 7/30\n",
      "\u001b[1m46/46\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - loss: 0.0061 - val_loss: 0.0077\n",
      "Epoch 8/30\n",
      "\u001b[1m46/46\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - loss: 0.0051 - val_loss: 0.0046\n",
      "Epoch 9/30\n",
      "\u001b[1m46/46\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 0.0060 - val_loss: 0.0047\n",
      "Epoch 10/30\n",
      "\u001b[1m46/46\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - loss: 0.0046 - val_loss: 0.0039\n",
      "Epoch 11/30\n",
      "\u001b[1m46/46\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - loss: 0.0052 - val_loss: 0.0033\n",
      "Epoch 12/30\n",
      "\u001b[1m46/46\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - loss: 0.0040 - val_loss: 0.0032\n",
      "Epoch 13/30\n",
      "\u001b[1m46/46\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - loss: 0.0042 - val_loss: 0.0034\n",
      "Epoch 14/30\n",
      "\u001b[1m46/46\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 0.0040 - val_loss: 0.0035\n",
      "Epoch 15/30\n",
      "\u001b[1m46/46\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - loss: 0.0043 - val_loss: 0.0030\n",
      "Epoch 16/30\n",
      "\u001b[1m46/46\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - loss: 0.0037 - val_loss: 0.0047\n",
      "Epoch 17/30\n",
      "\u001b[1m46/46\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - loss: 0.0048 - val_loss: 0.0034\n",
      "Epoch 18/30\n",
      "\u001b[1m46/46\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - loss: 0.0035 - val_loss: 0.0027\n",
      "Epoch 19/30\n",
      "\u001b[1m46/46\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - loss: 0.0031 - val_loss: 0.0027\n",
      "Epoch 20/30\n",
      "\u001b[1m46/46\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - loss: 0.0033 - val_loss: 0.0032\n",
      "Epoch 21/30\n",
      "\u001b[1m46/46\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - loss: 0.0032 - val_loss: 0.0055\n",
      "Epoch 22/30\n",
      "\u001b[1m46/46\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - loss: 0.0034 - val_loss: 0.0029\n",
      "Epoch 23/30\n",
      "\u001b[1m46/46\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 0.0029 - val_loss: 0.0043\n",
      "Epoch 24/30\n",
      "\u001b[1m46/46\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - loss: 0.0032 - val_loss: 0.0031\n",
      "Epoch 25/30\n",
      "\u001b[1m46/46\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - loss: 0.0031 - val_loss: 0.0027\n",
      "Epoch 26/30\n",
      "\u001b[1m46/46\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - loss: 0.0040 - val_loss: 0.0024\n",
      "Epoch 27/30\n",
      "\u001b[1m46/46\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - loss: 0.0036 - val_loss: 0.0025\n",
      "Epoch 28/30\n",
      "\u001b[1m46/46\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - loss: 0.0029 - val_loss: 0.0037\n",
      "Epoch 29/30\n",
      "\u001b[1m46/46\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - loss: 0.0025 - val_loss: 0.0034\n",
      "Epoch 30/30\n",
      "\u001b[1m46/46\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - loss: 0.0032 - val_loss: 0.0025\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:The `save_format` argument is deprecated in Keras 3. We recommend removing this argument as it can be inferred from the file path. Received: save_format=keras\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Finished: Comoros | MAE: 0.05 | RMSE: 0.09 | R²: 0.88\n",
      "Epoch 1/30\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/dejauhnaebeadle/School/MachineLearning/machine-learning-project/code/rain-prediction/.venv/lib/python3.11/site-packages/keras/src/layers/rnn/rnn.py:200: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
      "  super().__init__(**kwargs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m46/46\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 12ms/step - loss: 0.0238 - val_loss: 0.0107\n",
      "Epoch 2/30\n",
      "\u001b[1m46/46\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 0.0057 - val_loss: 0.0045\n",
      "Epoch 3/30\n",
      "\u001b[1m46/46\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 0.0045 - val_loss: 0.0037\n",
      "Epoch 4/30\n",
      "\u001b[1m46/46\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 0.0029 - val_loss: 0.0110\n",
      "Epoch 5/30\n",
      "\u001b[1m46/46\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 0.0036 - val_loss: 0.0061\n",
      "Epoch 6/30\n",
      "\u001b[1m46/46\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - loss: 0.0032 - val_loss: 0.0062\n",
      "Epoch 7/30\n",
      "\u001b[1m46/46\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - loss: 0.0030 - val_loss: 0.0032\n",
      "Epoch 8/30\n",
      "\u001b[1m46/46\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 0.0024 - val_loss: 0.0022\n",
      "Epoch 9/30\n",
      "\u001b[1m46/46\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 0.0029 - val_loss: 0.0024\n",
      "Epoch 10/30\n",
      "\u001b[1m46/46\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 0.0025 - val_loss: 0.0014\n",
      "Epoch 11/30\n",
      "\u001b[1m46/46\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 0.0026 - val_loss: 0.0021\n",
      "Epoch 12/30\n",
      "\u001b[1m46/46\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - loss: 0.0023 - val_loss: 0.0029\n",
      "Epoch 13/30\n",
      "\u001b[1m46/46\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - loss: 0.0028 - val_loss: 0.0015\n",
      "Epoch 14/30\n",
      "\u001b[1m46/46\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - loss: 0.0022 - val_loss: 0.0027\n",
      "Epoch 15/30\n",
      "\u001b[1m46/46\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 0.0021 - val_loss: 0.0024\n",
      "Epoch 16/30\n",
      "\u001b[1m46/46\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 0.0030 - val_loss: 0.0014\n",
      "Epoch 17/30\n",
      "\u001b[1m46/46\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 0.0024 - val_loss: 0.0011\n",
      "Epoch 18/30\n",
      "\u001b[1m46/46\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - loss: 0.0021 - val_loss: 8.9274e-04\n",
      "Epoch 19/30\n",
      "\u001b[1m46/46\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - loss: 0.0021 - val_loss: 0.0026\n",
      "Epoch 20/30\n",
      "\u001b[1m46/46\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - loss: 0.0017 - val_loss: 0.0032\n",
      "Epoch 21/30\n",
      "\u001b[1m46/46\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - loss: 0.0019 - val_loss: 0.0019\n",
      "Epoch 22/30\n",
      "\u001b[1m46/46\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - loss: 0.0015 - val_loss: 0.0013\n",
      "Epoch 23/30\n",
      "\u001b[1m46/46\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - loss: 0.0017 - val_loss: 0.0021\n",
      "Epoch 24/30\n",
      "\u001b[1m46/46\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - loss: 0.0026 - val_loss: 8.3989e-04\n",
      "Epoch 25/30\n",
      "\u001b[1m46/46\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 0.0014 - val_loss: 0.0017\n",
      "Epoch 26/30\n",
      "\u001b[1m46/46\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - loss: 0.0013 - val_loss: 0.0018\n",
      "Epoch 27/30\n",
      "\u001b[1m46/46\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - loss: 0.0016 - val_loss: 0.0014\n",
      "Epoch 28/30\n",
      "\u001b[1m46/46\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - loss: 0.0016 - val_loss: 7.8198e-04\n",
      "Epoch 29/30\n",
      "\u001b[1m46/46\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - loss: 0.0023 - val_loss: 0.0016\n",
      "Epoch 30/30\n",
      "\u001b[1m46/46\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - loss: 0.0022 - val_loss: 6.8191e-04\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:The `save_format` argument is deprecated in Keras 3. We recommend removing this argument as it can be inferred from the file path. Received: save_format=keras\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Finished: Congo | MAE: 0.06 | RMSE: 0.09 | R²: 0.90\n",
      "Epoch 1/30\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/dejauhnaebeadle/School/MachineLearning/machine-learning-project/code/rain-prediction/.venv/lib/python3.11/site-packages/keras/src/layers/rnn/rnn.py:200: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
      "  super().__init__(**kwargs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m46/46\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 13ms/step - loss: 0.0879 - val_loss: 0.0070\n",
      "Epoch 2/30\n",
      "\u001b[1m46/46\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - loss: 0.0150 - val_loss: 0.0040\n",
      "Epoch 3/30\n",
      "\u001b[1m46/46\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - loss: 0.0117 - val_loss: 0.0079\n",
      "Epoch 4/30\n",
      "\u001b[1m46/46\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - loss: 0.0097 - val_loss: 0.0093\n",
      "Epoch 5/30\n",
      "\u001b[1m46/46\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - loss: 0.0085 - val_loss: 0.0044\n",
      "Epoch 6/30\n",
      "\u001b[1m46/46\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - loss: 0.0073 - val_loss: 0.0089\n",
      "Epoch 7/30\n",
      "\u001b[1m46/46\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - loss: 0.0085 - val_loss: 0.0036\n",
      "Epoch 8/30\n",
      "\u001b[1m46/46\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - loss: 0.0062 - val_loss: 0.0065\n",
      "Epoch 9/30\n",
      "\u001b[1m46/46\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 0.0076 - val_loss: 0.0087\n",
      "Epoch 10/30\n",
      "\u001b[1m46/46\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - loss: 0.0084 - val_loss: 0.0021\n",
      "Epoch 11/30\n",
      "\u001b[1m46/46\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - loss: 0.0055 - val_loss: 0.0019\n",
      "Epoch 12/30\n",
      "\u001b[1m46/46\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - loss: 0.0051 - val_loss: 0.0012\n",
      "Epoch 13/30\n",
      "\u001b[1m46/46\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - loss: 0.0071 - val_loss: 0.0022\n",
      "Epoch 14/30\n",
      "\u001b[1m46/46\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - loss: 0.0068 - val_loss: 0.0023\n",
      "Epoch 15/30\n",
      "\u001b[1m46/46\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - loss: 0.0068 - val_loss: 0.0011\n",
      "Epoch 16/30\n",
      "\u001b[1m46/46\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - loss: 0.0045 - val_loss: 0.0019\n",
      "Epoch 17/30\n",
      "\u001b[1m46/46\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - loss: 0.0062 - val_loss: 0.0016\n",
      "Epoch 18/30\n",
      "\u001b[1m46/46\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - loss: 0.0045 - val_loss: 0.0019\n",
      "Epoch 19/30\n",
      "\u001b[1m46/46\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - loss: 0.0060 - val_loss: 0.0036\n",
      "Epoch 20/30\n",
      "\u001b[1m46/46\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - loss: 0.0050 - val_loss: 0.0014\n",
      "Epoch 21/30\n",
      "\u001b[1m46/46\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - loss: 0.0048 - val_loss: 0.0010\n",
      "Epoch 22/30\n",
      "\u001b[1m46/46\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - loss: 0.0047 - val_loss: 0.0044\n",
      "Epoch 23/30\n",
      "\u001b[1m46/46\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - loss: 0.0045 - val_loss: 0.0018\n",
      "Epoch 24/30\n",
      "\u001b[1m46/46\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - loss: 0.0068 - val_loss: 0.0021\n",
      "Epoch 25/30\n",
      "\u001b[1m46/46\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - loss: 0.0047 - val_loss: 0.0012\n",
      "Epoch 26/30\n",
      "\u001b[1m46/46\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 11ms/step - loss: 0.0044 - val_loss: 0.0012\n",
      "Epoch 27/30\n",
      "\u001b[1m46/46\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - loss: 0.0053 - val_loss: 0.0018\n",
      "Epoch 28/30\n",
      "\u001b[1m46/46\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 12ms/step - loss: 0.0043 - val_loss: 0.0012\n",
      "Epoch 29/30\n",
      "\u001b[1m46/46\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - loss: 0.0053 - val_loss: 0.0026\n",
      "Epoch 30/30\n",
      "\u001b[1m46/46\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - loss: 0.0048 - val_loss: 0.0019\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:The `save_format` argument is deprecated in Keras 3. We recommend removing this argument as it can be inferred from the file path. Received: save_format=keras\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Finished: Cook Islands | MAE: 0.07 | RMSE: 0.11 | R²: 0.82\n",
      "Epoch 1/30\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/dejauhnaebeadle/School/MachineLearning/machine-learning-project/code/rain-prediction/.venv/lib/python3.11/site-packages/keras/src/layers/rnn/rnn.py:200: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
      "  super().__init__(**kwargs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m46/46\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 30ms/step - loss: 0.0965 - val_loss: 0.0049\n",
      "Epoch 2/30\n",
      "\u001b[1m46/46\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 12ms/step - loss: 0.0111 - val_loss: 0.0058\n",
      "Epoch 3/30\n",
      "\u001b[1m46/46\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 10ms/step - loss: 0.0093 - val_loss: 0.0020\n",
      "Epoch 4/30\n",
      "\u001b[1m46/46\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - loss: 0.0085 - val_loss: 0.0023\n",
      "Epoch 5/30\n",
      "\u001b[1m46/46\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - loss: 0.0080 - val_loss: 0.0026\n",
      "Epoch 6/30\n",
      "\u001b[1m46/46\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - loss: 0.0058 - val_loss: 0.0024\n",
      "Epoch 7/30\n",
      "\u001b[1m46/46\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - loss: 0.0062 - val_loss: 0.0034\n",
      "Epoch 8/30\n",
      "\u001b[1m46/46\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 12ms/step - loss: 0.0055 - val_loss: 0.0036\n",
      "Epoch 9/30\n",
      "\u001b[1m46/46\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - loss: 0.0043 - val_loss: 0.0032\n",
      "Epoch 10/30\n",
      "\u001b[1m46/46\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - loss: 0.0053 - val_loss: 0.0042\n",
      "Epoch 11/30\n",
      "\u001b[1m46/46\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - loss: 0.0057 - val_loss: 0.0066\n",
      "Epoch 12/30\n",
      "\u001b[1m46/46\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - loss: 0.0055 - val_loss: 0.0082\n",
      "Epoch 13/30\n",
      "\u001b[1m46/46\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - loss: 0.0051 - val_loss: 0.0039\n",
      "Epoch 14/30\n",
      "\u001b[1m46/46\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 11ms/step - loss: 0.0039 - val_loss: 0.0017\n",
      "Epoch 15/30\n",
      "\u001b[1m46/46\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - loss: 0.0041 - val_loss: 0.0012\n",
      "Epoch 16/30\n",
      "\u001b[1m46/46\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - loss: 0.0039 - val_loss: 0.0032\n",
      "Epoch 17/30\n",
      "\u001b[1m46/46\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - loss: 0.0039 - val_loss: 0.0016\n",
      "Epoch 18/30\n",
      "\u001b[1m46/46\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - loss: 0.0048 - val_loss: 0.0011\n",
      "Epoch 19/30\n",
      "\u001b[1m46/46\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - loss: 0.0038 - val_loss: 0.0035\n",
      "Epoch 20/30\n",
      "\u001b[1m46/46\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - loss: 0.0032 - val_loss: 0.0052\n",
      "Epoch 21/30\n",
      "\u001b[1m46/46\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 10ms/step - loss: 0.0043 - val_loss: 0.0038\n",
      "Epoch 22/30\n",
      "\u001b[1m46/46\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 17ms/step - loss: 0.0042 - val_loss: 0.0010\n",
      "Epoch 23/30\n",
      "\u001b[1m46/46\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 10ms/step - loss: 0.0038 - val_loss: 0.0016\n",
      "Epoch 24/30\n",
      "\u001b[1m46/46\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - loss: 0.0030 - val_loss: 0.0041\n",
      "Epoch 25/30\n",
      "\u001b[1m46/46\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 11ms/step - loss: 0.0034 - val_loss: 0.0013\n",
      "Epoch 26/30\n",
      "\u001b[1m46/46\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - loss: 0.0027 - val_loss: 0.0010\n",
      "Epoch 27/30\n",
      "\u001b[1m46/46\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - loss: 0.0030 - val_loss: 8.5961e-04\n",
      "Epoch 28/30\n",
      "\u001b[1m46/46\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - loss: 0.0026 - val_loss: 0.0021\n",
      "Epoch 29/30\n",
      "\u001b[1m46/46\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - loss: 0.0028 - val_loss: 0.0010\n",
      "Epoch 30/30\n",
      "\u001b[1m46/46\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - loss: 0.0035 - val_loss: 0.0025\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:The `save_format` argument is deprecated in Keras 3. We recommend removing this argument as it can be inferred from the file path. Received: save_format=keras\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Finished: Costa Rica | MAE: 0.14 | RMSE: 0.16 | R²: 0.65\n",
      "Epoch 1/30\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/dejauhnaebeadle/School/MachineLearning/machine-learning-project/code/rain-prediction/.venv/lib/python3.11/site-packages/keras/src/layers/rnn/rnn.py:200: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
      "  super().__init__(**kwargs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m46/46\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 20ms/step - loss: 0.0790 - val_loss: 0.0070\n",
      "Epoch 2/30\n",
      "\u001b[1m46/46\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 11ms/step - loss: 0.0071 - val_loss: 0.0011\n",
      "Epoch 3/30\n",
      "\u001b[1m46/46\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - loss: 0.0064 - val_loss: 0.0016\n",
      "Epoch 4/30\n",
      "\u001b[1m46/46\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - loss: 0.0072 - val_loss: 0.0024\n",
      "Epoch 5/30\n",
      "\u001b[1m46/46\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - loss: 0.0054 - val_loss: 0.0035\n",
      "Epoch 6/30\n",
      "\u001b[1m46/46\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - loss: 0.0040 - val_loss: 0.0011\n",
      "Epoch 7/30\n",
      "\u001b[1m46/46\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - loss: 0.0045 - val_loss: 0.0067\n",
      "Epoch 8/30\n",
      "\u001b[1m46/46\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - loss: 0.0041 - val_loss: 0.0031\n",
      "Epoch 9/30\n",
      "\u001b[1m46/46\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - loss: 0.0034 - val_loss: 0.0039\n",
      "Epoch 10/30\n",
      "\u001b[1m46/46\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - loss: 0.0026 - val_loss: 0.0013\n",
      "Epoch 11/30\n",
      "\u001b[1m46/46\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - loss: 0.0033 - val_loss: 0.0023\n",
      "Epoch 12/30\n",
      "\u001b[1m46/46\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - loss: 0.0024 - val_loss: 0.0023\n",
      "Epoch 13/30\n",
      "\u001b[1m46/46\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - loss: 0.0027 - val_loss: 6.7452e-04\n",
      "Epoch 14/30\n",
      "\u001b[1m46/46\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - loss: 0.0025 - val_loss: 0.0024\n",
      "Epoch 15/30\n",
      "\u001b[1m46/46\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - loss: 0.0031 - val_loss: 4.3496e-04\n",
      "Epoch 16/30\n",
      "\u001b[1m46/46\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - loss: 0.0029 - val_loss: 0.0027\n",
      "Epoch 17/30\n",
      "\u001b[1m46/46\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - loss: 0.0025 - val_loss: 8.0652e-04\n",
      "Epoch 18/30\n",
      "\u001b[1m46/46\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - loss: 0.0027 - val_loss: 0.0011\n",
      "Epoch 19/30\n",
      "\u001b[1m46/46\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - loss: 0.0025 - val_loss: 4.0216e-04\n",
      "Epoch 20/30\n",
      "\u001b[1m46/46\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 0.0025 - val_loss: 0.0028\n",
      "Epoch 21/30\n",
      "\u001b[1m46/46\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - loss: 0.0024 - val_loss: 4.2403e-04\n",
      "Epoch 22/30\n",
      "\u001b[1m46/46\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - loss: 0.0019 - val_loss: 0.0034\n",
      "Epoch 23/30\n",
      "\u001b[1m46/46\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - loss: 0.0027 - val_loss: 4.9497e-04\n",
      "Epoch 24/30\n",
      "\u001b[1m46/46\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - loss: 0.0018 - val_loss: 5.0464e-04\n",
      "Epoch 25/30\n",
      "\u001b[1m46/46\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - loss: 0.0022 - val_loss: 3.5735e-04\n",
      "Epoch 26/30\n",
      "\u001b[1m46/46\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 0.0022 - val_loss: 3.3685e-04\n",
      "Epoch 27/30\n",
      "\u001b[1m46/46\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - loss: 0.0020 - val_loss: 3.3391e-04\n",
      "Epoch 28/30\n",
      "\u001b[1m46/46\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 0.0021 - val_loss: 5.1773e-04\n",
      "Epoch 29/30\n",
      "\u001b[1m46/46\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - loss: 0.0015 - val_loss: 5.2970e-04\n",
      "Epoch 30/30\n",
      "\u001b[1m46/46\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - loss: 0.0022 - val_loss: 5.8000e-04\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:The `save_format` argument is deprecated in Keras 3. We recommend removing this argument as it can be inferred from the file path. Received: save_format=keras\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Finished: Cote d'Ivoire | MAE: 0.08 | RMSE: 0.10 | R²: 0.81\n",
      "Epoch 1/30\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/dejauhnaebeadle/School/MachineLearning/machine-learning-project/code/rain-prediction/.venv/lib/python3.11/site-packages/keras/src/layers/rnn/rnn.py:200: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
      "  super().__init__(**kwargs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m46/46\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 12ms/step - loss: 0.0739 - val_loss: 0.0045\n",
      "Epoch 2/30\n",
      "\u001b[1m46/46\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - loss: 0.0059 - val_loss: 0.0054\n",
      "Epoch 3/30\n",
      "\u001b[1m46/46\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 0.0058 - val_loss: 0.0056\n",
      "Epoch 4/30\n",
      "\u001b[1m46/46\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - loss: 0.0051 - val_loss: 0.0046\n",
      "Epoch 5/30\n",
      "\u001b[1m46/46\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 0.0044 - val_loss: 0.0039\n",
      "Epoch 6/30\n",
      "\u001b[1m46/46\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 0.0044 - val_loss: 0.0037\n",
      "Epoch 7/30\n",
      "\u001b[1m46/46\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - loss: 0.0038 - val_loss: 0.0037\n",
      "Epoch 8/30\n",
      "\u001b[1m46/46\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 0.0033 - val_loss: 0.0029\n",
      "Epoch 9/30\n",
      "\u001b[1m46/46\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 0.0033 - val_loss: 0.0040\n",
      "Epoch 10/30\n",
      "\u001b[1m46/46\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - loss: 0.0033 - val_loss: 0.0062\n",
      "Epoch 11/30\n",
      "\u001b[1m46/46\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - loss: 0.0031 - val_loss: 0.0033\n",
      "Epoch 12/30\n",
      "\u001b[1m46/46\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 0.0026 - val_loss: 0.0030\n",
      "Epoch 13/30\n",
      "\u001b[1m46/46\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 0.0027 - val_loss: 0.0038\n",
      "Epoch 14/30\n",
      "\u001b[1m46/46\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 0.0026 - val_loss: 0.0023\n",
      "Epoch 15/30\n",
      "\u001b[1m46/46\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 0.0026 - val_loss: 0.0031\n",
      "Epoch 16/30\n",
      "\u001b[1m46/46\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - loss: 0.0029 - val_loss: 0.0031\n",
      "Epoch 17/30\n",
      "\u001b[1m46/46\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - loss: 0.0023 - val_loss: 0.0020\n",
      "Epoch 18/30\n",
      "\u001b[1m46/46\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - loss: 0.0023 - val_loss: 0.0017\n",
      "Epoch 19/30\n",
      "\u001b[1m46/46\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - loss: 0.0023 - val_loss: 0.0029\n",
      "Epoch 20/30\n",
      "\u001b[1m46/46\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - loss: 0.0028 - val_loss: 0.0029\n",
      "Epoch 21/30\n",
      "\u001b[1m46/46\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 11ms/step - loss: 0.0022 - val_loss: 0.0016\n",
      "Epoch 22/30\n",
      "\u001b[1m46/46\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - loss: 0.0023 - val_loss: 0.0022\n",
      "Epoch 23/30\n",
      "\u001b[1m46/46\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 0.0021 - val_loss: 0.0016\n",
      "Epoch 24/30\n",
      "\u001b[1m46/46\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - loss: 0.0020 - val_loss: 0.0015\n",
      "Epoch 25/30\n",
      "\u001b[1m46/46\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - loss: 0.0018 - val_loss: 0.0019\n",
      "Epoch 26/30\n",
      "\u001b[1m46/46\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - loss: 0.0023 - val_loss: 0.0017\n",
      "Epoch 27/30\n",
      "\u001b[1m46/46\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - loss: 0.0019 - val_loss: 0.0014\n",
      "Epoch 28/30\n",
      "\u001b[1m46/46\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - loss: 0.0020 - val_loss: 0.0017\n",
      "Epoch 29/30\n",
      "\u001b[1m46/46\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - loss: 0.0020 - val_loss: 0.0024\n",
      "Epoch 30/30\n",
      "\u001b[1m46/46\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - loss: 0.0021 - val_loss: 0.0027\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:The `save_format` argument is deprecated in Keras 3. We recommend removing this argument as it can be inferred from the file path. Received: save_format=keras\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Finished: Croatia | MAE: 0.31 | RMSE: 0.34 | R²: 0.65\n",
      "Epoch 1/30\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/dejauhnaebeadle/School/MachineLearning/machine-learning-project/code/rain-prediction/.venv/lib/python3.11/site-packages/keras/src/layers/rnn/rnn.py:200: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
      "  super().__init__(**kwargs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m46/46\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 12ms/step - loss: 0.0871 - val_loss: 0.0115\n",
      "Epoch 2/30\n",
      "\u001b[1m46/46\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - loss: 0.0129 - val_loss: 0.0096\n",
      "Epoch 3/30\n",
      "\u001b[1m46/46\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - loss: 0.0113 - val_loss: 0.0055\n",
      "Epoch 4/30\n",
      "\u001b[1m46/46\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - loss: 0.0112 - val_loss: 0.0037\n",
      "Epoch 5/30\n",
      "\u001b[1m46/46\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - loss: 0.0087 - val_loss: 0.0081\n",
      "Epoch 6/30\n",
      "\u001b[1m46/46\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - loss: 0.0059 - val_loss: 0.0048\n",
      "Epoch 7/30\n",
      "\u001b[1m46/46\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - loss: 0.0063 - val_loss: 0.0056\n",
      "Epoch 8/30\n",
      "\u001b[1m46/46\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - loss: 0.0078 - val_loss: 0.0025\n",
      "Epoch 9/30\n",
      "\u001b[1m46/46\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - loss: 0.0060 - val_loss: 0.0030\n",
      "Epoch 10/30\n",
      "\u001b[1m46/46\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 0.0069 - val_loss: 0.0024\n",
      "Epoch 11/30\n",
      "\u001b[1m46/46\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 0.0055 - val_loss: 0.0050\n",
      "Epoch 12/30\n",
      "\u001b[1m46/46\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 0.0062 - val_loss: 0.0024\n",
      "Epoch 13/30\n",
      "\u001b[1m46/46\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - loss: 0.0051 - val_loss: 0.0022\n",
      "Epoch 14/30\n",
      "\u001b[1m46/46\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - loss: 0.0057 - val_loss: 0.0022\n",
      "Epoch 15/30\n",
      "\u001b[1m46/46\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - loss: 0.0052 - val_loss: 0.0022\n",
      "Epoch 16/30\n",
      "\u001b[1m46/46\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - loss: 0.0055 - val_loss: 0.0025\n",
      "Epoch 17/30\n",
      "\u001b[1m46/46\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - loss: 0.0042 - val_loss: 0.0029\n",
      "Epoch 18/30\n",
      "\u001b[1m46/46\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - loss: 0.0060 - val_loss: 0.0019\n",
      "Epoch 19/30\n",
      "\u001b[1m46/46\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 0.0042 - val_loss: 0.0026\n",
      "Epoch 20/30\n",
      "\u001b[1m46/46\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - loss: 0.0037 - val_loss: 0.0063\n",
      "Epoch 21/30\n",
      "\u001b[1m46/46\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - loss: 0.0053 - val_loss: 0.0018\n",
      "Epoch 22/30\n",
      "\u001b[1m46/46\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - loss: 0.0042 - val_loss: 0.0036\n",
      "Epoch 23/30\n",
      "\u001b[1m46/46\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - loss: 0.0035 - val_loss: 0.0049\n",
      "Epoch 24/30\n",
      "\u001b[1m46/46\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 0.0041 - val_loss: 0.0041\n",
      "Epoch 25/30\n",
      "\u001b[1m46/46\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 0.0030 - val_loss: 0.0033\n",
      "Epoch 26/30\n",
      "\u001b[1m46/46\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 0.0037 - val_loss: 0.0039\n",
      "Epoch 27/30\n",
      "\u001b[1m46/46\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 0.0024 - val_loss: 0.0035\n",
      "Epoch 28/30\n",
      "\u001b[1m46/46\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - loss: 0.0025 - val_loss: 0.0018\n",
      "Epoch 29/30\n",
      "\u001b[1m46/46\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - loss: 0.0030 - val_loss: 0.0020\n",
      "Epoch 30/30\n",
      "\u001b[1m46/46\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - loss: 0.0033 - val_loss: 0.0028\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:The `save_format` argument is deprecated in Keras 3. We recommend removing this argument as it can be inferred from the file path. Received: save_format=keras\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Finished: Cuba | MAE: 0.10 | RMSE: 0.13 | R²: 0.87\n",
      "Epoch 1/30\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/dejauhnaebeadle/School/MachineLearning/machine-learning-project/code/rain-prediction/.venv/lib/python3.11/site-packages/keras/src/layers/rnn/rnn.py:200: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
      "  super().__init__(**kwargs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m46/46\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 14ms/step - loss: 0.0632 - val_loss: 0.0063\n",
      "Epoch 2/30\n",
      "\u001b[1m46/46\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - loss: 0.0121 - val_loss: 0.0029\n",
      "Epoch 3/30\n",
      "\u001b[1m46/46\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - loss: 0.0093 - val_loss: 0.0031\n",
      "Epoch 4/30\n",
      "\u001b[1m46/46\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - loss: 0.0081 - val_loss: 0.0015\n",
      "Epoch 5/30\n",
      "\u001b[1m46/46\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 0.0062 - val_loss: 0.0073\n",
      "Epoch 6/30\n",
      "\u001b[1m46/46\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - loss: 0.0060 - val_loss: 0.0035\n",
      "Epoch 7/30\n",
      "\u001b[1m46/46\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - loss: 0.0051 - val_loss: 0.0023\n",
      "Epoch 8/30\n",
      "\u001b[1m46/46\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 0.0072 - val_loss: 0.0024\n",
      "Epoch 9/30\n",
      "\u001b[1m46/46\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - loss: 0.0057 - val_loss: 0.0022\n",
      "Epoch 10/30\n",
      "\u001b[1m46/46\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - loss: 0.0044 - val_loss: 0.0021\n",
      "Epoch 11/30\n",
      "\u001b[1m46/46\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - loss: 0.0052 - val_loss: 0.0035\n",
      "Epoch 12/30\n",
      "\u001b[1m46/46\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - loss: 0.0051 - val_loss: 0.0012\n",
      "Epoch 13/30\n",
      "\u001b[1m46/46\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - loss: 0.0054 - val_loss: 0.0012\n",
      "Epoch 14/30\n",
      "\u001b[1m46/46\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - loss: 0.0034 - val_loss: 0.0018\n",
      "Epoch 15/30\n",
      "\u001b[1m46/46\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - loss: 0.0030 - val_loss: 0.0014\n",
      "Epoch 16/30\n",
      "\u001b[1m46/46\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - loss: 0.0033 - val_loss: 0.0031\n",
      "Epoch 17/30\n",
      "\u001b[1m46/46\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - loss: 0.0037 - val_loss: 0.0021\n",
      "Epoch 18/30\n",
      "\u001b[1m46/46\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - loss: 0.0037 - val_loss: 0.0020\n",
      "Epoch 19/30\n",
      "\u001b[1m46/46\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - loss: 0.0038 - val_loss: 0.0010\n",
      "Epoch 20/30\n",
      "\u001b[1m46/46\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - loss: 0.0043 - val_loss: 0.0011\n",
      "Epoch 21/30\n",
      "\u001b[1m46/46\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 13ms/step - loss: 0.0030 - val_loss: 0.0020\n",
      "Epoch 22/30\n",
      "\u001b[1m46/46\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - loss: 0.0048 - val_loss: 0.0012\n",
      "Epoch 23/30\n",
      "\u001b[1m46/46\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - loss: 0.0036 - val_loss: 9.8685e-04\n",
      "Epoch 24/30\n",
      "\u001b[1m46/46\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - loss: 0.0032 - val_loss: 8.2589e-04\n",
      "Epoch 25/30\n",
      "\u001b[1m46/46\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - loss: 0.0036 - val_loss: 0.0014\n",
      "Epoch 26/30\n",
      "\u001b[1m46/46\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - loss: 0.0026 - val_loss: 0.0014\n",
      "Epoch 27/30\n",
      "\u001b[1m46/46\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - loss: 0.0034 - val_loss: 8.0748e-04\n",
      "Epoch 28/30\n",
      "\u001b[1m46/46\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - loss: 0.0031 - val_loss: 8.7282e-04\n",
      "Epoch 29/30\n",
      "\u001b[1m46/46\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - loss: 0.0029 - val_loss: 7.2901e-04\n",
      "Epoch 30/30\n",
      "\u001b[1m46/46\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - loss: 0.0029 - val_loss: 7.4179e-04\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:The `save_format` argument is deprecated in Keras 3. We recommend removing this argument as it can be inferred from the file path. Received: save_format=keras\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Finished: Cyprus | MAE: 0.05 | RMSE: 0.16 | R²: 0.83\n",
      "Epoch 1/30\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/dejauhnaebeadle/School/MachineLearning/machine-learning-project/code/rain-prediction/.venv/lib/python3.11/site-packages/keras/src/layers/rnn/rnn.py:200: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
      "  super().__init__(**kwargs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m46/46\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 11ms/step - loss: 0.0568 - val_loss: 0.0035\n",
      "Epoch 2/30\n",
      "\u001b[1m46/46\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 0.0072 - val_loss: 0.0053\n",
      "Epoch 3/30\n",
      "\u001b[1m46/46\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 0.0065 - val_loss: 0.0037\n",
      "Epoch 4/30\n",
      "\u001b[1m46/46\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 0.0070 - val_loss: 0.0038\n",
      "Epoch 5/30\n",
      "\u001b[1m46/46\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 0.0060 - val_loss: 0.0042\n",
      "Epoch 6/30\n",
      "\u001b[1m46/46\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 0.0047 - val_loss: 0.0027\n",
      "Epoch 7/30\n",
      "\u001b[1m46/46\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 0.0045 - val_loss: 0.0048\n",
      "Epoch 8/30\n",
      "\u001b[1m46/46\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 0.0039 - val_loss: 0.0052\n",
      "Epoch 9/30\n",
      "\u001b[1m46/46\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 0.0039 - val_loss: 0.0021\n",
      "Epoch 10/30\n",
      "\u001b[1m46/46\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 0.0041 - val_loss: 0.0030\n",
      "Epoch 11/30\n",
      "\u001b[1m46/46\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 0.0037 - val_loss: 0.0025\n",
      "Epoch 12/30\n",
      "\u001b[1m46/46\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 0.0033 - val_loss: 0.0025\n",
      "Epoch 13/30\n",
      "\u001b[1m46/46\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 0.0033 - val_loss: 0.0023\n",
      "Epoch 14/30\n",
      "\u001b[1m46/46\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 0.0034 - val_loss: 0.0024\n",
      "Epoch 15/30\n",
      "\u001b[1m46/46\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - loss: 0.0034 - val_loss: 0.0022\n",
      "Epoch 16/30\n",
      "\u001b[1m46/46\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - loss: 0.0032 - val_loss: 0.0012\n",
      "Epoch 17/30\n",
      "\u001b[1m46/46\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - loss: 0.0037 - val_loss: 0.0019\n",
      "Epoch 18/30\n",
      "\u001b[1m46/46\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 0.0035 - val_loss: 0.0012\n",
      "Epoch 19/30\n",
      "\u001b[1m46/46\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - loss: 0.0037 - val_loss: 0.0019\n",
      "Epoch 20/30\n",
      "\u001b[1m46/46\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - loss: 0.0026 - val_loss: 0.0014\n",
      "Epoch 21/30\n",
      "\u001b[1m46/46\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - loss: 0.0024 - val_loss: 0.0021\n",
      "Epoch 22/30\n",
      "\u001b[1m46/46\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 0.0030 - val_loss: 0.0020\n",
      "Epoch 23/30\n",
      "\u001b[1m46/46\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 0.0027 - val_loss: 0.0011\n",
      "Epoch 24/30\n",
      "\u001b[1m46/46\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - loss: 0.0024 - val_loss: 0.0035\n",
      "Epoch 25/30\n",
      "\u001b[1m46/46\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - loss: 0.0027 - val_loss: 0.0014\n",
      "Epoch 26/30\n",
      "\u001b[1m46/46\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - loss: 0.0025 - val_loss: 0.0014\n",
      "Epoch 27/30\n",
      "\u001b[1m46/46\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - loss: 0.0028 - val_loss: 0.0011\n",
      "Epoch 28/30\n",
      "\u001b[1m46/46\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 0.0021 - val_loss: 9.4706e-04\n",
      "Epoch 29/30\n",
      "\u001b[1m46/46\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - loss: 0.0019 - val_loss: 0.0033\n",
      "Epoch 30/30\n",
      "\u001b[1m46/46\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - loss: 0.0029 - val_loss: 9.5409e-04\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:The `save_format` argument is deprecated in Keras 3. We recommend removing this argument as it can be inferred from the file path. Received: save_format=keras\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Finished: Czechia | MAE: 0.14 | RMSE: 0.26 | R²: 0.89\n",
      "Epoch 1/30\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/dejauhnaebeadle/School/MachineLearning/machine-learning-project/code/rain-prediction/.venv/lib/python3.11/site-packages/keras/src/layers/rnn/rnn.py:200: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
      "  super().__init__(**kwargs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m46/46\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 17ms/step - loss: 0.0291 - val_loss: 0.0068\n",
      "Epoch 2/30\n",
      "\u001b[1m46/46\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - loss: 0.0044 - val_loss: 0.0030\n",
      "Epoch 3/30\n",
      "\u001b[1m46/46\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - loss: 0.0045 - val_loss: 0.0065\n",
      "Epoch 4/30\n",
      "\u001b[1m46/46\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - loss: 0.0038 - val_loss: 0.0042\n",
      "Epoch 5/30\n",
      "\u001b[1m46/46\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - loss: 0.0031 - val_loss: 0.0020\n",
      "Epoch 6/30\n",
      "\u001b[1m46/46\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - loss: 0.0027 - val_loss: 0.0037\n",
      "Epoch 7/30\n",
      "\u001b[1m46/46\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - loss: 0.0029 - val_loss: 0.0046\n",
      "Epoch 8/30\n",
      "\u001b[1m46/46\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - loss: 0.0027 - val_loss: 0.0017\n",
      "Epoch 9/30\n",
      "\u001b[1m46/46\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - loss: 0.0026 - val_loss: 0.0022\n",
      "Epoch 10/30\n",
      "\u001b[1m46/46\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - loss: 0.0022 - val_loss: 0.0015\n",
      "Epoch 11/30\n",
      "\u001b[1m46/46\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - loss: 0.0019 - val_loss: 0.0013\n",
      "Epoch 12/30\n",
      "\u001b[1m46/46\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - loss: 0.0018 - val_loss: 0.0021\n",
      "Epoch 13/30\n",
      "\u001b[1m46/46\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - loss: 0.0018 - val_loss: 9.6433e-04\n",
      "Epoch 14/30\n",
      "\u001b[1m46/46\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - loss: 0.0016 - val_loss: 6.2492e-04\n",
      "Epoch 15/30\n",
      "\u001b[1m46/46\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 0.0018 - val_loss: 5.7588e-04\n",
      "Epoch 16/30\n",
      "\u001b[1m46/46\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 0.0017 - val_loss: 7.8025e-04\n",
      "Epoch 17/30\n",
      "\u001b[1m46/46\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - loss: 0.0016 - val_loss: 5.4915e-04\n",
      "Epoch 18/30\n",
      "\u001b[1m46/46\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - loss: 0.0014 - val_loss: 7.3059e-04\n",
      "Epoch 19/30\n",
      "\u001b[1m46/46\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - loss: 0.0013 - val_loss: 0.0010\n",
      "Epoch 20/30\n",
      "\u001b[1m46/46\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - loss: 0.0015 - val_loss: 8.9124e-04\n",
      "Epoch 21/30\n",
      "\u001b[1m46/46\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 0.0015 - val_loss: 6.6473e-04\n",
      "Epoch 22/30\n",
      "\u001b[1m46/46\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - loss: 0.0018 - val_loss: 4.9510e-04\n",
      "Epoch 23/30\n",
      "\u001b[1m46/46\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - loss: 0.0016 - val_loss: 5.5570e-04\n",
      "Epoch 24/30\n",
      "\u001b[1m46/46\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - loss: 8.5855e-04 - val_loss: 0.0012\n",
      "Epoch 25/30\n",
      "\u001b[1m46/46\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 7ms/step - loss: 0.0015 - val_loss: 0.0013\n",
      "Epoch 26/30\n",
      "\u001b[1m46/46\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - loss: 0.0016 - val_loss: 6.8460e-04\n",
      "Epoch 27/30\n",
      "\u001b[1m46/46\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - loss: 0.0011 - val_loss: 6.0186e-04\n",
      "Epoch 28/30\n",
      "\u001b[1m46/46\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 10ms/step - loss: 0.0014 - val_loss: 5.2997e-04\n",
      "Epoch 29/30\n",
      "\u001b[1m46/46\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - loss: 8.9809e-04 - val_loss: 0.0014\n",
      "Epoch 30/30\n",
      "\u001b[1m46/46\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - loss: 0.0018 - val_loss: 5.8670e-04\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:The `save_format` argument is deprecated in Keras 3. We recommend removing this argument as it can be inferred from the file path. Received: save_format=keras\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Finished: Democratic Republic of Congo | MAE: 0.12 | RMSE: 0.14 | R²: 0.85\n",
      "Epoch 1/30\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/dejauhnaebeadle/School/MachineLearning/machine-learning-project/code/rain-prediction/.venv/lib/python3.11/site-packages/keras/src/layers/rnn/rnn.py:200: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
      "  super().__init__(**kwargs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m46/46\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 13ms/step - loss: 0.0583 - val_loss: 0.0060\n",
      "Epoch 2/30\n",
      "\u001b[1m46/46\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 0.0144 - val_loss: 0.0062\n",
      "Epoch 3/30\n",
      "\u001b[1m46/46\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - loss: 0.0144 - val_loss: 0.0029\n",
      "Epoch 4/30\n",
      "\u001b[1m46/46\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - loss: 0.0111 - val_loss: 0.0067\n",
      "Epoch 5/30\n",
      "\u001b[1m46/46\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - loss: 0.0105 - val_loss: 0.0049\n",
      "Epoch 6/30\n",
      "\u001b[1m46/46\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - loss: 0.0086 - val_loss: 0.0032\n",
      "Epoch 7/30\n",
      "\u001b[1m46/46\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - loss: 0.0073 - val_loss: 0.0043\n",
      "Epoch 8/30\n",
      "\u001b[1m46/46\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 0.0084 - val_loss: 0.0032\n",
      "Epoch 9/30\n",
      "\u001b[1m46/46\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 0.0082 - val_loss: 0.0041\n",
      "Epoch 10/30\n",
      "\u001b[1m46/46\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 0.0069 - val_loss: 0.0034\n",
      "Epoch 11/30\n",
      "\u001b[1m46/46\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - loss: 0.0070 - val_loss: 0.0090\n",
      "Epoch 12/30\n",
      "\u001b[1m46/46\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - loss: 0.0071 - val_loss: 0.0029\n",
      "Epoch 13/30\n",
      "\u001b[1m46/46\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 0.0055 - val_loss: 0.0027\n",
      "Epoch 14/30\n",
      "\u001b[1m46/46\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - loss: 0.0065 - val_loss: 0.0027\n",
      "Epoch 15/30\n",
      "\u001b[1m46/46\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 0.0066 - val_loss: 0.0024\n",
      "Epoch 16/30\n",
      "\u001b[1m46/46\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 0.0069 - val_loss: 0.0019\n",
      "Epoch 17/30\n",
      "\u001b[1m46/46\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 0.0072 - val_loss: 0.0016\n",
      "Epoch 18/30\n",
      "\u001b[1m46/46\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 0.0069 - val_loss: 0.0017\n",
      "Epoch 19/30\n",
      "\u001b[1m46/46\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 0.0068 - val_loss: 0.0016\n",
      "Epoch 20/30\n",
      "\u001b[1m46/46\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 0.0062 - val_loss: 0.0018\n",
      "Epoch 21/30\n",
      "\u001b[1m46/46\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 0.0052 - val_loss: 0.0017\n",
      "Epoch 22/30\n",
      "\u001b[1m46/46\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - loss: 0.0057 - val_loss: 0.0015\n",
      "Epoch 23/30\n",
      "\u001b[1m46/46\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 0.0051 - val_loss: 0.0052\n",
      "Epoch 24/30\n",
      "\u001b[1m46/46\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 0.0058 - val_loss: 0.0020\n",
      "Epoch 25/30\n",
      "\u001b[1m46/46\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 0.0041 - val_loss: 0.0045\n",
      "Epoch 26/30\n",
      "\u001b[1m46/46\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 0.0068 - val_loss: 0.0018\n",
      "Epoch 27/30\n",
      "\u001b[1m46/46\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 0.0046 - val_loss: 0.0025\n",
      "Epoch 28/30\n",
      "\u001b[1m46/46\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 0.0050 - val_loss: 0.0021\n",
      "Epoch 29/30\n",
      "\u001b[1m46/46\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - loss: 0.0054 - val_loss: 0.0015\n",
      "Epoch 30/30\n",
      "\u001b[1m46/46\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - loss: 0.0044 - val_loss: 0.0022\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:The `save_format` argument is deprecated in Keras 3. We recommend removing this argument as it can be inferred from the file path. Received: save_format=keras\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Finished: Denmark | MAE: 0.15 | RMSE: 0.28 | R²: 0.85\n",
      "Epoch 1/30\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/dejauhnaebeadle/School/MachineLearning/machine-learning-project/code/rain-prediction/.venv/lib/python3.11/site-packages/keras/src/layers/rnn/rnn.py:200: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
      "  super().__init__(**kwargs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m46/46\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 15ms/step - loss: 0.0819 - val_loss: 6.5892e-04\n",
      "Epoch 2/30\n",
      "\u001b[1m46/46\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - loss: 0.0046 - val_loss: 9.6823e-04\n",
      "Epoch 3/30\n",
      "\u001b[1m46/46\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - loss: 0.0042 - val_loss: 8.4226e-04\n",
      "Epoch 4/30\n",
      "\u001b[1m46/46\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - loss: 0.0037 - val_loss: 8.2269e-04\n",
      "Epoch 5/30\n",
      "\u001b[1m46/46\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 7ms/step - loss: 0.0036 - val_loss: 5.8815e-04\n",
      "Epoch 6/30\n",
      "\u001b[1m46/46\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - loss: 0.0033 - val_loss: 5.7516e-04\n",
      "Epoch 7/30\n",
      "\u001b[1m46/46\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - loss: 0.0035 - val_loss: 6.2276e-04\n",
      "Epoch 8/30\n",
      "\u001b[1m46/46\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - loss: 0.0032 - val_loss: 8.7858e-04\n",
      "Epoch 9/30\n",
      "\u001b[1m46/46\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - loss: 0.0027 - val_loss: 7.3665e-04\n",
      "Epoch 10/30\n",
      "\u001b[1m46/46\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - loss: 0.0024 - val_loss: 4.8840e-04\n",
      "Epoch 11/30\n",
      "\u001b[1m46/46\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - loss: 0.0020 - val_loss: 0.0012\n",
      "Epoch 12/30\n",
      "\u001b[1m46/46\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - loss: 0.0028 - val_loss: 7.7169e-04\n",
      "Epoch 13/30\n",
      "\u001b[1m46/46\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 10ms/step - loss: 0.0023 - val_loss: 4.0132e-04\n",
      "Epoch 14/30\n",
      "\u001b[1m46/46\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - loss: 0.0024 - val_loss: 4.8307e-04\n",
      "Epoch 15/30\n",
      "\u001b[1m46/46\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - loss: 0.0022 - val_loss: 5.4775e-04\n",
      "Epoch 16/30\n",
      "\u001b[1m46/46\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - loss: 0.0025 - val_loss: 5.1185e-04\n",
      "Epoch 17/30\n",
      "\u001b[1m46/46\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - loss: 0.0023 - val_loss: 3.6887e-04\n",
      "Epoch 18/30\n",
      "\u001b[1m46/46\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - loss: 0.0024 - val_loss: 5.0321e-04\n",
      "Epoch 19/30\n",
      "\u001b[1m46/46\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - loss: 0.0028 - val_loss: 3.5697e-04\n",
      "Epoch 20/30\n",
      "\u001b[1m46/46\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - loss: 0.0019 - val_loss: 3.5589e-04\n",
      "Epoch 21/30\n",
      "\u001b[1m46/46\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - loss: 0.0021 - val_loss: 6.9122e-04\n",
      "Epoch 22/30\n",
      "\u001b[1m46/46\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - loss: 0.0022 - val_loss: 3.3632e-04\n",
      "Epoch 23/30\n",
      "\u001b[1m46/46\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - loss: 0.0024 - val_loss: 3.3445e-04\n",
      "Epoch 24/30\n",
      "\u001b[1m46/46\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - loss: 0.0017 - val_loss: 4.3294e-04\n",
      "Epoch 25/30\n",
      "\u001b[1m46/46\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - loss: 0.0019 - val_loss: 3.6670e-04\n",
      "Epoch 26/30\n",
      "\u001b[1m46/46\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - loss: 0.0018 - val_loss: 7.9790e-04\n",
      "Epoch 27/30\n",
      "\u001b[1m46/46\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - loss: 0.0015 - val_loss: 4.3706e-04\n",
      "Epoch 28/30\n",
      "\u001b[1m46/46\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - loss: 0.0018 - val_loss: 3.2256e-04\n",
      "Epoch 29/30\n",
      "\u001b[1m46/46\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - loss: 0.0013 - val_loss: 7.7929e-04\n",
      "Epoch 30/30\n",
      "\u001b[1m46/46\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - loss: 0.0019 - val_loss: 3.0649e-04\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:The `save_format` argument is deprecated in Keras 3. We recommend removing this argument as it can be inferred from the file path. Received: save_format=keras\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Finished: Djibouti | MAE: 0.05 | RMSE: 0.11 | R²: 0.94\n",
      "Epoch 1/30\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/dejauhnaebeadle/School/MachineLearning/machine-learning-project/code/rain-prediction/.venv/lib/python3.11/site-packages/keras/src/layers/rnn/rnn.py:200: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
      "  super().__init__(**kwargs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m46/46\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 16ms/step - loss: 0.0503 - val_loss: 0.0128\n",
      "Epoch 2/30\n",
      "\u001b[1m46/46\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - loss: 0.0090 - val_loss: 0.0083\n",
      "Epoch 3/30\n",
      "\u001b[1m46/46\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - loss: 0.0069 - val_loss: 0.0059\n",
      "Epoch 4/30\n",
      "\u001b[1m46/46\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - loss: 0.0072 - val_loss: 0.0070\n",
      "Epoch 5/30\n",
      "\u001b[1m46/46\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - loss: 0.0050 - val_loss: 0.0022\n",
      "Epoch 6/30\n",
      "\u001b[1m46/46\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - loss: 0.0041 - val_loss: 0.0039\n",
      "Epoch 7/30\n",
      "\u001b[1m46/46\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - loss: 0.0049 - val_loss: 0.0088\n",
      "Epoch 8/30\n",
      "\u001b[1m46/46\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - loss: 0.0051 - val_loss: 0.0029\n",
      "Epoch 9/30\n",
      "\u001b[1m46/46\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - loss: 0.0044 - val_loss: 0.0018\n",
      "Epoch 10/30\n",
      "\u001b[1m46/46\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 11ms/step - loss: 0.0037 - val_loss: 0.0015\n",
      "Epoch 11/30\n",
      "\u001b[1m46/46\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - loss: 0.0032 - val_loss: 0.0021\n",
      "Epoch 12/30\n",
      "\u001b[1m46/46\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - loss: 0.0037 - val_loss: 0.0013\n",
      "Epoch 13/30\n",
      "\u001b[1m46/46\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - loss: 0.0033 - val_loss: 0.0023\n",
      "Epoch 14/30\n",
      "\u001b[1m46/46\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - loss: 0.0026 - val_loss: 0.0011\n",
      "Epoch 15/30\n",
      "\u001b[1m46/46\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - loss: 0.0023 - val_loss: 0.0044\n",
      "Epoch 16/30\n",
      "\u001b[1m46/46\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - loss: 0.0032 - val_loss: 0.0010\n",
      "Epoch 17/30\n",
      "\u001b[1m46/46\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - loss: 0.0028 - val_loss: 0.0011\n",
      "Epoch 18/30\n",
      "\u001b[1m46/46\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - loss: 0.0021 - val_loss: 0.0025\n",
      "Epoch 19/30\n",
      "\u001b[1m46/46\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - loss: 0.0023 - val_loss: 0.0013\n",
      "Epoch 20/30\n",
      "\u001b[1m46/46\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - loss: 0.0027 - val_loss: 0.0017\n",
      "Epoch 21/30\n",
      "\u001b[1m46/46\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - loss: 0.0020 - val_loss: 9.2570e-04\n",
      "Epoch 22/30\n",
      "\u001b[1m46/46\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - loss: 0.0017 - val_loss: 0.0016\n",
      "Epoch 23/30\n",
      "\u001b[1m46/46\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - loss: 0.0021 - val_loss: 8.7902e-04\n",
      "Epoch 24/30\n",
      "\u001b[1m46/46\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - loss: 0.0025 - val_loss: 8.8119e-04\n",
      "Epoch 25/30\n",
      "\u001b[1m46/46\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - loss: 0.0025 - val_loss: 0.0011\n",
      "Epoch 26/30\n",
      "\u001b[1m46/46\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - loss: 0.0026 - val_loss: 0.0012\n",
      "Epoch 27/30\n",
      "\u001b[1m46/46\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - loss: 0.0016 - val_loss: 0.0036\n",
      "Epoch 28/30\n",
      "\u001b[1m46/46\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - loss: 0.0022 - val_loss: 0.0023\n",
      "Epoch 29/30\n",
      "\u001b[1m46/46\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 0.0021 - val_loss: 0.0018\n",
      "Epoch 30/30\n",
      "\u001b[1m46/46\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - loss: 0.0021 - val_loss: 8.5128e-04\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:The `save_format` argument is deprecated in Keras 3. We recommend removing this argument as it can be inferred from the file path. Received: save_format=keras\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Finished: Dominican Republic | MAE: 0.05 | RMSE: 0.09 | R²: 0.93\n",
      "Epoch 1/30\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/dejauhnaebeadle/School/MachineLearning/machine-learning-project/code/rain-prediction/.venv/lib/python3.11/site-packages/keras/src/layers/rnn/rnn.py:200: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
      "  super().__init__(**kwargs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m46/46\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 12ms/step - loss: 0.0604 - val_loss: 0.0124\n",
      "Epoch 2/30\n",
      "\u001b[1m46/46\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 0.0088 - val_loss: 0.0097\n",
      "Epoch 3/30\n",
      "\u001b[1m46/46\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - loss: 0.0080 - val_loss: 0.0100\n",
      "Epoch 4/30\n",
      "\u001b[1m46/46\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - loss: 0.0066 - val_loss: 0.0092\n",
      "Epoch 5/30\n",
      "\u001b[1m46/46\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - loss: 0.0065 - val_loss: 0.0056\n",
      "Epoch 6/30\n",
      "\u001b[1m46/46\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - loss: 0.0057 - val_loss: 0.0082\n",
      "Epoch 7/30\n",
      "\u001b[1m46/46\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 0.0041 - val_loss: 0.0056\n",
      "Epoch 8/30\n",
      "\u001b[1m46/46\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 0.0047 - val_loss: 0.0047\n",
      "Epoch 9/30\n",
      "\u001b[1m46/46\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - loss: 0.0043 - val_loss: 0.0048\n",
      "Epoch 10/30\n",
      "\u001b[1m46/46\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 0.0039 - val_loss: 0.0046\n",
      "Epoch 11/30\n",
      "\u001b[1m46/46\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 0.0042 - val_loss: 0.0041\n",
      "Epoch 12/30\n",
      "\u001b[1m46/46\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 0.0038 - val_loss: 0.0047\n",
      "Epoch 13/30\n",
      "\u001b[1m46/46\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 0.0035 - val_loss: 0.0039\n",
      "Epoch 14/30\n",
      "\u001b[1m46/46\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 0.0032 - val_loss: 0.0036\n",
      "Epoch 15/30\n",
      "\u001b[1m46/46\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 0.0027 - val_loss: 0.0043\n",
      "Epoch 16/30\n",
      "\u001b[1m46/46\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - loss: 0.0033 - val_loss: 0.0037\n",
      "Epoch 17/30\n",
      "\u001b[1m46/46\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - loss: 0.0027 - val_loss: 0.0036\n",
      "Epoch 18/30\n",
      "\u001b[1m46/46\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - loss: 0.0028 - val_loss: 0.0034\n",
      "Epoch 19/30\n",
      "\u001b[1m46/46\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - loss: 0.0029 - val_loss: 0.0030\n",
      "Epoch 20/30\n",
      "\u001b[1m46/46\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - loss: 0.0027 - val_loss: 0.0034\n",
      "Epoch 21/30\n",
      "\u001b[1m46/46\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - loss: 0.0026 - val_loss: 0.0066\n",
      "Epoch 22/30\n",
      "\u001b[1m46/46\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 0.0026 - val_loss: 0.0028\n",
      "Epoch 23/30\n",
      "\u001b[1m46/46\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 0.0032 - val_loss: 0.0028\n",
      "Epoch 24/30\n",
      "\u001b[1m46/46\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 0.0037 - val_loss: 0.0028\n",
      "Epoch 25/30\n",
      "\u001b[1m46/46\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - loss: 0.0029 - val_loss: 0.0028\n",
      "Epoch 26/30\n",
      "\u001b[1m46/46\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 14ms/step - loss: 0.0025 - val_loss: 0.0045\n",
      "Epoch 27/30\n",
      "\u001b[1m46/46\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 13ms/step - loss: 0.0035 - val_loss: 0.0026\n",
      "Epoch 28/30\n",
      "\u001b[1m46/46\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 12ms/step - loss: 0.0022 - val_loss: 0.0030\n",
      "Epoch 29/30\n",
      "\u001b[1m46/46\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 10ms/step - loss: 0.0024 - val_loss: 0.0027\n",
      "Epoch 30/30\n",
      "\u001b[1m46/46\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - loss: 0.0019 - val_loss: 0.0037\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:The `save_format` argument is deprecated in Keras 3. We recommend removing this argument as it can be inferred from the file path. Received: save_format=keras\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Finished: East Timor | MAE: 0.12 | RMSE: 0.16 | R²: 0.72\n",
      "Epoch 1/30\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/dejauhnaebeadle/School/MachineLearning/machine-learning-project/code/rain-prediction/.venv/lib/python3.11/site-packages/keras/src/layers/rnn/rnn.py:200: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
      "  super().__init__(**kwargs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m46/46\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 12ms/step - loss: 0.0492 - val_loss: 0.0020\n",
      "Epoch 2/30\n",
      "\u001b[1m46/46\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 0.0078 - val_loss: 0.0035\n",
      "Epoch 3/30\n",
      "\u001b[1m46/46\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 0.0056 - val_loss: 0.0037\n",
      "Epoch 4/30\n",
      "\u001b[1m46/46\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 0.0054 - val_loss: 0.0022\n",
      "Epoch 5/30\n",
      "\u001b[1m46/46\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 0.0057 - val_loss: 0.0027\n",
      "Epoch 6/30\n",
      "\u001b[1m46/46\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - loss: 0.0044 - val_loss: 0.0016\n",
      "Epoch 7/30\n",
      "\u001b[1m46/46\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - loss: 0.0032 - val_loss: 0.0020\n",
      "Epoch 8/30\n",
      "\u001b[1m46/46\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - loss: 0.0037 - val_loss: 0.0012\n",
      "Epoch 9/30\n",
      "\u001b[1m46/46\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - loss: 0.0037 - val_loss: 0.0012\n",
      "Epoch 10/30\n",
      "\u001b[1m46/46\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - loss: 0.0042 - val_loss: 0.0014\n",
      "Epoch 11/30\n",
      "\u001b[1m46/46\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - loss: 0.0033 - val_loss: 0.0011\n",
      "Epoch 12/30\n",
      "\u001b[1m46/46\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - loss: 0.0036 - val_loss: 0.0016\n",
      "Epoch 13/30\n",
      "\u001b[1m46/46\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - loss: 0.0023 - val_loss: 0.0012\n",
      "Epoch 14/30\n",
      "\u001b[1m46/46\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - loss: 0.0027 - val_loss: 0.0014\n",
      "Epoch 15/30\n",
      "\u001b[1m46/46\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - loss: 0.0025 - val_loss: 9.8456e-04\n",
      "Epoch 16/30\n",
      "\u001b[1m46/46\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - loss: 0.0029 - val_loss: 9.1281e-04\n",
      "Epoch 17/30\n",
      "\u001b[1m46/46\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - loss: 0.0026 - val_loss: 8.9332e-04\n",
      "Epoch 18/30\n",
      "\u001b[1m46/46\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - loss: 0.0032 - val_loss: 8.7914e-04\n",
      "Epoch 19/30\n",
      "\u001b[1m46/46\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - loss: 0.0025 - val_loss: 0.0010\n",
      "Epoch 20/30\n",
      "\u001b[1m46/46\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - loss: 0.0021 - val_loss: 8.3861e-04\n",
      "Epoch 21/30\n",
      "\u001b[1m46/46\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - loss: 0.0018 - val_loss: 9.9445e-04\n",
      "Epoch 22/30\n",
      "\u001b[1m46/46\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - loss: 0.0026 - val_loss: 8.1343e-04\n",
      "Epoch 23/30\n",
      "\u001b[1m46/46\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - loss: 0.0021 - val_loss: 7.9113e-04\n",
      "Epoch 24/30\n",
      "\u001b[1m46/46\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - loss: 0.0020 - val_loss: 8.3718e-04\n",
      "Epoch 25/30\n",
      "\u001b[1m46/46\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - loss: 0.0023 - val_loss: 0.0020\n",
      "Epoch 26/30\n",
      "\u001b[1m46/46\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - loss: 0.0027 - val_loss: 0.0014\n",
      "Epoch 27/30\n",
      "\u001b[1m46/46\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - loss: 0.0017 - val_loss: 7.3559e-04\n",
      "Epoch 28/30\n",
      "\u001b[1m46/46\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - loss: 0.0023 - val_loss: 8.5651e-04\n",
      "Epoch 29/30\n",
      "\u001b[1m46/46\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - loss: 0.0018 - val_loss: 0.0012\n",
      "Epoch 30/30\n",
      "\u001b[1m46/46\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - loss: 0.0019 - val_loss: 9.8521e-04\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:The `save_format` argument is deprecated in Keras 3. We recommend removing this argument as it can be inferred from the file path. Received: save_format=keras\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Finished: Ecuador | MAE: 0.08 | RMSE: 0.12 | R²: 0.88\n",
      "Epoch 1/30\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/dejauhnaebeadle/School/MachineLearning/machine-learning-project/code/rain-prediction/.venv/lib/python3.11/site-packages/keras/src/layers/rnn/rnn.py:200: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
      "  super().__init__(**kwargs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m46/46\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 14ms/step - loss: 0.0621 - val_loss: 0.0064\n",
      "Epoch 2/30\n",
      "\u001b[1m46/46\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - loss: 0.0072 - val_loss: 0.0081\n",
      "Epoch 3/30\n",
      "\u001b[1m46/46\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - loss: 0.0072 - val_loss: 0.0024\n",
      "Epoch 4/30\n",
      "\u001b[1m46/46\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - loss: 0.0060 - val_loss: 0.0109\n",
      "Epoch 5/30\n",
      "\u001b[1m46/46\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - loss: 0.0052 - val_loss: 6.0962e-04\n",
      "Epoch 6/30\n",
      "\u001b[1m46/46\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 10ms/step - loss: 0.0046 - val_loss: 0.0057\n",
      "Epoch 7/30\n",
      "\u001b[1m46/46\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 10ms/step - loss: 0.0039 - val_loss: 8.9870e-04\n",
      "Epoch 8/30\n",
      "\u001b[1m46/46\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - loss: 0.0040 - val_loss: 0.0038\n",
      "Epoch 9/30\n",
      "\u001b[1m46/46\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 14ms/step - loss: 0.0039 - val_loss: 0.0013\n",
      "Epoch 10/30\n",
      "\u001b[1m46/46\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - loss: 0.0037 - val_loss: 0.0020\n",
      "Epoch 11/30\n",
      "\u001b[1m46/46\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 11ms/step - loss: 0.0030 - val_loss: 0.0036\n",
      "Epoch 12/30\n",
      "\u001b[1m46/46\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - loss: 0.0035 - val_loss: 5.4865e-04\n",
      "Epoch 13/30\n",
      "\u001b[1m46/46\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - loss: 0.0023 - val_loss: 0.0035\n",
      "Epoch 14/30\n",
      "\u001b[1m46/46\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - loss: 0.0034 - val_loss: 0.0016\n",
      "Epoch 15/30\n",
      "\u001b[1m46/46\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - loss: 0.0025 - val_loss: 7.1901e-04\n",
      "Epoch 16/30\n",
      "\u001b[1m46/46\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 11ms/step - loss: 0.0021 - val_loss: 0.0015\n",
      "Epoch 17/30\n",
      "\u001b[1m46/46\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - loss: 0.0035 - val_loss: 2.4852e-04\n",
      "Epoch 18/30\n",
      "\u001b[1m46/46\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - loss: 0.0024 - val_loss: 9.1309e-04\n",
      "Epoch 19/30\n",
      "\u001b[1m46/46\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - loss: 0.0022 - val_loss: 0.0010\n",
      "Epoch 20/30\n",
      "\u001b[1m46/46\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - loss: 0.0023 - val_loss: 9.6184e-04\n",
      "Epoch 21/30\n",
      "\u001b[1m46/46\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - loss: 0.0025 - val_loss: 1.6539e-04\n",
      "Epoch 22/30\n",
      "\u001b[1m46/46\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - loss: 0.0034 - val_loss: 1.8543e-04\n",
      "Epoch 23/30\n",
      "\u001b[1m46/46\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - loss: 0.0020 - val_loss: 8.5842e-04\n",
      "Epoch 24/30\n",
      "\u001b[1m46/46\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - loss: 0.0015 - val_loss: 0.0011\n",
      "Epoch 25/30\n",
      "\u001b[1m46/46\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - loss: 0.0021 - val_loss: 3.7667e-04\n",
      "Epoch 26/30\n",
      "\u001b[1m46/46\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - loss: 0.0023 - val_loss: 3.1588e-04\n",
      "Epoch 27/30\n",
      "\u001b[1m46/46\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - loss: 0.0019 - val_loss: 0.0011\n",
      "Epoch 28/30\n",
      "\u001b[1m46/46\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 13ms/step - loss: 0.0016 - val_loss: 0.0038\n",
      "Epoch 29/30\n",
      "\u001b[1m46/46\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 12ms/step - loss: 0.0025 - val_loss: 2.1643e-04\n",
      "Epoch 30/30\n",
      "\u001b[1m46/46\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - loss: 0.0018 - val_loss: 8.2489e-04\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:The `save_format` argument is deprecated in Keras 3. We recommend removing this argument as it can be inferred from the file path. Received: save_format=keras\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Finished: Egypt | MAE: 0.17 | RMSE: 0.26 | R²: 0.69\n",
      "Epoch 1/30\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/dejauhnaebeadle/School/MachineLearning/machine-learning-project/code/rain-prediction/.venv/lib/python3.11/site-packages/keras/src/layers/rnn/rnn.py:200: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
      "  super().__init__(**kwargs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m46/46\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 18ms/step - loss: 0.0373 - val_loss: 0.0022\n",
      "Epoch 2/30\n",
      "\u001b[1m46/46\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - loss: 0.0057 - val_loss: 0.0021\n",
      "Epoch 3/30\n",
      "\u001b[1m46/46\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - loss: 0.0049 - val_loss: 0.0031\n",
      "Epoch 4/30\n",
      "\u001b[1m46/46\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - loss: 0.0054 - val_loss: 0.0018\n",
      "Epoch 5/30\n",
      "\u001b[1m46/46\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - loss: 0.0037 - val_loss: 0.0024\n",
      "Epoch 6/30\n",
      "\u001b[1m46/46\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - loss: 0.0030 - val_loss: 0.0025\n",
      "Epoch 7/30\n",
      "\u001b[1m46/46\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - loss: 0.0038 - val_loss: 0.0020\n",
      "Epoch 8/30\n",
      "\u001b[1m46/46\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - loss: 0.0034 - val_loss: 0.0025\n",
      "Epoch 9/30\n",
      "\u001b[1m46/46\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - loss: 0.0031 - val_loss: 0.0024\n",
      "Epoch 10/30\n",
      "\u001b[1m46/46\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - loss: 0.0026 - val_loss: 0.0023\n",
      "Epoch 11/30\n",
      "\u001b[1m46/46\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - loss: 0.0026 - val_loss: 0.0013\n",
      "Epoch 12/30\n",
      "\u001b[1m46/46\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 11ms/step - loss: 0.0026 - val_loss: 0.0015\n",
      "Epoch 13/30\n",
      "\u001b[1m46/46\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - loss: 0.0026 - val_loss: 0.0011\n",
      "Epoch 14/30\n",
      "\u001b[1m46/46\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - loss: 0.0022 - val_loss: 0.0014\n",
      "Epoch 15/30\n",
      "\u001b[1m46/46\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - loss: 0.0029 - val_loss: 0.0011\n",
      "Epoch 16/30\n",
      "\u001b[1m46/46\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - loss: 0.0025 - val_loss: 0.0017\n",
      "Epoch 17/30\n",
      "\u001b[1m46/46\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - loss: 0.0025 - val_loss: 0.0018\n",
      "Epoch 18/30\n",
      "\u001b[1m46/46\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - loss: 0.0023 - val_loss: 0.0012\n",
      "Epoch 19/30\n",
      "\u001b[1m46/46\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - loss: 0.0024 - val_loss: 0.0013\n",
      "Epoch 20/30\n",
      "\u001b[1m46/46\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - loss: 0.0021 - val_loss: 0.0010\n",
      "Epoch 21/30\n",
      "\u001b[1m46/46\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - loss: 0.0026 - val_loss: 0.0013\n",
      "Epoch 22/30\n",
      "\u001b[1m46/46\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - loss: 0.0027 - val_loss: 9.5588e-04\n",
      "Epoch 23/30\n",
      "\u001b[1m46/46\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - loss: 0.0024 - val_loss: 0.0016\n",
      "Epoch 24/30\n",
      "\u001b[1m46/46\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - loss: 0.0023 - val_loss: 0.0011\n",
      "Epoch 25/30\n",
      "\u001b[1m46/46\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - loss: 0.0027 - val_loss: 8.9460e-04\n",
      "Epoch 26/30\n",
      "\u001b[1m46/46\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - loss: 0.0025 - val_loss: 0.0012\n",
      "Epoch 27/30\n",
      "\u001b[1m46/46\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - loss: 0.0021 - val_loss: 9.5502e-04\n",
      "Epoch 28/30\n",
      "\u001b[1m46/46\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - loss: 0.0022 - val_loss: 9.4354e-04\n",
      "Epoch 29/30\n",
      "\u001b[1m46/46\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - loss: 0.0019 - val_loss: 9.9045e-04\n",
      "Epoch 30/30\n",
      "\u001b[1m46/46\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 10ms/step - loss: 0.0017 - val_loss: 0.0016\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:The `save_format` argument is deprecated in Keras 3. We recommend removing this argument as it can be inferred from the file path. Received: save_format=keras\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Finished: El Salvador | MAE: 0.17 | RMSE: 0.21 | R²: 0.79\n",
      "Epoch 1/30\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/dejauhnaebeadle/School/MachineLearning/machine-learning-project/code/rain-prediction/.venv/lib/python3.11/site-packages/keras/src/layers/rnn/rnn.py:200: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
      "  super().__init__(**kwargs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m46/46\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 16ms/step - loss: 0.0203 - val_loss: 0.0024\n",
      "Epoch 2/30\n",
      "\u001b[1m46/46\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - loss: 0.0036 - val_loss: 0.0013\n",
      "Epoch 3/30\n",
      "\u001b[1m46/46\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - loss: 0.0032 - val_loss: 0.0016\n",
      "Epoch 4/30\n",
      "\u001b[1m46/46\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - loss: 0.0029 - val_loss: 0.0017\n",
      "Epoch 5/30\n",
      "\u001b[1m46/46\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - loss: 0.0023 - val_loss: 0.0023\n",
      "Epoch 6/30\n",
      "\u001b[1m46/46\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - loss: 0.0022 - val_loss: 9.4969e-04\n",
      "Epoch 7/30\n",
      "\u001b[1m46/46\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - loss: 0.0021 - val_loss: 8.8001e-04\n",
      "Epoch 8/30\n",
      "\u001b[1m46/46\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - loss: 0.0024 - val_loss: 4.6525e-04\n",
      "Epoch 9/30\n",
      "\u001b[1m46/46\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - loss: 0.0018 - val_loss: 6.5781e-04\n",
      "Epoch 10/30\n",
      "\u001b[1m46/46\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - loss: 0.0015 - val_loss: 0.0027\n",
      "Epoch 11/30\n",
      "\u001b[1m46/46\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - loss: 0.0017 - val_loss: 6.8994e-04\n",
      "Epoch 12/30\n",
      "\u001b[1m46/46\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - loss: 0.0015 - val_loss: 0.0012\n",
      "Epoch 13/30\n",
      "\u001b[1m46/46\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - loss: 0.0018 - val_loss: 0.0013\n",
      "Epoch 14/30\n",
      "\u001b[1m46/46\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - loss: 0.0014 - val_loss: 7.0851e-04\n",
      "Epoch 15/30\n",
      "\u001b[1m46/46\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - loss: 0.0017 - val_loss: 6.3582e-04\n",
      "Epoch 16/30\n",
      "\u001b[1m46/46\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - loss: 0.0016 - val_loss: 0.0017\n",
      "Epoch 17/30\n",
      "\u001b[1m46/46\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - loss: 0.0018 - val_loss: 8.1560e-04\n",
      "Epoch 18/30\n",
      "\u001b[1m46/46\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - loss: 0.0013 - val_loss: 0.0026\n",
      "Epoch 19/30\n",
      "\u001b[1m46/46\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - loss: 0.0016 - val_loss: 3.4676e-04\n",
      "Epoch 20/30\n",
      "\u001b[1m46/46\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - loss: 0.0013 - val_loss: 0.0024\n",
      "Epoch 21/30\n",
      "\u001b[1m46/46\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - loss: 0.0014 - val_loss: 0.0024\n",
      "Epoch 22/30\n",
      "\u001b[1m46/46\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - loss: 0.0011 - val_loss: 3.4340e-04\n",
      "Epoch 23/30\n",
      "\u001b[1m46/46\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - loss: 9.7266e-04 - val_loss: 0.0011\n",
      "Epoch 24/30\n",
      "\u001b[1m46/46\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 14ms/step - loss: 0.0012 - val_loss: 7.7355e-04\n",
      "Epoch 25/30\n",
      "\u001b[1m46/46\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 12ms/step - loss: 0.0011 - val_loss: 0.0011\n",
      "Epoch 26/30\n",
      "\u001b[1m46/46\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 13ms/step - loss: 0.0016 - val_loss: 5.6157e-04\n",
      "Epoch 27/30\n",
      "\u001b[1m46/46\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - loss: 7.8454e-04 - val_loss: 0.0018\n",
      "Epoch 28/30\n",
      "\u001b[1m46/46\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - loss: 0.0016 - val_loss: 6.7516e-04\n",
      "Epoch 29/30\n",
      "\u001b[1m46/46\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - loss: 0.0018 - val_loss: 3.6304e-04\n",
      "Epoch 30/30\n",
      "\u001b[1m46/46\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - loss: 0.0014 - val_loss: 4.4291e-04\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:The `save_format` argument is deprecated in Keras 3. We recommend removing this argument as it can be inferred from the file path. Received: save_format=keras\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Finished: Equatorial Guinea | MAE: 0.07 | RMSE: 0.09 | R²: 0.91\n",
      "Epoch 1/30\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/dejauhnaebeadle/School/MachineLearning/machine-learning-project/code/rain-prediction/.venv/lib/python3.11/site-packages/keras/src/layers/rnn/rnn.py:200: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
      "  super().__init__(**kwargs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m46/46\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 15ms/step - loss: 0.0645 - val_loss: 8.7937e-04\n",
      "Epoch 2/30\n",
      "\u001b[1m46/46\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - loss: 0.0052 - val_loss: 9.0552e-04\n",
      "Epoch 3/30\n",
      "\u001b[1m46/46\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - loss: 0.0042 - val_loss: 8.3364e-04\n",
      "Epoch 4/30\n",
      "\u001b[1m46/46\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - loss: 0.0044 - val_loss: 6.9016e-04\n",
      "Epoch 5/30\n",
      "\u001b[1m46/46\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - loss: 0.0040 - val_loss: 0.0016\n",
      "Epoch 6/30\n",
      "\u001b[1m46/46\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - loss: 0.0045 - val_loss: 8.1128e-04\n",
      "Epoch 7/30\n",
      "\u001b[1m46/46\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - loss: 0.0038 - val_loss: 5.8232e-04\n",
      "Epoch 8/30\n",
      "\u001b[1m46/46\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - loss: 0.0038 - val_loss: 5.3927e-04\n",
      "Epoch 9/30\n",
      "\u001b[1m46/46\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 11ms/step - loss: 0.0029 - val_loss: 9.7241e-04\n",
      "Epoch 10/30\n",
      "\u001b[1m46/46\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 15ms/step - loss: 0.0033 - val_loss: 8.1499e-04\n",
      "Epoch 11/30\n",
      "\u001b[1m46/46\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - loss: 0.0032 - val_loss: 0.0013\n",
      "Epoch 12/30\n",
      "\u001b[1m46/46\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - loss: 0.0030 - val_loss: 7.9781e-04\n",
      "Epoch 13/30\n",
      "\u001b[1m46/46\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - loss: 0.0025 - val_loss: 9.0985e-04\n",
      "Epoch 14/30\n",
      "\u001b[1m46/46\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 12ms/step - loss: 0.0026 - val_loss: 0.0014\n",
      "Epoch 15/30\n",
      "\u001b[1m46/46\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - loss: 0.0028 - val_loss: 6.7561e-04\n",
      "Epoch 16/30\n",
      "\u001b[1m46/46\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - loss: 0.0020 - val_loss: 4.2960e-04\n",
      "Epoch 17/30\n",
      "\u001b[1m46/46\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 14ms/step - loss: 0.0025 - val_loss: 9.3246e-04\n",
      "Epoch 18/30\n",
      "\u001b[1m46/46\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 9ms/step - loss: 0.0023 - val_loss: 6.8772e-04\n",
      "Epoch 19/30\n",
      "\u001b[1m46/46\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - loss: 0.0026 - val_loss: 3.9706e-04\n",
      "Epoch 20/30\n",
      "\u001b[1m46/46\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - loss: 0.0021 - val_loss: 0.0012\n",
      "Epoch 21/30\n",
      "\u001b[1m46/46\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 11ms/step - loss: 0.0021 - val_loss: 0.0012\n",
      "Epoch 22/30\n",
      "\u001b[1m46/46\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - loss: 0.0020 - val_loss: 7.7448e-04\n",
      "Epoch 23/30\n",
      "\u001b[1m46/46\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - loss: 0.0024 - val_loss: 4.7420e-04\n",
      "Epoch 24/30\n",
      "\u001b[1m46/46\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - loss: 0.0022 - val_loss: 7.4560e-04\n",
      "Epoch 25/30\n",
      "\u001b[1m46/46\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 13ms/step - loss: 0.0030 - val_loss: 3.3823e-04\n",
      "Epoch 26/30\n",
      "\u001b[1m46/46\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - loss: 0.0017 - val_loss: 3.3409e-04\n",
      "Epoch 27/30\n",
      "\u001b[1m46/46\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - loss: 0.0018 - val_loss: 3.3291e-04\n",
      "Epoch 28/30\n",
      "\u001b[1m46/46\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - loss: 0.0018 - val_loss: 4.4054e-04\n",
      "Epoch 29/30\n",
      "\u001b[1m46/46\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - loss: 0.0018 - val_loss: 3.1582e-04\n",
      "Epoch 30/30\n",
      "\u001b[1m46/46\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - loss: 0.0015 - val_loss: 3.4754e-04\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:The `save_format` argument is deprecated in Keras 3. We recommend removing this argument as it can be inferred from the file path. Received: save_format=keras\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Finished: Eritrea | MAE: 0.06 | RMSE: 0.13 | R²: 0.83\n",
      "Epoch 1/30\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/dejauhnaebeadle/School/MachineLearning/machine-learning-project/code/rain-prediction/.venv/lib/python3.11/site-packages/keras/src/layers/rnn/rnn.py:200: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
      "  super().__init__(**kwargs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m46/46\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 16ms/step - loss: 0.0724 - val_loss: 0.0019\n",
      "Epoch 2/30\n",
      "\u001b[1m46/46\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - loss: 0.0129 - val_loss: 0.0057\n",
      "Epoch 3/30\n",
      "\u001b[1m46/46\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 12ms/step - loss: 0.0111 - val_loss: 0.0012\n",
      "Epoch 4/30\n",
      "\u001b[1m46/46\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 13ms/step - loss: 0.0085 - val_loss: 0.0034\n",
      "Epoch 5/30\n",
      "\u001b[1m46/46\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - loss: 0.0069 - val_loss: 0.0054\n",
      "Epoch 6/30\n",
      "\u001b[1m46/46\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - loss: 0.0079 - val_loss: 0.0014\n",
      "Epoch 7/30\n",
      "\u001b[1m46/46\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - loss: 0.0067 - val_loss: 0.0018\n",
      "Epoch 8/30\n",
      "\u001b[1m46/46\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - loss: 0.0073 - val_loss: 0.0010\n",
      "Epoch 9/30\n",
      "\u001b[1m46/46\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - loss: 0.0072 - val_loss: 7.6458e-04\n",
      "Epoch 10/30\n",
      "\u001b[1m46/46\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - loss: 0.0070 - val_loss: 0.0012\n",
      "Epoch 11/30\n",
      "\u001b[1m46/46\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - loss: 0.0064 - val_loss: 0.0028\n",
      "Epoch 12/30\n",
      "\u001b[1m46/46\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 11ms/step - loss: 0.0066 - val_loss: 0.0011\n",
      "Epoch 13/30\n",
      "\u001b[1m46/46\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - loss: 0.0047 - val_loss: 9.1374e-04\n",
      "Epoch 14/30\n",
      "\u001b[1m46/46\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - loss: 0.0037 - val_loss: 0.0033\n",
      "Epoch 15/30\n",
      "\u001b[1m46/46\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - loss: 0.0046 - val_loss: 8.6610e-04\n",
      "Epoch 16/30\n",
      "\u001b[1m46/46\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - loss: 0.0045 - val_loss: 0.0017\n",
      "Epoch 17/30\n",
      "\u001b[1m46/46\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - loss: 0.0057 - val_loss: 6.0574e-04\n",
      "Epoch 18/30\n",
      "\u001b[1m46/46\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 10ms/step - loss: 0.0041 - val_loss: 5.8407e-04\n",
      "Epoch 19/30\n",
      "\u001b[1m46/46\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - loss: 0.0057 - val_loss: 7.5478e-04\n",
      "Epoch 20/30\n",
      "\u001b[1m46/46\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - loss: 0.0047 - val_loss: 0.0046\n",
      "Epoch 21/30\n",
      "\u001b[1m46/46\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - loss: 0.0061 - val_loss: 4.3379e-04\n",
      "Epoch 22/30\n",
      "\u001b[1m46/46\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - loss: 0.0054 - val_loss: 0.0011\n",
      "Epoch 23/30\n",
      "\u001b[1m46/46\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - loss: 0.0042 - val_loss: 4.7127e-04\n",
      "Epoch 24/30\n",
      "\u001b[1m46/46\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - loss: 0.0043 - val_loss: 7.9435e-04\n",
      "Epoch 25/30\n",
      "\u001b[1m46/46\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - loss: 0.0035 - val_loss: 0.0014\n",
      "Epoch 26/30\n",
      "\u001b[1m46/46\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - loss: 0.0034 - val_loss: 5.9189e-04\n",
      "Epoch 27/30\n",
      "\u001b[1m46/46\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 11ms/step - loss: 0.0036 - val_loss: 9.9784e-04\n",
      "Epoch 28/30\n",
      "\u001b[1m46/46\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 12ms/step - loss: 0.0032 - val_loss: 8.2286e-04\n",
      "Epoch 29/30\n",
      "\u001b[1m46/46\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - loss: 0.0042 - val_loss: 0.0032\n",
      "Epoch 30/30\n",
      "\u001b[1m46/46\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - loss: 0.0039 - val_loss: 0.0013\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:The `save_format` argument is deprecated in Keras 3. We recommend removing this argument as it can be inferred from the file path. Received: save_format=keras\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Finished: Estonia | MAE: 0.26 | RMSE: 0.36 | R²: 0.81\n",
      "Epoch 1/30\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/dejauhnaebeadle/School/MachineLearning/machine-learning-project/code/rain-prediction/.venv/lib/python3.11/site-packages/keras/src/layers/rnn/rnn.py:200: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
      "  super().__init__(**kwargs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m46/46\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 14ms/step - loss: 0.1046 - val_loss: 0.0084\n",
      "Epoch 2/30\n",
      "\u001b[1m46/46\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - loss: 0.0172 - val_loss: 0.0089\n",
      "Epoch 3/30\n",
      "\u001b[1m46/46\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - loss: 0.0127 - val_loss: 0.0089\n",
      "Epoch 4/30\n",
      "\u001b[1m46/46\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - loss: 0.0130 - val_loss: 0.0079\n",
      "Epoch 5/30\n",
      "\u001b[1m46/46\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - loss: 0.0121 - val_loss: 0.0052\n",
      "Epoch 6/30\n",
      "\u001b[1m46/46\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - loss: 0.0114 - val_loss: 0.0064\n",
      "Epoch 7/30\n",
      "\u001b[1m46/46\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 11ms/step - loss: 0.0074 - val_loss: 0.0058\n",
      "Epoch 8/30\n",
      "\u001b[1m46/46\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - loss: 0.0079 - val_loss: 0.0038\n",
      "Epoch 9/30\n",
      "\u001b[1m46/46\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - loss: 0.0062 - val_loss: 0.0069\n",
      "Epoch 10/30\n",
      "\u001b[1m46/46\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - loss: 0.0058 - val_loss: 0.0051\n",
      "Epoch 11/30\n",
      "\u001b[1m46/46\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - loss: 0.0072 - val_loss: 0.0044\n",
      "Epoch 12/30\n",
      "\u001b[1m46/46\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - loss: 0.0067 - val_loss: 0.0045\n",
      "Epoch 13/30\n",
      "\u001b[1m46/46\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - loss: 0.0071 - val_loss: 0.0038\n",
      "Epoch 14/30\n",
      "\u001b[1m46/46\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - loss: 0.0069 - val_loss: 0.0037\n",
      "Epoch 15/30\n",
      "\u001b[1m46/46\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - loss: 0.0058 - val_loss: 0.0032\n",
      "Epoch 16/30\n",
      "\u001b[1m46/46\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - loss: 0.0050 - val_loss: 0.0029\n",
      "Epoch 17/30\n",
      "\u001b[1m46/46\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - loss: 0.0045 - val_loss: 0.0028\n",
      "Epoch 18/30\n",
      "\u001b[1m46/46\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - loss: 0.0048 - val_loss: 0.0026\n",
      "Epoch 19/30\n",
      "\u001b[1m46/46\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - loss: 0.0062 - val_loss: 0.0028\n",
      "Epoch 20/30\n",
      "\u001b[1m46/46\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - loss: 0.0050 - val_loss: 0.0033\n",
      "Epoch 21/30\n",
      "\u001b[1m46/46\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - loss: 0.0049 - val_loss: 0.0027\n",
      "Epoch 22/30\n",
      "\u001b[1m46/46\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - loss: 0.0037 - val_loss: 0.0031\n",
      "Epoch 23/30\n",
      "\u001b[1m46/46\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - loss: 0.0050 - val_loss: 0.0029\n",
      "Epoch 24/30\n",
      "\u001b[1m46/46\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - loss: 0.0038 - val_loss: 0.0024\n",
      "Epoch 25/30\n",
      "\u001b[1m46/46\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - loss: 0.0037 - val_loss: 0.0025\n",
      "Epoch 26/30\n",
      "\u001b[1m46/46\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - loss: 0.0047 - val_loss: 0.0022\n",
      "Epoch 27/30\n",
      "\u001b[1m46/46\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - loss: 0.0039 - val_loss: 0.0028\n",
      "Epoch 28/30\n",
      "\u001b[1m46/46\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - loss: 0.0050 - val_loss: 0.0022\n",
      "Epoch 29/30\n",
      "\u001b[1m46/46\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - loss: 0.0066 - val_loss: 0.0022\n",
      "Epoch 30/30\n",
      "\u001b[1m46/46\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - loss: 0.0034 - val_loss: 0.0024\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:The `save_format` argument is deprecated in Keras 3. We recommend removing this argument as it can be inferred from the file path. Received: save_format=keras\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Finished: Eswatini | MAE: 0.09 | RMSE: 0.15 | R²: 0.85\n",
      "Epoch 1/30\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/dejauhnaebeadle/School/MachineLearning/machine-learning-project/code/rain-prediction/.venv/lib/python3.11/site-packages/keras/src/layers/rnn/rnn.py:200: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
      "  super().__init__(**kwargs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m46/46\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 15ms/step - loss: 0.1080 - val_loss: 0.0029\n",
      "Epoch 2/30\n",
      "\u001b[1m46/46\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - loss: 0.0051 - val_loss: 0.0024\n",
      "Epoch 3/30\n",
      "\u001b[1m46/46\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - loss: 0.0042 - val_loss: 0.0038\n",
      "Epoch 4/30\n",
      "\u001b[1m46/46\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - loss: 0.0045 - val_loss: 0.0019\n",
      "Epoch 5/30\n",
      "\u001b[1m46/46\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - loss: 0.0035 - val_loss: 0.0018\n",
      "Epoch 6/30\n",
      "\u001b[1m46/46\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - loss: 0.0035 - val_loss: 0.0011\n",
      "Epoch 7/30\n",
      "\u001b[1m46/46\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - loss: 0.0037 - val_loss: 0.0016\n",
      "Epoch 8/30\n",
      "\u001b[1m46/46\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - loss: 0.0030 - val_loss: 0.0010\n",
      "Epoch 9/30\n",
      "\u001b[1m46/46\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - loss: 0.0029 - val_loss: 0.0016\n",
      "Epoch 10/30\n",
      "\u001b[1m46/46\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - loss: 0.0025 - val_loss: 0.0013\n",
      "Epoch 11/30\n",
      "\u001b[1m46/46\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - loss: 0.0027 - val_loss: 8.9432e-04\n",
      "Epoch 12/30\n",
      "\u001b[1m46/46\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - loss: 0.0030 - val_loss: 9.4424e-04\n",
      "Epoch 13/30\n",
      "\u001b[1m46/46\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - loss: 0.0026 - val_loss: 0.0012\n",
      "Epoch 14/30\n",
      "\u001b[1m46/46\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - loss: 0.0027 - val_loss: 0.0015\n",
      "Epoch 15/30\n",
      "\u001b[1m46/46\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - loss: 0.0023 - val_loss: 0.0012\n",
      "Epoch 16/30\n",
      "\u001b[1m46/46\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - loss: 0.0024 - val_loss: 6.4281e-04\n",
      "Epoch 17/30\n",
      "\u001b[1m46/46\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - loss: 0.0025 - val_loss: 9.2820e-04\n",
      "Epoch 18/30\n",
      "\u001b[1m46/46\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - loss: 0.0021 - val_loss: 0.0019\n",
      "Epoch 19/30\n",
      "\u001b[1m46/46\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - loss: 0.0020 - val_loss: 9.9160e-04\n",
      "Epoch 20/30\n",
      "\u001b[1m46/46\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - loss: 0.0020 - val_loss: 6.4451e-04\n",
      "Epoch 21/30\n",
      "\u001b[1m46/46\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - loss: 0.0019 - val_loss: 5.8707e-04\n",
      "Epoch 22/30\n",
      "\u001b[1m46/46\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - loss: 0.0017 - val_loss: 6.0653e-04\n",
      "Epoch 23/30\n",
      "\u001b[1m46/46\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - loss: 0.0022 - val_loss: 8.6138e-04\n",
      "Epoch 24/30\n",
      "\u001b[1m46/46\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - loss: 0.0020 - val_loss: 5.7661e-04\n",
      "Epoch 25/30\n",
      "\u001b[1m46/46\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - loss: 0.0017 - val_loss: 0.0015\n",
      "Epoch 26/30\n",
      "\u001b[1m46/46\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - loss: 0.0021 - val_loss: 5.8592e-04\n",
      "Epoch 27/30\n",
      "\u001b[1m46/46\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - loss: 0.0020 - val_loss: 5.3869e-04\n",
      "Epoch 28/30\n",
      "\u001b[1m46/46\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - loss: 0.0022 - val_loss: 6.8555e-04\n",
      "Epoch 29/30\n",
      "\u001b[1m46/46\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - loss: 0.0017 - val_loss: 8.8199e-04\n",
      "Epoch 30/30\n",
      "\u001b[1m46/46\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - loss: 0.0019 - val_loss: 5.5854e-04\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:The `save_format` argument is deprecated in Keras 3. We recommend removing this argument as it can be inferred from the file path. Received: save_format=keras\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Finished: Ethiopia | MAE: 0.06 | RMSE: 0.11 | R²: 0.86\n",
      "Epoch 1/30\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/dejauhnaebeadle/School/MachineLearning/machine-learning-project/code/rain-prediction/.venv/lib/python3.11/site-packages/keras/src/layers/rnn/rnn.py:200: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
      "  super().__init__(**kwargs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m46/46\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 12ms/step - loss: 0.0912 - val_loss: 0.0251\n",
      "Epoch 2/30\n",
      "\u001b[1m46/46\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 0.0106 - val_loss: 0.0251\n",
      "Epoch 3/30\n",
      "\u001b[1m46/46\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 0.0107 - val_loss: 0.0217\n",
      "Epoch 4/30\n",
      "\u001b[1m46/46\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 0.0075 - val_loss: 0.0189\n",
      "Epoch 5/30\n",
      "\u001b[1m46/46\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 0.0075 - val_loss: 0.0157\n",
      "Epoch 6/30\n",
      "\u001b[1m46/46\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 0.0068 - val_loss: 0.0142\n",
      "Epoch 7/30\n",
      "\u001b[1m46/46\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 0.0062 - val_loss: 0.0177\n",
      "Epoch 8/30\n",
      "\u001b[1m46/46\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 0.0057 - val_loss: 0.0131\n",
      "Epoch 9/30\n",
      "\u001b[1m46/46\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 0.0059 - val_loss: 0.0126\n",
      "Epoch 10/30\n",
      "\u001b[1m46/46\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 0.0050 - val_loss: 0.0124\n",
      "Epoch 11/30\n",
      "\u001b[1m46/46\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - loss: 0.0051 - val_loss: 0.0119\n",
      "Epoch 12/30\n",
      "\u001b[1m46/46\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 0.0053 - val_loss: 0.0120\n",
      "Epoch 13/30\n",
      "\u001b[1m46/46\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 0.0052 - val_loss: 0.0112\n",
      "Epoch 14/30\n",
      "\u001b[1m46/46\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - loss: 0.0050 - val_loss: 0.0120\n",
      "Epoch 15/30\n",
      "\u001b[1m46/46\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 0.0041 - val_loss: 0.0110\n",
      "Epoch 16/30\n",
      "\u001b[1m46/46\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 0.0045 - val_loss: 0.0108\n",
      "Epoch 17/30\n",
      "\u001b[1m46/46\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - loss: 0.0045 - val_loss: 0.0102\n",
      "Epoch 18/30\n",
      "\u001b[1m46/46\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - loss: 0.0042 - val_loss: 0.0100\n",
      "Epoch 19/30\n",
      "\u001b[1m46/46\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 0.0051 - val_loss: 0.0108\n",
      "Epoch 20/30\n",
      "\u001b[1m46/46\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 0.0054 - val_loss: 0.0105\n",
      "Epoch 21/30\n",
      "\u001b[1m46/46\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 0.0042 - val_loss: 0.0095\n",
      "Epoch 22/30\n",
      "\u001b[1m46/46\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 0.0042 - val_loss: 0.0093\n",
      "Epoch 23/30\n",
      "\u001b[1m46/46\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - loss: 0.0036 - val_loss: 0.0090\n",
      "Epoch 24/30\n",
      "\u001b[1m46/46\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 0.0038 - val_loss: 0.0090\n",
      "Epoch 25/30\n",
      "\u001b[1m46/46\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - loss: 0.0039 - val_loss: 0.0087\n",
      "Epoch 26/30\n",
      "\u001b[1m46/46\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - loss: 0.0035 - val_loss: 0.0090\n",
      "Epoch 27/30\n",
      "\u001b[1m46/46\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 0.0034 - val_loss: 0.0085\n",
      "Epoch 28/30\n",
      "\u001b[1m46/46\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - loss: 0.0032 - val_loss: 0.0082\n",
      "Epoch 29/30\n",
      "\u001b[1m46/46\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 0.0031 - val_loss: 0.0087\n",
      "Epoch 30/30\n",
      "\u001b[1m46/46\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 0.0044 - val_loss: 0.0084\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:The `save_format` argument is deprecated in Keras 3. We recommend removing this argument as it can be inferred from the file path. Received: save_format=keras\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Finished: Falkland Islands | MAE: 0.08 | RMSE: 0.13 | R²: 0.86\n",
      "Epoch 1/30\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/dejauhnaebeadle/School/MachineLearning/machine-learning-project/code/rain-prediction/.venv/lib/python3.11/site-packages/keras/src/layers/rnn/rnn.py:200: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
      "  super().__init__(**kwargs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m46/46\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 10ms/step - loss: 0.1042 - val_loss: 0.0200\n",
      "Epoch 2/30\n",
      "\u001b[1m46/46\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 0.0117 - val_loss: 0.0265\n",
      "Epoch 3/30\n",
      "\u001b[1m46/46\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 0.0114 - val_loss: 0.0145\n",
      "Epoch 4/30\n",
      "\u001b[1m46/46\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 0.0102 - val_loss: 0.0195\n",
      "Epoch 5/30\n",
      "\u001b[1m46/46\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 0.0085 - val_loss: 0.0123\n",
      "Epoch 6/30\n",
      "\u001b[1m46/46\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 0.0072 - val_loss: 0.0162\n",
      "Epoch 7/30\n",
      "\u001b[1m46/46\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 0.0073 - val_loss: 0.0102\n",
      "Epoch 8/30\n",
      "\u001b[1m46/46\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 0.0077 - val_loss: 0.0153\n",
      "Epoch 9/30\n",
      "\u001b[1m46/46\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 0.0063 - val_loss: 0.0136\n",
      "Epoch 10/30\n",
      "\u001b[1m46/46\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 0.0068 - val_loss: 0.0121\n",
      "Epoch 11/30\n",
      "\u001b[1m46/46\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 0.0058 - val_loss: 0.0062\n",
      "Epoch 12/30\n",
      "\u001b[1m46/46\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 0.0068 - val_loss: 0.0112\n",
      "Epoch 13/30\n",
      "\u001b[1m46/46\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 0.0050 - val_loss: 0.0095\n",
      "Epoch 14/30\n",
      "\u001b[1m46/46\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 0.0049 - val_loss: 0.0054\n",
      "Epoch 15/30\n",
      "\u001b[1m46/46\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 0.0046 - val_loss: 0.0070\n",
      "Epoch 16/30\n",
      "\u001b[1m46/46\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 0.0046 - val_loss: 0.0078\n",
      "Epoch 17/30\n",
      "\u001b[1m46/46\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 0.0057 - val_loss: 0.0090\n",
      "Epoch 18/30\n",
      "\u001b[1m46/46\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - loss: 0.0053 - val_loss: 0.0064\n",
      "Epoch 19/30\n",
      "\u001b[1m46/46\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 0.0044 - val_loss: 0.0055\n",
      "Epoch 20/30\n",
      "\u001b[1m46/46\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 0.0041 - val_loss: 0.0051\n",
      "Epoch 21/30\n",
      "\u001b[1m46/46\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 0.0036 - val_loss: 0.0053\n",
      "Epoch 22/30\n",
      "\u001b[1m46/46\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 0.0034 - val_loss: 0.0069\n",
      "Epoch 23/30\n",
      "\u001b[1m46/46\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 0.0032 - val_loss: 0.0047\n",
      "Epoch 24/30\n",
      "\u001b[1m46/46\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 0.0031 - val_loss: 0.0100\n",
      "Epoch 25/30\n",
      "\u001b[1m46/46\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 0.0036 - val_loss: 0.0065\n",
      "Epoch 26/30\n",
      "\u001b[1m46/46\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 0.0045 - val_loss: 0.0075\n",
      "Epoch 27/30\n",
      "\u001b[1m46/46\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 0.0041 - val_loss: 0.0065\n",
      "Epoch 28/30\n",
      "\u001b[1m46/46\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 0.0031 - val_loss: 0.0074\n",
      "Epoch 29/30\n",
      "\u001b[1m46/46\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 0.0034 - val_loss: 0.0043\n",
      "Epoch 30/30\n",
      "\u001b[1m46/46\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 0.0039 - val_loss: 0.0056\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:The `save_format` argument is deprecated in Keras 3. We recommend removing this argument as it can be inferred from the file path. Received: save_format=keras\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Finished: Faroe Islands | MAE: 0.12 | RMSE: 0.17 | R²: 0.69\n",
      "Epoch 1/30\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/dejauhnaebeadle/School/MachineLearning/machine-learning-project/code/rain-prediction/.venv/lib/python3.11/site-packages/keras/src/layers/rnn/rnn.py:200: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
      "  super().__init__(**kwargs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m46/46\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 10ms/step - loss: 0.0362 - val_loss: 0.0099\n",
      "Epoch 2/30\n",
      "\u001b[1m46/46\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 0.0067 - val_loss: 0.0115\n",
      "Epoch 3/30\n",
      "\u001b[1m46/46\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 0.0053 - val_loss: 0.0115\n",
      "Epoch 4/30\n",
      "\u001b[1m46/46\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 0.0054 - val_loss: 0.0078\n",
      "Epoch 5/30\n",
      "\u001b[1m46/46\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 0.0040 - val_loss: 0.0074\n",
      "Epoch 6/30\n",
      "\u001b[1m46/46\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 0.0041 - val_loss: 0.0048\n",
      "Epoch 7/30\n",
      "\u001b[1m46/46\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 0.0032 - val_loss: 0.0051\n",
      "Epoch 8/30\n",
      "\u001b[1m46/46\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 0.0031 - val_loss: 0.0062\n",
      "Epoch 9/30\n",
      "\u001b[1m46/46\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 0.0033 - val_loss: 0.0097\n",
      "Epoch 10/30\n",
      "\u001b[1m46/46\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 0.0029 - val_loss: 0.0051\n",
      "Epoch 11/30\n",
      "\u001b[1m46/46\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - loss: 0.0021 - val_loss: 0.0042\n",
      "Epoch 12/30\n",
      "\u001b[1m46/46\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 0.0026 - val_loss: 0.0051\n",
      "Epoch 13/30\n",
      "\u001b[1m46/46\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - loss: 0.0031 - val_loss: 0.0041\n",
      "Epoch 14/30\n",
      "\u001b[1m46/46\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 0.0029 - val_loss: 0.0055\n",
      "Epoch 15/30\n",
      "\u001b[1m46/46\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - loss: 0.0027 - val_loss: 0.0041\n",
      "Epoch 16/30\n",
      "\u001b[1m46/46\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 0.0024 - val_loss: 0.0062\n",
      "Epoch 17/30\n",
      "\u001b[1m46/46\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 0.0026 - val_loss: 0.0045\n",
      "Epoch 18/30\n",
      "\u001b[1m46/46\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 0.0036 - val_loss: 0.0037\n",
      "Epoch 19/30\n",
      "\u001b[1m46/46\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - loss: 0.0025 - val_loss: 0.0034\n",
      "Epoch 20/30\n",
      "\u001b[1m46/46\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 0.0030 - val_loss: 0.0036\n",
      "Epoch 21/30\n",
      "\u001b[1m46/46\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - loss: 0.0034 - val_loss: 0.0048\n",
      "Epoch 22/30\n",
      "\u001b[1m46/46\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 0.0023 - val_loss: 0.0033\n",
      "Epoch 23/30\n",
      "\u001b[1m46/46\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 0.0018 - val_loss: 0.0036\n",
      "Epoch 24/30\n",
      "\u001b[1m46/46\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - loss: 0.0026 - val_loss: 0.0032\n",
      "Epoch 25/30\n",
      "\u001b[1m46/46\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 0.0017 - val_loss: 0.0037\n",
      "Epoch 26/30\n",
      "\u001b[1m46/46\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - loss: 0.0018 - val_loss: 0.0032\n",
      "Epoch 27/30\n",
      "\u001b[1m46/46\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - loss: 0.0027 - val_loss: 0.0048\n",
      "Epoch 28/30\n",
      "\u001b[1m46/46\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 0.0022 - val_loss: 0.0032\n",
      "Epoch 29/30\n",
      "\u001b[1m46/46\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - loss: 0.0019 - val_loss: 0.0042\n",
      "Epoch 30/30\n",
      "\u001b[1m46/46\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - loss: 0.0018 - val_loss: 0.0034\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:The `save_format` argument is deprecated in Keras 3. We recommend removing this argument as it can be inferred from the file path. Received: save_format=keras\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Finished: Fiji | MAE: 0.08 | RMSE: 0.12 | R²: 0.88\n",
      "Epoch 1/30\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/dejauhnaebeadle/School/MachineLearning/machine-learning-project/code/rain-prediction/.venv/lib/python3.11/site-packages/keras/src/layers/rnn/rnn.py:200: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
      "  super().__init__(**kwargs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m46/46\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 12ms/step - loss: 0.0512 - val_loss: 0.0020\n",
      "Epoch 2/30\n",
      "\u001b[1m46/46\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 0.0180 - val_loss: 0.0017\n",
      "Epoch 3/30\n",
      "\u001b[1m46/46\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - loss: 0.0144 - val_loss: 0.0020\n",
      "Epoch 4/30\n",
      "\u001b[1m46/46\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 0.0109 - val_loss: 0.0057\n",
      "Epoch 5/30\n",
      "\u001b[1m46/46\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 0.0101 - val_loss: 0.0023\n",
      "Epoch 6/30\n",
      "\u001b[1m46/46\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 0.0087 - val_loss: 0.0054\n",
      "Epoch 7/30\n",
      "\u001b[1m46/46\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 0.0100 - val_loss: 9.6698e-04\n",
      "Epoch 8/30\n",
      "\u001b[1m46/46\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 0.0077 - val_loss: 0.0022\n",
      "Epoch 9/30\n",
      "\u001b[1m46/46\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 0.0086 - val_loss: 0.0012\n",
      "Epoch 10/30\n",
      "\u001b[1m46/46\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - loss: 0.0071 - val_loss: 0.0010\n",
      "Epoch 11/30\n",
      "\u001b[1m46/46\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 0.0052 - val_loss: 0.0037\n",
      "Epoch 12/30\n",
      "\u001b[1m46/46\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - loss: 0.0068 - val_loss: 0.0027\n",
      "Epoch 13/30\n",
      "\u001b[1m46/46\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - loss: 0.0069 - val_loss: 9.8064e-04\n",
      "Epoch 14/30\n",
      "\u001b[1m46/46\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 0.0073 - val_loss: 0.0017\n",
      "Epoch 15/30\n",
      "\u001b[1m46/46\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - loss: 0.0076 - val_loss: 0.0044\n",
      "Epoch 16/30\n",
      "\u001b[1m46/46\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 0.0081 - val_loss: 4.1576e-04\n",
      "Epoch 17/30\n",
      "\u001b[1m46/46\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - loss: 0.0064 - val_loss: 9.2728e-04\n",
      "Epoch 18/30\n",
      "\u001b[1m46/46\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - loss: 0.0060 - val_loss: 6.1259e-04\n",
      "Epoch 19/30\n",
      "\u001b[1m46/46\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - loss: 0.0065 - val_loss: 0.0044\n",
      "Epoch 20/30\n",
      "\u001b[1m46/46\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - loss: 0.0066 - val_loss: 0.0011\n",
      "Epoch 21/30\n",
      "\u001b[1m46/46\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - loss: 0.0064 - val_loss: 4.9674e-04\n",
      "Epoch 22/30\n",
      "\u001b[1m46/46\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - loss: 0.0048 - val_loss: 0.0012\n",
      "Epoch 23/30\n",
      "\u001b[1m46/46\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - loss: 0.0060 - val_loss: 0.0013\n",
      "Epoch 24/30\n",
      "\u001b[1m46/46\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - loss: 0.0054 - val_loss: 8.5479e-04\n",
      "Epoch 25/30\n",
      "\u001b[1m46/46\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - loss: 0.0054 - val_loss: 0.0029\n",
      "Epoch 26/30\n",
      "\u001b[1m46/46\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - loss: 0.0055 - val_loss: 7.5848e-04\n",
      "Epoch 27/30\n",
      "\u001b[1m46/46\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - loss: 0.0073 - val_loss: 3.5712e-04\n",
      "Epoch 28/30\n",
      "\u001b[1m46/46\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - loss: 0.0056 - val_loss: 0.0013\n",
      "Epoch 29/30\n",
      "\u001b[1m46/46\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 0.0060 - val_loss: 4.1765e-04\n",
      "Epoch 30/30\n",
      "\u001b[1m46/46\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - loss: 0.0063 - val_loss: 0.0011\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:The `save_format` argument is deprecated in Keras 3. We recommend removing this argument as it can be inferred from the file path. Received: save_format=keras\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Finished: Finland | MAE: 0.22 | RMSE: 0.37 | R²: 0.79\n",
      "Epoch 1/30\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/dejauhnaebeadle/School/MachineLearning/machine-learning-project/code/rain-prediction/.venv/lib/python3.11/site-packages/keras/src/layers/rnn/rnn.py:200: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
      "  super().__init__(**kwargs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m46/46\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 11ms/step - loss: 0.0418 - val_loss: 0.0045\n",
      "Epoch 2/30\n",
      "\u001b[1m46/46\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 0.0093 - val_loss: 0.0075\n",
      "Epoch 3/30\n",
      "\u001b[1m46/46\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - loss: 0.0071 - val_loss: 0.0077\n",
      "Epoch 4/30\n",
      "\u001b[1m46/46\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - loss: 0.0064 - val_loss: 0.0035\n",
      "Epoch 5/30\n",
      "\u001b[1m46/46\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - loss: 0.0048 - val_loss: 0.0064\n",
      "Epoch 6/30\n",
      "\u001b[1m46/46\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 0.0045 - val_loss: 0.0028\n",
      "Epoch 7/30\n",
      "\u001b[1m46/46\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 0.0048 - val_loss: 0.0026\n",
      "Epoch 8/30\n",
      "\u001b[1m46/46\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 0.0050 - val_loss: 0.0058\n",
      "Epoch 9/30\n",
      "\u001b[1m46/46\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - loss: 0.0041 - val_loss: 0.0033\n",
      "Epoch 10/30\n",
      "\u001b[1m46/46\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - loss: 0.0035 - val_loss: 0.0021\n",
      "Epoch 11/30\n",
      "\u001b[1m46/46\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - loss: 0.0041 - val_loss: 0.0029\n",
      "Epoch 12/30\n",
      "\u001b[1m46/46\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - loss: 0.0039 - val_loss: 0.0051\n",
      "Epoch 13/30\n",
      "\u001b[1m46/46\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - loss: 0.0046 - val_loss: 0.0033\n",
      "Epoch 14/30\n",
      "\u001b[1m46/46\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 0.0032 - val_loss: 0.0020\n",
      "Epoch 15/30\n",
      "\u001b[1m46/46\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - loss: 0.0039 - val_loss: 0.0024\n",
      "Epoch 16/30\n",
      "\u001b[1m46/46\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - loss: 0.0037 - val_loss: 0.0020\n",
      "Epoch 17/30\n",
      "\u001b[1m46/46\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - loss: 0.0033 - val_loss: 0.0023\n",
      "Epoch 18/30\n",
      "\u001b[1m46/46\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 0.0037 - val_loss: 0.0045\n",
      "Epoch 19/30\n",
      "\u001b[1m46/46\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - loss: 0.0033 - val_loss: 0.0020\n",
      "Epoch 20/30\n",
      "\u001b[1m46/46\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 0.0029 - val_loss: 0.0017\n",
      "Epoch 21/30\n",
      "\u001b[1m46/46\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 0.0026 - val_loss: 0.0041\n",
      "Epoch 22/30\n",
      "\u001b[1m46/46\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 0.0035 - val_loss: 0.0017\n",
      "Epoch 23/30\n",
      "\u001b[1m46/46\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - loss: 0.0036 - val_loss: 0.0015\n",
      "Epoch 24/30\n",
      "\u001b[1m46/46\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - loss: 0.0030 - val_loss: 0.0020\n",
      "Epoch 25/30\n",
      "\u001b[1m46/46\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - loss: 0.0027 - val_loss: 0.0015\n",
      "Epoch 26/30\n",
      "\u001b[1m46/46\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 0.0029 - val_loss: 0.0014\n",
      "Epoch 27/30\n",
      "\u001b[1m46/46\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 0.0035 - val_loss: 0.0018\n",
      "Epoch 28/30\n",
      "\u001b[1m46/46\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 0.0025 - val_loss: 0.0026\n",
      "Epoch 29/30\n",
      "\u001b[1m46/46\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - loss: 0.0029 - val_loss: 0.0016\n",
      "Epoch 30/30\n",
      "\u001b[1m46/46\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - loss: 0.0023 - val_loss: 0.0014\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:The `save_format` argument is deprecated in Keras 3. We recommend removing this argument as it can be inferred from the file path. Received: save_format=keras\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Finished: France | MAE: 0.08 | RMSE: 0.22 | R²: 0.86\n",
      "Epoch 1/30\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/dejauhnaebeadle/School/MachineLearning/machine-learning-project/code/rain-prediction/.venv/lib/python3.11/site-packages/keras/src/layers/rnn/rnn.py:200: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
      "  super().__init__(**kwargs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m46/46\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 11ms/step - loss: 0.0576 - val_loss: 0.0123\n",
      "Epoch 2/30\n",
      "\u001b[1m46/46\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - loss: 0.0090 - val_loss: 0.0114\n",
      "Epoch 3/30\n",
      "\u001b[1m46/46\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 0.0092 - val_loss: 0.0061\n",
      "Epoch 4/30\n",
      "\u001b[1m46/46\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 0.0078 - val_loss: 0.0067\n",
      "Epoch 5/30\n",
      "\u001b[1m46/46\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - loss: 0.0073 - val_loss: 0.0055\n",
      "Epoch 6/30\n",
      "\u001b[1m46/46\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - loss: 0.0050 - val_loss: 0.0076\n",
      "Epoch 7/30\n",
      "\u001b[1m46/46\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - loss: 0.0053 - val_loss: 0.0058\n",
      "Epoch 8/30\n",
      "\u001b[1m46/46\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 0.0052 - val_loss: 0.0052\n",
      "Epoch 9/30\n",
      "\u001b[1m46/46\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 0.0051 - val_loss: 0.0049\n",
      "Epoch 10/30\n",
      "\u001b[1m46/46\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 0.0049 - val_loss: 0.0049\n",
      "Epoch 11/30\n",
      "\u001b[1m46/46\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - loss: 0.0048 - val_loss: 0.0067\n",
      "Epoch 12/30\n",
      "\u001b[1m46/46\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - loss: 0.0042 - val_loss: 0.0040\n",
      "Epoch 13/30\n",
      "\u001b[1m46/46\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 0.0043 - val_loss: 0.0046\n",
      "Epoch 14/30\n",
      "\u001b[1m46/46\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 0.0038 - val_loss: 0.0044\n",
      "Epoch 15/30\n",
      "\u001b[1m46/46\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 0.0039 - val_loss: 0.0036\n",
      "Epoch 16/30\n",
      "\u001b[1m46/46\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 0.0042 - val_loss: 0.0040\n",
      "Epoch 17/30\n",
      "\u001b[1m46/46\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 0.0048 - val_loss: 0.0036\n",
      "Epoch 18/30\n",
      "\u001b[1m46/46\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - loss: 0.0035 - val_loss: 0.0039\n",
      "Epoch 19/30\n",
      "\u001b[1m46/46\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - loss: 0.0038 - val_loss: 0.0033\n",
      "Epoch 20/30\n",
      "\u001b[1m46/46\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - loss: 0.0031 - val_loss: 0.0032\n",
      "Epoch 21/30\n",
      "\u001b[1m46/46\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - loss: 0.0027 - val_loss: 0.0035\n",
      "Epoch 22/30\n",
      "\u001b[1m46/46\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - loss: 0.0031 - val_loss: 0.0030\n",
      "Epoch 23/30\n",
      "\u001b[1m46/46\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - loss: 0.0039 - val_loss: 0.0030\n",
      "Epoch 24/30\n",
      "\u001b[1m46/46\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - loss: 0.0035 - val_loss: 0.0030\n",
      "Epoch 25/30\n",
      "\u001b[1m46/46\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - loss: 0.0020 - val_loss: 0.0031\n",
      "Epoch 26/30\n",
      "\u001b[1m46/46\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - loss: 0.0030 - val_loss: 0.0040\n",
      "Epoch 27/30\n",
      "\u001b[1m46/46\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - loss: 0.0042 - val_loss: 0.0031\n",
      "Epoch 28/30\n",
      "\u001b[1m46/46\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - loss: 0.0020 - val_loss: 0.0046\n",
      "Epoch 29/30\n",
      "\u001b[1m46/46\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 0.0034 - val_loss: 0.0028\n",
      "Epoch 30/30\n",
      "\u001b[1m46/46\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 0.0039 - val_loss: 0.0028\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:The `save_format` argument is deprecated in Keras 3. We recommend removing this argument as it can be inferred from the file path. Received: save_format=keras\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Finished: French Polynesia | MAE: 0.03 | RMSE: 0.10 | R²: 0.87\n",
      "Epoch 1/30\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/dejauhnaebeadle/School/MachineLearning/machine-learning-project/code/rain-prediction/.venv/lib/python3.11/site-packages/keras/src/layers/rnn/rnn.py:200: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
      "  super().__init__(**kwargs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m46/46\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 11ms/step - loss: 0.0228 - val_loss: 0.0068\n",
      "Epoch 2/30\n",
      "\u001b[1m46/46\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 0.0046 - val_loss: 0.0034\n",
      "Epoch 3/30\n",
      "\u001b[1m46/46\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - loss: 0.0040 - val_loss: 0.0026\n",
      "Epoch 4/30\n",
      "\u001b[1m46/46\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - loss: 0.0040 - val_loss: 0.0017\n",
      "Epoch 5/30\n",
      "\u001b[1m46/46\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - loss: 0.0034 - val_loss: 0.0029\n",
      "Epoch 6/30\n",
      "\u001b[1m46/46\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - loss: 0.0026 - val_loss: 0.0073\n",
      "Epoch 7/30\n",
      "\u001b[1m46/46\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - loss: 0.0032 - val_loss: 0.0014\n",
      "Epoch 8/30\n",
      "\u001b[1m46/46\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - loss: 0.0033 - val_loss: 0.0044\n",
      "Epoch 9/30\n",
      "\u001b[1m46/46\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 0.0027 - val_loss: 0.0032\n",
      "Epoch 10/30\n",
      "\u001b[1m46/46\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - loss: 0.0028 - val_loss: 0.0029\n",
      "Epoch 11/30\n",
      "\u001b[1m46/46\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 0.0020 - val_loss: 0.0035\n",
      "Epoch 12/30\n",
      "\u001b[1m46/46\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - loss: 0.0023 - val_loss: 0.0027\n",
      "Epoch 13/30\n",
      "\u001b[1m46/46\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - loss: 0.0019 - val_loss: 0.0019\n",
      "Epoch 14/30\n",
      "\u001b[1m46/46\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - loss: 0.0025 - val_loss: 0.0015\n",
      "Epoch 15/30\n",
      "\u001b[1m46/46\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 0.0024 - val_loss: 0.0021\n",
      "Epoch 16/30\n",
      "\u001b[1m46/46\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 0.0018 - val_loss: 0.0015\n",
      "Epoch 17/30\n",
      "\u001b[1m46/46\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - loss: 0.0016 - val_loss: 0.0032\n",
      "Epoch 18/30\n",
      "\u001b[1m46/46\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 0.0017 - val_loss: 0.0011\n",
      "Epoch 19/30\n",
      "\u001b[1m46/46\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - loss: 0.0018 - val_loss: 9.7798e-04\n",
      "Epoch 20/30\n",
      "\u001b[1m46/46\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - loss: 0.0017 - val_loss: 0.0026\n",
      "Epoch 21/30\n",
      "\u001b[1m46/46\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 0.0017 - val_loss: 0.0020\n",
      "Epoch 22/30\n",
      "\u001b[1m46/46\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - loss: 0.0017 - val_loss: 0.0011\n",
      "Epoch 23/30\n",
      "\u001b[1m46/46\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 0.0020 - val_loss: 0.0012\n",
      "Epoch 24/30\n",
      "\u001b[1m46/46\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - loss: 0.0020 - val_loss: 9.3408e-04\n",
      "Epoch 25/30\n",
      "\u001b[1m46/46\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 9.9509e-04 - val_loss: 0.0025\n",
      "Epoch 26/30\n",
      "\u001b[1m46/46\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - loss: 0.0019 - val_loss: 0.0011\n",
      "Epoch 27/30\n",
      "\u001b[1m46/46\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 0.0013 - val_loss: 9.0916e-04\n",
      "Epoch 28/30\n",
      "\u001b[1m46/46\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - loss: 0.0016 - val_loss: 0.0013\n",
      "Epoch 29/30\n",
      "\u001b[1m46/46\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 8.8598e-04 - val_loss: 0.0017\n",
      "Epoch 30/30\n",
      "\u001b[1m46/46\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - loss: 0.0017 - val_loss: 8.7661e-04\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:The `save_format` argument is deprecated in Keras 3. We recommend removing this argument as it can be inferred from the file path. Received: save_format=keras\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Finished: Gabon | MAE: 0.07 | RMSE: 0.09 | R²: 0.88\n",
      "Epoch 1/30\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/dejauhnaebeadle/School/MachineLearning/machine-learning-project/code/rain-prediction/.venv/lib/python3.11/site-packages/keras/src/layers/rnn/rnn.py:200: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
      "  super().__init__(**kwargs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m46/46\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 13ms/step - loss: 0.0821 - val_loss: 0.0058\n",
      "Epoch 2/30\n",
      "\u001b[1m46/46\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - loss: 0.0095 - val_loss: 0.0080\n",
      "Epoch 3/30\n",
      "\u001b[1m46/46\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 0.0081 - val_loss: 0.0057\n",
      "Epoch 4/30\n",
      "\u001b[1m46/46\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - loss: 0.0088 - val_loss: 0.0061\n",
      "Epoch 5/30\n",
      "\u001b[1m46/46\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 0.0075 - val_loss: 0.0040\n",
      "Epoch 6/30\n",
      "\u001b[1m46/46\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 0.0071 - val_loss: 0.0050\n",
      "Epoch 7/30\n",
      "\u001b[1m46/46\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 0.0056 - val_loss: 0.0037\n",
      "Epoch 8/30\n",
      "\u001b[1m46/46\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - loss: 0.0041 - val_loss: 0.0032\n",
      "Epoch 9/30\n",
      "\u001b[1m46/46\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - loss: 0.0056 - val_loss: 0.0032\n",
      "Epoch 10/30\n",
      "\u001b[1m46/46\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - loss: 0.0053 - val_loss: 0.0036\n",
      "Epoch 11/30\n",
      "\u001b[1m46/46\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - loss: 0.0053 - val_loss: 0.0029\n",
      "Epoch 12/30\n",
      "\u001b[1m46/46\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - loss: 0.0051 - val_loss: 0.0029\n",
      "Epoch 13/30\n",
      "\u001b[1m46/46\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 0.0051 - val_loss: 0.0041\n",
      "Epoch 14/30\n",
      "\u001b[1m46/46\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 0.0037 - val_loss: 0.0026\n",
      "Epoch 15/30\n",
      "\u001b[1m46/46\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 0.0050 - val_loss: 0.0027\n",
      "Epoch 16/30\n",
      "\u001b[1m46/46\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - loss: 0.0043 - val_loss: 0.0025\n",
      "Epoch 17/30\n",
      "\u001b[1m46/46\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 0.0040 - val_loss: 0.0047\n",
      "Epoch 18/30\n",
      "\u001b[1m46/46\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 0.0038 - val_loss: 0.0027\n",
      "Epoch 19/30\n",
      "\u001b[1m46/46\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - loss: 0.0046 - val_loss: 0.0025\n",
      "Epoch 20/30\n",
      "\u001b[1m46/46\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 0.0032 - val_loss: 0.0023\n",
      "Epoch 21/30\n",
      "\u001b[1m46/46\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 0.0039 - val_loss: 0.0024\n",
      "Epoch 22/30\n",
      "\u001b[1m46/46\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - loss: 0.0051 - val_loss: 0.0021\n",
      "Epoch 23/30\n",
      "\u001b[1m46/46\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - loss: 0.0037 - val_loss: 0.0026\n",
      "Epoch 24/30\n",
      "\u001b[1m46/46\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - loss: 0.0042 - val_loss: 0.0021\n",
      "Epoch 25/30\n",
      "\u001b[1m46/46\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - loss: 0.0027 - val_loss: 0.0023\n",
      "Epoch 26/30\n",
      "\u001b[1m46/46\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - loss: 0.0025 - val_loss: 0.0028\n",
      "Epoch 27/30\n",
      "\u001b[1m46/46\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - loss: 0.0031 - val_loss: 0.0020\n",
      "Epoch 28/30\n",
      "\u001b[1m46/46\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - loss: 0.0039 - val_loss: 0.0029\n",
      "Epoch 29/30\n",
      "\u001b[1m46/46\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 0.0039 - val_loss: 0.0019\n",
      "Epoch 30/30\n",
      "\u001b[1m46/46\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - loss: 0.0028 - val_loss: 0.0019\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:The `save_format` argument is deprecated in Keras 3. We recommend removing this argument as it can be inferred from the file path. Received: save_format=keras\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Finished: Gambia | MAE: 0.05 | RMSE: 0.11 | R²: 0.82\n",
      "Epoch 1/30\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/dejauhnaebeadle/School/MachineLearning/machine-learning-project/code/rain-prediction/.venv/lib/python3.11/site-packages/keras/src/layers/rnn/rnn.py:200: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
      "  super().__init__(**kwargs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m46/46\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 10ms/step - loss: 0.0625 - val_loss: 0.0019\n",
      "Epoch 2/30\n",
      "\u001b[1m46/46\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 0.0127 - val_loss: 0.0026\n",
      "Epoch 3/30\n",
      "\u001b[1m46/46\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 0.0110 - val_loss: 0.0030\n",
      "Epoch 4/30\n",
      "\u001b[1m46/46\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - loss: 0.0086 - val_loss: 0.0017\n",
      "Epoch 5/30\n",
      "\u001b[1m46/46\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - loss: 0.0072 - val_loss: 0.0023\n",
      "Epoch 6/30\n",
      "\u001b[1m46/46\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - loss: 0.0070 - val_loss: 0.0018\n",
      "Epoch 7/30\n",
      "\u001b[1m46/46\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 0.0062 - val_loss: 8.2289e-04\n",
      "Epoch 8/30\n",
      "\u001b[1m46/46\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - loss: 0.0063 - val_loss: 0.0022\n",
      "Epoch 9/30\n",
      "\u001b[1m46/46\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 0.0057 - val_loss: 0.0017\n",
      "Epoch 10/30\n",
      "\u001b[1m46/46\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - loss: 0.0059 - val_loss: 0.0011\n",
      "Epoch 11/30\n",
      "\u001b[1m46/46\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 0.0062 - val_loss: 7.6180e-04\n",
      "Epoch 12/30\n",
      "\u001b[1m46/46\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 0.0045 - val_loss: 0.0017\n",
      "Epoch 13/30\n",
      "\u001b[1m46/46\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 0.0045 - val_loss: 0.0021\n",
      "Epoch 14/30\n",
      "\u001b[1m46/46\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 0.0052 - val_loss: 7.6259e-04\n",
      "Epoch 15/30\n",
      "\u001b[1m46/46\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - loss: 0.0059 - val_loss: 7.2635e-04\n",
      "Epoch 16/30\n",
      "\u001b[1m46/46\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 0.0045 - val_loss: 6.5783e-04\n",
      "Epoch 17/30\n",
      "\u001b[1m46/46\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 0.0060 - val_loss: 7.6951e-04\n",
      "Epoch 18/30\n",
      "\u001b[1m46/46\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 0.0036 - val_loss: 5.7535e-04\n",
      "Epoch 19/30\n",
      "\u001b[1m46/46\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 0.0053 - val_loss: 0.0016\n",
      "Epoch 20/30\n",
      "\u001b[1m46/46\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - loss: 0.0044 - val_loss: 0.0011\n",
      "Epoch 21/30\n",
      "\u001b[1m46/46\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - loss: 0.0062 - val_loss: 8.7479e-04\n",
      "Epoch 22/30\n",
      "\u001b[1m46/46\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - loss: 0.0043 - val_loss: 0.0061\n",
      "Epoch 23/30\n",
      "\u001b[1m46/46\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - loss: 0.0051 - val_loss: 0.0011\n",
      "Epoch 24/30\n",
      "\u001b[1m46/46\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - loss: 0.0039 - val_loss: 5.7537e-04\n",
      "Epoch 25/30\n",
      "\u001b[1m46/46\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - loss: 0.0029 - val_loss: 5.9354e-04\n",
      "Epoch 26/30\n",
      "\u001b[1m46/46\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - loss: 0.0034 - val_loss: 0.0037\n",
      "Epoch 27/30\n",
      "\u001b[1m46/46\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - loss: 0.0043 - val_loss: 5.8052e-04\n",
      "Epoch 28/30\n",
      "\u001b[1m46/46\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - loss: 0.0040 - val_loss: 4.7436e-04\n",
      "Epoch 29/30\n",
      "\u001b[1m46/46\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 10ms/step - loss: 0.0037 - val_loss: 4.8033e-04\n",
      "Epoch 30/30\n",
      "\u001b[1m46/46\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 10ms/step - loss: 0.0043 - val_loss: 0.0015\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:The `save_format` argument is deprecated in Keras 3. We recommend removing this argument as it can be inferred from the file path. Received: save_format=keras\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Finished: Georgia | MAE: 0.41 | RMSE: 0.48 | R²: 0.46\n",
      "Epoch 1/30\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/dejauhnaebeadle/School/MachineLearning/machine-learning-project/code/rain-prediction/.venv/lib/python3.11/site-packages/keras/src/layers/rnn/rnn.py:200: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
      "  super().__init__(**kwargs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m46/46\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 18ms/step - loss: 0.0975 - val_loss: 0.0058\n",
      "Epoch 2/30\n",
      "\u001b[1m46/46\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - loss: 0.0125 - val_loss: 0.0061\n",
      "Epoch 3/30\n",
      "\u001b[1m46/46\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - loss: 0.0109 - val_loss: 0.0044\n",
      "Epoch 4/30\n",
      "\u001b[1m46/46\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 13ms/step - loss: 0.0098 - val_loss: 0.0036\n",
      "Epoch 5/30\n",
      "\u001b[1m46/46\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - loss: 0.0091 - val_loss: 0.0024\n",
      "Epoch 6/30\n",
      "\u001b[1m46/46\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - loss: 0.0075 - val_loss: 0.0058\n",
      "Epoch 7/30\n",
      "\u001b[1m46/46\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - loss: 0.0078 - val_loss: 0.0018\n",
      "Epoch 8/30\n",
      "\u001b[1m46/46\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - loss: 0.0071 - val_loss: 0.0020\n",
      "Epoch 9/30\n",
      "\u001b[1m46/46\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - loss: 0.0058 - val_loss: 0.0038\n",
      "Epoch 10/30\n",
      "\u001b[1m46/46\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - loss: 0.0057 - val_loss: 0.0036\n",
      "Epoch 11/30\n",
      "\u001b[1m46/46\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - loss: 0.0063 - val_loss: 0.0017\n",
      "Epoch 12/30\n",
      "\u001b[1m46/46\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - loss: 0.0049 - val_loss: 0.0015\n",
      "Epoch 13/30\n",
      "\u001b[1m46/46\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - loss: 0.0056 - val_loss: 0.0020\n",
      "Epoch 14/30\n",
      "\u001b[1m46/46\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - loss: 0.0043 - val_loss: 0.0046\n",
      "Epoch 15/30\n",
      "\u001b[1m46/46\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - loss: 0.0044 - val_loss: 0.0029\n",
      "Epoch 16/30\n",
      "\u001b[1m46/46\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - loss: 0.0044 - val_loss: 0.0075\n",
      "Epoch 17/30\n",
      "\u001b[1m46/46\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - loss: 0.0043 - val_loss: 0.0022\n",
      "Epoch 18/30\n",
      "\u001b[1m46/46\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - loss: 0.0046 - val_loss: 9.2369e-04\n",
      "Epoch 19/30\n",
      "\u001b[1m46/46\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - loss: 0.0046 - val_loss: 0.0012\n",
      "Epoch 20/30\n",
      "\u001b[1m46/46\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - loss: 0.0042 - val_loss: 0.0019\n",
      "Epoch 21/30\n",
      "\u001b[1m46/46\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - loss: 0.0045 - val_loss: 0.0030\n",
      "Epoch 22/30\n",
      "\u001b[1m46/46\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - loss: 0.0037 - val_loss: 0.0013\n",
      "Epoch 23/30\n",
      "\u001b[1m46/46\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - loss: 0.0040 - val_loss: 8.0599e-04\n",
      "Epoch 24/30\n",
      "\u001b[1m46/46\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 11ms/step - loss: 0.0036 - val_loss: 0.0024\n",
      "Epoch 25/30\n",
      "\u001b[1m46/46\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - loss: 0.0029 - val_loss: 7.5082e-04\n",
      "Epoch 26/30\n",
      "\u001b[1m46/46\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - loss: 0.0032 - val_loss: 0.0020\n",
      "Epoch 27/30\n",
      "\u001b[1m46/46\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 16ms/step - loss: 0.0028 - val_loss: 0.0014\n",
      "Epoch 28/30\n",
      "\u001b[1m46/46\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 11ms/step - loss: 0.0032 - val_loss: 0.0012\n",
      "Epoch 29/30\n",
      "\u001b[1m46/46\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 17ms/step - loss: 0.0027 - val_loss: 0.0023\n",
      "Epoch 30/30\n",
      "\u001b[1m46/46\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - loss: 0.0031 - val_loss: 0.0026\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:The `save_format` argument is deprecated in Keras 3. We recommend removing this argument as it can be inferred from the file path. Received: save_format=keras\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Finished: Germany | MAE: 0.26 | RMSE: 0.35 | R²: 0.80\n",
      "Epoch 1/30\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/dejauhnaebeadle/School/MachineLearning/machine-learning-project/code/rain-prediction/.venv/lib/python3.11/site-packages/keras/src/layers/rnn/rnn.py:200: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
      "  super().__init__(**kwargs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m46/46\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 18ms/step - loss: 0.0641 - val_loss: 0.0044\n",
      "Epoch 2/30\n",
      "\u001b[1m46/46\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - loss: 0.0066 - val_loss: 0.0021\n",
      "Epoch 3/30\n",
      "\u001b[1m46/46\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - loss: 0.0067 - val_loss: 2.3513e-04\n",
      "Epoch 4/30\n",
      "\u001b[1m46/46\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - loss: 0.0049 - val_loss: 6.8357e-04\n",
      "Epoch 5/30\n",
      "\u001b[1m46/46\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - loss: 0.0056 - val_loss: 0.0035\n",
      "Epoch 6/30\n",
      "\u001b[1m46/46\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - loss: 0.0046 - val_loss: 0.0071\n",
      "Epoch 7/30\n",
      "\u001b[1m46/46\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - loss: 0.0043 - val_loss: 9.9577e-04\n",
      "Epoch 8/30\n",
      "\u001b[1m46/46\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - loss: 0.0039 - val_loss: 0.0012\n",
      "Epoch 9/30\n",
      "\u001b[1m46/46\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - loss: 0.0031 - val_loss: 3.7859e-04\n",
      "Epoch 10/30\n",
      "\u001b[1m46/46\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - loss: 0.0030 - val_loss: 0.0035\n",
      "Epoch 11/30\n",
      "\u001b[1m46/46\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - loss: 0.0035 - val_loss: 0.0047\n",
      "Epoch 12/30\n",
      "\u001b[1m46/46\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - loss: 0.0037 - val_loss: 0.0040\n",
      "Epoch 13/30\n",
      "\u001b[1m46/46\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - loss: 0.0027 - val_loss: 3.5705e-04\n",
      "Epoch 14/30\n",
      "\u001b[1m46/46\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - loss: 0.0024 - val_loss: 0.0011\n",
      "Epoch 15/30\n",
      "\u001b[1m46/46\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - loss: 0.0028 - val_loss: 3.4166e-04\n",
      "Epoch 16/30\n",
      "\u001b[1m46/46\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - loss: 0.0024 - val_loss: 9.1318e-04\n",
      "Epoch 17/30\n",
      "\u001b[1m46/46\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - loss: 0.0034 - val_loss: 0.0012\n",
      "Epoch 18/30\n",
      "\u001b[1m46/46\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - loss: 0.0031 - val_loss: 4.5180e-04\n",
      "Epoch 19/30\n",
      "\u001b[1m46/46\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - loss: 0.0020 - val_loss: 0.0029\n",
      "Epoch 20/30\n",
      "\u001b[1m46/46\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - loss: 0.0027 - val_loss: 1.6864e-04\n",
      "Epoch 21/30\n",
      "\u001b[1m46/46\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - loss: 0.0025 - val_loss: 3.2922e-04\n",
      "Epoch 22/30\n",
      "\u001b[1m46/46\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - loss: 0.0020 - val_loss: 0.0012\n",
      "Epoch 23/30\n",
      "\u001b[1m46/46\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - loss: 0.0020 - val_loss: 4.7022e-04\n",
      "Epoch 24/30\n",
      "\u001b[1m46/46\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - loss: 0.0025 - val_loss: 0.0011\n",
      "Epoch 25/30\n",
      "\u001b[1m46/46\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - loss: 0.0024 - val_loss: 0.0010\n",
      "Epoch 26/30\n",
      "\u001b[1m46/46\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - loss: 0.0019 - val_loss: 1.5994e-04\n",
      "Epoch 27/30\n",
      "\u001b[1m46/46\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - loss: 0.0019 - val_loss: 5.6419e-04\n",
      "Epoch 28/30\n",
      "\u001b[1m46/46\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - loss: 0.0025 - val_loss: 0.0011\n",
      "Epoch 29/30\n",
      "\u001b[1m46/46\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - loss: 0.0019 - val_loss: 8.6088e-05\n",
      "Epoch 30/30\n",
      "\u001b[1m46/46\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - loss: 0.0018 - val_loss: 8.0917e-04\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:The `save_format` argument is deprecated in Keras 3. We recommend removing this argument as it can be inferred from the file path. Received: save_format=keras\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Finished: Ghana | MAE: 0.13 | RMSE: 0.15 | R²: 0.69\n",
      "Epoch 1/30\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/dejauhnaebeadle/School/MachineLearning/machine-learning-project/code/rain-prediction/.venv/lib/python3.11/site-packages/keras/src/layers/rnn/rnn.py:200: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
      "  super().__init__(**kwargs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m46/46\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 16ms/step - loss: 0.0453 - val_loss: 0.0052\n",
      "Epoch 2/30\n",
      "\u001b[1m46/46\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - loss: 0.0102 - val_loss: 0.0054\n",
      "Epoch 3/30\n",
      "\u001b[1m46/46\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - loss: 0.0086 - val_loss: 0.0037\n",
      "Epoch 4/30\n",
      "\u001b[1m46/46\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - loss: 0.0076 - val_loss: 0.0027\n",
      "Epoch 5/30\n",
      "\u001b[1m46/46\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - loss: 0.0052 - val_loss: 0.0043\n",
      "Epoch 6/30\n",
      "\u001b[1m46/46\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - loss: 0.0051 - val_loss: 0.0046\n",
      "Epoch 7/30\n",
      "\u001b[1m46/46\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - loss: 0.0047 - val_loss: 0.0053\n",
      "Epoch 8/30\n",
      "\u001b[1m46/46\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - loss: 0.0051 - val_loss: 0.0026\n",
      "Epoch 9/30\n",
      "\u001b[1m46/46\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - loss: 0.0047 - val_loss: 0.0021\n",
      "Epoch 10/30\n",
      "\u001b[1m46/46\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - loss: 0.0034 - val_loss: 0.0020\n",
      "Epoch 11/30\n",
      "\u001b[1m46/46\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - loss: 0.0040 - val_loss: 0.0020\n",
      "Epoch 12/30\n",
      "\u001b[1m46/46\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - loss: 0.0037 - val_loss: 0.0017\n",
      "Epoch 13/30\n",
      "\u001b[1m46/46\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - loss: 0.0051 - val_loss: 0.0019\n",
      "Epoch 14/30\n",
      "\u001b[1m46/46\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - loss: 0.0053 - val_loss: 0.0016\n",
      "Epoch 15/30\n",
      "\u001b[1m46/46\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - loss: 0.0053 - val_loss: 0.0018\n",
      "Epoch 16/30\n",
      "\u001b[1m46/46\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - loss: 0.0042 - val_loss: 0.0015\n",
      "Epoch 17/30\n",
      "\u001b[1m46/46\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - loss: 0.0043 - val_loss: 0.0015\n",
      "Epoch 18/30\n",
      "\u001b[1m46/46\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - loss: 0.0032 - val_loss: 0.0020\n",
      "Epoch 19/30\n",
      "\u001b[1m46/46\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - loss: 0.0044 - val_loss: 0.0014\n",
      "Epoch 20/30\n",
      "\u001b[1m46/46\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - loss: 0.0037 - val_loss: 0.0017\n",
      "Epoch 21/30\n",
      "\u001b[1m46/46\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - loss: 0.0035 - val_loss: 0.0022\n",
      "Epoch 22/30\n",
      "\u001b[1m46/46\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - loss: 0.0034 - val_loss: 0.0018\n",
      "Epoch 23/30\n",
      "\u001b[1m46/46\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - loss: 0.0042 - val_loss: 0.0016\n",
      "Epoch 24/30\n",
      "\u001b[1m46/46\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - loss: 0.0026 - val_loss: 0.0017\n",
      "Epoch 25/30\n",
      "\u001b[1m46/46\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - loss: 0.0029 - val_loss: 0.0015\n",
      "Epoch 26/30\n",
      "\u001b[1m46/46\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - loss: 0.0042 - val_loss: 0.0013\n",
      "Epoch 27/30\n",
      "\u001b[1m46/46\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - loss: 0.0038 - val_loss: 0.0012\n",
      "Epoch 28/30\n",
      "\u001b[1m46/46\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - loss: 0.0025 - val_loss: 0.0026\n",
      "Epoch 29/30\n",
      "\u001b[1m46/46\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - loss: 0.0023 - val_loss: 0.0018\n",
      "Epoch 30/30\n",
      "\u001b[1m46/46\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - loss: 0.0026 - val_loss: 0.0013\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:The `save_format` argument is deprecated in Keras 3. We recommend removing this argument as it can be inferred from the file path. Received: save_format=keras\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Finished: Greece | MAE: 0.12 | RMSE: 0.18 | R²: 0.82\n",
      "Epoch 1/30\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/dejauhnaebeadle/School/MachineLearning/machine-learning-project/code/rain-prediction/.venv/lib/python3.11/site-packages/keras/src/layers/rnn/rnn.py:200: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
      "  super().__init__(**kwargs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m46/46\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 13ms/step - loss: 0.0514 - val_loss: 0.0087\n",
      "Epoch 2/30\n",
      "\u001b[1m46/46\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - loss: 0.0076 - val_loss: 0.0079\n",
      "Epoch 3/30\n",
      "\u001b[1m46/46\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - loss: 0.0077 - val_loss: 0.0075\n",
      "Epoch 4/30\n",
      "\u001b[1m46/46\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - loss: 0.0063 - val_loss: 0.0052\n",
      "Epoch 5/30\n",
      "\u001b[1m46/46\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - loss: 0.0060 - val_loss: 0.0032\n",
      "Epoch 6/30\n",
      "\u001b[1m46/46\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - loss: 0.0041 - val_loss: 0.0037\n",
      "Epoch 7/30\n",
      "\u001b[1m46/46\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - loss: 0.0052 - val_loss: 0.0089\n",
      "Epoch 8/30\n",
      "\u001b[1m46/46\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - loss: 0.0047 - val_loss: 0.0024\n",
      "Epoch 9/30\n",
      "\u001b[1m46/46\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - loss: 0.0039 - val_loss: 0.0077\n",
      "Epoch 10/30\n",
      "\u001b[1m46/46\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - loss: 0.0039 - val_loss: 0.0025\n",
      "Epoch 11/30\n",
      "\u001b[1m46/46\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - loss: 0.0041 - val_loss: 0.0035\n",
      "Epoch 12/30\n",
      "\u001b[1m46/46\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - loss: 0.0037 - val_loss: 0.0027\n",
      "Epoch 13/30\n",
      "\u001b[1m46/46\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - loss: 0.0039 - val_loss: 0.0018\n",
      "Epoch 14/30\n",
      "\u001b[1m46/46\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - loss: 0.0039 - val_loss: 0.0027\n",
      "Epoch 15/30\n",
      "\u001b[1m46/46\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - loss: 0.0036 - val_loss: 0.0024\n",
      "Epoch 16/30\n",
      "\u001b[1m46/46\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - loss: 0.0028 - val_loss: 0.0029\n",
      "Epoch 17/30\n",
      "\u001b[1m46/46\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - loss: 0.0039 - val_loss: 0.0056\n",
      "Epoch 18/30\n",
      "\u001b[1m46/46\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - loss: 0.0030 - val_loss: 0.0027\n",
      "Epoch 19/30\n",
      "\u001b[1m46/46\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - loss: 0.0027 - val_loss: 0.0016\n",
      "Epoch 20/30\n",
      "\u001b[1m46/46\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - loss: 0.0034 - val_loss: 0.0023\n",
      "Epoch 21/30\n",
      "\u001b[1m46/46\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - loss: 0.0031 - val_loss: 0.0037\n",
      "Epoch 22/30\n",
      "\u001b[1m46/46\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - loss: 0.0028 - val_loss: 0.0017\n",
      "Epoch 23/30\n",
      "\u001b[1m46/46\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - loss: 0.0025 - val_loss: 0.0034\n",
      "Epoch 24/30\n",
      "\u001b[1m46/46\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - loss: 0.0030 - val_loss: 0.0015\n",
      "Epoch 25/30\n",
      "\u001b[1m46/46\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - loss: 0.0032 - val_loss: 0.0035\n",
      "Epoch 26/30\n",
      "\u001b[1m46/46\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - loss: 0.0027 - val_loss: 0.0017\n",
      "Epoch 27/30\n",
      "\u001b[1m46/46\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - loss: 0.0030 - val_loss: 0.0041\n",
      "Epoch 28/30\n",
      "\u001b[1m46/46\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - loss: 0.0025 - val_loss: 0.0032\n",
      "Epoch 29/30\n",
      "\u001b[1m46/46\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - loss: 0.0033 - val_loss: 0.0014\n",
      "Epoch 30/30\n",
      "\u001b[1m46/46\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - loss: 0.0028 - val_loss: 0.0016\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:The `save_format` argument is deprecated in Keras 3. We recommend removing this argument as it can be inferred from the file path. Received: save_format=keras\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Finished: Greenland | MAE: 0.23 | RMSE: 0.48 | R²: 0.74\n",
      "Epoch 1/30\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/dejauhnaebeadle/School/MachineLearning/machine-learning-project/code/rain-prediction/.venv/lib/python3.11/site-packages/keras/src/layers/rnn/rnn.py:200: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
      "  super().__init__(**kwargs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m46/46\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 13ms/step - loss: 0.0357 - val_loss: 0.0037\n",
      "Epoch 2/30\n",
      "\u001b[1m46/46\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - loss: 0.0044 - val_loss: 0.0068\n",
      "Epoch 3/30\n",
      "\u001b[1m46/46\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - loss: 0.0044 - val_loss: 0.0042\n",
      "Epoch 4/30\n",
      "\u001b[1m46/46\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - loss: 0.0033 - val_loss: 0.0029\n",
      "Epoch 5/30\n",
      "\u001b[1m46/46\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - loss: 0.0039 - val_loss: 0.0045\n",
      "Epoch 6/30\n",
      "\u001b[1m46/46\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - loss: 0.0035 - val_loss: 0.0023\n",
      "Epoch 7/30\n",
      "\u001b[1m46/46\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - loss: 0.0032 - val_loss: 0.0020\n",
      "Epoch 8/30\n",
      "\u001b[1m46/46\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - loss: 0.0028 - val_loss: 0.0021\n",
      "Epoch 9/30\n",
      "\u001b[1m46/46\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - loss: 0.0028 - val_loss: 0.0027\n",
      "Epoch 10/30\n",
      "\u001b[1m46/46\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - loss: 0.0023 - val_loss: 0.0032\n",
      "Epoch 11/30\n",
      "\u001b[1m46/46\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - loss: 0.0021 - val_loss: 0.0019\n",
      "Epoch 12/30\n",
      "\u001b[1m46/46\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - loss: 0.0025 - val_loss: 0.0036\n",
      "Epoch 13/30\n",
      "\u001b[1m46/46\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - loss: 0.0024 - val_loss: 0.0016\n",
      "Epoch 14/30\n",
      "\u001b[1m46/46\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - loss: 0.0020 - val_loss: 0.0018\n",
      "Epoch 15/30\n",
      "\u001b[1m46/46\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - loss: 0.0019 - val_loss: 0.0023\n",
      "Epoch 16/30\n",
      "\u001b[1m46/46\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - loss: 0.0023 - val_loss: 0.0015\n",
      "Epoch 17/30\n",
      "\u001b[1m46/46\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - loss: 0.0017 - val_loss: 0.0014\n",
      "Epoch 18/30\n",
      "\u001b[1m46/46\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - loss: 0.0016 - val_loss: 0.0016\n",
      "Epoch 19/30\n",
      "\u001b[1m46/46\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - loss: 0.0019 - val_loss: 0.0018\n",
      "Epoch 20/30\n",
      "\u001b[1m46/46\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - loss: 0.0023 - val_loss: 0.0014\n",
      "Epoch 21/30\n",
      "\u001b[1m46/46\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - loss: 0.0020 - val_loss: 0.0014\n",
      "Epoch 22/30\n",
      "\u001b[1m46/46\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - loss: 0.0016 - val_loss: 0.0019\n",
      "Epoch 23/30\n",
      "\u001b[1m46/46\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - loss: 0.0014 - val_loss: 0.0013\n",
      "Epoch 24/30\n",
      "\u001b[1m46/46\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - loss: 0.0020 - val_loss: 0.0014\n",
      "Epoch 25/30\n",
      "\u001b[1m46/46\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - loss: 0.0016 - val_loss: 0.0013\n",
      "Epoch 26/30\n",
      "\u001b[1m46/46\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - loss: 0.0020 - val_loss: 0.0013\n",
      "Epoch 27/30\n",
      "\u001b[1m46/46\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - loss: 0.0011 - val_loss: 0.0014\n",
      "Epoch 28/30\n",
      "\u001b[1m46/46\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - loss: 0.0017 - val_loss: 0.0017\n",
      "Epoch 29/30\n",
      "\u001b[1m46/46\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - loss: 0.0014 - val_loss: 0.0012\n",
      "Epoch 30/30\n",
      "\u001b[1m46/46\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - loss: 0.0018 - val_loss: 0.0012\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:The `save_format` argument is deprecated in Keras 3. We recommend removing this argument as it can be inferred from the file path. Received: save_format=keras\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Finished: Guatemala | MAE: 0.09 | RMSE: 0.13 | R²: 0.89\n",
      "Epoch 1/30\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/dejauhnaebeadle/School/MachineLearning/machine-learning-project/code/rain-prediction/.venv/lib/python3.11/site-packages/keras/src/layers/rnn/rnn.py:200: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
      "  super().__init__(**kwargs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m46/46\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 13ms/step - loss: 0.0760 - val_loss: 0.0036\n",
      "Epoch 2/30\n",
      "\u001b[1m46/46\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - loss: 0.0077 - val_loss: 0.0028\n",
      "Epoch 3/30\n",
      "\u001b[1m46/46\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - loss: 0.0067 - val_loss: 0.0018\n",
      "Epoch 4/30\n",
      "\u001b[1m46/46\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - loss: 0.0057 - val_loss: 0.0022\n",
      "Epoch 5/30\n",
      "\u001b[1m46/46\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - loss: 0.0050 - val_loss: 0.0024\n",
      "Epoch 6/30\n",
      "\u001b[1m46/46\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - loss: 0.0046 - val_loss: 0.0021\n",
      "Epoch 7/30\n",
      "\u001b[1m46/46\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - loss: 0.0040 - val_loss: 0.0022\n",
      "Epoch 8/30\n",
      "\u001b[1m46/46\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - loss: 0.0048 - val_loss: 6.9783e-04\n",
      "Epoch 9/30\n",
      "\u001b[1m46/46\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - loss: 0.0034 - val_loss: 6.0889e-04\n",
      "Epoch 10/30\n",
      "\u001b[1m46/46\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - loss: 0.0034 - val_loss: 0.0025\n",
      "Epoch 11/30\n",
      "\u001b[1m46/46\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - loss: 0.0028 - val_loss: 5.2247e-04\n",
      "Epoch 12/30\n",
      "\u001b[1m46/46\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - loss: 0.0032 - val_loss: 0.0013\n",
      "Epoch 13/30\n",
      "\u001b[1m46/46\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - loss: 0.0029 - val_loss: 5.5417e-04\n",
      "Epoch 14/30\n",
      "\u001b[1m46/46\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - loss: 0.0033 - val_loss: 6.5682e-04\n",
      "Epoch 15/30\n",
      "\u001b[1m46/46\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - loss: 0.0032 - val_loss: 8.6832e-04\n",
      "Epoch 16/30\n",
      "\u001b[1m46/46\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - loss: 0.0022 - val_loss: 7.3772e-04\n",
      "Epoch 17/30\n",
      "\u001b[1m46/46\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - loss: 0.0032 - val_loss: 0.0013\n",
      "Epoch 18/30\n",
      "\u001b[1m46/46\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - loss: 0.0027 - val_loss: 5.2239e-04\n",
      "Epoch 19/30\n",
      "\u001b[1m46/46\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - loss: 0.0021 - val_loss: 0.0016\n",
      "Epoch 20/30\n",
      "\u001b[1m46/46\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - loss: 0.0024 - val_loss: 5.2503e-04\n",
      "Epoch 21/30\n",
      "\u001b[1m46/46\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - loss: 0.0025 - val_loss: 5.9823e-04\n",
      "Epoch 22/30\n",
      "\u001b[1m46/46\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - loss: 0.0022 - val_loss: 7.0603e-04\n",
      "Epoch 23/30\n",
      "\u001b[1m46/46\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - loss: 0.0022 - val_loss: 6.3861e-04\n",
      "Epoch 24/30\n",
      "\u001b[1m46/46\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - loss: 0.0018 - val_loss: 5.6856e-04\n",
      "Epoch 25/30\n",
      "\u001b[1m46/46\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - loss: 0.0019 - val_loss: 3.5941e-04\n",
      "Epoch 26/30\n",
      "\u001b[1m46/46\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - loss: 0.0019 - val_loss: 0.0023\n",
      "Epoch 27/30\n",
      "\u001b[1m46/46\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - loss: 0.0020 - val_loss: 4.1198e-04\n",
      "Epoch 28/30\n",
      "\u001b[1m46/46\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - loss: 0.0015 - val_loss: 8.3640e-04\n",
      "Epoch 29/30\n",
      "\u001b[1m46/46\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - loss: 0.0021 - val_loss: 3.4772e-04\n",
      "Epoch 30/30\n",
      "\u001b[1m46/46\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - loss: 0.0018 - val_loss: 5.8310e-04\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:The `save_format` argument is deprecated in Keras 3. We recommend removing this argument as it can be inferred from the file path. Received: save_format=keras\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Finished: Guinea | MAE: 0.07 | RMSE: 0.10 | R²: 0.91\n",
      "Epoch 1/30\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/dejauhnaebeadle/School/MachineLearning/machine-learning-project/code/rain-prediction/.venv/lib/python3.11/site-packages/keras/src/layers/rnn/rnn.py:200: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
      "  super().__init__(**kwargs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m46/46\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 14ms/step - loss: 0.0912 - val_loss: 0.0031\n",
      "Epoch 2/30\n",
      "\u001b[1m46/46\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - loss: 0.0101 - val_loss: 0.0049\n",
      "Epoch 3/30\n",
      "\u001b[1m46/46\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - loss: 0.0084 - val_loss: 0.0033\n",
      "Epoch 4/30\n",
      "\u001b[1m46/46\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - loss: 0.0083 - val_loss: 0.0019\n",
      "Epoch 5/30\n",
      "\u001b[1m46/46\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - loss: 0.0074 - val_loss: 0.0028\n",
      "Epoch 6/30\n",
      "\u001b[1m46/46\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - loss: 0.0063 - val_loss: 0.0023\n",
      "Epoch 7/30\n",
      "\u001b[1m46/46\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - loss: 0.0056 - val_loss: 0.0015\n",
      "Epoch 8/30\n",
      "\u001b[1m46/46\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - loss: 0.0044 - val_loss: 0.0016\n",
      "Epoch 9/30\n",
      "\u001b[1m46/46\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - loss: 0.0049 - val_loss: 0.0023\n",
      "Epoch 10/30\n",
      "\u001b[1m46/46\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - loss: 0.0050 - val_loss: 0.0029\n",
      "Epoch 11/30\n",
      "\u001b[1m46/46\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - loss: 0.0056 - val_loss: 0.0016\n",
      "Epoch 12/30\n",
      "\u001b[1m46/46\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - loss: 0.0038 - val_loss: 0.0012\n",
      "Epoch 13/30\n",
      "\u001b[1m46/46\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - loss: 0.0039 - val_loss: 0.0011\n",
      "Epoch 14/30\n",
      "\u001b[1m46/46\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - loss: 0.0047 - val_loss: 0.0021\n",
      "Epoch 15/30\n",
      "\u001b[1m46/46\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - loss: 0.0038 - val_loss: 0.0024\n",
      "Epoch 16/30\n",
      "\u001b[1m46/46\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - loss: 0.0037 - val_loss: 9.8922e-04\n",
      "Epoch 17/30\n",
      "\u001b[1m46/46\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - loss: 0.0034 - val_loss: 0.0012\n",
      "Epoch 18/30\n",
      "\u001b[1m46/46\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - loss: 0.0034 - val_loss: 0.0041\n",
      "Epoch 19/30\n",
      "\u001b[1m46/46\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - loss: 0.0036 - val_loss: 0.0020\n",
      "Epoch 20/30\n",
      "\u001b[1m46/46\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - loss: 0.0041 - val_loss: 0.0010\n",
      "Epoch 21/30\n",
      "\u001b[1m46/46\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - loss: 0.0028 - val_loss: 0.0026\n",
      "Epoch 22/30\n",
      "\u001b[1m46/46\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - loss: 0.0029 - val_loss: 8.3272e-04\n",
      "Epoch 23/30\n",
      "\u001b[1m46/46\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - loss: 0.0032 - val_loss: 9.4938e-04\n",
      "Epoch 24/30\n",
      "\u001b[1m46/46\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - loss: 0.0037 - val_loss: 7.7691e-04\n",
      "Epoch 25/30\n",
      "\u001b[1m46/46\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - loss: 0.0033 - val_loss: 0.0012\n",
      "Epoch 26/30\n",
      "\u001b[1m46/46\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - loss: 0.0029 - val_loss: 7.7369e-04\n",
      "Epoch 27/30\n",
      "\u001b[1m46/46\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - loss: 0.0028 - val_loss: 7.2910e-04\n",
      "Epoch 28/30\n",
      "\u001b[1m46/46\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - loss: 0.0043 - val_loss: 7.2617e-04\n",
      "Epoch 29/30\n",
      "\u001b[1m46/46\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - loss: 0.0032 - val_loss: 7.0986e-04\n",
      "Epoch 30/30\n",
      "\u001b[1m46/46\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - loss: 0.0028 - val_loss: 8.4420e-04\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:The `save_format` argument is deprecated in Keras 3. We recommend removing this argument as it can be inferred from the file path. Received: save_format=keras\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Finished: Guinea-Bissau | MAE: 0.05 | RMSE: 0.10 | R²: 0.89\n",
      "Epoch 1/30\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/dejauhnaebeadle/School/MachineLearning/machine-learning-project/code/rain-prediction/.venv/lib/python3.11/site-packages/keras/src/layers/rnn/rnn.py:200: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
      "  super().__init__(**kwargs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m46/46\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 12ms/step - loss: 0.0609 - val_loss: 0.0049\n",
      "Epoch 2/30\n",
      "\u001b[1m46/46\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - loss: 0.0072 - val_loss: 0.0036\n",
      "Epoch 3/30\n",
      "\u001b[1m46/46\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - loss: 0.0054 - val_loss: 0.0026\n",
      "Epoch 4/30\n",
      "\u001b[1m46/46\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - loss: 0.0050 - val_loss: 0.0037\n",
      "Epoch 5/30\n",
      "\u001b[1m46/46\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - loss: 0.0041 - val_loss: 0.0019\n",
      "Epoch 6/30\n",
      "\u001b[1m46/46\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - loss: 0.0044 - val_loss: 0.0016\n",
      "Epoch 7/30\n",
      "\u001b[1m46/46\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - loss: 0.0036 - val_loss: 0.0020\n",
      "Epoch 8/30\n",
      "\u001b[1m46/46\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - loss: 0.0038 - val_loss: 0.0015\n",
      "Epoch 9/30\n",
      "\u001b[1m46/46\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - loss: 0.0033 - val_loss: 0.0017\n",
      "Epoch 10/30\n",
      "\u001b[1m46/46\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - loss: 0.0029 - val_loss: 0.0017\n",
      "Epoch 11/30\n",
      "\u001b[1m46/46\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - loss: 0.0028 - val_loss: 0.0023\n",
      "Epoch 12/30\n",
      "\u001b[1m46/46\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - loss: 0.0031 - val_loss: 0.0012\n",
      "Epoch 13/30\n",
      "\u001b[1m46/46\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - loss: 0.0029 - val_loss: 0.0015\n",
      "Epoch 14/30\n",
      "\u001b[1m46/46\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - loss: 0.0025 - val_loss: 9.9011e-04\n",
      "Epoch 15/30\n",
      "\u001b[1m46/46\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - loss: 0.0029 - val_loss: 0.0025\n",
      "Epoch 16/30\n",
      "\u001b[1m46/46\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - loss: 0.0027 - val_loss: 9.0460e-04\n",
      "Epoch 17/30\n",
      "\u001b[1m46/46\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - loss: 0.0027 - val_loss: 0.0032\n",
      "Epoch 18/30\n",
      "\u001b[1m46/46\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - loss: 0.0029 - val_loss: 0.0010\n",
      "Epoch 19/30\n",
      "\u001b[1m46/46\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - loss: 0.0026 - val_loss: 0.0022\n",
      "Epoch 20/30\n",
      "\u001b[1m46/46\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - loss: 0.0018 - val_loss: 8.2128e-04\n",
      "Epoch 21/30\n",
      "\u001b[1m46/46\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - loss: 0.0026 - val_loss: 7.9515e-04\n",
      "Epoch 22/30\n",
      "\u001b[1m46/46\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - loss: 0.0024 - val_loss: 0.0012\n",
      "Epoch 23/30\n",
      "\u001b[1m46/46\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - loss: 0.0018 - val_loss: 9.6073e-04\n",
      "Epoch 24/30\n",
      "\u001b[1m46/46\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - loss: 0.0019 - val_loss: 8.0440e-04\n",
      "Epoch 25/30\n",
      "\u001b[1m46/46\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - loss: 0.0023 - val_loss: 0.0025\n",
      "Epoch 26/30\n",
      "\u001b[1m46/46\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - loss: 0.0024 - val_loss: 0.0012\n",
      "Epoch 27/30\n",
      "\u001b[1m46/46\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - loss: 0.0018 - val_loss: 0.0011\n",
      "Epoch 28/30\n",
      "\u001b[1m46/46\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - loss: 0.0020 - val_loss: 8.2851e-04\n",
      "Epoch 29/30\n",
      "\u001b[1m46/46\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - loss: 0.0024 - val_loss: 8.1382e-04\n",
      "Epoch 30/30\n",
      "\u001b[1m46/46\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - loss: 0.0020 - val_loss: 6.7994e-04\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:The `save_format` argument is deprecated in Keras 3. We recommend removing this argument as it can be inferred from the file path. Received: save_format=keras\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Finished: Guyana | MAE: 0.04 | RMSE: 0.10 | R²: 0.92\n",
      "Epoch 1/30\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/dejauhnaebeadle/School/MachineLearning/machine-learning-project/code/rain-prediction/.venv/lib/python3.11/site-packages/keras/src/layers/rnn/rnn.py:200: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
      "  super().__init__(**kwargs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m46/46\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 13ms/step - loss: 0.0386 - val_loss: 0.0045\n",
      "Epoch 2/30\n",
      "\u001b[1m46/46\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - loss: 0.0090 - val_loss: 0.0036\n",
      "Epoch 3/30\n",
      "\u001b[1m46/46\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - loss: 0.0078 - val_loss: 0.0048\n",
      "Epoch 4/30\n",
      "\u001b[1m46/46\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - loss: 0.0070 - val_loss: 0.0023\n",
      "Epoch 5/30\n",
      "\u001b[1m46/46\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - loss: 0.0056 - val_loss: 0.0020\n",
      "Epoch 6/30\n",
      "\u001b[1m46/46\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - loss: 0.0045 - val_loss: 0.0038\n",
      "Epoch 7/30\n",
      "\u001b[1m46/46\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - loss: 0.0046 - val_loss: 0.0019\n",
      "Epoch 8/30\n",
      "\u001b[1m46/46\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - loss: 0.0046 - val_loss: 0.0040\n",
      "Epoch 9/30\n",
      "\u001b[1m46/46\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - loss: 0.0048 - val_loss: 0.0032\n",
      "Epoch 10/30\n",
      "\u001b[1m46/46\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - loss: 0.0041 - val_loss: 0.0025\n",
      "Epoch 11/30\n",
      "\u001b[1m46/46\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - loss: 0.0039 - val_loss: 0.0028\n",
      "Epoch 12/30\n",
      "\u001b[1m46/46\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - loss: 0.0044 - val_loss: 0.0030\n",
      "Epoch 13/30\n",
      "\u001b[1m46/46\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - loss: 0.0034 - val_loss: 0.0020\n",
      "Epoch 14/30\n",
      "\u001b[1m46/46\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - loss: 0.0028 - val_loss: 0.0034\n",
      "Epoch 15/30\n",
      "\u001b[1m46/46\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - loss: 0.0026 - val_loss: 0.0014\n",
      "Epoch 16/30\n",
      "\u001b[1m46/46\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - loss: 0.0037 - val_loss: 0.0014\n",
      "Epoch 17/30\n",
      "\u001b[1m46/46\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - loss: 0.0026 - val_loss: 0.0014\n",
      "Epoch 18/30\n",
      "\u001b[1m46/46\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - loss: 0.0028 - val_loss: 0.0014\n",
      "Epoch 19/30\n",
      "\u001b[1m46/46\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - loss: 0.0025 - val_loss: 0.0030\n",
      "Epoch 20/30\n",
      "\u001b[1m46/46\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - loss: 0.0027 - val_loss: 0.0014\n",
      "Epoch 21/30\n",
      "\u001b[1m46/46\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - loss: 0.0035 - val_loss: 0.0020\n",
      "Epoch 22/30\n",
      "\u001b[1m46/46\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - loss: 0.0024 - val_loss: 0.0015\n",
      "Epoch 23/30\n",
      "\u001b[1m46/46\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - loss: 0.0029 - val_loss: 0.0013\n",
      "Epoch 24/30\n",
      "\u001b[1m46/46\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - loss: 0.0031 - val_loss: 0.0015\n",
      "Epoch 25/30\n",
      "\u001b[1m46/46\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - loss: 0.0031 - val_loss: 0.0011\n",
      "Epoch 26/30\n",
      "\u001b[1m46/46\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - loss: 0.0026 - val_loss: 0.0029\n",
      "Epoch 27/30\n",
      "\u001b[1m46/46\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - loss: 0.0026 - val_loss: 0.0011\n",
      "Epoch 28/30\n",
      "\u001b[1m46/46\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - loss: 0.0025 - val_loss: 0.0012\n",
      "Epoch 29/30\n",
      "\u001b[1m46/46\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - loss: 0.0021 - val_loss: 0.0032\n",
      "Epoch 30/30\n",
      "\u001b[1m46/46\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - loss: 0.0029 - val_loss: 0.0013\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:The `save_format` argument is deprecated in Keras 3. We recommend removing this argument as it can be inferred from the file path. Received: save_format=keras\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Finished: Haiti | MAE: 0.07 | RMSE: 0.10 | R²: 0.92\n",
      "Epoch 1/30\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/dejauhnaebeadle/School/MachineLearning/machine-learning-project/code/rain-prediction/.venv/lib/python3.11/site-packages/keras/src/layers/rnn/rnn.py:200: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
      "  super().__init__(**kwargs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m46/46\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 13ms/step - loss: 0.0816 - val_loss: 0.0056\n",
      "Epoch 2/30\n",
      "\u001b[1m46/46\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - loss: 0.0075 - val_loss: 0.0054\n",
      "Epoch 3/30\n",
      "\u001b[1m46/46\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - loss: 0.0064 - val_loss: 0.0047\n",
      "Epoch 4/30\n",
      "\u001b[1m46/46\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - loss: 0.0068 - val_loss: 0.0053\n",
      "Epoch 5/30\n",
      "\u001b[1m46/46\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - loss: 0.0055 - val_loss: 0.0043\n",
      "Epoch 6/30\n",
      "\u001b[1m46/46\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - loss: 0.0043 - val_loss: 0.0039\n",
      "Epoch 7/30\n",
      "\u001b[1m46/46\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - loss: 0.0053 - val_loss: 0.0034\n",
      "Epoch 8/30\n",
      "\u001b[1m46/46\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - loss: 0.0035 - val_loss: 0.0032\n",
      "Epoch 9/30\n",
      "\u001b[1m46/46\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - loss: 0.0048 - val_loss: 0.0034\n",
      "Epoch 10/30\n",
      "\u001b[1m46/46\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - loss: 0.0042 - val_loss: 0.0032\n",
      "Epoch 11/30\n",
      "\u001b[1m46/46\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 13ms/step - loss: 0.0033 - val_loss: 0.0050\n",
      "Epoch 12/30\n",
      "\u001b[1m46/46\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - loss: 0.0045 - val_loss: 0.0031\n",
      "Epoch 13/30\n",
      "\u001b[1m46/46\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - loss: 0.0041 - val_loss: 0.0030\n",
      "Epoch 14/30\n",
      "\u001b[1m46/46\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - loss: 0.0029 - val_loss: 0.0029\n",
      "Epoch 15/30\n",
      "\u001b[1m46/46\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - loss: 0.0038 - val_loss: 0.0027\n",
      "Epoch 16/30\n",
      "\u001b[1m46/46\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - loss: 0.0031 - val_loss: 0.0027\n",
      "Epoch 17/30\n",
      "\u001b[1m46/46\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - loss: 0.0028 - val_loss: 0.0031\n",
      "Epoch 18/30\n",
      "\u001b[1m46/46\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - loss: 0.0033 - val_loss: 0.0025\n",
      "Epoch 19/30\n",
      "\u001b[1m46/46\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - loss: 0.0024 - val_loss: 0.0025\n",
      "Epoch 20/30\n",
      "\u001b[1m46/46\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - loss: 0.0033 - val_loss: 0.0026\n",
      "Epoch 21/30\n",
      "\u001b[1m46/46\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - loss: 0.0031 - val_loss: 0.0031\n",
      "Epoch 22/30\n",
      "\u001b[1m46/46\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - loss: 0.0030 - val_loss: 0.0023\n",
      "Epoch 23/30\n",
      "\u001b[1m46/46\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - loss: 0.0023 - val_loss: 0.0024\n",
      "Epoch 24/30\n",
      "\u001b[1m46/46\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - loss: 0.0029 - val_loss: 0.0024\n",
      "Epoch 25/30\n",
      "\u001b[1m46/46\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - loss: 0.0026 - val_loss: 0.0022\n",
      "Epoch 26/30\n",
      "\u001b[1m46/46\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - loss: 0.0033 - val_loss: 0.0022\n",
      "Epoch 27/30\n",
      "\u001b[1m46/46\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - loss: 0.0029 - val_loss: 0.0022\n",
      "Epoch 28/30\n",
      "\u001b[1m46/46\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - loss: 0.0024 - val_loss: 0.0021\n",
      "Epoch 29/30\n",
      "\u001b[1m46/46\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - loss: 0.0023 - val_loss: 0.0045\n",
      "Epoch 30/30\n",
      "\u001b[1m46/46\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - loss: 0.0029 - val_loss: 0.0021\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:The `save_format` argument is deprecated in Keras 3. We recommend removing this argument as it can be inferred from the file path. Received: save_format=keras\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Finished: Heard Island and McDonald Islands | MAE: 0.04 | RMSE: 0.09 | R²: 0.89\n",
      "Epoch 1/30\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/dejauhnaebeadle/School/MachineLearning/machine-learning-project/code/rain-prediction/.venv/lib/python3.11/site-packages/keras/src/layers/rnn/rnn.py:200: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
      "  super().__init__(**kwargs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m46/46\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 13ms/step - loss: 0.0556 - val_loss: 0.0017\n",
      "Epoch 2/30\n",
      "\u001b[1m46/46\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - loss: 0.0051 - val_loss: 0.0025\n",
      "Epoch 3/30\n",
      "\u001b[1m46/46\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - loss: 0.0047 - val_loss: 0.0032\n",
      "Epoch 4/30\n",
      "\u001b[1m46/46\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - loss: 0.0050 - val_loss: 0.0028\n",
      "Epoch 5/30\n",
      "\u001b[1m46/46\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - loss: 0.0038 - val_loss: 0.0020\n",
      "Epoch 6/30\n",
      "\u001b[1m46/46\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - loss: 0.0040 - val_loss: 0.0018\n",
      "Epoch 7/30\n",
      "\u001b[1m46/46\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - loss: 0.0038 - val_loss: 0.0010\n",
      "Epoch 8/30\n",
      "\u001b[1m46/46\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - loss: 0.0031 - val_loss: 0.0049\n",
      "Epoch 9/30\n",
      "\u001b[1m46/46\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - loss: 0.0035 - val_loss: 0.0018\n",
      "Epoch 10/30\n",
      "\u001b[1m46/46\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - loss: 0.0032 - val_loss: 0.0022\n",
      "Epoch 11/30\n",
      "\u001b[1m46/46\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - loss: 0.0024 - val_loss: 0.0025\n",
      "Epoch 12/30\n",
      "\u001b[1m46/46\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - loss: 0.0024 - val_loss: 0.0010\n",
      "Epoch 13/30\n",
      "\u001b[1m46/46\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - loss: 0.0023 - val_loss: 8.9546e-04\n",
      "Epoch 14/30\n",
      "\u001b[1m46/46\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - loss: 0.0026 - val_loss: 8.3366e-04\n",
      "Epoch 15/30\n",
      "\u001b[1m46/46\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - loss: 0.0025 - val_loss: 7.6412e-04\n",
      "Epoch 16/30\n",
      "\u001b[1m46/46\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - loss: 0.0026 - val_loss: 7.2823e-04\n",
      "Epoch 17/30\n",
      "\u001b[1m46/46\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - loss: 0.0024 - val_loss: 0.0036\n",
      "Epoch 18/30\n",
      "\u001b[1m46/46\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - loss: 0.0024 - val_loss: 7.8668e-04\n",
      "Epoch 19/30\n",
      "\u001b[1m46/46\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - loss: 0.0018 - val_loss: 0.0030\n",
      "Epoch 20/30\n",
      "\u001b[1m46/46\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - loss: 0.0022 - val_loss: 0.0013\n",
      "Epoch 21/30\n",
      "\u001b[1m46/46\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - loss: 0.0023 - val_loss: 6.5072e-04\n",
      "Epoch 22/30\n",
      "\u001b[1m46/46\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - loss: 0.0020 - val_loss: 9.5504e-04\n",
      "Epoch 23/30\n",
      "\u001b[1m46/46\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - loss: 0.0016 - val_loss: 8.3328e-04\n",
      "Epoch 24/30\n",
      "\u001b[1m46/46\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - loss: 0.0020 - val_loss: 0.0015\n",
      "Epoch 25/30\n",
      "\u001b[1m46/46\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - loss: 0.0018 - val_loss: 0.0023\n",
      "Epoch 26/30\n",
      "\u001b[1m46/46\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - loss: 0.0020 - val_loss: 0.0012\n",
      "Epoch 27/30\n",
      "\u001b[1m46/46\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - loss: 0.0019 - val_loss: 6.2415e-04\n",
      "Epoch 28/30\n",
      "\u001b[1m46/46\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - loss: 0.0018 - val_loss: 7.9062e-04\n",
      "Epoch 29/30\n",
      "\u001b[1m46/46\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - loss: 0.0019 - val_loss: 9.9940e-04\n",
      "Epoch 30/30\n",
      "\u001b[1m46/46\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - loss: 0.0015 - val_loss: 0.0011\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:The `save_format` argument is deprecated in Keras 3. We recommend removing this argument as it can be inferred from the file path. Received: save_format=keras\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Finished: Honduras | MAE: 0.14 | RMSE: 0.18 | R²: 0.83\n",
      "Epoch 1/30\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/dejauhnaebeadle/School/MachineLearning/machine-learning-project/code/rain-prediction/.venv/lib/python3.11/site-packages/keras/src/layers/rnn/rnn.py:200: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
      "  super().__init__(**kwargs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m46/46\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 12ms/step - loss: 0.0395 - val_loss: 0.0083\n",
      "Epoch 2/30\n",
      "\u001b[1m46/46\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - loss: 0.0081 - val_loss: 0.0040\n",
      "Epoch 3/30\n",
      "\u001b[1m46/46\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - loss: 0.0072 - val_loss: 0.0045\n",
      "Epoch 4/30\n",
      "\u001b[1m46/46\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - loss: 0.0053 - val_loss: 0.0093\n",
      "Epoch 5/30\n",
      "\u001b[1m46/46\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - loss: 0.0060 - val_loss: 0.0032\n",
      "Epoch 6/30\n",
      "\u001b[1m46/46\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - loss: 0.0056 - val_loss: 0.0081\n",
      "Epoch 7/30\n",
      "\u001b[1m46/46\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - loss: 0.0050 - val_loss: 0.0024\n",
      "Epoch 8/30\n",
      "\u001b[1m46/46\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - loss: 0.0050 - val_loss: 0.0024\n",
      "Epoch 9/30\n",
      "\u001b[1m46/46\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - loss: 0.0046 - val_loss: 0.0039\n",
      "Epoch 10/30\n",
      "\u001b[1m46/46\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - loss: 0.0040 - val_loss: 0.0030\n",
      "Epoch 11/30\n",
      "\u001b[1m46/46\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - loss: 0.0042 - val_loss: 0.0032\n",
      "Epoch 12/30\n",
      "\u001b[1m46/46\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - loss: 0.0036 - val_loss: 0.0039\n",
      "Epoch 13/30\n",
      "\u001b[1m46/46\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - loss: 0.0044 - val_loss: 0.0022\n",
      "Epoch 14/30\n",
      "\u001b[1m46/46\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - loss: 0.0041 - val_loss: 0.0019\n",
      "Epoch 15/30\n",
      "\u001b[1m46/46\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - loss: 0.0033 - val_loss: 0.0032\n",
      "Epoch 16/30\n",
      "\u001b[1m46/46\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - loss: 0.0037 - val_loss: 0.0023\n",
      "Epoch 17/30\n",
      "\u001b[1m46/46\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - loss: 0.0036 - val_loss: 0.0018\n",
      "Epoch 18/30\n",
      "\u001b[1m46/46\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - loss: 0.0032 - val_loss: 0.0056\n",
      "Epoch 19/30\n",
      "\u001b[1m46/46\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - loss: 0.0027 - val_loss: 0.0020\n",
      "Epoch 20/30\n",
      "\u001b[1m46/46\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - loss: 0.0041 - val_loss: 0.0019\n",
      "Epoch 21/30\n",
      "\u001b[1m46/46\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - loss: 0.0039 - val_loss: 0.0017\n",
      "Epoch 22/30\n",
      "\u001b[1m46/46\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - loss: 0.0027 - val_loss: 0.0017\n",
      "Epoch 23/30\n",
      "\u001b[1m46/46\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - loss: 0.0031 - val_loss: 0.0020\n",
      "Epoch 24/30\n",
      "\u001b[1m46/46\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - loss: 0.0026 - val_loss: 0.0018\n",
      "Epoch 25/30\n",
      "\u001b[1m46/46\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - loss: 0.0036 - val_loss: 0.0027\n",
      "Epoch 26/30\n",
      "\u001b[1m46/46\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - loss: 0.0025 - val_loss: 0.0020\n",
      "Epoch 27/30\n",
      "\u001b[1m46/46\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - loss: 0.0030 - val_loss: 0.0018\n",
      "Epoch 28/30\n",
      "\u001b[1m46/46\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - loss: 0.0024 - val_loss: 0.0015\n",
      "Epoch 29/30\n",
      "\u001b[1m46/46\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - loss: 0.0027 - val_loss: 0.0015\n",
      "Epoch 30/30\n",
      "\u001b[1m46/46\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - loss: 0.0021 - val_loss: 0.0019\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:The `save_format` argument is deprecated in Keras 3. We recommend removing this argument as it can be inferred from the file path. Received: save_format=keras\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Finished: Hong Kong | MAE: 0.07 | RMSE: 0.12 | R²: 0.91\n",
      "Epoch 1/30\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/dejauhnaebeadle/School/MachineLearning/machine-learning-project/code/rain-prediction/.venv/lib/python3.11/site-packages/keras/src/layers/rnn/rnn.py:200: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
      "  super().__init__(**kwargs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m46/46\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 14ms/step - loss: 0.0959 - val_loss: 0.0070\n",
      "Epoch 2/30\n",
      "\u001b[1m46/46\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - loss: 0.0076 - val_loss: 0.0079\n",
      "Epoch 3/30\n",
      "\u001b[1m46/46\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - loss: 0.0064 - val_loss: 0.0061\n",
      "Epoch 4/30\n",
      "\u001b[1m46/46\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - loss: 0.0065 - val_loss: 0.0055\n",
      "Epoch 5/30\n",
      "\u001b[1m46/46\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - loss: 0.0065 - val_loss: 0.0054\n",
      "Epoch 6/30\n",
      "\u001b[1m46/46\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - loss: 0.0057 - val_loss: 0.0090\n",
      "Epoch 7/30\n",
      "\u001b[1m46/46\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - loss: 0.0056 - val_loss: 0.0049\n",
      "Epoch 8/30\n",
      "\u001b[1m46/46\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - loss: 0.0042 - val_loss: 0.0039\n",
      "Epoch 9/30\n",
      "\u001b[1m46/46\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - loss: 0.0046 - val_loss: 0.0040\n",
      "Epoch 10/30\n",
      "\u001b[1m46/46\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - loss: 0.0037 - val_loss: 0.0050\n",
      "Epoch 11/30\n",
      "\u001b[1m46/46\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - loss: 0.0040 - val_loss: 0.0043\n",
      "Epoch 12/30\n",
      "\u001b[1m46/46\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - loss: 0.0039 - val_loss: 0.0033\n",
      "Epoch 13/30\n",
      "\u001b[1m46/46\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - loss: 0.0037 - val_loss: 0.0035\n",
      "Epoch 14/30\n",
      "\u001b[1m46/46\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - loss: 0.0031 - val_loss: 0.0039\n",
      "Epoch 15/30\n",
      "\u001b[1m46/46\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - loss: 0.0034 - val_loss: 0.0030\n",
      "Epoch 16/30\n",
      "\u001b[1m46/46\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - loss: 0.0031 - val_loss: 0.0038\n",
      "Epoch 17/30\n",
      "\u001b[1m46/46\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - loss: 0.0031 - val_loss: 0.0046\n",
      "Epoch 18/30\n",
      "\u001b[1m46/46\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - loss: 0.0032 - val_loss: 0.0034\n",
      "Epoch 19/30\n",
      "\u001b[1m46/46\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - loss: 0.0033 - val_loss: 0.0032\n",
      "Epoch 20/30\n",
      "\u001b[1m46/46\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - loss: 0.0033 - val_loss: 0.0030\n",
      "Epoch 21/30\n",
      "\u001b[1m46/46\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - loss: 0.0026 - val_loss: 0.0038\n",
      "Epoch 22/30\n",
      "\u001b[1m46/46\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - loss: 0.0027 - val_loss: 0.0024\n",
      "Epoch 23/30\n",
      "\u001b[1m46/46\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - loss: 0.0026 - val_loss: 0.0026\n",
      "Epoch 24/30\n",
      "\u001b[1m46/46\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - loss: 0.0028 - val_loss: 0.0026\n",
      "Epoch 25/30\n",
      "\u001b[1m46/46\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - loss: 0.0030 - val_loss: 0.0023\n",
      "Epoch 26/30\n",
      "\u001b[1m46/46\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - loss: 0.0033 - val_loss: 0.0023\n",
      "Epoch 27/30\n",
      "\u001b[1m46/46\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - loss: 0.0023 - val_loss: 0.0028\n",
      "Epoch 28/30\n",
      "\u001b[1m46/46\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - loss: 0.0033 - val_loss: 0.0034\n",
      "Epoch 29/30\n",
      "\u001b[1m46/46\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - loss: 0.0028 - val_loss: 0.0025\n",
      "Epoch 30/30\n",
      "\u001b[1m46/46\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - loss: 0.0025 - val_loss: 0.0032\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:The `save_format` argument is deprecated in Keras 3. We recommend removing this argument as it can be inferred from the file path. Received: save_format=keras\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Finished: Hungary | MAE: 0.30 | RMSE: 0.34 | R²: 0.68\n",
      "Epoch 1/30\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/dejauhnaebeadle/School/MachineLearning/machine-learning-project/code/rain-prediction/.venv/lib/python3.11/site-packages/keras/src/layers/rnn/rnn.py:200: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
      "  super().__init__(**kwargs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m46/46\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 13ms/step - loss: 0.0747 - val_loss: 0.0070\n",
      "Epoch 2/30\n",
      "\u001b[1m46/46\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - loss: 0.0124 - val_loss: 0.0052\n",
      "Epoch 3/30\n",
      "\u001b[1m46/46\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - loss: 0.0100 - val_loss: 0.0030\n",
      "Epoch 4/30\n",
      "\u001b[1m46/46\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - loss: 0.0087 - val_loss: 0.0051\n",
      "Epoch 5/30\n",
      "\u001b[1m46/46\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - loss: 0.0064 - val_loss: 0.0040\n",
      "Epoch 6/30\n",
      "\u001b[1m46/46\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - loss: 0.0065 - val_loss: 0.0021\n",
      "Epoch 7/30\n",
      "\u001b[1m46/46\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - loss: 0.0047 - val_loss: 0.0032\n",
      "Epoch 8/30\n",
      "\u001b[1m46/46\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - loss: 0.0054 - val_loss: 0.0016\n",
      "Epoch 9/30\n",
      "\u001b[1m46/46\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - loss: 0.0060 - val_loss: 0.0040\n",
      "Epoch 10/30\n",
      "\u001b[1m46/46\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - loss: 0.0059 - val_loss: 0.0030\n",
      "Epoch 11/30\n",
      "\u001b[1m46/46\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - loss: 0.0042 - val_loss: 0.0019\n",
      "Epoch 12/30\n",
      "\u001b[1m46/46\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - loss: 0.0050 - val_loss: 0.0046\n",
      "Epoch 13/30\n",
      "\u001b[1m46/46\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - loss: 0.0038 - val_loss: 0.0022\n",
      "Epoch 14/30\n",
      "\u001b[1m46/46\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - loss: 0.0044 - val_loss: 0.0023\n",
      "Epoch 15/30\n",
      "\u001b[1m46/46\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - loss: 0.0053 - val_loss: 0.0031\n",
      "Epoch 16/30\n",
      "\u001b[1m46/46\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - loss: 0.0046 - val_loss: 0.0012\n",
      "Epoch 17/30\n",
      "\u001b[1m46/46\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - loss: 0.0036 - val_loss: 0.0012\n",
      "Epoch 18/30\n",
      "\u001b[1m46/46\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - loss: 0.0042 - val_loss: 0.0019\n",
      "Epoch 19/30\n",
      "\u001b[1m46/46\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - loss: 0.0032 - val_loss: 0.0011\n",
      "Epoch 20/30\n",
      "\u001b[1m46/46\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - loss: 0.0038 - val_loss: 0.0016\n",
      "Epoch 21/30\n",
      "\u001b[1m46/46\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 6ms/step - loss: 0.0028 - val_loss: 0.0012\n",
      "Epoch 22/30\n",
      "\u001b[1m46/46\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - loss: 0.0030 - val_loss: 0.0019\n",
      "Epoch 23/30\n",
      "\u001b[1m46/46\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - loss: 0.0041 - val_loss: 0.0011\n",
      "Epoch 24/30\n",
      "\u001b[1m46/46\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - loss: 0.0052 - val_loss: 0.0010\n",
      "Epoch 25/30\n",
      "\u001b[1m46/46\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - loss: 0.0028 - val_loss: 0.0022\n",
      "Epoch 26/30\n",
      "\u001b[1m46/46\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - loss: 0.0039 - val_loss: 9.4795e-04\n",
      "Epoch 27/30\n",
      "\u001b[1m46/46\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - loss: 0.0033 - val_loss: 9.8862e-04\n",
      "Epoch 28/30\n",
      "\u001b[1m46/46\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - loss: 0.0031 - val_loss: 0.0011\n",
      "Epoch 29/30\n",
      "\u001b[1m46/46\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - loss: 0.0026 - val_loss: 0.0025\n",
      "Epoch 30/30\n",
      "\u001b[1m46/46\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - loss: 0.0033 - val_loss: 0.0014\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:The `save_format` argument is deprecated in Keras 3. We recommend removing this argument as it can be inferred from the file path. Received: save_format=keras\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Finished: Iceland | MAE: 0.14 | RMSE: 0.22 | R²: 0.82\n",
      "Epoch 1/30\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/dejauhnaebeadle/School/MachineLearning/machine-learning-project/code/rain-prediction/.venv/lib/python3.11/site-packages/keras/src/layers/rnn/rnn.py:200: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
      "  super().__init__(**kwargs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m46/46\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 13ms/step - loss: 0.1187 - val_loss: 0.0039\n",
      "Epoch 2/30\n",
      "\u001b[1m46/46\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - loss: 0.0093 - val_loss: 0.0058\n",
      "Epoch 3/30\n",
      "\u001b[1m46/46\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - loss: 0.0084 - val_loss: 0.0049\n",
      "Epoch 4/30\n",
      "\u001b[1m46/46\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - loss: 0.0101 - val_loss: 0.0036\n",
      "Epoch 5/30\n",
      "\u001b[1m46/46\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - loss: 0.0074 - val_loss: 0.0024\n",
      "Epoch 6/30\n",
      "\u001b[1m46/46\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - loss: 0.0070 - val_loss: 0.0031\n",
      "Epoch 7/30\n",
      "\u001b[1m46/46\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - loss: 0.0059 - val_loss: 0.0019\n",
      "Epoch 8/30\n",
      "\u001b[1m46/46\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - loss: 0.0051 - val_loss: 0.0017\n",
      "Epoch 9/30\n",
      "\u001b[1m46/46\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - loss: 0.0050 - val_loss: 0.0026\n",
      "Epoch 10/30\n",
      "\u001b[1m46/46\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - loss: 0.0049 - val_loss: 0.0031\n",
      "Epoch 11/30\n",
      "\u001b[1m46/46\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - loss: 0.0040 - val_loss: 0.0047\n",
      "Epoch 12/30\n",
      "\u001b[1m46/46\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - loss: 0.0042 - val_loss: 0.0024\n",
      "Epoch 13/30\n",
      "\u001b[1m46/46\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - loss: 0.0033 - val_loss: 0.0039\n",
      "Epoch 14/30\n",
      "\u001b[1m46/46\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - loss: 0.0044 - val_loss: 0.0030\n",
      "Epoch 15/30\n",
      "\u001b[1m46/46\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - loss: 0.0043 - val_loss: 0.0013\n",
      "Epoch 16/30\n",
      "\u001b[1m46/46\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - loss: 0.0035 - val_loss: 0.0014\n",
      "Epoch 17/30\n",
      "\u001b[1m46/46\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - loss: 0.0045 - val_loss: 0.0015\n",
      "Epoch 18/30\n",
      "\u001b[1m46/46\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - loss: 0.0033 - val_loss: 0.0012\n",
      "Epoch 19/30\n",
      "\u001b[1m46/46\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - loss: 0.0031 - val_loss: 0.0026\n",
      "Epoch 20/30\n",
      "\u001b[1m46/46\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - loss: 0.0043 - val_loss: 0.0012\n",
      "Epoch 21/30\n",
      "\u001b[1m46/46\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - loss: 0.0043 - val_loss: 0.0019\n",
      "Epoch 22/30\n",
      "\u001b[1m46/46\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - loss: 0.0027 - val_loss: 0.0011\n",
      "Epoch 23/30\n",
      "\u001b[1m46/46\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - loss: 0.0027 - val_loss: 0.0011\n",
      "Epoch 24/30\n",
      "\u001b[1m46/46\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - loss: 0.0036 - val_loss: 0.0013\n",
      "Epoch 25/30\n",
      "\u001b[1m46/46\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - loss: 0.0029 - val_loss: 0.0018\n",
      "Epoch 26/30\n",
      "\u001b[1m46/46\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - loss: 0.0028 - val_loss: 0.0025\n",
      "Epoch 27/30\n",
      "\u001b[1m46/46\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - loss: 0.0035 - val_loss: 0.0011\n",
      "Epoch 28/30\n",
      "\u001b[1m46/46\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - loss: 0.0036 - val_loss: 9.6760e-04\n",
      "Epoch 29/30\n",
      "\u001b[1m46/46\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - loss: 0.0025 - val_loss: 0.0013\n",
      "Epoch 30/30\n",
      "\u001b[1m46/46\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - loss: 0.0029 - val_loss: 0.0013\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:The `save_format` argument is deprecated in Keras 3. We recommend removing this argument as it can be inferred from the file path. Received: save_format=keras\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Finished: India | MAE: 0.08 | RMSE: 0.11 | R²: 0.83\n",
      "Epoch 1/30\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/dejauhnaebeadle/School/MachineLearning/machine-learning-project/code/rain-prediction/.venv/lib/python3.11/site-packages/keras/src/layers/rnn/rnn.py:200: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
      "  super().__init__(**kwargs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m46/46\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 12ms/step - loss: 0.0238 - val_loss: 0.0011\n",
      "Epoch 2/30\n",
      "\u001b[1m46/46\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - loss: 0.0026 - val_loss: 7.8828e-04\n",
      "Epoch 3/30\n",
      "\u001b[1m46/46\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - loss: 0.0022 - val_loss: 4.3878e-04\n",
      "Epoch 4/30\n",
      "\u001b[1m46/46\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - loss: 0.0025 - val_loss: 3.9769e-04\n",
      "Epoch 5/30\n",
      "\u001b[1m46/46\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - loss: 0.0019 - val_loss: 0.0011\n",
      "Epoch 6/30\n",
      "\u001b[1m46/46\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - loss: 0.0020 - val_loss: 0.0018\n",
      "Epoch 7/30\n",
      "\u001b[1m46/46\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - loss: 0.0021 - val_loss: 2.7242e-04\n",
      "Epoch 8/30\n",
      "\u001b[1m46/46\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - loss: 0.0014 - val_loss: 0.0021\n",
      "Epoch 9/30\n",
      "\u001b[1m46/46\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - loss: 0.0015 - val_loss: 2.4245e-04\n",
      "Epoch 10/30\n",
      "\u001b[1m46/46\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - loss: 0.0016 - val_loss: 2.6056e-04\n",
      "Epoch 11/30\n",
      "\u001b[1m46/46\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - loss: 0.0016 - val_loss: 3.3105e-04\n",
      "Epoch 12/30\n",
      "\u001b[1m46/46\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - loss: 0.0016 - val_loss: 2.4010e-04\n",
      "Epoch 13/30\n",
      "\u001b[1m46/46\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - loss: 0.0014 - val_loss: 2.2151e-04\n",
      "Epoch 14/30\n",
      "\u001b[1m46/46\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - loss: 0.0017 - val_loss: 2.5991e-04\n",
      "Epoch 15/30\n",
      "\u001b[1m46/46\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - loss: 0.0012 - val_loss: 6.1409e-04\n",
      "Epoch 16/30\n",
      "\u001b[1m46/46\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - loss: 9.6624e-04 - val_loss: 4.2959e-04\n",
      "Epoch 17/30\n",
      "\u001b[1m46/46\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - loss: 0.0011 - val_loss: 2.0557e-04\n",
      "Epoch 18/30\n",
      "\u001b[1m46/46\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - loss: 0.0012 - val_loss: 2.7708e-04\n",
      "Epoch 19/30\n",
      "\u001b[1m46/46\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - loss: 9.6633e-04 - val_loss: 2.5309e-04\n",
      "Epoch 20/30\n",
      "\u001b[1m46/46\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - loss: 0.0017 - val_loss: 6.4545e-04\n",
      "Epoch 21/30\n",
      "\u001b[1m46/46\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - loss: 0.0012 - val_loss: 0.0019\n",
      "Epoch 22/30\n",
      "\u001b[1m46/46\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - loss: 0.0011 - val_loss: 1.8999e-04\n",
      "Epoch 23/30\n",
      "\u001b[1m46/46\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - loss: 0.0010 - val_loss: 3.1982e-04\n",
      "Epoch 24/30\n",
      "\u001b[1m46/46\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - loss: 9.6418e-04 - val_loss: 3.6976e-04\n",
      "Epoch 25/30\n",
      "\u001b[1m46/46\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - loss: 0.0010 - val_loss: 5.3103e-04\n",
      "Epoch 26/30\n",
      "\u001b[1m46/46\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - loss: 8.2628e-04 - val_loss: 4.4150e-04\n",
      "Epoch 27/30\n",
      "\u001b[1m46/46\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - loss: 7.8388e-04 - val_loss: 1.8070e-04\n",
      "Epoch 28/30\n",
      "\u001b[1m46/46\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - loss: 9.6546e-04 - val_loss: 5.0270e-04\n",
      "Epoch 29/30\n",
      "\u001b[1m46/46\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - loss: 8.3387e-04 - val_loss: 9.4435e-04\n",
      "Epoch 30/30\n",
      "\u001b[1m46/46\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - loss: 9.7812e-04 - val_loss: 4.5901e-04\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:The `save_format` argument is deprecated in Keras 3. We recommend removing this argument as it can be inferred from the file path. Received: save_format=keras\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Finished: Indonesia | MAE: 0.07 | RMSE: 0.09 | R²: 0.87\n",
      "Epoch 1/30\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/dejauhnaebeadle/School/MachineLearning/machine-learning-project/code/rain-prediction/.venv/lib/python3.11/site-packages/keras/src/layers/rnn/rnn.py:200: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
      "  super().__init__(**kwargs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m46/46\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 13ms/step - loss: 0.0539 - val_loss: 0.0047\n",
      "Epoch 2/30\n",
      "\u001b[1m46/46\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - loss: 0.0109 - val_loss: 0.0028\n",
      "Epoch 3/30\n",
      "\u001b[1m46/46\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - loss: 0.0083 - val_loss: 0.0028\n",
      "Epoch 4/30\n",
      "\u001b[1m46/46\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - loss: 0.0077 - val_loss: 0.0021\n",
      "Epoch 5/30\n",
      "\u001b[1m46/46\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - loss: 0.0068 - val_loss: 0.0035\n",
      "Epoch 6/30\n",
      "\u001b[1m46/46\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - loss: 0.0044 - val_loss: 0.0053\n",
      "Epoch 7/30\n",
      "\u001b[1m46/46\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - loss: 0.0062 - val_loss: 0.0040\n",
      "Epoch 8/30\n",
      "\u001b[1m46/46\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - loss: 0.0059 - val_loss: 0.0023\n",
      "Epoch 9/30\n",
      "\u001b[1m46/46\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - loss: 0.0048 - val_loss: 0.0011\n",
      "Epoch 10/30\n",
      "\u001b[1m46/46\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - loss: 0.0039 - val_loss: 0.0102\n",
      "Epoch 11/30\n",
      "\u001b[1m46/46\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - loss: 0.0055 - val_loss: 0.0011\n",
      "Epoch 12/30\n",
      "\u001b[1m46/46\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - loss: 0.0047 - val_loss: 0.0013\n",
      "Epoch 13/30\n",
      "\u001b[1m46/46\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - loss: 0.0041 - val_loss: 0.0011\n",
      "Epoch 14/30\n",
      "\u001b[1m46/46\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - loss: 0.0047 - val_loss: 0.0016\n",
      "Epoch 15/30\n",
      "\u001b[1m46/46\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - loss: 0.0034 - val_loss: 9.2515e-04\n",
      "Epoch 16/30\n",
      "\u001b[1m46/46\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - loss: 0.0034 - val_loss: 8.3991e-04\n",
      "Epoch 17/30\n",
      "\u001b[1m46/46\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - loss: 0.0027 - val_loss: 0.0018\n",
      "Epoch 18/30\n",
      "\u001b[1m46/46\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - loss: 0.0032 - val_loss: 0.0010\n",
      "Epoch 19/30\n",
      "\u001b[1m46/46\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - loss: 0.0037 - val_loss: 8.1886e-04\n",
      "Epoch 20/30\n",
      "\u001b[1m46/46\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - loss: 0.0027 - val_loss: 0.0011\n",
      "Epoch 21/30\n",
      "\u001b[1m46/46\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - loss: 0.0046 - val_loss: 7.8868e-04\n",
      "Epoch 22/30\n",
      "\u001b[1m46/46\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - loss: 0.0041 - val_loss: 0.0010\n",
      "Epoch 23/30\n",
      "\u001b[1m46/46\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - loss: 0.0038 - val_loss: 0.0012\n",
      "Epoch 24/30\n",
      "\u001b[1m46/46\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - loss: 0.0032 - val_loss: 0.0011\n",
      "Epoch 25/30\n",
      "\u001b[1m46/46\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - loss: 0.0035 - val_loss: 8.0906e-04\n",
      "Epoch 26/30\n",
      "\u001b[1m46/46\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - loss: 0.0025 - val_loss: 7.1621e-04\n",
      "Epoch 27/30\n",
      "\u001b[1m46/46\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - loss: 0.0026 - val_loss: 8.6898e-04\n",
      "Epoch 28/30\n",
      "\u001b[1m46/46\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - loss: 0.0032 - val_loss: 7.5198e-04\n",
      "Epoch 29/30\n",
      "\u001b[1m46/46\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - loss: 0.0034 - val_loss: 6.7848e-04\n",
      "Epoch 30/30\n",
      "\u001b[1m46/46\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - loss: 0.0036 - val_loss: 0.0014\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:The `save_format` argument is deprecated in Keras 3. We recommend removing this argument as it can be inferred from the file path. Received: save_format=keras\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Finished: Iran | MAE: 0.18 | RMSE: 0.24 | R²: 0.78\n",
      "Epoch 1/30\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/dejauhnaebeadle/School/MachineLearning/machine-learning-project/code/rain-prediction/.venv/lib/python3.11/site-packages/keras/src/layers/rnn/rnn.py:200: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
      "  super().__init__(**kwargs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m46/46\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 12ms/step - loss: 0.0816 - val_loss: 0.0082\n",
      "Epoch 2/30\n",
      "\u001b[1m46/46\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - loss: 0.0135 - val_loss: 0.0039\n",
      "Epoch 3/30\n",
      "\u001b[1m46/46\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - loss: 0.0103 - val_loss: 0.0061\n",
      "Epoch 4/30\n",
      "\u001b[1m46/46\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - loss: 0.0098 - val_loss: 0.0024\n",
      "Epoch 5/30\n",
      "\u001b[1m46/46\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - loss: 0.0087 - val_loss: 0.0019\n",
      "Epoch 6/30\n",
      "\u001b[1m46/46\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - loss: 0.0062 - val_loss: 4.6420e-04\n",
      "Epoch 7/30\n",
      "\u001b[1m46/46\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - loss: 0.0064 - val_loss: 9.2526e-04\n",
      "Epoch 8/30\n",
      "\u001b[1m46/46\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - loss: 0.0062 - val_loss: 0.0021\n",
      "Epoch 9/30\n",
      "\u001b[1m46/46\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - loss: 0.0060 - val_loss: 0.0020\n",
      "Epoch 10/30\n",
      "\u001b[1m46/46\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - loss: 0.0060 - val_loss: 0.0022\n",
      "Epoch 11/30\n",
      "\u001b[1m46/46\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - loss: 0.0049 - val_loss: 0.0018\n",
      "Epoch 12/30\n",
      "\u001b[1m46/46\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - loss: 0.0058 - val_loss: 0.0040\n",
      "Epoch 13/30\n",
      "\u001b[1m46/46\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - loss: 0.0053 - val_loss: 3.6258e-04\n",
      "Epoch 14/30\n",
      "\u001b[1m46/46\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - loss: 0.0049 - val_loss: 0.0019\n",
      "Epoch 15/30\n",
      "\u001b[1m46/46\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - loss: 0.0044 - val_loss: 0.0019\n",
      "Epoch 16/30\n",
      "\u001b[1m46/46\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - loss: 0.0037 - val_loss: 3.0741e-04\n",
      "Epoch 17/30\n",
      "\u001b[1m46/46\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - loss: 0.0036 - val_loss: 6.5584e-04\n",
      "Epoch 18/30\n",
      "\u001b[1m46/46\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - loss: 0.0045 - val_loss: 0.0012\n",
      "Epoch 19/30\n",
      "\u001b[1m46/46\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - loss: 0.0038 - val_loss: 0.0047\n",
      "Epoch 20/30\n",
      "\u001b[1m46/46\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - loss: 0.0040 - val_loss: 6.5358e-04\n",
      "Epoch 21/30\n",
      "\u001b[1m46/46\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - loss: 0.0039 - val_loss: 0.0025\n",
      "Epoch 22/30\n",
      "\u001b[1m46/46\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - loss: 0.0035 - val_loss: 4.1874e-04\n",
      "Epoch 23/30\n",
      "\u001b[1m46/46\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - loss: 0.0043 - val_loss: 2.6823e-04\n",
      "Epoch 24/30\n",
      "\u001b[1m46/46\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - loss: 0.0038 - val_loss: 3.5222e-04\n",
      "Epoch 25/30\n",
      "\u001b[1m46/46\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - loss: 0.0034 - val_loss: 6.7480e-04\n",
      "Epoch 26/30\n",
      "\u001b[1m46/46\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - loss: 0.0037 - val_loss: 0.0013\n",
      "Epoch 27/30\n",
      "\u001b[1m46/46\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - loss: 0.0044 - val_loss: 6.0540e-04\n",
      "Epoch 28/30\n",
      "\u001b[1m46/46\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - loss: 0.0047 - val_loss: 2.1068e-04\n",
      "Epoch 29/30\n",
      "\u001b[1m46/46\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - loss: 0.0030 - val_loss: 2.7636e-04\n",
      "Epoch 30/30\n",
      "\u001b[1m46/46\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - loss: 0.0023 - val_loss: 8.9553e-04\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:The `save_format` argument is deprecated in Keras 3. We recommend removing this argument as it can be inferred from the file path. Received: save_format=keras\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Finished: Iraq | MAE: 0.17 | RMSE: 0.27 | R²: 0.78\n",
      "Epoch 1/30\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/dejauhnaebeadle/School/MachineLearning/machine-learning-project/code/rain-prediction/.venv/lib/python3.11/site-packages/keras/src/layers/rnn/rnn.py:200: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
      "  super().__init__(**kwargs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m46/46\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 15ms/step - loss: 0.1746 - val_loss: 0.0111\n",
      "Epoch 2/30\n",
      "\u001b[1m46/46\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - loss: 0.0178 - val_loss: 0.0073\n",
      "Epoch 3/30\n",
      "\u001b[1m46/46\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - loss: 0.0155 - val_loss: 0.0099\n",
      "Epoch 4/30\n",
      "\u001b[1m46/46\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - loss: 0.0125 - val_loss: 0.0068\n",
      "Epoch 5/30\n",
      "\u001b[1m46/46\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - loss: 0.0117 - val_loss: 0.0055\n",
      "Epoch 6/30\n",
      "\u001b[1m46/46\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - loss: 0.0095 - val_loss: 0.0029\n",
      "Epoch 7/30\n",
      "\u001b[1m46/46\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - loss: 0.0081 - val_loss: 0.0070\n",
      "Epoch 8/30\n",
      "\u001b[1m46/46\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - loss: 0.0096 - val_loss: 0.0044\n",
      "Epoch 9/30\n",
      "\u001b[1m46/46\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - loss: 0.0079 - val_loss: 0.0025\n",
      "Epoch 10/30\n",
      "\u001b[1m46/46\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - loss: 0.0080 - val_loss: 0.0032\n",
      "Epoch 11/30\n",
      "\u001b[1m46/46\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - loss: 0.0071 - val_loss: 0.0023\n",
      "Epoch 12/30\n",
      "\u001b[1m46/46\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - loss: 0.0063 - val_loss: 0.0058\n",
      "Epoch 13/30\n",
      "\u001b[1m46/46\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - loss: 0.0065 - val_loss: 0.0022\n",
      "Epoch 14/30\n",
      "\u001b[1m46/46\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - loss: 0.0068 - val_loss: 0.0022\n",
      "Epoch 15/30\n",
      "\u001b[1m46/46\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - loss: 0.0071 - val_loss: 0.0021\n",
      "Epoch 16/30\n",
      "\u001b[1m46/46\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - loss: 0.0065 - val_loss: 0.0033\n",
      "Epoch 17/30\n",
      "\u001b[1m46/46\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - loss: 0.0052 - val_loss: 0.0035\n",
      "Epoch 18/30\n",
      "\u001b[1m46/46\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - loss: 0.0069 - val_loss: 0.0064\n",
      "Epoch 19/30\n",
      "\u001b[1m46/46\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - loss: 0.0052 - val_loss: 0.0030\n",
      "Epoch 20/30\n",
      "\u001b[1m46/46\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - loss: 0.0055 - val_loss: 0.0022\n",
      "Epoch 21/30\n",
      "\u001b[1m46/46\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - loss: 0.0045 - val_loss: 0.0020\n",
      "Epoch 22/30\n",
      "\u001b[1m46/46\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - loss: 0.0058 - val_loss: 0.0028\n",
      "Epoch 23/30\n",
      "\u001b[1m46/46\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - loss: 0.0050 - val_loss: 0.0027\n",
      "Epoch 24/30\n",
      "\u001b[1m46/46\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - loss: 0.0051 - val_loss: 0.0023\n",
      "Epoch 25/30\n",
      "\u001b[1m46/46\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - loss: 0.0052 - val_loss: 0.0027\n",
      "Epoch 26/30\n",
      "\u001b[1m46/46\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - loss: 0.0045 - val_loss: 0.0038\n",
      "Epoch 27/30\n",
      "\u001b[1m46/46\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - loss: 0.0055 - val_loss: 0.0022\n",
      "Epoch 28/30\n",
      "\u001b[1m46/46\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - loss: 0.0038 - val_loss: 0.0038\n",
      "Epoch 29/30\n",
      "\u001b[1m46/46\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - loss: 0.0052 - val_loss: 0.0022\n",
      "Epoch 30/30\n",
      "\u001b[1m46/46\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - loss: 0.0045 - val_loss: 0.0019\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:The `save_format` argument is deprecated in Keras 3. We recommend removing this argument as it can be inferred from the file path. Received: save_format=keras\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Finished: Ireland | MAE: 0.07 | RMSE: 0.15 | R²: 0.89\n",
      "Epoch 1/30\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/dejauhnaebeadle/School/MachineLearning/machine-learning-project/code/rain-prediction/.venv/lib/python3.11/site-packages/keras/src/layers/rnn/rnn.py:200: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
      "  super().__init__(**kwargs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m46/46\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 13ms/step - loss: 0.0447 - val_loss: 0.0067\n",
      "Epoch 2/30\n",
      "\u001b[1m46/46\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - loss: 0.0113 - val_loss: 0.0104\n",
      "Epoch 3/30\n",
      "\u001b[1m46/46\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - loss: 0.0088 - val_loss: 0.0069\n",
      "Epoch 4/30\n",
      "\u001b[1m46/46\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - loss: 0.0077 - val_loss: 0.0056\n",
      "Epoch 5/30\n",
      "\u001b[1m46/46\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - loss: 0.0067 - val_loss: 0.0078\n",
      "Epoch 6/30\n",
      "\u001b[1m46/46\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - loss: 0.0062 - val_loss: 0.0084\n",
      "Epoch 7/30\n",
      "\u001b[1m46/46\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - loss: 0.0060 - val_loss: 0.0041\n",
      "Epoch 8/30\n",
      "\u001b[1m46/46\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - loss: 0.0064 - val_loss: 0.0047\n",
      "Epoch 9/30\n",
      "\u001b[1m46/46\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - loss: 0.0062 - val_loss: 0.0041\n",
      "Epoch 10/30\n",
      "\u001b[1m46/46\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - loss: 0.0052 - val_loss: 0.0026\n",
      "Epoch 11/30\n",
      "\u001b[1m46/46\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - loss: 0.0041 - val_loss: 0.0031\n",
      "Epoch 12/30\n",
      "\u001b[1m46/46\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - loss: 0.0040 - val_loss: 0.0025\n",
      "Epoch 13/30\n",
      "\u001b[1m46/46\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - loss: 0.0048 - val_loss: 0.0050\n",
      "Epoch 14/30\n",
      "\u001b[1m46/46\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - loss: 0.0047 - val_loss: 0.0044\n",
      "Epoch 15/30\n",
      "\u001b[1m46/46\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - loss: 0.0049 - val_loss: 0.0028\n",
      "Epoch 16/30\n",
      "\u001b[1m46/46\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - loss: 0.0062 - val_loss: 0.0035\n",
      "Epoch 17/30\n",
      "\u001b[1m46/46\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - loss: 0.0044 - val_loss: 0.0050\n",
      "Epoch 18/30\n",
      "\u001b[1m46/46\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - loss: 0.0048 - val_loss: 0.0023\n",
      "Epoch 19/30\n",
      "\u001b[1m46/46\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - loss: 0.0037 - val_loss: 0.0027\n",
      "Epoch 20/30\n",
      "\u001b[1m46/46\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - loss: 0.0034 - val_loss: 0.0059\n",
      "Epoch 21/30\n",
      "\u001b[1m46/46\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - loss: 0.0047 - val_loss: 0.0026\n",
      "Epoch 22/30\n",
      "\u001b[1m46/46\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - loss: 0.0046 - val_loss: 0.0026\n",
      "Epoch 23/30\n",
      "\u001b[1m46/46\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - loss: 0.0048 - val_loss: 0.0039\n",
      "Epoch 24/30\n",
      "\u001b[1m46/46\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - loss: 0.0045 - val_loss: 0.0021\n",
      "Epoch 25/30\n",
      "\u001b[1m46/46\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - loss: 0.0034 - val_loss: 0.0020\n",
      "Epoch 26/30\n",
      "\u001b[1m46/46\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - loss: 0.0047 - val_loss: 0.0033\n",
      "Epoch 27/30\n",
      "\u001b[1m46/46\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - loss: 0.0036 - val_loss: 0.0041\n",
      "Epoch 28/30\n",
      "\u001b[1m46/46\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - loss: 0.0032 - val_loss: 0.0026\n",
      "Epoch 29/30\n",
      "\u001b[1m46/46\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - loss: 0.0034 - val_loss: 0.0023\n",
      "Epoch 30/30\n",
      "\u001b[1m46/46\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - loss: 0.0040 - val_loss: 0.0020\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:The `save_format` argument is deprecated in Keras 3. We recommend removing this argument as it can be inferred from the file path. Received: save_format=keras\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Finished: Isle of Man | MAE: 0.05 | RMSE: 0.16 | R²: 0.88\n",
      "Epoch 1/30\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/dejauhnaebeadle/School/MachineLearning/machine-learning-project/code/rain-prediction/.venv/lib/python3.11/site-packages/keras/src/layers/rnn/rnn.py:200: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
      "  super().__init__(**kwargs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m46/46\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 13ms/step - loss: 0.0315 - val_loss: 0.0028\n",
      "Epoch 2/30\n",
      "\u001b[1m46/46\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - loss: 0.0085 - val_loss: 0.0011\n",
      "Epoch 3/30\n",
      "\u001b[1m46/46\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - loss: 0.0075 - val_loss: 7.2140e-04\n",
      "Epoch 4/30\n",
      "\u001b[1m46/46\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - loss: 0.0057 - val_loss: 0.0049\n",
      "Epoch 5/30\n",
      "\u001b[1m46/46\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - loss: 0.0048 - val_loss: 0.0043\n",
      "Epoch 6/30\n",
      "\u001b[1m46/46\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - loss: 0.0046 - val_loss: 6.1021e-04\n",
      "Epoch 7/30\n",
      "\u001b[1m46/46\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - loss: 0.0060 - val_loss: 0.0042\n",
      "Epoch 8/30\n",
      "\u001b[1m46/46\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - loss: 0.0048 - val_loss: 0.0032\n",
      "Epoch 9/30\n",
      "\u001b[1m46/46\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - loss: 0.0034 - val_loss: 0.0037\n",
      "Epoch 10/30\n",
      "\u001b[1m46/46\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - loss: 0.0041 - val_loss: 0.0018\n",
      "Epoch 11/30\n",
      "\u001b[1m46/46\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - loss: 0.0029 - val_loss: 0.0011\n",
      "Epoch 12/30\n",
      "\u001b[1m46/46\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - loss: 0.0042 - val_loss: 4.6194e-04\n",
      "Epoch 13/30\n",
      "\u001b[1m46/46\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - loss: 0.0040 - val_loss: 0.0023\n",
      "Epoch 14/30\n",
      "\u001b[1m46/46\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - loss: 0.0034 - val_loss: 0.0015\n",
      "Epoch 15/30\n",
      "\u001b[1m46/46\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - loss: 0.0033 - val_loss: 4.6242e-04\n",
      "Epoch 16/30\n",
      "\u001b[1m46/46\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - loss: 0.0028 - val_loss: 4.5071e-04\n",
      "Epoch 17/30\n",
      "\u001b[1m46/46\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - loss: 0.0031 - val_loss: 4.0788e-04\n",
      "Epoch 18/30\n",
      "\u001b[1m46/46\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - loss: 0.0026 - val_loss: 6.0852e-04\n",
      "Epoch 19/30\n",
      "\u001b[1m46/46\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - loss: 0.0030 - val_loss: 0.0021\n",
      "Epoch 20/30\n",
      "\u001b[1m46/46\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - loss: 0.0025 - val_loss: 0.0017\n",
      "Epoch 21/30\n",
      "\u001b[1m46/46\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - loss: 0.0020 - val_loss: 0.0016\n",
      "Epoch 22/30\n",
      "\u001b[1m46/46\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - loss: 0.0028 - val_loss: 0.0016\n",
      "Epoch 23/30\n",
      "\u001b[1m46/46\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - loss: 0.0020 - val_loss: 0.0023\n",
      "Epoch 24/30\n",
      "\u001b[1m46/46\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - loss: 0.0024 - val_loss: 3.5026e-04\n",
      "Epoch 25/30\n",
      "\u001b[1m46/46\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - loss: 0.0032 - val_loss: 0.0012\n",
      "Epoch 26/30\n",
      "\u001b[1m46/46\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 0.0017 - val_loss: 2.8948e-04\n",
      "Epoch 27/30\n",
      "\u001b[1m46/46\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 0.0030 - val_loss: 8.9269e-04\n",
      "Epoch 28/30\n",
      "\u001b[1m46/46\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 0.0027 - val_loss: 3.1048e-04\n",
      "Epoch 29/30\n",
      "\u001b[1m46/46\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - loss: 0.0027 - val_loss: 9.1505e-04\n",
      "Epoch 30/30\n",
      "\u001b[1m46/46\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - loss: 0.0023 - val_loss: 0.0011\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:The `save_format` argument is deprecated in Keras 3. We recommend removing this argument as it can be inferred from the file path. Received: save_format=keras\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Finished: Israel | MAE: 0.19 | RMSE: 0.27 | R²: 0.70\n",
      "Epoch 1/30\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/dejauhnaebeadle/School/MachineLearning/machine-learning-project/code/rain-prediction/.venv/lib/python3.11/site-packages/keras/src/layers/rnn/rnn.py:200: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
      "  super().__init__(**kwargs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m46/46\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 10ms/step - loss: 0.0608 - val_loss: 0.0057\n",
      "Epoch 2/30\n",
      "\u001b[1m46/46\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 0.0058 - val_loss: 0.0055\n",
      "Epoch 3/30\n",
      "\u001b[1m46/46\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 0.0051 - val_loss: 0.0077\n",
      "Epoch 4/30\n",
      "\u001b[1m46/46\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 0.0050 - val_loss: 0.0038\n",
      "Epoch 5/30\n",
      "\u001b[1m46/46\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 0.0044 - val_loss: 0.0064\n",
      "Epoch 6/30\n",
      "\u001b[1m46/46\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - loss: 0.0044 - val_loss: 0.0037\n",
      "Epoch 7/30\n",
      "\u001b[1m46/46\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 0.0043 - val_loss: 0.0035\n",
      "Epoch 8/30\n",
      "\u001b[1m46/46\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 0.0038 - val_loss: 0.0032\n",
      "Epoch 9/30\n",
      "\u001b[1m46/46\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 0.0031 - val_loss: 0.0027\n",
      "Epoch 10/30\n",
      "\u001b[1m46/46\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 0.0034 - val_loss: 0.0029\n",
      "Epoch 11/30\n",
      "\u001b[1m46/46\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 0.0029 - val_loss: 0.0029\n",
      "Epoch 12/30\n",
      "\u001b[1m46/46\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 0.0029 - val_loss: 0.0020\n",
      "Epoch 13/30\n",
      "\u001b[1m46/46\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 0.0031 - val_loss: 0.0019\n",
      "Epoch 14/30\n",
      "\u001b[1m46/46\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 0.0025 - val_loss: 0.0019\n",
      "Epoch 15/30\n",
      "\u001b[1m46/46\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 0.0030 - val_loss: 0.0019\n",
      "Epoch 16/30\n",
      "\u001b[1m46/46\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 0.0028 - val_loss: 0.0038\n",
      "Epoch 17/30\n",
      "\u001b[1m46/46\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 0.0025 - val_loss: 0.0024\n",
      "Epoch 18/30\n",
      "\u001b[1m46/46\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - loss: 0.0021 - val_loss: 0.0026\n",
      "Epoch 19/30\n",
      "\u001b[1m46/46\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 0.0024 - val_loss: 0.0023\n",
      "Epoch 20/30\n",
      "\u001b[1m46/46\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 0.0021 - val_loss: 0.0038\n",
      "Epoch 21/30\n",
      "\u001b[1m46/46\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 0.0023 - val_loss: 0.0027\n",
      "Epoch 22/30\n",
      "\u001b[1m46/46\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 0.0021 - val_loss: 0.0019\n",
      "Epoch 23/30\n",
      "\u001b[1m46/46\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 0.0021 - val_loss: 0.0020\n",
      "Epoch 24/30\n",
      "\u001b[1m46/46\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 0.0018 - val_loss: 0.0014\n",
      "Epoch 25/30\n",
      "\u001b[1m46/46\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 0.0024 - val_loss: 0.0016\n",
      "Epoch 26/30\n",
      "\u001b[1m46/46\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 0.0014 - val_loss: 0.0044\n",
      "Epoch 27/30\n",
      "\u001b[1m46/46\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 0.0022 - val_loss: 0.0014\n",
      "Epoch 28/30\n",
      "\u001b[1m46/46\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - loss: 0.0021 - val_loss: 0.0013\n",
      "Epoch 29/30\n",
      "\u001b[1m46/46\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 0.0020 - val_loss: 0.0018\n",
      "Epoch 30/30\n",
      "\u001b[1m46/46\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - loss: 0.0019 - val_loss: 0.0014\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:The `save_format` argument is deprecated in Keras 3. We recommend removing this argument as it can be inferred from the file path. Received: save_format=keras\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Finished: Italy | MAE: 0.10 | RMSE: 0.15 | R²: 0.90\n",
      "Epoch 1/30\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/dejauhnaebeadle/School/MachineLearning/machine-learning-project/code/rain-prediction/.venv/lib/python3.11/site-packages/keras/src/layers/rnn/rnn.py:200: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
      "  super().__init__(**kwargs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m46/46\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 11ms/step - loss: 0.0311 - val_loss: 0.0031\n",
      "Epoch 2/30\n",
      "\u001b[1m46/46\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 0.0044 - val_loss: 0.0012\n",
      "Epoch 3/30\n",
      "\u001b[1m46/46\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - loss: 0.0033 - val_loss: 0.0013\n",
      "Epoch 4/30\n",
      "\u001b[1m46/46\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - loss: 0.0034 - val_loss: 0.0025\n",
      "Epoch 5/30\n",
      "\u001b[1m46/46\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - loss: 0.0032 - val_loss: 0.0011\n",
      "Epoch 6/30\n",
      "\u001b[1m46/46\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - loss: 0.0030 - val_loss: 0.0011\n",
      "Epoch 7/30\n",
      "\u001b[1m46/46\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - loss: 0.0032 - val_loss: 0.0026\n",
      "Epoch 8/30\n",
      "\u001b[1m46/46\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 0.0026 - val_loss: 0.0010\n",
      "Epoch 9/30\n",
      "\u001b[1m46/46\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 0.0023 - val_loss: 0.0016\n",
      "Epoch 10/30\n",
      "\u001b[1m46/46\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 0.0021 - val_loss: 0.0015\n",
      "Epoch 11/30\n",
      "\u001b[1m46/46\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 0.0023 - val_loss: 0.0038\n",
      "Epoch 12/30\n",
      "\u001b[1m46/46\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 0.0022 - val_loss: 0.0013\n",
      "Epoch 13/30\n",
      "\u001b[1m46/46\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 0.0019 - val_loss: 0.0012\n",
      "Epoch 14/30\n",
      "\u001b[1m46/46\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 0.0015 - val_loss: 7.9231e-04\n",
      "Epoch 15/30\n",
      "\u001b[1m46/46\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - loss: 0.0017 - val_loss: 6.7410e-04\n",
      "Epoch 16/30\n",
      "\u001b[1m46/46\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 0.0017 - val_loss: 7.6682e-04\n",
      "Epoch 17/30\n",
      "\u001b[1m46/46\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 0.0018 - val_loss: 0.0014\n",
      "Epoch 18/30\n",
      "\u001b[1m46/46\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 0.0014 - val_loss: 6.6261e-04\n",
      "Epoch 19/30\n",
      "\u001b[1m46/46\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 0.0017 - val_loss: 0.0016\n",
      "Epoch 20/30\n",
      "\u001b[1m46/46\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 0.0024 - val_loss: 0.0012\n",
      "Epoch 21/30\n",
      "\u001b[1m46/46\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 0.0014 - val_loss: 5.9221e-04\n",
      "Epoch 22/30\n",
      "\u001b[1m46/46\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 0.0016 - val_loss: 5.7843e-04\n",
      "Epoch 23/30\n",
      "\u001b[1m46/46\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 0.0015 - val_loss: 6.3800e-04\n",
      "Epoch 24/30\n",
      "\u001b[1m46/46\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 0.0016 - val_loss: 6.5736e-04\n",
      "Epoch 25/30\n",
      "\u001b[1m46/46\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - loss: 0.0017 - val_loss: 6.1354e-04\n",
      "Epoch 26/30\n",
      "\u001b[1m46/46\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 0.0013 - val_loss: 8.1159e-04\n",
      "Epoch 27/30\n",
      "\u001b[1m46/46\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 0.0020 - val_loss: 7.3724e-04\n",
      "Epoch 28/30\n",
      "\u001b[1m46/46\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - loss: 0.0020 - val_loss: 6.7948e-04\n",
      "Epoch 29/30\n",
      "\u001b[1m46/46\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 0.0010 - val_loss: 7.9305e-04\n",
      "Epoch 30/30\n",
      "\u001b[1m46/46\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 0.0015 - val_loss: 5.1932e-04\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:The `save_format` argument is deprecated in Keras 3. We recommend removing this argument as it can be inferred from the file path. Received: save_format=keras\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Finished: Jamaica | MAE: 0.05 | RMSE: 0.08 | R²: 0.96\n",
      "Epoch 1/30\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/dejauhnaebeadle/School/MachineLearning/machine-learning-project/code/rain-prediction/.venv/lib/python3.11/site-packages/keras/src/layers/rnn/rnn.py:200: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
      "  super().__init__(**kwargs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m46/46\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 11ms/step - loss: 0.0650 - val_loss: 0.0061\n",
      "Epoch 2/30\n",
      "\u001b[1m46/46\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - loss: 0.0066 - val_loss: 0.0058\n",
      "Epoch 3/30\n",
      "\u001b[1m46/46\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - loss: 0.0063 - val_loss: 0.0051\n",
      "Epoch 4/30\n",
      "\u001b[1m46/46\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - loss: 0.0055 - val_loss: 0.0047\n",
      "Epoch 5/30\n",
      "\u001b[1m46/46\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - loss: 0.0044 - val_loss: 0.0035\n",
      "Epoch 6/30\n",
      "\u001b[1m46/46\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - loss: 0.0047 - val_loss: 0.0051\n",
      "Epoch 7/30\n",
      "\u001b[1m46/46\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 0.0042 - val_loss: 0.0043\n",
      "Epoch 8/30\n",
      "\u001b[1m46/46\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 0.0034 - val_loss: 0.0053\n",
      "Epoch 9/30\n",
      "\u001b[1m46/46\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 0.0038 - val_loss: 0.0047\n",
      "Epoch 10/30\n",
      "\u001b[1m46/46\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 0.0035 - val_loss: 0.0027\n",
      "Epoch 11/30\n",
      "\u001b[1m46/46\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 0.0028 - val_loss: 0.0048\n",
      "Epoch 12/30\n",
      "\u001b[1m46/46\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 0.0037 - val_loss: 0.0031\n",
      "Epoch 13/30\n",
      "\u001b[1m46/46\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 0.0028 - val_loss: 0.0027\n",
      "Epoch 14/30\n",
      "\u001b[1m46/46\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 0.0035 - val_loss: 0.0024\n",
      "Epoch 15/30\n",
      "\u001b[1m46/46\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 0.0031 - val_loss: 0.0031\n",
      "Epoch 16/30\n",
      "\u001b[1m46/46\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 0.0027 - val_loss: 0.0026\n",
      "Epoch 17/30\n",
      "\u001b[1m46/46\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 0.0023 - val_loss: 0.0022\n",
      "Epoch 18/30\n",
      "\u001b[1m46/46\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 0.0026 - val_loss: 0.0022\n",
      "Epoch 19/30\n",
      "\u001b[1m46/46\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 0.0028 - val_loss: 0.0021\n",
      "Epoch 20/30\n",
      "\u001b[1m46/46\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 0.0027 - val_loss: 0.0021\n",
      "Epoch 21/30\n",
      "\u001b[1m46/46\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 0.0031 - val_loss: 0.0021\n",
      "Epoch 22/30\n",
      "\u001b[1m46/46\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 0.0022 - val_loss: 0.0020\n",
      "Epoch 23/30\n",
      "\u001b[1m46/46\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 0.0024 - val_loss: 0.0038\n",
      "Epoch 24/30\n",
      "\u001b[1m46/46\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 0.0025 - val_loss: 0.0021\n",
      "Epoch 25/30\n",
      "\u001b[1m46/46\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 0.0029 - val_loss: 0.0019\n",
      "Epoch 26/30\n",
      "\u001b[1m46/46\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - loss: 0.0023 - val_loss: 0.0021\n",
      "Epoch 27/30\n",
      "\u001b[1m46/46\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - loss: 0.0020 - val_loss: 0.0018\n",
      "Epoch 28/30\n",
      "\u001b[1m46/46\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 0.0023 - val_loss: 0.0018\n",
      "Epoch 29/30\n",
      "\u001b[1m46/46\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - loss: 0.0018 - val_loss: 0.0020\n",
      "Epoch 30/30\n",
      "\u001b[1m46/46\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 0.0024 - val_loss: 0.0024\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:The `save_format` argument is deprecated in Keras 3. We recommend removing this argument as it can be inferred from the file path. Received: save_format=keras\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Finished: Japan | MAE: 0.15 | RMSE: 0.18 | R²: 0.87\n",
      "Epoch 1/30\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/dejauhnaebeadle/School/MachineLearning/machine-learning-project/code/rain-prediction/.venv/lib/python3.11/site-packages/keras/src/layers/rnn/rnn.py:200: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
      "  super().__init__(**kwargs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m46/46\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 11ms/step - loss: 0.0552 - val_loss: 0.0056\n",
      "Epoch 2/30\n",
      "\u001b[1m46/46\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 0.0115 - val_loss: 0.0034\n",
      "Epoch 3/30\n",
      "\u001b[1m46/46\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 0.0088 - val_loss: 0.0068\n",
      "Epoch 4/30\n",
      "\u001b[1m46/46\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 0.0080 - val_loss: 0.0016\n",
      "Epoch 5/30\n",
      "\u001b[1m46/46\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 0.0069 - val_loss: 0.0038\n",
      "Epoch 6/30\n",
      "\u001b[1m46/46\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - loss: 0.0057 - val_loss: 0.0015\n",
      "Epoch 7/30\n",
      "\u001b[1m46/46\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 0.0048 - val_loss: 0.0039\n",
      "Epoch 8/30\n",
      "\u001b[1m46/46\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 0.0044 - val_loss: 0.0012\n",
      "Epoch 9/30\n",
      "\u001b[1m46/46\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 0.0049 - val_loss: 7.2360e-04\n",
      "Epoch 10/30\n",
      "\u001b[1m46/46\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 0.0040 - val_loss: 5.0573e-04\n",
      "Epoch 11/30\n",
      "\u001b[1m46/46\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 0.0042 - val_loss: 0.0018\n",
      "Epoch 12/30\n",
      "\u001b[1m46/46\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 0.0039 - val_loss: 0.0016\n",
      "Epoch 13/30\n",
      "\u001b[1m46/46\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 0.0053 - val_loss: 4.1916e-04\n",
      "Epoch 14/30\n",
      "\u001b[1m46/46\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 0.0052 - val_loss: 3.4174e-04\n",
      "Epoch 15/30\n",
      "\u001b[1m46/46\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 0.0038 - val_loss: 0.0033\n",
      "Epoch 16/30\n",
      "\u001b[1m46/46\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 0.0039 - val_loss: 0.0018\n",
      "Epoch 17/30\n",
      "\u001b[1m46/46\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 0.0032 - val_loss: 0.0021\n",
      "Epoch 18/30\n",
      "\u001b[1m46/46\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - loss: 0.0037 - val_loss: 0.0034\n",
      "Epoch 19/30\n",
      "\u001b[1m46/46\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 0.0035 - val_loss: 0.0013\n",
      "Epoch 20/30\n",
      "\u001b[1m46/46\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 0.0030 - val_loss: 0.0019\n",
      "Epoch 21/30\n",
      "\u001b[1m46/46\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 0.0033 - val_loss: 0.0044\n",
      "Epoch 22/30\n",
      "\u001b[1m46/46\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 0.0029 - val_loss: 0.0021\n",
      "Epoch 23/30\n",
      "\u001b[1m46/46\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 0.0032 - val_loss: 3.6430e-04\n",
      "Epoch 24/30\n",
      "\u001b[1m46/46\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - loss: 0.0024 - val_loss: 2.6674e-04\n",
      "Epoch 25/30\n",
      "\u001b[1m46/46\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 0.0032 - val_loss: 0.0012\n",
      "Epoch 26/30\n",
      "\u001b[1m46/46\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 0.0058 - val_loss: 8.3543e-04\n",
      "Epoch 27/30\n",
      "\u001b[1m46/46\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 0.0032 - val_loss: 8.2730e-04\n",
      "Epoch 28/30\n",
      "\u001b[1m46/46\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - loss: 0.0030 - val_loss: 3.8813e-04\n",
      "Epoch 29/30\n",
      "\u001b[1m46/46\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 0.0023 - val_loss: 3.6549e-04\n",
      "Epoch 30/30\n",
      "\u001b[1m46/46\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 0.0038 - val_loss: 4.8223e-04\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:The `save_format` argument is deprecated in Keras 3. We recommend removing this argument as it can be inferred from the file path. Received: save_format=keras\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Finished: Jordan | MAE: 0.14 | RMSE: 0.27 | R²: 0.78\n",
      "Epoch 1/30\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/dejauhnaebeadle/School/MachineLearning/machine-learning-project/code/rain-prediction/.venv/lib/python3.11/site-packages/keras/src/layers/rnn/rnn.py:200: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
      "  super().__init__(**kwargs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m46/46\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 11ms/step - loss: 0.1518 - val_loss: 0.0251\n",
      "Epoch 2/30\n",
      "\u001b[1m46/46\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - loss: 0.0173 - val_loss: 0.0137\n",
      "Epoch 3/30\n",
      "\u001b[1m46/46\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - loss: 0.0148 - val_loss: 0.0148\n",
      "Epoch 4/30\n",
      "\u001b[1m46/46\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - loss: 0.0146 - val_loss: 0.0161\n",
      "Epoch 5/30\n",
      "\u001b[1m46/46\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - loss: 0.0117 - val_loss: 0.0129\n",
      "Epoch 6/30\n",
      "\u001b[1m46/46\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - loss: 0.0099 - val_loss: 0.0086\n",
      "Epoch 7/30\n",
      "\u001b[1m46/46\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - loss: 0.0105 - val_loss: 0.0091\n",
      "Epoch 8/30\n",
      "\u001b[1m46/46\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - loss: 0.0080 - val_loss: 0.0058\n",
      "Epoch 9/30\n",
      "\u001b[1m46/46\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - loss: 0.0093 - val_loss: 0.0076\n",
      "Epoch 10/30\n",
      "\u001b[1m46/46\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - loss: 0.0096 - val_loss: 0.0071\n",
      "Epoch 11/30\n",
      "\u001b[1m46/46\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - loss: 0.0068 - val_loss: 0.0126\n",
      "Epoch 12/30\n",
      "\u001b[1m46/46\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - loss: 0.0089 - val_loss: 0.0049\n",
      "Epoch 13/30\n",
      "\u001b[1m46/46\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - loss: 0.0074 - val_loss: 0.0044\n",
      "Epoch 14/30\n",
      "\u001b[1m46/46\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - loss: 0.0086 - val_loss: 0.0040\n",
      "Epoch 15/30\n",
      "\u001b[1m46/46\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - loss: 0.0060 - val_loss: 0.0093\n",
      "Epoch 16/30\n",
      "\u001b[1m46/46\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 0.0059 - val_loss: 0.0060\n",
      "Epoch 17/30\n",
      "\u001b[1m46/46\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 0.0062 - val_loss: 0.0101\n",
      "Epoch 18/30\n",
      "\u001b[1m46/46\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - loss: 0.0089 - val_loss: 0.0029\n",
      "Epoch 19/30\n",
      "\u001b[1m46/46\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 0.0061 - val_loss: 0.0034\n",
      "Epoch 20/30\n",
      "\u001b[1m46/46\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - loss: 0.0069 - val_loss: 0.0047\n",
      "Epoch 21/30\n",
      "\u001b[1m46/46\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - loss: 0.0048 - val_loss: 0.0033\n",
      "Epoch 22/30\n",
      "\u001b[1m46/46\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 0.0053 - val_loss: 0.0025\n",
      "Epoch 23/30\n",
      "\u001b[1m46/46\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - loss: 0.0059 - val_loss: 0.0070\n",
      "Epoch 24/30\n",
      "\u001b[1m46/46\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - loss: 0.0042 - val_loss: 0.0033\n",
      "Epoch 25/30\n",
      "\u001b[1m46/46\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - loss: 0.0053 - val_loss: 0.0037\n",
      "Epoch 26/30\n",
      "\u001b[1m46/46\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 0.0051 - val_loss: 0.0026\n",
      "Epoch 27/30\n",
      "\u001b[1m46/46\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 0.0056 - val_loss: 0.0035\n",
      "Epoch 28/30\n",
      "\u001b[1m46/46\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 0.0044 - val_loss: 0.0021\n",
      "Epoch 29/30\n",
      "\u001b[1m46/46\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 0.0040 - val_loss: 0.0026\n",
      "Epoch 30/30\n",
      "\u001b[1m46/46\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - loss: 0.0053 - val_loss: 0.0034\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:The `save_format` argument is deprecated in Keras 3. We recommend removing this argument as it can be inferred from the file path. Received: save_format=keras\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Finished: Kazakhstan | MAE: 0.24 | RMSE: 0.33 | R²: 0.78\n",
      "Epoch 1/30\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/dejauhnaebeadle/School/MachineLearning/machine-learning-project/code/rain-prediction/.venv/lib/python3.11/site-packages/keras/src/layers/rnn/rnn.py:200: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
      "  super().__init__(**kwargs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m46/46\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 11ms/step - loss: 0.1155 - val_loss: 0.0048\n",
      "Epoch 2/30\n",
      "\u001b[1m46/46\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - loss: 0.0082 - val_loss: 0.0039\n",
      "Epoch 3/30\n",
      "\u001b[1m46/46\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 0.0075 - val_loss: 0.0013\n",
      "Epoch 4/30\n",
      "\u001b[1m46/46\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 0.0069 - val_loss: 0.0014\n",
      "Epoch 5/30\n",
      "\u001b[1m46/46\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 0.0067 - val_loss: 0.0020\n",
      "Epoch 6/30\n",
      "\u001b[1m46/46\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 0.0054 - val_loss: 0.0017\n",
      "Epoch 7/30\n",
      "\u001b[1m46/46\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 0.0042 - val_loss: 0.0017\n",
      "Epoch 8/30\n",
      "\u001b[1m46/46\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 0.0046 - val_loss: 9.3414e-04\n",
      "Epoch 9/30\n",
      "\u001b[1m46/46\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 0.0042 - val_loss: 9.0156e-04\n",
      "Epoch 10/30\n",
      "\u001b[1m46/46\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 0.0033 - val_loss: 9.7196e-04\n",
      "Epoch 11/30\n",
      "\u001b[1m46/46\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 0.0033 - val_loss: 0.0011\n",
      "Epoch 12/30\n",
      "\u001b[1m46/46\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 0.0038 - val_loss: 0.0103\n",
      "Epoch 13/30\n",
      "\u001b[1m46/46\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 0.0046 - val_loss: 0.0016\n",
      "Epoch 14/30\n",
      "\u001b[1m46/46\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 0.0035 - val_loss: 0.0025\n",
      "Epoch 15/30\n",
      "\u001b[1m46/46\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - loss: 0.0035 - val_loss: 5.5864e-04\n",
      "Epoch 16/30\n",
      "\u001b[1m46/46\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 0.0028 - val_loss: 0.0046\n",
      "Epoch 17/30\n",
      "\u001b[1m46/46\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 0.0026 - val_loss: 0.0038\n",
      "Epoch 18/30\n",
      "\u001b[1m46/46\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 0.0035 - val_loss: 0.0025\n",
      "Epoch 19/30\n",
      "\u001b[1m46/46\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - loss: 0.0035 - val_loss: 9.8778e-04\n",
      "Epoch 20/30\n",
      "\u001b[1m46/46\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 0.0040 - val_loss: 0.0027\n",
      "Epoch 21/30\n",
      "\u001b[1m46/46\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 0.0024 - val_loss: 8.1974e-04\n",
      "Epoch 22/30\n",
      "\u001b[1m46/46\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - loss: 0.0028 - val_loss: 0.0027\n",
      "Epoch 23/30\n",
      "\u001b[1m46/46\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 0.0024 - val_loss: 4.6803e-04\n",
      "Epoch 24/30\n",
      "\u001b[1m46/46\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 0.0033 - val_loss: 0.0018\n",
      "Epoch 25/30\n",
      "\u001b[1m46/46\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - loss: 0.0022 - val_loss: 4.3683e-04\n",
      "Epoch 26/30\n",
      "\u001b[1m46/46\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 0.0022 - val_loss: 4.0326e-04\n",
      "Epoch 27/30\n",
      "\u001b[1m46/46\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 0.0026 - val_loss: 4.1900e-04\n",
      "Epoch 28/30\n",
      "\u001b[1m46/46\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 0.0022 - val_loss: 0.0018\n",
      "Epoch 29/30\n",
      "\u001b[1m46/46\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 0.0026 - val_loss: 0.0027\n",
      "Epoch 30/30\n",
      "\u001b[1m46/46\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 0.0025 - val_loss: 0.0011\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:The `save_format` argument is deprecated in Keras 3. We recommend removing this argument as it can be inferred from the file path. Received: save_format=keras\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Finished: Kenya | MAE: 0.11 | RMSE: 0.15 | R²: 0.64\n",
      "Epoch 1/30\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/dejauhnaebeadle/School/MachineLearning/machine-learning-project/code/rain-prediction/.venv/lib/python3.11/site-packages/keras/src/layers/rnn/rnn.py:200: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
      "  super().__init__(**kwargs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m46/46\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 11ms/step - loss: 0.0825 - val_loss: 0.0139\n",
      "Epoch 2/30\n",
      "\u001b[1m46/46\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - loss: 0.0167 - val_loss: 0.0124\n",
      "Epoch 3/30\n",
      "\u001b[1m46/46\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - loss: 0.0144 - val_loss: 0.0106\n",
      "Epoch 4/30\n",
      "\u001b[1m46/46\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - loss: 0.0121 - val_loss: 0.0162\n",
      "Epoch 5/30\n",
      "\u001b[1m46/46\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 0.0103 - val_loss: 0.0100\n",
      "Epoch 6/30\n",
      "\u001b[1m46/46\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 0.0101 - val_loss: 0.0073\n",
      "Epoch 7/30\n",
      "\u001b[1m46/46\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 0.0124 - val_loss: 0.0109\n",
      "Epoch 8/30\n",
      "\u001b[1m46/46\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 0.0075 - val_loss: 0.0072\n",
      "Epoch 9/30\n",
      "\u001b[1m46/46\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 0.0075 - val_loss: 0.0066\n",
      "Epoch 10/30\n",
      "\u001b[1m46/46\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 0.0084 - val_loss: 0.0066\n",
      "Epoch 11/30\n",
      "\u001b[1m46/46\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 0.0075 - val_loss: 0.0063\n",
      "Epoch 12/30\n",
      "\u001b[1m46/46\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 0.0060 - val_loss: 0.0068\n",
      "Epoch 13/30\n",
      "\u001b[1m46/46\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 0.0072 - val_loss: 0.0055\n",
      "Epoch 14/30\n",
      "\u001b[1m46/46\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 0.0082 - val_loss: 0.0053\n",
      "Epoch 15/30\n",
      "\u001b[1m46/46\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 0.0072 - val_loss: 0.0052\n",
      "Epoch 16/30\n",
      "\u001b[1m46/46\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - loss: 0.0067 - val_loss: 0.0050\n",
      "Epoch 17/30\n",
      "\u001b[1m46/46\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - loss: 0.0078 - val_loss: 0.0049\n",
      "Epoch 18/30\n",
      "\u001b[1m46/46\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 0.0070 - val_loss: 0.0047\n",
      "Epoch 19/30\n",
      "\u001b[1m46/46\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 0.0076 - val_loss: 0.0047\n",
      "Epoch 20/30\n",
      "\u001b[1m46/46\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 0.0063 - val_loss: 0.0045\n",
      "Epoch 21/30\n",
      "\u001b[1m46/46\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 0.0066 - val_loss: 0.0052\n",
      "Epoch 22/30\n",
      "\u001b[1m46/46\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 0.0061 - val_loss: 0.0080\n",
      "Epoch 23/30\n",
      "\u001b[1m46/46\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 0.0081 - val_loss: 0.0056\n",
      "Epoch 24/30\n",
      "\u001b[1m46/46\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 0.0066 - val_loss: 0.0064\n",
      "Epoch 25/30\n",
      "\u001b[1m46/46\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 0.0041 - val_loss: 0.0052\n",
      "Epoch 26/30\n",
      "\u001b[1m46/46\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - loss: 0.0055 - val_loss: 0.0043\n",
      "Epoch 27/30\n",
      "\u001b[1m46/46\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 0.0040 - val_loss: 0.0051\n",
      "Epoch 28/30\n",
      "\u001b[1m46/46\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 0.0053 - val_loss: 0.0043\n",
      "Epoch 29/30\n",
      "\u001b[1m46/46\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 0.0069 - val_loss: 0.0048\n",
      "Epoch 30/30\n",
      "\u001b[1m46/46\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 0.0055 - val_loss: 0.0042\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:The `save_format` argument is deprecated in Keras 3. We recommend removing this argument as it can be inferred from the file path. Received: save_format=keras\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Finished: Kiribati | MAE: 0.07 | RMSE: 0.16 | R²: 0.88\n",
      "Epoch 1/30\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/dejauhnaebeadle/School/MachineLearning/machine-learning-project/code/rain-prediction/.venv/lib/python3.11/site-packages/keras/src/layers/rnn/rnn.py:200: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
      "  super().__init__(**kwargs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m46/46\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 11ms/step - loss: 0.0927 - val_loss: 0.0091\n",
      "Epoch 2/30\n",
      "\u001b[1m46/46\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 0.0079 - val_loss: 0.0062\n",
      "Epoch 3/30\n",
      "\u001b[1m46/46\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - loss: 0.0065 - val_loss: 0.0058\n",
      "Epoch 4/30\n",
      "\u001b[1m46/46\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - loss: 0.0063 - val_loss: 0.0063\n",
      "Epoch 5/30\n",
      "\u001b[1m46/46\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 0.0054 - val_loss: 0.0044\n",
      "Epoch 6/30\n",
      "\u001b[1m46/46\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - loss: 0.0057 - val_loss: 0.0057\n",
      "Epoch 7/30\n",
      "\u001b[1m46/46\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 0.0045 - val_loss: 0.0040\n",
      "Epoch 8/30\n",
      "\u001b[1m46/46\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 0.0036 - val_loss: 0.0030\n",
      "Epoch 9/30\n",
      "\u001b[1m46/46\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 0.0042 - val_loss: 0.0065\n",
      "Epoch 10/30\n",
      "\u001b[1m46/46\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 0.0040 - val_loss: 0.0064\n",
      "Epoch 11/30\n",
      "\u001b[1m46/46\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 0.0037 - val_loss: 0.0048\n",
      "Epoch 12/30\n",
      "\u001b[1m46/46\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 0.0037 - val_loss: 0.0032\n",
      "Epoch 13/30\n",
      "\u001b[1m46/46\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 0.0035 - val_loss: 0.0046\n",
      "Epoch 14/30\n",
      "\u001b[1m46/46\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 0.0036 - val_loss: 0.0050\n",
      "Epoch 15/30\n",
      "\u001b[1m46/46\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - loss: 0.0033 - val_loss: 0.0028\n",
      "Epoch 16/30\n",
      "\u001b[1m46/46\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 0.0033 - val_loss: 0.0022\n",
      "Epoch 17/30\n",
      "\u001b[1m46/46\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 0.0036 - val_loss: 0.0026\n",
      "Epoch 18/30\n",
      "\u001b[1m46/46\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - loss: 0.0028 - val_loss: 0.0020\n",
      "Epoch 19/30\n",
      "\u001b[1m46/46\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 0.0042 - val_loss: 0.0026\n",
      "Epoch 20/30\n",
      "\u001b[1m46/46\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 0.0022 - val_loss: 0.0019\n",
      "Epoch 21/30\n",
      "\u001b[1m46/46\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 0.0027 - val_loss: 0.0032\n",
      "Epoch 22/30\n",
      "\u001b[1m46/46\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 0.0022 - val_loss: 0.0038\n",
      "Epoch 23/30\n",
      "\u001b[1m46/46\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 0.0026 - val_loss: 0.0040\n",
      "Epoch 24/30\n",
      "\u001b[1m46/46\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 0.0030 - val_loss: 0.0019\n",
      "Epoch 25/30\n",
      "\u001b[1m46/46\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 0.0023 - val_loss: 0.0021\n",
      "Epoch 26/30\n",
      "\u001b[1m46/46\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 0.0028 - val_loss: 0.0018\n",
      "Epoch 27/30\n",
      "\u001b[1m46/46\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 0.0023 - val_loss: 0.0016\n",
      "Epoch 28/30\n",
      "\u001b[1m46/46\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - loss: 0.0025 - val_loss: 0.0024\n",
      "Epoch 29/30\n",
      "\u001b[1m46/46\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 0.0025 - val_loss: 0.0025\n",
      "Epoch 30/30\n",
      "\u001b[1m46/46\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 0.0020 - val_loss: 0.0016\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:The `save_format` argument is deprecated in Keras 3. We recommend removing this argument as it can be inferred from the file path. Received: save_format=keras\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Finished: Kosovo | MAE: 0.08 | RMSE: 0.14 | R²: 0.87\n",
      "Epoch 1/30\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/dejauhnaebeadle/School/MachineLearning/machine-learning-project/code/rain-prediction/.venv/lib/python3.11/site-packages/keras/src/layers/rnn/rnn.py:200: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
      "  super().__init__(**kwargs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m46/46\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 11ms/step - loss: 0.0385 - val_loss: 0.0019\n",
      "Epoch 2/30\n",
      "\u001b[1m46/46\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - loss: 0.0087 - val_loss: 0.0031\n",
      "Epoch 3/30\n",
      "\u001b[1m46/46\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - loss: 0.0075 - val_loss: 0.0029\n",
      "Epoch 4/30\n",
      "\u001b[1m46/46\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 0.0070 - val_loss: 0.0016\n",
      "Epoch 5/30\n",
      "\u001b[1m46/46\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 0.0061 - val_loss: 4.2224e-04\n",
      "Epoch 6/30\n",
      "\u001b[1m46/46\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 0.0049 - val_loss: 0.0016\n",
      "Epoch 7/30\n",
      "\u001b[1m46/46\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 0.0054 - val_loss: 8.9271e-04\n",
      "Epoch 8/30\n",
      "\u001b[1m46/46\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 0.0041 - val_loss: 0.0014\n",
      "Epoch 9/30\n",
      "\u001b[1m46/46\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 0.0043 - val_loss: 0.0016\n",
      "Epoch 10/30\n",
      "\u001b[1m46/46\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 0.0045 - val_loss: 0.0029\n",
      "Epoch 11/30\n",
      "\u001b[1m46/46\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 0.0046 - val_loss: 6.6220e-04\n",
      "Epoch 12/30\n",
      "\u001b[1m46/46\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 0.0036 - val_loss: 0.0021\n",
      "Epoch 13/30\n",
      "\u001b[1m46/46\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 0.0046 - val_loss: 3.0759e-04\n",
      "Epoch 14/30\n",
      "\u001b[1m46/46\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 0.0038 - val_loss: 0.0012\n",
      "Epoch 15/30\n",
      "\u001b[1m46/46\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - loss: 0.0029 - val_loss: 3.1575e-04\n",
      "Epoch 16/30\n",
      "\u001b[1m46/46\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - loss: 0.0036 - val_loss: 3.0805e-04\n",
      "Epoch 17/30\n",
      "\u001b[1m46/46\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 0.0034 - val_loss: 3.7374e-04\n",
      "Epoch 18/30\n",
      "\u001b[1m46/46\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 0.0027 - val_loss: 7.1240e-04\n",
      "Epoch 19/30\n",
      "\u001b[1m46/46\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 0.0031 - val_loss: 0.0013\n",
      "Epoch 20/30\n",
      "\u001b[1m46/46\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 0.0033 - val_loss: 2.1687e-04\n",
      "Epoch 21/30\n",
      "\u001b[1m46/46\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 0.0041 - val_loss: 7.0176e-04\n",
      "Epoch 22/30\n",
      "\u001b[1m46/46\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 0.0034 - val_loss: 6.9767e-04\n",
      "Epoch 23/30\n",
      "\u001b[1m46/46\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 0.0039 - val_loss: 4.3609e-04\n",
      "Epoch 24/30\n",
      "\u001b[1m46/46\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 0.0029 - val_loss: 0.0012\n",
      "Epoch 25/30\n",
      "\u001b[1m46/46\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 0.0043 - val_loss: 5.7450e-04\n",
      "Epoch 26/30\n",
      "\u001b[1m46/46\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - loss: 0.0029 - val_loss: 2.3407e-04\n",
      "Epoch 27/30\n",
      "\u001b[1m46/46\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 0.0024 - val_loss: 2.4759e-04\n",
      "Epoch 28/30\n",
      "\u001b[1m46/46\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 0.0023 - val_loss: 2.0274e-04\n",
      "Epoch 29/30\n",
      "\u001b[1m46/46\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 0.0032 - val_loss: 2.5144e-04\n",
      "Epoch 30/30\n",
      "\u001b[1m46/46\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 0.0027 - val_loss: 2.2557e-04\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:The `save_format` argument is deprecated in Keras 3. We recommend removing this argument as it can be inferred from the file path. Received: save_format=keras\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Finished: Kuwait | MAE: 0.07 | RMSE: 0.19 | R²: 0.87\n",
      "Epoch 1/30\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/dejauhnaebeadle/School/MachineLearning/machine-learning-project/code/rain-prediction/.venv/lib/python3.11/site-packages/keras/src/layers/rnn/rnn.py:200: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
      "  super().__init__(**kwargs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m46/46\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 13ms/step - loss: 0.0715 - val_loss: 0.0117\n",
      "Epoch 2/30\n",
      "\u001b[1m46/46\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - loss: 0.0161 - val_loss: 0.0138\n",
      "Epoch 3/30\n",
      "\u001b[1m46/46\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 0.0177 - val_loss: 0.0087\n",
      "Epoch 4/30\n",
      "\u001b[1m46/46\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 0.0124 - val_loss: 0.0107\n",
      "Epoch 5/30\n",
      "\u001b[1m46/46\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 0.0124 - val_loss: 0.0104\n",
      "Epoch 6/30\n",
      "\u001b[1m46/46\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - loss: 0.0082 - val_loss: 0.0088\n",
      "Epoch 7/30\n",
      "\u001b[1m46/46\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 0.0082 - val_loss: 0.0114\n",
      "Epoch 8/30\n",
      "\u001b[1m46/46\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 0.0080 - val_loss: 0.0086\n",
      "Epoch 9/30\n",
      "\u001b[1m46/46\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 0.0079 - val_loss: 0.0152\n",
      "Epoch 10/30\n",
      "\u001b[1m46/46\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 0.0076 - val_loss: 0.0087\n",
      "Epoch 11/30\n",
      "\u001b[1m46/46\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - loss: 0.0077 - val_loss: 0.0051\n",
      "Epoch 12/30\n",
      "\u001b[1m46/46\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 0.0096 - val_loss: 0.0052\n",
      "Epoch 13/30\n",
      "\u001b[1m46/46\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 0.0060 - val_loss: 0.0056\n",
      "Epoch 14/30\n",
      "\u001b[1m46/46\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 0.0067 - val_loss: 0.0051\n",
      "Epoch 15/30\n",
      "\u001b[1m46/46\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 0.0062 - val_loss: 0.0045\n",
      "Epoch 16/30\n",
      "\u001b[1m46/46\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 0.0074 - val_loss: 0.0052\n",
      "Epoch 17/30\n",
      "\u001b[1m46/46\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 0.0055 - val_loss: 0.0071\n",
      "Epoch 18/30\n",
      "\u001b[1m46/46\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - loss: 0.0082 - val_loss: 0.0072\n",
      "Epoch 19/30\n",
      "\u001b[1m46/46\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 0.0053 - val_loss: 0.0057\n",
      "Epoch 20/30\n",
      "\u001b[1m46/46\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 0.0055 - val_loss: 0.0043\n",
      "Epoch 21/30\n",
      "\u001b[1m46/46\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 0.0081 - val_loss: 0.0046\n",
      "Epoch 22/30\n",
      "\u001b[1m46/46\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 0.0060 - val_loss: 0.0056\n",
      "Epoch 23/30\n",
      "\u001b[1m46/46\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 0.0055 - val_loss: 0.0039\n",
      "Epoch 24/30\n",
      "\u001b[1m46/46\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - loss: 0.0052 - val_loss: 0.0044\n",
      "Epoch 25/30\n",
      "\u001b[1m46/46\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - loss: 0.0064 - val_loss: 0.0038\n",
      "Epoch 26/30\n",
      "\u001b[1m46/46\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - loss: 0.0043 - val_loss: 0.0048\n",
      "Epoch 27/30\n",
      "\u001b[1m46/46\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - loss: 0.0048 - val_loss: 0.0037\n",
      "Epoch 28/30\n",
      "\u001b[1m46/46\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - loss: 0.0043 - val_loss: 0.0073\n",
      "Epoch 29/30\n",
      "\u001b[1m46/46\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - loss: 0.0048 - val_loss: 0.0049\n",
      "Epoch 30/30\n",
      "\u001b[1m46/46\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - loss: 0.0045 - val_loss: 0.0047\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:The `save_format` argument is deprecated in Keras 3. We recommend removing this argument as it can be inferred from the file path. Received: save_format=keras\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Finished: Kyrgyzstan | MAE: 0.13 | RMSE: 0.20 | R²: 0.84\n",
      "Epoch 1/30\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/dejauhnaebeadle/School/MachineLearning/machine-learning-project/code/rain-prediction/.venv/lib/python3.11/site-packages/keras/src/layers/rnn/rnn.py:200: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
      "  super().__init__(**kwargs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m46/46\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 13ms/step - loss: 0.0690 - val_loss: 0.0082\n",
      "Epoch 2/30\n",
      "\u001b[1m46/46\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - loss: 0.0072 - val_loss: 0.0049\n",
      "Epoch 3/30\n",
      "\u001b[1m46/46\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - loss: 0.0056 - val_loss: 0.0038\n",
      "Epoch 4/30\n",
      "\u001b[1m46/46\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - loss: 0.0048 - val_loss: 0.0043\n",
      "Epoch 5/30\n",
      "\u001b[1m46/46\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - loss: 0.0041 - val_loss: 0.0061\n",
      "Epoch 6/30\n",
      "\u001b[1m46/46\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - loss: 0.0043 - val_loss: 0.0038\n",
      "Epoch 7/30\n",
      "\u001b[1m46/46\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - loss: 0.0042 - val_loss: 0.0030\n",
      "Epoch 8/30\n",
      "\u001b[1m46/46\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - loss: 0.0037 - val_loss: 0.0025\n",
      "Epoch 9/30\n",
      "\u001b[1m46/46\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - loss: 0.0032 - val_loss: 0.0025\n",
      "Epoch 10/30\n",
      "\u001b[1m46/46\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - loss: 0.0034 - val_loss: 0.0029\n",
      "Epoch 11/30\n",
      "\u001b[1m46/46\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - loss: 0.0032 - val_loss: 0.0029\n",
      "Epoch 12/30\n",
      "\u001b[1m46/46\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - loss: 0.0028 - val_loss: 0.0030\n",
      "Epoch 13/30\n",
      "\u001b[1m46/46\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - loss: 0.0027 - val_loss: 0.0032\n",
      "Epoch 14/30\n",
      "\u001b[1m46/46\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - loss: 0.0029 - val_loss: 0.0021\n",
      "Epoch 15/30\n",
      "\u001b[1m46/46\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - loss: 0.0029 - val_loss: 0.0020\n",
      "Epoch 16/30\n",
      "\u001b[1m46/46\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - loss: 0.0020 - val_loss: 0.0021\n",
      "Epoch 17/30\n",
      "\u001b[1m46/46\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - loss: 0.0020 - val_loss: 0.0030\n",
      "Epoch 18/30\n",
      "\u001b[1m46/46\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - loss: 0.0026 - val_loss: 0.0020\n",
      "Epoch 19/30\n",
      "\u001b[1m46/46\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - loss: 0.0022 - val_loss: 0.0018\n",
      "Epoch 20/30\n",
      "\u001b[1m46/46\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - loss: 0.0022 - val_loss: 0.0017\n",
      "Epoch 21/30\n",
      "\u001b[1m46/46\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - loss: 0.0021 - val_loss: 0.0017\n",
      "Epoch 22/30\n",
      "\u001b[1m46/46\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - loss: 0.0018 - val_loss: 0.0017\n",
      "Epoch 23/30\n",
      "\u001b[1m46/46\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - loss: 0.0018 - val_loss: 0.0016\n",
      "Epoch 24/30\n",
      "\u001b[1m46/46\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - loss: 0.0026 - val_loss: 0.0019\n",
      "Epoch 25/30\n",
      "\u001b[1m46/46\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - loss: 0.0025 - val_loss: 0.0025\n",
      "Epoch 26/30\n",
      "\u001b[1m46/46\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - loss: 0.0020 - val_loss: 0.0027\n",
      "Epoch 27/30\n",
      "\u001b[1m46/46\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - loss: 0.0017 - val_loss: 0.0018\n",
      "Epoch 28/30\n",
      "\u001b[1m46/46\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - loss: 0.0015 - val_loss: 0.0014\n",
      "Epoch 29/30\n",
      "\u001b[1m46/46\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - loss: 0.0014 - val_loss: 0.0016\n",
      "Epoch 30/30\n",
      "\u001b[1m46/46\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - loss: 0.0016 - val_loss: 0.0014\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:The `save_format` argument is deprecated in Keras 3. We recommend removing this argument as it can be inferred from the file path. Received: save_format=keras\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Finished: Laos | MAE: 0.07 | RMSE: 0.17 | R²: 0.88\n",
      "Epoch 1/30\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/dejauhnaebeadle/School/MachineLearning/machine-learning-project/code/rain-prediction/.venv/lib/python3.11/site-packages/keras/src/layers/rnn/rnn.py:200: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
      "  super().__init__(**kwargs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m46/46\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 14ms/step - loss: 0.0410 - val_loss: 0.0027\n",
      "Epoch 2/30\n",
      "\u001b[1m46/46\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - loss: 0.0100 - val_loss: 0.0055\n",
      "Epoch 3/30\n",
      "\u001b[1m46/46\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - loss: 0.0100 - val_loss: 0.0030\n",
      "Epoch 4/30\n",
      "\u001b[1m46/46\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - loss: 0.0074 - val_loss: 0.0016\n",
      "Epoch 5/30\n",
      "\u001b[1m46/46\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - loss: 0.0079 - val_loss: 0.0019\n",
      "Epoch 6/30\n",
      "\u001b[1m46/46\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - loss: 0.0065 - val_loss: 0.0015\n",
      "Epoch 7/30\n",
      "\u001b[1m46/46\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - loss: 0.0057 - val_loss: 0.0013\n",
      "Epoch 8/30\n",
      "\u001b[1m46/46\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - loss: 0.0060 - val_loss: 0.0026\n",
      "Epoch 9/30\n",
      "\u001b[1m46/46\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - loss: 0.0045 - val_loss: 0.0015\n",
      "Epoch 10/30\n",
      "\u001b[1m46/46\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - loss: 0.0063 - val_loss: 0.0031\n",
      "Epoch 11/30\n",
      "\u001b[1m46/46\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - loss: 0.0046 - val_loss: 0.0030\n",
      "Epoch 12/30\n",
      "\u001b[1m46/46\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - loss: 0.0059 - val_loss: 7.6649e-04\n",
      "Epoch 13/30\n",
      "\u001b[1m46/46\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - loss: 0.0045 - val_loss: 7.7016e-04\n",
      "Epoch 14/30\n",
      "\u001b[1m46/46\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - loss: 0.0048 - val_loss: 0.0019\n",
      "Epoch 15/30\n",
      "\u001b[1m46/46\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - loss: 0.0046 - val_loss: 0.0022\n",
      "Epoch 16/30\n",
      "\u001b[1m46/46\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - loss: 0.0049 - val_loss: 9.9538e-04\n",
      "Epoch 17/30\n",
      "\u001b[1m46/46\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - loss: 0.0041 - val_loss: 0.0040\n",
      "Epoch 18/30\n",
      "\u001b[1m46/46\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - loss: 0.0053 - val_loss: 6.1031e-04\n",
      "Epoch 19/30\n",
      "\u001b[1m46/46\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - loss: 0.0043 - val_loss: 0.0014\n",
      "Epoch 20/30\n",
      "\u001b[1m46/46\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - loss: 0.0042 - val_loss: 6.3302e-04\n",
      "Epoch 21/30\n",
      "\u001b[1m46/46\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - loss: 0.0031 - val_loss: 9.3392e-04\n",
      "Epoch 22/30\n",
      "\u001b[1m46/46\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - loss: 0.0039 - val_loss: 9.1040e-04\n",
      "Epoch 23/30\n",
      "\u001b[1m46/46\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - loss: 0.0036 - val_loss: 0.0024\n",
      "Epoch 24/30\n",
      "\u001b[1m46/46\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - loss: 0.0035 - val_loss: 0.0020\n",
      "Epoch 25/30\n",
      "\u001b[1m46/46\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - loss: 0.0049 - val_loss: 7.3882e-04\n",
      "Epoch 26/30\n",
      "\u001b[1m46/46\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 0.0035 - val_loss: 7.2553e-04\n",
      "Epoch 27/30\n",
      "\u001b[1m46/46\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 0.0037 - val_loss: 5.8294e-04\n",
      "Epoch 28/30\n",
      "\u001b[1m46/46\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - loss: 0.0037 - val_loss: 0.0020\n",
      "Epoch 29/30\n",
      "\u001b[1m46/46\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - loss: 0.0037 - val_loss: 5.2099e-04\n",
      "Epoch 30/30\n",
      "\u001b[1m46/46\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - loss: 0.0036 - val_loss: 5.4652e-04\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:The `save_format` argument is deprecated in Keras 3. We recommend removing this argument as it can be inferred from the file path. Received: save_format=keras\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Finished: Latvia | MAE: 0.11 | RMSE: 0.26 | R²: 0.90\n",
      "Epoch 1/30\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/dejauhnaebeadle/School/MachineLearning/machine-learning-project/code/rain-prediction/.venv/lib/python3.11/site-packages/keras/src/layers/rnn/rnn.py:200: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
      "  super().__init__(**kwargs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m46/46\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 13ms/step - loss: 0.0374 - val_loss: 0.0020\n",
      "Epoch 2/30\n",
      "\u001b[1m46/46\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - loss: 0.0103 - val_loss: 0.0014\n",
      "Epoch 3/30\n",
      "\u001b[1m46/46\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - loss: 0.0088 - val_loss: 0.0015\n",
      "Epoch 4/30\n",
      "\u001b[1m46/46\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - loss: 0.0079 - val_loss: 0.0050\n",
      "Epoch 5/30\n",
      "\u001b[1m46/46\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - loss: 0.0073 - val_loss: 0.0018\n",
      "Epoch 6/30\n",
      "\u001b[1m46/46\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - loss: 0.0054 - val_loss: 0.0011\n",
      "Epoch 7/30\n",
      "\u001b[1m46/46\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - loss: 0.0080 - val_loss: 9.1373e-04\n",
      "Epoch 8/30\n",
      "\u001b[1m46/46\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - loss: 0.0046 - val_loss: 0.0027\n",
      "Epoch 9/30\n",
      "\u001b[1m46/46\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - loss: 0.0044 - val_loss: 0.0034\n",
      "Epoch 10/30\n",
      "\u001b[1m46/46\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - loss: 0.0040 - val_loss: 0.0033\n",
      "Epoch 11/30\n",
      "\u001b[1m46/46\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - loss: 0.0046 - val_loss: 0.0020\n",
      "Epoch 12/30\n",
      "\u001b[1m46/46\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - loss: 0.0044 - val_loss: 0.0021\n",
      "Epoch 13/30\n",
      "\u001b[1m46/46\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 0.0045 - val_loss: 0.0018\n",
      "Epoch 14/30\n",
      "\u001b[1m46/46\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - loss: 0.0042 - val_loss: 0.0029\n",
      "Epoch 15/30\n",
      "\u001b[1m46/46\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - loss: 0.0040 - val_loss: 0.0030\n",
      "Epoch 16/30\n",
      "\u001b[1m46/46\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - loss: 0.0063 - val_loss: 0.0011\n",
      "Epoch 17/30\n",
      "\u001b[1m46/46\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - loss: 0.0039 - val_loss: 6.1944e-04\n",
      "Epoch 18/30\n",
      "\u001b[1m46/46\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - loss: 0.0028 - val_loss: 0.0014\n",
      "Epoch 19/30\n",
      "\u001b[1m46/46\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - loss: 0.0032 - val_loss: 5.4013e-04\n",
      "Epoch 20/30\n",
      "\u001b[1m46/46\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - loss: 0.0036 - val_loss: 0.0016\n",
      "Epoch 21/30\n",
      "\u001b[1m46/46\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 0.0036 - val_loss: 8.7561e-04\n",
      "Epoch 22/30\n",
      "\u001b[1m46/46\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - loss: 0.0028 - val_loss: 6.1353e-04\n",
      "Epoch 23/30\n",
      "\u001b[1m46/46\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - loss: 0.0031 - val_loss: 8.9231e-04\n",
      "Epoch 24/30\n",
      "\u001b[1m46/46\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - loss: 0.0028 - val_loss: 5.5187e-04\n",
      "Epoch 25/30\n",
      "\u001b[1m46/46\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 0.0034 - val_loss: 7.9630e-04\n",
      "Epoch 26/30\n",
      "\u001b[1m46/46\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 0.0031 - val_loss: 5.7756e-04\n",
      "Epoch 27/30\n",
      "\u001b[1m46/46\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - loss: 0.0050 - val_loss: 7.4259e-04\n",
      "Epoch 28/30\n",
      "\u001b[1m46/46\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 0.0035 - val_loss: 8.0074e-04\n",
      "Epoch 29/30\n",
      "\u001b[1m46/46\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 0.0034 - val_loss: 0.0035\n",
      "Epoch 30/30\n",
      "\u001b[1m46/46\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 0.0030 - val_loss: 0.0021\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:The `save_format` argument is deprecated in Keras 3. We recommend removing this argument as it can be inferred from the file path. Received: save_format=keras\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Finished: Lebanon | MAE: 0.28 | RMSE: 0.35 | R²: 0.65\n",
      "Epoch 1/30\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/dejauhnaebeadle/School/MachineLearning/machine-learning-project/code/rain-prediction/.venv/lib/python3.11/site-packages/keras/src/layers/rnn/rnn.py:200: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
      "  super().__init__(**kwargs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m46/46\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 17ms/step - loss: 0.0494 - val_loss: 0.0102\n",
      "Epoch 2/30\n",
      "\u001b[1m46/46\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - loss: 0.0089 - val_loss: 0.0080\n",
      "Epoch 3/30\n",
      "\u001b[1m46/46\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - loss: 0.0072 - val_loss: 0.0078\n",
      "Epoch 4/30\n",
      "\u001b[1m46/46\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - loss: 0.0067 - val_loss: 0.0056\n",
      "Epoch 5/30\n",
      "\u001b[1m46/46\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - loss: 0.0054 - val_loss: 0.0044\n",
      "Epoch 6/30\n",
      "\u001b[1m46/46\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - loss: 0.0044 - val_loss: 0.0072\n",
      "Epoch 7/30\n",
      "\u001b[1m46/46\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - loss: 0.0045 - val_loss: 0.0047\n",
      "Epoch 8/30\n",
      "\u001b[1m46/46\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 0.0039 - val_loss: 0.0037\n",
      "Epoch 9/30\n",
      "\u001b[1m46/46\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 0.0040 - val_loss: 0.0051\n",
      "Epoch 10/30\n",
      "\u001b[1m46/46\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 0.0036 - val_loss: 0.0043\n",
      "Epoch 11/30\n",
      "\u001b[1m46/46\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - loss: 0.0040 - val_loss: 0.0033\n",
      "Epoch 12/30\n",
      "\u001b[1m46/46\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 0.0042 - val_loss: 0.0032\n",
      "Epoch 13/30\n",
      "\u001b[1m46/46\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - loss: 0.0033 - val_loss: 0.0037\n",
      "Epoch 14/30\n",
      "\u001b[1m46/46\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - loss: 0.0035 - val_loss: 0.0038\n",
      "Epoch 15/30\n",
      "\u001b[1m46/46\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - loss: 0.0032 - val_loss: 0.0032\n",
      "Epoch 16/30\n",
      "\u001b[1m46/46\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - loss: 0.0033 - val_loss: 0.0030\n",
      "Epoch 17/30\n",
      "\u001b[1m46/46\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 0.0029 - val_loss: 0.0035\n",
      "Epoch 18/30\n",
      "\u001b[1m46/46\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 0.0026 - val_loss: 0.0027\n",
      "Epoch 19/30\n",
      "\u001b[1m46/46\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 0.0032 - val_loss: 0.0028\n",
      "Epoch 20/30\n",
      "\u001b[1m46/46\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 0.0035 - val_loss: 0.0026\n",
      "Epoch 21/30\n",
      "\u001b[1m46/46\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 0.0029 - val_loss: 0.0029\n",
      "Epoch 22/30\n",
      "\u001b[1m46/46\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - loss: 0.0030 - val_loss: 0.0027\n",
      "Epoch 23/30\n",
      "\u001b[1m46/46\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 0.0027 - val_loss: 0.0025\n",
      "Epoch 24/30\n",
      "\u001b[1m46/46\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 0.0028 - val_loss: 0.0027\n",
      "Epoch 25/30\n",
      "\u001b[1m46/46\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 0.0023 - val_loss: 0.0027\n",
      "Epoch 26/30\n",
      "\u001b[1m46/46\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 0.0025 - val_loss: 0.0025\n",
      "Epoch 27/30\n",
      "\u001b[1m46/46\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 0.0025 - val_loss: 0.0024\n",
      "Epoch 28/30\n",
      "\u001b[1m46/46\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - loss: 0.0024 - val_loss: 0.0025\n",
      "Epoch 29/30\n",
      "\u001b[1m46/46\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 0.0024 - val_loss: 0.0024\n",
      "Epoch 30/30\n",
      "\u001b[1m46/46\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 0.0036 - val_loss: 0.0027\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:The `save_format` argument is deprecated in Keras 3. We recommend removing this argument as it can be inferred from the file path. Received: save_format=keras\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Finished: Lesotho | MAE: 0.13 | RMSE: 0.22 | R²: 0.84\n",
      "Epoch 1/30\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/dejauhnaebeadle/School/MachineLearning/machine-learning-project/code/rain-prediction/.venv/lib/python3.11/site-packages/keras/src/layers/rnn/rnn.py:200: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
      "  super().__init__(**kwargs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m46/46\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 10ms/step - loss: 0.0313 - val_loss: 3.8518e-04\n",
      "Epoch 2/30\n",
      "\u001b[1m46/46\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 0.0042 - val_loss: 4.3973e-04\n",
      "Epoch 3/30\n",
      "\u001b[1m46/46\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 0.0031 - val_loss: 3.3653e-04\n",
      "Epoch 4/30\n",
      "\u001b[1m46/46\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 0.0029 - val_loss: 2.9235e-04\n",
      "Epoch 5/30\n",
      "\u001b[1m46/46\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 0.0032 - val_loss: 6.4144e-04\n",
      "Epoch 6/30\n",
      "\u001b[1m46/46\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 0.0030 - val_loss: 2.6463e-04\n",
      "Epoch 7/30\n",
      "\u001b[1m46/46\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 0.0025 - val_loss: 7.9117e-04\n",
      "Epoch 8/30\n",
      "\u001b[1m46/46\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 0.0024 - val_loss: 3.6410e-04\n",
      "Epoch 9/30\n",
      "\u001b[1m46/46\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 0.0023 - val_loss: 3.1656e-04\n",
      "Epoch 10/30\n",
      "\u001b[1m46/46\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 0.0019 - val_loss: 7.7867e-04\n",
      "Epoch 11/30\n",
      "\u001b[1m46/46\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 0.0019 - val_loss: 3.2332e-04\n",
      "Epoch 12/30\n",
      "\u001b[1m46/46\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 0.0017 - val_loss: 4.0391e-04\n",
      "Epoch 13/30\n",
      "\u001b[1m46/46\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 0.0015 - val_loss: 1.9984e-04\n",
      "Epoch 14/30\n",
      "\u001b[1m46/46\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 0.0013 - val_loss: 6.1470e-04\n",
      "Epoch 15/30\n",
      "\u001b[1m46/46\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 0.0014 - val_loss: 3.8286e-04\n",
      "Epoch 16/30\n",
      "\u001b[1m46/46\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 0.0017 - val_loss: 1.9159e-04\n",
      "Epoch 17/30\n",
      "\u001b[1m46/46\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 0.0017 - val_loss: 0.0010\n",
      "Epoch 18/30\n",
      "\u001b[1m46/46\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 0.0012 - val_loss: 3.1079e-04\n",
      "Epoch 19/30\n",
      "\u001b[1m46/46\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 0.0022 - val_loss: 6.9302e-04\n",
      "Epoch 20/30\n",
      "\u001b[1m46/46\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 0.0017 - val_loss: 3.0473e-04\n",
      "Epoch 21/30\n",
      "\u001b[1m46/46\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 0.0011 - val_loss: 1.5904e-04\n",
      "Epoch 22/30\n",
      "\u001b[1m46/46\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 0.0013 - val_loss: 4.2303e-04\n",
      "Epoch 23/30\n",
      "\u001b[1m46/46\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 0.0013 - val_loss: 1.8166e-04\n",
      "Epoch 24/30\n",
      "\u001b[1m46/46\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 0.0011 - val_loss: 2.5222e-04\n",
      "Epoch 25/30\n",
      "\u001b[1m46/46\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 0.0017 - val_loss: 1.8628e-04\n",
      "Epoch 26/30\n",
      "\u001b[1m46/46\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 0.0014 - val_loss: 2.7906e-04\n",
      "Epoch 27/30\n",
      "\u001b[1m46/46\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 0.0015 - val_loss: 1.8487e-04\n",
      "Epoch 28/30\n",
      "\u001b[1m46/46\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 0.0011 - val_loss: 2.2669e-04\n",
      "Epoch 29/30\n",
      "\u001b[1m46/46\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 0.0012 - val_loss: 1.7330e-04\n",
      "Epoch 30/30\n",
      "\u001b[1m46/46\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 7.9001e-04 - val_loss: 1.3120e-04\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:The `save_format` argument is deprecated in Keras 3. We recommend removing this argument as it can be inferred from the file path. Received: save_format=keras\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Finished: Liberia | MAE: 0.05 | RMSE: 0.08 | R²: 0.95\n",
      "Epoch 1/30\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/dejauhnaebeadle/School/MachineLearning/machine-learning-project/code/rain-prediction/.venv/lib/python3.11/site-packages/keras/src/layers/rnn/rnn.py:200: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
      "  super().__init__(**kwargs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m46/46\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 10ms/step - loss: 0.0676 - val_loss: 0.0023\n",
      "Epoch 2/30\n",
      "\u001b[1m46/46\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 0.0069 - val_loss: 0.0012\n",
      "Epoch 3/30\n",
      "\u001b[1m46/46\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 0.0063 - val_loss: 0.0014\n",
      "Epoch 4/30\n",
      "\u001b[1m46/46\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 0.0058 - val_loss: 0.0047\n",
      "Epoch 5/30\n",
      "\u001b[1m46/46\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 0.0059 - val_loss: 4.3174e-04\n",
      "Epoch 6/30\n",
      "\u001b[1m46/46\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 0.0051 - val_loss: 0.0074\n",
      "Epoch 7/30\n",
      "\u001b[1m46/46\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 0.0047 - val_loss: 0.0011\n",
      "Epoch 8/30\n",
      "\u001b[1m46/46\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 0.0034 - val_loss: 0.0040\n",
      "Epoch 9/30\n",
      "\u001b[1m46/46\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 0.0039 - val_loss: 5.3525e-04\n",
      "Epoch 10/30\n",
      "\u001b[1m46/46\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 0.0035 - val_loss: 2.7521e-04\n",
      "Epoch 11/30\n",
      "\u001b[1m46/46\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 0.0030 - val_loss: 7.5047e-04\n",
      "Epoch 12/30\n",
      "\u001b[1m46/46\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 0.0032 - val_loss: 0.0015\n",
      "Epoch 13/30\n",
      "\u001b[1m46/46\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 0.0030 - val_loss: 3.3084e-04\n",
      "Epoch 14/30\n",
      "\u001b[1m46/46\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 0.0038 - val_loss: 2.4474e-04\n",
      "Epoch 15/30\n",
      "\u001b[1m46/46\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 0.0027 - val_loss: 2.6115e-04\n",
      "Epoch 16/30\n",
      "\u001b[1m46/46\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 0.0029 - val_loss: 2.4437e-04\n",
      "Epoch 17/30\n",
      "\u001b[1m46/46\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 0.0026 - val_loss: 2.7367e-04\n",
      "Epoch 18/30\n",
      "\u001b[1m46/46\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 0.0017 - val_loss: 1.9774e-04\n",
      "Epoch 19/30\n",
      "\u001b[1m46/46\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 0.0026 - val_loss: 5.6467e-04\n",
      "Epoch 20/30\n",
      "\u001b[1m46/46\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 0.0026 - val_loss: 1.6457e-04\n",
      "Epoch 21/30\n",
      "\u001b[1m46/46\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 0.0022 - val_loss: 0.0010\n",
      "Epoch 22/30\n",
      "\u001b[1m46/46\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - loss: 0.0022 - val_loss: 2.5391e-04\n",
      "Epoch 23/30\n",
      "\u001b[1m46/46\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - loss: 0.0023 - val_loss: 1.4379e-04\n",
      "Epoch 24/30\n",
      "\u001b[1m46/46\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 0.0017 - val_loss: 2.6256e-04\n",
      "Epoch 25/30\n",
      "\u001b[1m46/46\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 0.0015 - val_loss: 1.7429e-04\n",
      "Epoch 26/30\n",
      "\u001b[1m46/46\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 0.0022 - val_loss: 4.2739e-04\n",
      "Epoch 27/30\n",
      "\u001b[1m46/46\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - loss: 0.0020 - val_loss: 3.6016e-04\n",
      "Epoch 28/30\n",
      "\u001b[1m46/46\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - loss: 0.0023 - val_loss: 1.6285e-04\n",
      "Epoch 29/30\n",
      "\u001b[1m46/46\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - loss: 0.0018 - val_loss: 2.0160e-04\n",
      "Epoch 30/30\n",
      "\u001b[1m46/46\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - loss: 0.0022 - val_loss: 1.2247e-04\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:The `save_format` argument is deprecated in Keras 3. We recommend removing this argument as it can be inferred from the file path. Received: save_format=keras\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Finished: Libya | MAE: 0.12 | RMSE: 0.29 | R²: 0.78\n",
      "Epoch 1/30\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/dejauhnaebeadle/School/MachineLearning/machine-learning-project/code/rain-prediction/.venv/lib/python3.11/site-packages/keras/src/layers/rnn/rnn.py:200: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
      "  super().__init__(**kwargs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m46/46\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 12ms/step - loss: 0.0673 - val_loss: 0.0037\n",
      "Epoch 2/30\n",
      "\u001b[1m46/46\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 0.0094 - val_loss: 0.0050\n",
      "Epoch 3/30\n",
      "\u001b[1m46/46\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - loss: 0.0093 - val_loss: 0.0032\n",
      "Epoch 4/30\n",
      "\u001b[1m46/46\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - loss: 0.0077 - val_loss: 0.0015\n",
      "Epoch 5/30\n",
      "\u001b[1m46/46\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - loss: 0.0074 - val_loss: 0.0015\n",
      "Epoch 6/30\n",
      "\u001b[1m46/46\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - loss: 0.0066 - val_loss: 0.0021\n",
      "Epoch 7/30\n",
      "\u001b[1m46/46\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - loss: 0.0057 - val_loss: 0.0030\n",
      "Epoch 8/30\n",
      "\u001b[1m46/46\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - loss: 0.0060 - val_loss: 0.0026\n",
      "Epoch 9/30\n",
      "\u001b[1m46/46\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - loss: 0.0060 - val_loss: 0.0013\n",
      "Epoch 10/30\n",
      "\u001b[1m46/46\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - loss: 0.0067 - val_loss: 0.0025\n",
      "Epoch 11/30\n",
      "\u001b[1m46/46\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - loss: 0.0057 - val_loss: 0.0011\n",
      "Epoch 12/30\n",
      "\u001b[1m46/46\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - loss: 0.0051 - val_loss: 0.0017\n",
      "Epoch 13/30\n",
      "\u001b[1m46/46\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - loss: 0.0054 - val_loss: 0.0011\n",
      "Epoch 14/30\n",
      "\u001b[1m46/46\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - loss: 0.0053 - val_loss: 0.0024\n",
      "Epoch 15/30\n",
      "\u001b[1m46/46\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - loss: 0.0057 - val_loss: 0.0013\n",
      "Epoch 16/30\n",
      "\u001b[1m46/46\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - loss: 0.0034 - val_loss: 0.0012\n",
      "Epoch 17/30\n",
      "\u001b[1m46/46\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - loss: 0.0034 - val_loss: 0.0035\n",
      "Epoch 18/30\n",
      "\u001b[1m46/46\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 7ms/step - loss: 0.0042 - val_loss: 0.0011\n",
      "Epoch 19/30\n",
      "\u001b[1m46/46\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - loss: 0.0043 - val_loss: 0.0010\n",
      "Epoch 20/30\n",
      "\u001b[1m46/46\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - loss: 0.0046 - val_loss: 0.0015\n",
      "Epoch 21/30\n",
      "\u001b[1m46/46\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - loss: 0.0037 - val_loss: 8.6052e-04\n",
      "Epoch 22/30\n",
      "\u001b[1m46/46\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - loss: 0.0045 - val_loss: 9.0231e-04\n",
      "Epoch 23/30\n",
      "\u001b[1m46/46\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - loss: 0.0037 - val_loss: 7.7425e-04\n",
      "Epoch 24/30\n",
      "\u001b[1m46/46\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - loss: 0.0040 - val_loss: 0.0012\n",
      "Epoch 25/30\n",
      "\u001b[1m46/46\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - loss: 0.0042 - val_loss: 0.0020\n",
      "Epoch 26/30\n",
      "\u001b[1m46/46\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - loss: 0.0050 - val_loss: 0.0017\n",
      "Epoch 27/30\n",
      "\u001b[1m46/46\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - loss: 0.0035 - val_loss: 0.0012\n",
      "Epoch 28/30\n",
      "\u001b[1m46/46\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - loss: 0.0027 - val_loss: 0.0013\n",
      "Epoch 29/30\n",
      "\u001b[1m46/46\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - loss: 0.0035 - val_loss: 0.0015\n",
      "Epoch 30/30\n",
      "\u001b[1m46/46\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - loss: 0.0040 - val_loss: 0.0013\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:The `save_format` argument is deprecated in Keras 3. We recommend removing this argument as it can be inferred from the file path. Received: save_format=keras\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Finished: Lithuania | MAE: 0.20 | RMSE: 0.28 | R²: 0.88\n",
      "Epoch 1/30\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/dejauhnaebeadle/School/MachineLearning/machine-learning-project/code/rain-prediction/.venv/lib/python3.11/site-packages/keras/src/layers/rnn/rnn.py:200: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
      "  super().__init__(**kwargs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m46/46\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 14ms/step - loss: 0.0959 - val_loss: 0.0074\n",
      "Epoch 2/30\n",
      "\u001b[1m46/46\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - loss: 0.0157 - val_loss: 0.0087\n",
      "Epoch 3/30\n",
      "\u001b[1m46/46\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - loss: 0.0121 - val_loss: 0.0055\n",
      "Epoch 4/30\n",
      "\u001b[1m46/46\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 0.0099 - val_loss: 0.0038\n",
      "Epoch 5/30\n",
      "\u001b[1m46/46\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - loss: 0.0085 - val_loss: 0.0102\n",
      "Epoch 6/30\n",
      "\u001b[1m46/46\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - loss: 0.0088 - val_loss: 0.0040\n",
      "Epoch 7/30\n",
      "\u001b[1m46/46\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 0.0083 - val_loss: 0.0132\n",
      "Epoch 8/30\n",
      "\u001b[1m46/46\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - loss: 0.0084 - val_loss: 0.0064\n",
      "Epoch 9/30\n",
      "\u001b[1m46/46\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 0.0061 - val_loss: 0.0024\n",
      "Epoch 10/30\n",
      "\u001b[1m46/46\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - loss: 0.0066 - val_loss: 0.0087\n",
      "Epoch 11/30\n",
      "\u001b[1m46/46\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - loss: 0.0065 - val_loss: 0.0042\n",
      "Epoch 12/30\n",
      "\u001b[1m46/46\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 0.0058 - val_loss: 0.0042\n",
      "Epoch 13/30\n",
      "\u001b[1m46/46\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - loss: 0.0062 - val_loss: 0.0020\n",
      "Epoch 14/30\n",
      "\u001b[1m46/46\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - loss: 0.0050 - val_loss: 0.0027\n",
      "Epoch 15/30\n",
      "\u001b[1m46/46\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - loss: 0.0059 - val_loss: 0.0034\n",
      "Epoch 16/30\n",
      "\u001b[1m46/46\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - loss: 0.0043 - val_loss: 0.0023\n",
      "Epoch 17/30\n",
      "\u001b[1m46/46\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - loss: 0.0049 - val_loss: 0.0042\n",
      "Epoch 18/30\n",
      "\u001b[1m46/46\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - loss: 0.0042 - val_loss: 0.0018\n",
      "Epoch 19/30\n",
      "\u001b[1m46/46\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - loss: 0.0051 - val_loss: 0.0017\n",
      "Epoch 20/30\n",
      "\u001b[1m46/46\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 0.0041 - val_loss: 0.0016\n",
      "Epoch 21/30\n",
      "\u001b[1m46/46\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 0.0050 - val_loss: 0.0020\n",
      "Epoch 22/30\n",
      "\u001b[1m46/46\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - loss: 0.0048 - val_loss: 0.0039\n",
      "Epoch 23/30\n",
      "\u001b[1m46/46\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - loss: 0.0028 - val_loss: 0.0019\n",
      "Epoch 24/30\n",
      "\u001b[1m46/46\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - loss: 0.0032 - val_loss: 0.0023\n",
      "Epoch 25/30\n",
      "\u001b[1m46/46\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - loss: 0.0054 - val_loss: 0.0026\n",
      "Epoch 26/30\n",
      "\u001b[1m46/46\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - loss: 0.0039 - val_loss: 0.0024\n",
      "Epoch 27/30\n",
      "\u001b[1m46/46\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 0.0036 - val_loss: 0.0030\n",
      "Epoch 28/30\n",
      "\u001b[1m46/46\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 11ms/step - loss: 0.0042 - val_loss: 0.0022\n",
      "Epoch 29/30\n",
      "\u001b[1m46/46\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - loss: 0.0041 - val_loss: 0.0019\n",
      "Epoch 30/30\n",
      "\u001b[1m46/46\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - loss: 0.0037 - val_loss: 0.0024\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:The `save_format` argument is deprecated in Keras 3. We recommend removing this argument as it can be inferred from the file path. Received: save_format=keras\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Finished: Luxembourg | MAE: 0.18 | RMSE: 0.30 | R²: 0.83\n",
      "Epoch 1/30\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/dejauhnaebeadle/School/MachineLearning/machine-learning-project/code/rain-prediction/.venv/lib/python3.11/site-packages/keras/src/layers/rnn/rnn.py:200: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
      "  super().__init__(**kwargs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m46/46\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 12ms/step - loss: 0.0541 - val_loss: 0.0047\n",
      "Epoch 2/30\n",
      "\u001b[1m46/46\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - loss: 0.0052 - val_loss: 0.0018\n",
      "Epoch 3/30\n",
      "\u001b[1m46/46\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 0.0049 - val_loss: 0.0011\n",
      "Epoch 4/30\n",
      "\u001b[1m46/46\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - loss: 0.0043 - val_loss: 0.0016\n",
      "Epoch 5/30\n",
      "\u001b[1m46/46\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - loss: 0.0044 - val_loss: 0.0024\n",
      "Epoch 6/30\n",
      "\u001b[1m46/46\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - loss: 0.0042 - val_loss: 0.0012\n",
      "Epoch 7/30\n",
      "\u001b[1m46/46\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - loss: 0.0039 - val_loss: 0.0012\n",
      "Epoch 8/30\n",
      "\u001b[1m46/46\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - loss: 0.0031 - val_loss: 6.8848e-04\n",
      "Epoch 9/30\n",
      "\u001b[1m46/46\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - loss: 0.0037 - val_loss: 6.5568e-04\n",
      "Epoch 10/30\n",
      "\u001b[1m46/46\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - loss: 0.0030 - val_loss: 7.0557e-04\n",
      "Epoch 11/30\n",
      "\u001b[1m46/46\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - loss: 0.0028 - val_loss: 9.3499e-04\n",
      "Epoch 12/30\n",
      "\u001b[1m46/46\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - loss: 0.0024 - val_loss: 6.1631e-04\n",
      "Epoch 13/30\n",
      "\u001b[1m46/46\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - loss: 0.0032 - val_loss: 5.7471e-04\n",
      "Epoch 14/30\n",
      "\u001b[1m46/46\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - loss: 0.0023 - val_loss: 6.2771e-04\n",
      "Epoch 15/30\n",
      "\u001b[1m46/46\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - loss: 0.0026 - val_loss: 5.9975e-04\n",
      "Epoch 16/30\n",
      "\u001b[1m46/46\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - loss: 0.0024 - val_loss: 5.3261e-04\n",
      "Epoch 17/30\n",
      "\u001b[1m46/46\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - loss: 0.0022 - val_loss: 6.0840e-04\n",
      "Epoch 18/30\n",
      "\u001b[1m46/46\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - loss: 0.0024 - val_loss: 5.3053e-04\n",
      "Epoch 19/30\n",
      "\u001b[1m46/46\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - loss: 0.0020 - val_loss: 5.9485e-04\n",
      "Epoch 20/30\n",
      "\u001b[1m46/46\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - loss: 0.0025 - val_loss: 5.1348e-04\n",
      "Epoch 21/30\n",
      "\u001b[1m46/46\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - loss: 0.0027 - val_loss: 0.0017\n",
      "Epoch 22/30\n",
      "\u001b[1m46/46\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - loss: 0.0024 - val_loss: 5.7337e-04\n",
      "Epoch 23/30\n",
      "\u001b[1m46/46\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - loss: 0.0019 - val_loss: 4.9617e-04\n",
      "Epoch 24/30\n",
      "\u001b[1m46/46\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 0.0020 - val_loss: 4.3532e-04\n",
      "Epoch 25/30\n",
      "\u001b[1m46/46\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 0.0017 - val_loss: 5.8239e-04\n",
      "Epoch 26/30\n",
      "\u001b[1m46/46\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - loss: 0.0017 - val_loss: 5.0269e-04\n",
      "Epoch 27/30\n",
      "\u001b[1m46/46\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - loss: 0.0020 - val_loss: 4.2498e-04\n",
      "Epoch 28/30\n",
      "\u001b[1m46/46\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - loss: 0.0017 - val_loss: 5.7901e-04\n",
      "Epoch 29/30\n",
      "\u001b[1m46/46\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - loss: 0.0020 - val_loss: 3.8654e-04\n",
      "Epoch 30/30\n",
      "\u001b[1m46/46\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 6ms/step - loss: 0.0015 - val_loss: 4.3843e-04\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:The `save_format` argument is deprecated in Keras 3. We recommend removing this argument as it can be inferred from the file path. Received: save_format=keras\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Finished: Madagascar | MAE: 0.05 | RMSE: 0.09 | R²: 0.85\n",
      "Epoch 1/30\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/dejauhnaebeadle/School/MachineLearning/machine-learning-project/code/rain-prediction/.venv/lib/python3.11/site-packages/keras/src/layers/rnn/rnn.py:200: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
      "  super().__init__(**kwargs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m46/46\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 10ms/step - loss: 0.0652 - val_loss: 0.0117\n",
      "Epoch 2/30\n",
      "\u001b[1m46/46\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 0.0130 - val_loss: 0.0114\n",
      "Epoch 3/30\n",
      "\u001b[1m46/46\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 0.0117 - val_loss: 0.0112\n",
      "Epoch 4/30\n",
      "\u001b[1m46/46\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 0.0098 - val_loss: 0.0070\n",
      "Epoch 5/30\n",
      "\u001b[1m46/46\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 0.0079 - val_loss: 0.0064\n",
      "Epoch 6/30\n",
      "\u001b[1m46/46\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 0.0065 - val_loss: 0.0070\n",
      "Epoch 7/30\n",
      "\u001b[1m46/46\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 0.0078 - val_loss: 0.0059\n",
      "Epoch 8/30\n",
      "\u001b[1m46/46\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 0.0064 - val_loss: 0.0075\n",
      "Epoch 9/30\n",
      "\u001b[1m46/46\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 0.0069 - val_loss: 0.0055\n",
      "Epoch 10/30\n",
      "\u001b[1m46/46\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 0.0054 - val_loss: 0.0052\n",
      "Epoch 11/30\n",
      "\u001b[1m46/46\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 0.0049 - val_loss: 0.0052\n",
      "Epoch 12/30\n",
      "\u001b[1m46/46\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 0.0059 - val_loss: 0.0057\n",
      "Epoch 13/30\n",
      "\u001b[1m46/46\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 0.0045 - val_loss: 0.0048\n",
      "Epoch 14/30\n",
      "\u001b[1m46/46\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 0.0059 - val_loss: 0.0045\n",
      "Epoch 15/30\n",
      "\u001b[1m46/46\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 0.0044 - val_loss: 0.0045\n",
      "Epoch 16/30\n",
      "\u001b[1m46/46\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 0.0059 - val_loss: 0.0045\n",
      "Epoch 17/30\n",
      "\u001b[1m46/46\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - loss: 0.0053 - val_loss: 0.0042\n",
      "Epoch 18/30\n",
      "\u001b[1m46/46\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 0.0047 - val_loss: 0.0043\n",
      "Epoch 19/30\n",
      "\u001b[1m46/46\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 0.0051 - val_loss: 0.0045\n",
      "Epoch 20/30\n",
      "\u001b[1m46/46\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 0.0049 - val_loss: 0.0039\n",
      "Epoch 21/30\n",
      "\u001b[1m46/46\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 0.0045 - val_loss: 0.0039\n",
      "Epoch 22/30\n",
      "\u001b[1m46/46\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 0.0039 - val_loss: 0.0037\n",
      "Epoch 23/30\n",
      "\u001b[1m46/46\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 0.0052 - val_loss: 0.0044\n",
      "Epoch 24/30\n",
      "\u001b[1m46/46\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 0.0046 - val_loss: 0.0037\n",
      "Epoch 25/30\n",
      "\u001b[1m46/46\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 0.0044 - val_loss: 0.0056\n",
      "Epoch 26/30\n",
      "\u001b[1m46/46\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 0.0055 - val_loss: 0.0049\n",
      "Epoch 27/30\n",
      "\u001b[1m46/46\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 0.0035 - val_loss: 0.0037\n",
      "Epoch 28/30\n",
      "\u001b[1m46/46\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 0.0030 - val_loss: 0.0040\n",
      "Epoch 29/30\n",
      "\u001b[1m46/46\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 0.0049 - val_loss: 0.0035\n",
      "Epoch 30/30\n",
      "\u001b[1m46/46\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 0.0038 - val_loss: 0.0035\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:The `save_format` argument is deprecated in Keras 3. We recommend removing this argument as it can be inferred from the file path. Received: save_format=keras\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Finished: Malawi | MAE: 0.04 | RMSE: 0.08 | R²: 0.92\n",
      "Epoch 1/30\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/dejauhnaebeadle/School/MachineLearning/machine-learning-project/code/rain-prediction/.venv/lib/python3.11/site-packages/keras/src/layers/rnn/rnn.py:200: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
      "  super().__init__(**kwargs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m46/46\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 10ms/step - loss: 0.0400 - val_loss: 0.0013\n",
      "Epoch 2/30\n",
      "\u001b[1m46/46\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 0.0044 - val_loss: 0.0016\n",
      "Epoch 3/30\n",
      "\u001b[1m46/46\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 0.0032 - val_loss: 0.0020\n",
      "Epoch 4/30\n",
      "\u001b[1m46/46\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 0.0032 - val_loss: 0.0012\n",
      "Epoch 5/30\n",
      "\u001b[1m46/46\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 0.0025 - val_loss: 0.0024\n",
      "Epoch 6/30\n",
      "\u001b[1m46/46\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 0.0028 - val_loss: 0.0015\n",
      "Epoch 7/30\n",
      "\u001b[1m46/46\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 0.0027 - val_loss: 0.0034\n",
      "Epoch 8/30\n",
      "\u001b[1m46/46\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 0.0024 - val_loss: 0.0015\n",
      "Epoch 9/30\n",
      "\u001b[1m46/46\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 0.0023 - val_loss: 0.0015\n",
      "Epoch 10/30\n",
      "\u001b[1m46/46\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 0.0022 - val_loss: 0.0015\n",
      "Epoch 11/30\n",
      "\u001b[1m46/46\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 0.0019 - val_loss: 8.1299e-04\n",
      "Epoch 12/30\n",
      "\u001b[1m46/46\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 0.0021 - val_loss: 7.3017e-04\n",
      "Epoch 13/30\n",
      "\u001b[1m46/46\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 0.0021 - val_loss: 9.9005e-04\n",
      "Epoch 14/30\n",
      "\u001b[1m46/46\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 0.0018 - val_loss: 0.0013\n",
      "Epoch 15/30\n",
      "\u001b[1m46/46\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 0.0017 - val_loss: 0.0014\n",
      "Epoch 16/30\n",
      "\u001b[1m46/46\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 0.0017 - val_loss: 7.7358e-04\n",
      "Epoch 17/30\n",
      "\u001b[1m46/46\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 0.0014 - val_loss: 0.0017\n",
      "Epoch 18/30\n",
      "\u001b[1m46/46\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 0.0013 - val_loss: 0.0014\n",
      "Epoch 19/30\n",
      "\u001b[1m46/46\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 0.0012 - val_loss: 9.4588e-04\n",
      "Epoch 20/30\n",
      "\u001b[1m46/46\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 0.0011 - val_loss: 6.5557e-04\n",
      "Epoch 21/30\n",
      "\u001b[1m46/46\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 0.0014 - val_loss: 5.8332e-04\n",
      "Epoch 22/30\n",
      "\u001b[1m46/46\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 0.0012 - val_loss: 8.3770e-04\n",
      "Epoch 23/30\n",
      "\u001b[1m46/46\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 0.0014 - val_loss: 6.4615e-04\n",
      "Epoch 24/30\n",
      "\u001b[1m46/46\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 0.0013 - val_loss: 5.6652e-04\n",
      "Epoch 25/30\n",
      "\u001b[1m46/46\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 0.0015 - val_loss: 8.5411e-04\n",
      "Epoch 26/30\n",
      "\u001b[1m46/46\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 0.0016 - val_loss: 8.5323e-04\n",
      "Epoch 27/30\n",
      "\u001b[1m46/46\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 0.0012 - val_loss: 0.0011\n",
      "Epoch 28/30\n",
      "\u001b[1m46/46\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 0.0013 - val_loss: 0.0015\n",
      "Epoch 29/30\n",
      "\u001b[1m46/46\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 0.0013 - val_loss: 7.4950e-04\n",
      "Epoch 30/30\n",
      "\u001b[1m46/46\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 0.0013 - val_loss: 5.6883e-04\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:The `save_format` argument is deprecated in Keras 3. We recommend removing this argument as it can be inferred from the file path. Received: save_format=keras\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Finished: Malaysia | MAE: 0.07 | RMSE: 0.11 | R²: 0.87\n",
      "Epoch 1/30\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/dejauhnaebeadle/School/MachineLearning/machine-learning-project/code/rain-prediction/.venv/lib/python3.11/site-packages/keras/src/layers/rnn/rnn.py:200: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
      "  super().__init__(**kwargs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m46/46\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 10ms/step - loss: 0.0571 - val_loss: 0.0019\n",
      "Epoch 2/30\n",
      "\u001b[1m46/46\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 0.0070 - val_loss: 0.0014\n",
      "Epoch 3/30\n",
      "\u001b[1m46/46\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 0.0071 - val_loss: 0.0018\n",
      "Epoch 4/30\n",
      "\u001b[1m46/46\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 0.0060 - val_loss: 0.0019\n",
      "Epoch 5/30\n",
      "\u001b[1m46/46\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 0.0056 - val_loss: 0.0042\n",
      "Epoch 6/30\n",
      "\u001b[1m46/46\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 0.0057 - val_loss: 8.2118e-04\n",
      "Epoch 7/30\n",
      "\u001b[1m46/46\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 0.0050 - val_loss: 0.0021\n",
      "Epoch 8/30\n",
      "\u001b[1m46/46\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 0.0038 - val_loss: 0.0013\n",
      "Epoch 9/30\n",
      "\u001b[1m46/46\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 0.0042 - val_loss: 0.0025\n",
      "Epoch 10/30\n",
      "\u001b[1m46/46\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 0.0040 - val_loss: 7.9260e-04\n",
      "Epoch 11/30\n",
      "\u001b[1m46/46\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 0.0041 - val_loss: 0.0019\n",
      "Epoch 12/30\n",
      "\u001b[1m46/46\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 0.0036 - val_loss: 9.9549e-04\n",
      "Epoch 13/30\n",
      "\u001b[1m46/46\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 0.0036 - val_loss: 6.0144e-04\n",
      "Epoch 14/30\n",
      "\u001b[1m46/46\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - loss: 0.0031 - val_loss: 0.0019\n",
      "Epoch 15/30\n",
      "\u001b[1m46/46\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 0.0028 - val_loss: 0.0014\n",
      "Epoch 16/30\n",
      "\u001b[1m46/46\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 0.0038 - val_loss: 5.7310e-04\n",
      "Epoch 17/30\n",
      "\u001b[1m46/46\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 0.0037 - val_loss: 8.3101e-04\n",
      "Epoch 18/30\n",
      "\u001b[1m46/46\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 0.0023 - val_loss: 0.0011\n",
      "Epoch 19/30\n",
      "\u001b[1m46/46\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 0.0029 - val_loss: 5.2140e-04\n",
      "Epoch 20/30\n",
      "\u001b[1m46/46\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 0.0026 - val_loss: 9.6014e-04\n",
      "Epoch 21/30\n",
      "\u001b[1m46/46\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 0.0035 - val_loss: 5.1226e-04\n",
      "Epoch 22/30\n",
      "\u001b[1m46/46\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 0.0024 - val_loss: 0.0013\n",
      "Epoch 23/30\n",
      "\u001b[1m46/46\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - loss: 0.0030 - val_loss: 0.0011\n",
      "Epoch 24/30\n",
      "\u001b[1m46/46\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - loss: 0.0022 - val_loss: 5.5278e-04\n",
      "Epoch 25/30\n",
      "\u001b[1m46/46\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - loss: 0.0021 - val_loss: 0.0013\n",
      "Epoch 26/30\n",
      "\u001b[1m46/46\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 0.0024 - val_loss: 4.6165e-04\n",
      "Epoch 27/30\n",
      "\u001b[1m46/46\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 0.0021 - val_loss: 4.6562e-04\n",
      "Epoch 28/30\n",
      "\u001b[1m46/46\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 0.0023 - val_loss: 4.1549e-04\n",
      "Epoch 29/30\n",
      "\u001b[1m46/46\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 0.0028 - val_loss: 4.9494e-04\n",
      "Epoch 30/30\n",
      "\u001b[1m46/46\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 0.0029 - val_loss: 8.2822e-04\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:The `save_format` argument is deprecated in Keras 3. We recommend removing this argument as it can be inferred from the file path. Received: save_format=keras\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Finished: Mali | MAE: 0.12 | RMSE: 0.18 | R²: 0.82\n",
      "Epoch 1/30\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/dejauhnaebeadle/School/MachineLearning/machine-learning-project/code/rain-prediction/.venv/lib/python3.11/site-packages/keras/src/layers/rnn/rnn.py:200: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
      "  super().__init__(**kwargs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m46/46\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 10ms/step - loss: 0.1133 - val_loss: 0.0102\n",
      "Epoch 2/30\n",
      "\u001b[1m46/46\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 0.0139 - val_loss: 0.0040\n",
      "Epoch 3/30\n",
      "\u001b[1m46/46\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 0.0129 - val_loss: 0.0069\n",
      "Epoch 4/30\n",
      "\u001b[1m46/46\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 0.0098 - val_loss: 0.0026\n",
      "Epoch 5/30\n",
      "\u001b[1m46/46\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 0.0085 - val_loss: 0.0017\n",
      "Epoch 6/30\n",
      "\u001b[1m46/46\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 0.0076 - val_loss: 0.0031\n",
      "Epoch 7/30\n",
      "\u001b[1m46/46\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 0.0066 - val_loss: 0.0039\n",
      "Epoch 8/30\n",
      "\u001b[1m46/46\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 0.0068 - val_loss: 0.0034\n",
      "Epoch 9/30\n",
      "\u001b[1m46/46\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 0.0064 - val_loss: 0.0019\n",
      "Epoch 10/30\n",
      "\u001b[1m46/46\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 0.0059 - val_loss: 0.0019\n",
      "Epoch 11/30\n",
      "\u001b[1m46/46\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 0.0056 - val_loss: 0.0043\n",
      "Epoch 12/30\n",
      "\u001b[1m46/46\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 0.0055 - val_loss: 0.0012\n",
      "Epoch 13/30\n",
      "\u001b[1m46/46\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 0.0056 - val_loss: 0.0018\n",
      "Epoch 14/30\n",
      "\u001b[1m46/46\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 0.0048 - val_loss: 0.0025\n",
      "Epoch 15/30\n",
      "\u001b[1m46/46\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 0.0053 - val_loss: 0.0047\n",
      "Epoch 16/30\n",
      "\u001b[1m46/46\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 0.0046 - val_loss: 0.0024\n",
      "Epoch 17/30\n",
      "\u001b[1m46/46\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 0.0042 - val_loss: 0.0015\n",
      "Epoch 18/30\n",
      "\u001b[1m46/46\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 0.0042 - val_loss: 0.0021\n",
      "Epoch 19/30\n",
      "\u001b[1m46/46\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 0.0052 - val_loss: 9.5122e-04\n",
      "Epoch 20/30\n",
      "\u001b[1m46/46\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 0.0035 - val_loss: 0.0011\n",
      "Epoch 21/30\n",
      "\u001b[1m46/46\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 0.0041 - val_loss: 0.0014\n",
      "Epoch 22/30\n",
      "\u001b[1m46/46\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 0.0036 - val_loss: 0.0013\n",
      "Epoch 23/30\n",
      "\u001b[1m46/46\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 0.0040 - val_loss: 0.0010\n",
      "Epoch 24/30\n",
      "\u001b[1m46/46\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 0.0035 - val_loss: 7.9787e-04\n",
      "Epoch 25/30\n",
      "\u001b[1m46/46\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 0.0032 - val_loss: 8.2818e-04\n",
      "Epoch 26/30\n",
      "\u001b[1m46/46\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 0.0034 - val_loss: 0.0061\n",
      "Epoch 27/30\n",
      "\u001b[1m46/46\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 0.0040 - val_loss: 7.5017e-04\n",
      "Epoch 28/30\n",
      "\u001b[1m46/46\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 0.0029 - val_loss: 7.9664e-04\n",
      "Epoch 29/30\n",
      "\u001b[1m46/46\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 0.0039 - val_loss: 8.5873e-04\n",
      "Epoch 30/30\n",
      "\u001b[1m46/46\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 0.0028 - val_loss: 0.0016\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:The `save_format` argument is deprecated in Keras 3. We recommend removing this argument as it can be inferred from the file path. Received: save_format=keras\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Finished: Mauritania | MAE: 0.16 | RMSE: 0.22 | R²: 0.80\n",
      "Epoch 1/30\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/dejauhnaebeadle/School/MachineLearning/machine-learning-project/code/rain-prediction/.venv/lib/python3.11/site-packages/keras/src/layers/rnn/rnn.py:200: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
      "  super().__init__(**kwargs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m46/46\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 10ms/step - loss: 0.0800 - val_loss: 0.0134\n",
      "Epoch 2/30\n",
      "\u001b[1m46/46\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 0.0122 - val_loss: 0.0129\n",
      "Epoch 3/30\n",
      "\u001b[1m46/46\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 0.0107 - val_loss: 0.0078\n",
      "Epoch 4/30\n",
      "\u001b[1m46/46\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 0.0101 - val_loss: 0.0088\n",
      "Epoch 5/30\n",
      "\u001b[1m46/46\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 0.0072 - val_loss: 0.0063\n",
      "Epoch 6/30\n",
      "\u001b[1m46/46\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 0.0066 - val_loss: 0.0045\n",
      "Epoch 7/30\n",
      "\u001b[1m46/46\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - loss: 0.0059 - val_loss: 0.0126\n",
      "Epoch 8/30\n",
      "\u001b[1m46/46\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 0.0060 - val_loss: 0.0048\n",
      "Epoch 9/30\n",
      "\u001b[1m46/46\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 0.0050 - val_loss: 0.0041\n",
      "Epoch 10/30\n",
      "\u001b[1m46/46\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 0.0049 - val_loss: 0.0051\n",
      "Epoch 11/30\n",
      "\u001b[1m46/46\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 0.0047 - val_loss: 0.0054\n",
      "Epoch 12/30\n",
      "\u001b[1m46/46\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 0.0049 - val_loss: 0.0034\n",
      "Epoch 13/30\n",
      "\u001b[1m46/46\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 0.0047 - val_loss: 0.0039\n",
      "Epoch 14/30\n",
      "\u001b[1m46/46\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 0.0045 - val_loss: 0.0038\n",
      "Epoch 15/30\n",
      "\u001b[1m46/46\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 0.0040 - val_loss: 0.0035\n",
      "Epoch 16/30\n",
      "\u001b[1m46/46\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 0.0039 - val_loss: 0.0029\n",
      "Epoch 17/30\n",
      "\u001b[1m46/46\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 0.0041 - val_loss: 0.0031\n",
      "Epoch 18/30\n",
      "\u001b[1m46/46\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 0.0033 - val_loss: 0.0030\n",
      "Epoch 19/30\n",
      "\u001b[1m46/46\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 0.0028 - val_loss: 0.0026\n",
      "Epoch 20/30\n",
      "\u001b[1m46/46\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 0.0036 - val_loss: 0.0026\n",
      "Epoch 21/30\n",
      "\u001b[1m46/46\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 0.0042 - val_loss: 0.0029\n",
      "Epoch 22/30\n",
      "\u001b[1m46/46\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 0.0035 - val_loss: 0.0024\n",
      "Epoch 23/30\n",
      "\u001b[1m46/46\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 0.0033 - val_loss: 0.0036\n",
      "Epoch 24/30\n",
      "\u001b[1m46/46\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 0.0033 - val_loss: 0.0049\n",
      "Epoch 25/30\n",
      "\u001b[1m46/46\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 0.0029 - val_loss: 0.0039\n",
      "Epoch 26/30\n",
      "\u001b[1m46/46\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 0.0032 - val_loss: 0.0024\n",
      "Epoch 27/30\n",
      "\u001b[1m46/46\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 0.0031 - val_loss: 0.0022\n",
      "Epoch 28/30\n",
      "\u001b[1m46/46\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 0.0024 - val_loss: 0.0026\n",
      "Epoch 29/30\n",
      "\u001b[1m46/46\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 0.0034 - val_loss: 0.0022\n",
      "Epoch 30/30\n",
      "\u001b[1m46/46\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 0.0026 - val_loss: 0.0021\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:The `save_format` argument is deprecated in Keras 3. We recommend removing this argument as it can be inferred from the file path. Received: save_format=keras\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Finished: Mauritius | MAE: 0.03 | RMSE: 0.10 | R²: 0.83\n",
      "Epoch 1/30\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/dejauhnaebeadle/School/MachineLearning/machine-learning-project/code/rain-prediction/.venv/lib/python3.11/site-packages/keras/src/layers/rnn/rnn.py:200: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
      "  super().__init__(**kwargs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m46/46\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 9ms/step - loss: 0.0398 - val_loss: 0.0039\n",
      "Epoch 2/30\n",
      "\u001b[1m46/46\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 0.0052 - val_loss: 0.0057\n",
      "Epoch 3/30\n",
      "\u001b[1m46/46\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 0.0041 - val_loss: 0.0041\n",
      "Epoch 4/30\n",
      "\u001b[1m46/46\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 0.0039 - val_loss: 0.0033\n",
      "Epoch 5/30\n",
      "\u001b[1m46/46\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 0.0033 - val_loss: 0.0034\n",
      "Epoch 6/30\n",
      "\u001b[1m46/46\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 0.0034 - val_loss: 0.0035\n",
      "Epoch 7/30\n",
      "\u001b[1m46/46\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 0.0028 - val_loss: 0.0027\n",
      "Epoch 8/30\n",
      "\u001b[1m46/46\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 0.0025 - val_loss: 0.0022\n",
      "Epoch 9/30\n",
      "\u001b[1m46/46\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 0.0022 - val_loss: 0.0030\n",
      "Epoch 10/30\n",
      "\u001b[1m46/46\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 0.0026 - val_loss: 0.0028\n",
      "Epoch 11/30\n",
      "\u001b[1m46/46\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 0.0019 - val_loss: 0.0021\n",
      "Epoch 12/30\n",
      "\u001b[1m46/46\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 0.0024 - val_loss: 0.0019\n",
      "Epoch 13/30\n",
      "\u001b[1m46/46\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 0.0021 - val_loss: 0.0020\n",
      "Epoch 14/30\n",
      "\u001b[1m46/46\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 0.0022 - val_loss: 0.0020\n",
      "Epoch 15/30\n",
      "\u001b[1m46/46\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 0.0018 - val_loss: 0.0017\n",
      "Epoch 16/30\n",
      "\u001b[1m46/46\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 0.0022 - val_loss: 0.0017\n",
      "Epoch 17/30\n",
      "\u001b[1m46/46\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 0.0016 - val_loss: 0.0016\n",
      "Epoch 18/30\n",
      "\u001b[1m46/46\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 0.0020 - val_loss: 0.0023\n",
      "Epoch 19/30\n",
      "\u001b[1m46/46\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 0.0018 - val_loss: 0.0016\n",
      "Epoch 20/30\n",
      "\u001b[1m46/46\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 0.0019 - val_loss: 0.0022\n",
      "Epoch 21/30\n",
      "\u001b[1m46/46\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 0.0017 - val_loss: 0.0015\n",
      "Epoch 22/30\n",
      "\u001b[1m46/46\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 0.0016 - val_loss: 0.0016\n",
      "Epoch 23/30\n",
      "\u001b[1m46/46\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - loss: 0.0020 - val_loss: 0.0015\n",
      "Epoch 24/30\n",
      "\u001b[1m46/46\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 0.0014 - val_loss: 0.0015\n",
      "Epoch 25/30\n",
      "\u001b[1m46/46\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 0.0017 - val_loss: 0.0017\n",
      "Epoch 26/30\n",
      "\u001b[1m46/46\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 0.0014 - val_loss: 0.0014\n",
      "Epoch 27/30\n",
      "\u001b[1m46/46\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 0.0019 - val_loss: 0.0015\n",
      "Epoch 28/30\n",
      "\u001b[1m46/46\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 0.0015 - val_loss: 0.0015\n",
      "Epoch 29/30\n",
      "\u001b[1m46/46\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 0.0014 - val_loss: 0.0016\n",
      "Epoch 30/30\n",
      "\u001b[1m46/46\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 0.0013 - val_loss: 0.0013\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:The `save_format` argument is deprecated in Keras 3. We recommend removing this argument as it can be inferred from the file path. Received: save_format=keras\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Finished: Mexico | MAE: 0.06 | RMSE: 0.13 | R²: 0.87\n",
      "Epoch 1/30\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/dejauhnaebeadle/School/MachineLearning/machine-learning-project/code/rain-prediction/.venv/lib/python3.11/site-packages/keras/src/layers/rnn/rnn.py:200: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
      "  super().__init__(**kwargs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m46/46\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 9ms/step - loss: 0.0812 - val_loss: 0.0150\n",
      "Epoch 2/30\n",
      "\u001b[1m46/46\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 0.0120 - val_loss: 0.0100\n",
      "Epoch 3/30\n",
      "\u001b[1m46/46\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 0.0102 - val_loss: 0.0095\n",
      "Epoch 4/30\n",
      "\u001b[1m46/46\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 0.0093 - val_loss: 0.0083\n",
      "Epoch 5/30\n",
      "\u001b[1m46/46\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 0.0076 - val_loss: 0.0081\n",
      "Epoch 6/30\n",
      "\u001b[1m46/46\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 0.0072 - val_loss: 0.0085\n",
      "Epoch 7/30\n",
      "\u001b[1m46/46\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 0.0076 - val_loss: 0.0055\n",
      "Epoch 8/30\n",
      "\u001b[1m46/46\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 0.0059 - val_loss: 0.0054\n",
      "Epoch 9/30\n",
      "\u001b[1m46/46\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 0.0066 - val_loss: 0.0046\n",
      "Epoch 10/30\n",
      "\u001b[1m46/46\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 0.0056 - val_loss: 0.0069\n",
      "Epoch 11/30\n",
      "\u001b[1m46/46\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 0.0058 - val_loss: 0.0054\n",
      "Epoch 12/30\n",
      "\u001b[1m46/46\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 0.0062 - val_loss: 0.0059\n",
      "Epoch 13/30\n",
      "\u001b[1m46/46\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 0.0047 - val_loss: 0.0035\n",
      "Epoch 14/30\n",
      "\u001b[1m46/46\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 0.0058 - val_loss: 0.0034\n",
      "Epoch 15/30\n",
      "\u001b[1m46/46\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 0.0044 - val_loss: 0.0035\n",
      "Epoch 16/30\n",
      "\u001b[1m46/46\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 0.0046 - val_loss: 0.0043\n",
      "Epoch 17/30\n",
      "\u001b[1m46/46\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 0.0046 - val_loss: 0.0030\n",
      "Epoch 18/30\n",
      "\u001b[1m46/46\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 0.0042 - val_loss: 0.0043\n",
      "Epoch 19/30\n",
      "\u001b[1m46/46\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 0.0041 - val_loss: 0.0031\n",
      "Epoch 20/30\n",
      "\u001b[1m46/46\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 0.0033 - val_loss: 0.0028\n",
      "Epoch 21/30\n",
      "\u001b[1m46/46\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 0.0041 - val_loss: 0.0028\n",
      "Epoch 22/30\n",
      "\u001b[1m46/46\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 0.0040 - val_loss: 0.0047\n",
      "Epoch 23/30\n",
      "\u001b[1m46/46\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 0.0053 - val_loss: 0.0026\n",
      "Epoch 24/30\n",
      "\u001b[1m46/46\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 0.0027 - val_loss: 0.0025\n",
      "Epoch 25/30\n",
      "\u001b[1m46/46\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 0.0043 - val_loss: 0.0035\n",
      "Epoch 26/30\n",
      "\u001b[1m46/46\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 0.0038 - val_loss: 0.0025\n",
      "Epoch 27/30\n",
      "\u001b[1m46/46\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 0.0035 - val_loss: 0.0027\n",
      "Epoch 28/30\n",
      "\u001b[1m46/46\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 0.0033 - val_loss: 0.0046\n",
      "Epoch 29/30\n",
      "\u001b[1m46/46\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 0.0033 - val_loss: 0.0024\n",
      "Epoch 30/30\n",
      "\u001b[1m46/46\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 0.0037 - val_loss: 0.0025\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:The `save_format` argument is deprecated in Keras 3. We recommend removing this argument as it can be inferred from the file path. Received: save_format=keras\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Finished: Moldova | MAE: 0.15 | RMSE: 0.25 | R²: 0.87\n",
      "Epoch 1/30\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/dejauhnaebeadle/School/MachineLearning/machine-learning-project/code/rain-prediction/.venv/lib/python3.11/site-packages/keras/src/layers/rnn/rnn.py:200: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
      "  super().__init__(**kwargs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m46/46\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 10ms/step - loss: 0.0842 - val_loss: 0.0263\n",
      "Epoch 2/30\n",
      "\u001b[1m46/46\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 0.0147 - val_loss: 0.0263\n",
      "Epoch 3/30\n",
      "\u001b[1m46/46\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 0.0117 - val_loss: 0.0186\n",
      "Epoch 4/30\n",
      "\u001b[1m46/46\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 0.0103 - val_loss: 0.0207\n",
      "Epoch 5/30\n",
      "\u001b[1m46/46\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 0.0092 - val_loss: 0.0138\n",
      "Epoch 6/30\n",
      "\u001b[1m46/46\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 0.0084 - val_loss: 0.0141\n",
      "Epoch 7/30\n",
      "\u001b[1m46/46\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 0.0067 - val_loss: 0.0147\n",
      "Epoch 8/30\n",
      "\u001b[1m46/46\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 0.0064 - val_loss: 0.0101\n",
      "Epoch 9/30\n",
      "\u001b[1m46/46\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 0.0067 - val_loss: 0.0116\n",
      "Epoch 10/30\n",
      "\u001b[1m46/46\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - loss: 0.0062 - val_loss: 0.0094\n",
      "Epoch 11/30\n",
      "\u001b[1m46/46\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 0.0059 - val_loss: 0.0088\n",
      "Epoch 12/30\n",
      "\u001b[1m46/46\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 0.0053 - val_loss: 0.0090\n",
      "Epoch 13/30\n",
      "\u001b[1m46/46\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 0.0058 - val_loss: 0.0083\n",
      "Epoch 14/30\n",
      "\u001b[1m46/46\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 0.0058 - val_loss: 0.0087\n",
      "Epoch 15/30\n",
      "\u001b[1m46/46\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 0.0047 - val_loss: 0.0083\n",
      "Epoch 16/30\n",
      "\u001b[1m46/46\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 0.0037 - val_loss: 0.0077\n",
      "Epoch 17/30\n",
      "\u001b[1m46/46\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 0.0039 - val_loss: 0.0094\n",
      "Epoch 18/30\n",
      "\u001b[1m46/46\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - loss: 0.0048 - val_loss: 0.0072\n",
      "Epoch 19/30\n",
      "\u001b[1m46/46\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 0.0054 - val_loss: 0.0071\n",
      "Epoch 20/30\n",
      "\u001b[1m46/46\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 0.0038 - val_loss: 0.0070\n",
      "Epoch 21/30\n",
      "\u001b[1m46/46\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - loss: 0.0035 - val_loss: 0.0066\n",
      "Epoch 22/30\n",
      "\u001b[1m46/46\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 0.0046 - val_loss: 0.0071\n",
      "Epoch 23/30\n",
      "\u001b[1m46/46\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 0.0041 - val_loss: 0.0070\n",
      "Epoch 24/30\n",
      "\u001b[1m46/46\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 0.0031 - val_loss: 0.0063\n",
      "Epoch 25/30\n",
      "\u001b[1m46/46\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 0.0036 - val_loss: 0.0074\n",
      "Epoch 26/30\n",
      "\u001b[1m46/46\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 0.0043 - val_loss: 0.0070\n",
      "Epoch 27/30\n",
      "\u001b[1m46/46\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 0.0037 - val_loss: 0.0069\n",
      "Epoch 28/30\n",
      "\u001b[1m46/46\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 0.0047 - val_loss: 0.0063\n",
      "Epoch 29/30\n",
      "\u001b[1m46/46\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 0.0037 - val_loss: 0.0062\n",
      "Epoch 30/30\n",
      "\u001b[1m46/46\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 0.0030 - val_loss: 0.0067\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:The `save_format` argument is deprecated in Keras 3. We recommend removing this argument as it can be inferred from the file path. Received: save_format=keras\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Finished: Mongolia | MAE: 0.12 | RMSE: 0.20 | R²: 0.90\n",
      "Epoch 1/30\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/dejauhnaebeadle/School/MachineLearning/machine-learning-project/code/rain-prediction/.venv/lib/python3.11/site-packages/keras/src/layers/rnn/rnn.py:200: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
      "  super().__init__(**kwargs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m46/46\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 10ms/step - loss: 0.0531 - val_loss: 0.0048\n",
      "Epoch 2/30\n",
      "\u001b[1m46/46\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 0.0054 - val_loss: 0.0088\n",
      "Epoch 3/30\n",
      "\u001b[1m46/46\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 0.0052 - val_loss: 0.0049\n",
      "Epoch 4/30\n",
      "\u001b[1m46/46\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 0.0040 - val_loss: 0.0048\n",
      "Epoch 5/30\n",
      "\u001b[1m46/46\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 0.0040 - val_loss: 0.0058\n",
      "Epoch 6/30\n",
      "\u001b[1m46/46\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 0.0040 - val_loss: 0.0049\n",
      "Epoch 7/30\n",
      "\u001b[1m46/46\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 0.0038 - val_loss: 0.0053\n",
      "Epoch 8/30\n",
      "\u001b[1m46/46\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 0.0034 - val_loss: 0.0034\n",
      "Epoch 9/30\n",
      "\u001b[1m46/46\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 0.0027 - val_loss: 0.0046\n",
      "Epoch 10/30\n",
      "\u001b[1m46/46\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 0.0023 - val_loss: 0.0030\n",
      "Epoch 11/30\n",
      "\u001b[1m46/46\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 0.0029 - val_loss: 0.0042\n",
      "Epoch 12/30\n",
      "\u001b[1m46/46\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - loss: 0.0027 - val_loss: 0.0035\n",
      "Epoch 13/30\n",
      "\u001b[1m46/46\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 0.0028 - val_loss: 0.0021\n",
      "Epoch 14/30\n",
      "\u001b[1m46/46\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 0.0025 - val_loss: 0.0022\n",
      "Epoch 15/30\n",
      "\u001b[1m46/46\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 0.0024 - val_loss: 0.0021\n",
      "Epoch 16/30\n",
      "\u001b[1m46/46\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 0.0022 - val_loss: 0.0023\n",
      "Epoch 17/30\n",
      "\u001b[1m46/46\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 0.0024 - val_loss: 0.0023\n",
      "Epoch 18/30\n",
      "\u001b[1m46/46\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - loss: 0.0026 - val_loss: 0.0026\n",
      "Epoch 19/30\n",
      "\u001b[1m46/46\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 0.0020 - val_loss: 0.0020\n",
      "Epoch 20/30\n",
      "\u001b[1m46/46\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - loss: 0.0024 - val_loss: 0.0018\n",
      "Epoch 21/30\n",
      "\u001b[1m46/46\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - loss: 0.0022 - val_loss: 0.0019\n",
      "Epoch 22/30\n",
      "\u001b[1m46/46\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - loss: 0.0023 - val_loss: 0.0019\n",
      "Epoch 23/30\n",
      "\u001b[1m46/46\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - loss: 0.0022 - val_loss: 0.0020\n",
      "Epoch 24/30\n",
      "\u001b[1m46/46\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - loss: 0.0019 - val_loss: 0.0023\n",
      "Epoch 25/30\n",
      "\u001b[1m46/46\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - loss: 0.0019 - val_loss: 0.0024\n",
      "Epoch 26/30\n",
      "\u001b[1m46/46\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - loss: 0.0018 - val_loss: 0.0019\n",
      "Epoch 27/30\n",
      "\u001b[1m46/46\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - loss: 0.0021 - val_loss: 0.0024\n",
      "Epoch 28/30\n",
      "\u001b[1m46/46\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - loss: 0.0018 - val_loss: 0.0016\n",
      "Epoch 29/30\n",
      "\u001b[1m46/46\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 0.0019 - val_loss: 0.0022\n",
      "Epoch 30/30\n",
      "\u001b[1m46/46\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - loss: 0.0017 - val_loss: 0.0015\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:The `save_format` argument is deprecated in Keras 3. We recommend removing this argument as it can be inferred from the file path. Received: save_format=keras\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Finished: Montenegro | MAE: 0.08 | RMSE: 0.13 | R²: 0.91\n",
      "Epoch 1/30\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/dejauhnaebeadle/School/MachineLearning/machine-learning-project/code/rain-prediction/.venv/lib/python3.11/site-packages/keras/src/layers/rnn/rnn.py:200: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
      "  super().__init__(**kwargs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m46/46\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 12ms/step - loss: 0.0591 - val_loss: 0.0020\n",
      "Epoch 2/30\n",
      "\u001b[1m46/46\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - loss: 0.0086 - val_loss: 0.0027\n",
      "Epoch 3/30\n",
      "\u001b[1m46/46\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - loss: 0.0074 - val_loss: 0.0022\n",
      "Epoch 4/30\n",
      "\u001b[1m46/46\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - loss: 0.0067 - val_loss: 0.0014\n",
      "Epoch 5/30\n",
      "\u001b[1m46/46\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - loss: 0.0061 - val_loss: 0.0011\n",
      "Epoch 6/30\n",
      "\u001b[1m46/46\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 0.0052 - val_loss: 0.0052\n",
      "Epoch 7/30\n",
      "\u001b[1m46/46\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - loss: 0.0044 - val_loss: 0.0012\n",
      "Epoch 8/30\n",
      "\u001b[1m46/46\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - loss: 0.0039 - val_loss: 0.0022\n",
      "Epoch 9/30\n",
      "\u001b[1m46/46\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - loss: 0.0042 - val_loss: 0.0016\n",
      "Epoch 10/30\n",
      "\u001b[1m46/46\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - loss: 0.0044 - val_loss: 0.0032\n",
      "Epoch 11/30\n",
      "\u001b[1m46/46\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - loss: 0.0038 - val_loss: 8.3634e-04\n",
      "Epoch 12/30\n",
      "\u001b[1m46/46\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - loss: 0.0039 - val_loss: 0.0015\n",
      "Epoch 13/30\n",
      "\u001b[1m46/46\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - loss: 0.0035 - val_loss: 0.0023\n",
      "Epoch 14/30\n",
      "\u001b[1m46/46\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - loss: 0.0030 - val_loss: 7.6141e-04\n",
      "Epoch 15/30\n",
      "\u001b[1m46/46\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 0.0035 - val_loss: 0.0014\n",
      "Epoch 16/30\n",
      "\u001b[1m46/46\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - loss: 0.0039 - val_loss: 9.0505e-04\n",
      "Epoch 17/30\n",
      "\u001b[1m46/46\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 0.0033 - val_loss: 0.0012\n",
      "Epoch 18/30\n",
      "\u001b[1m46/46\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 0.0034 - val_loss: 0.0021\n",
      "Epoch 19/30\n",
      "\u001b[1m46/46\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - loss: 0.0027 - val_loss: 0.0015\n",
      "Epoch 20/30\n",
      "\u001b[1m46/46\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - loss: 0.0026 - val_loss: 8.2939e-04\n",
      "Epoch 21/30\n",
      "\u001b[1m46/46\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - loss: 0.0025 - val_loss: 8.8140e-04\n",
      "Epoch 22/30\n",
      "\u001b[1m46/46\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - loss: 0.0029 - val_loss: 0.0021\n",
      "Epoch 23/30\n",
      "\u001b[1m46/46\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - loss: 0.0026 - val_loss: 8.4789e-04\n",
      "Epoch 24/30\n",
      "\u001b[1m46/46\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - loss: 0.0028 - val_loss: 0.0030\n",
      "Epoch 25/30\n",
      "\u001b[1m46/46\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - loss: 0.0034 - val_loss: 6.3653e-04\n",
      "Epoch 26/30\n",
      "\u001b[1m46/46\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - loss: 0.0021 - val_loss: 8.4575e-04\n",
      "Epoch 27/30\n",
      "\u001b[1m46/46\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - loss: 0.0025 - val_loss: 7.5018e-04\n",
      "Epoch 28/30\n",
      "\u001b[1m46/46\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - loss: 0.0024 - val_loss: 5.9269e-04\n",
      "Epoch 29/30\n",
      "\u001b[1m46/46\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - loss: 0.0028 - val_loss: 6.5961e-04\n",
      "Epoch 30/30\n",
      "\u001b[1m46/46\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - loss: 0.0020 - val_loss: 8.5606e-04\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:The `save_format` argument is deprecated in Keras 3. We recommend removing this argument as it can be inferred from the file path. Received: save_format=keras\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Finished: Morocco | MAE: 0.15 | RMSE: 0.21 | R²: 0.86\n",
      "Epoch 1/30\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/dejauhnaebeadle/School/MachineLearning/machine-learning-project/code/rain-prediction/.venv/lib/python3.11/site-packages/keras/src/layers/rnn/rnn.py:200: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
      "  super().__init__(**kwargs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m46/46\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 17ms/step - loss: 0.0604 - val_loss: 0.0099\n",
      "Epoch 2/30\n",
      "\u001b[1m46/46\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - loss: 0.0103 - val_loss: 0.0094\n",
      "Epoch 3/30\n",
      "\u001b[1m46/46\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - loss: 0.0099 - val_loss: 0.0084\n",
      "Epoch 4/30\n",
      "\u001b[1m46/46\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - loss: 0.0079 - val_loss: 0.0075\n",
      "Epoch 5/30\n",
      "\u001b[1m46/46\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - loss: 0.0071 - val_loss: 0.0055\n",
      "Epoch 6/30\n",
      "\u001b[1m46/46\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - loss: 0.0053 - val_loss: 0.0091\n",
      "Epoch 7/30\n",
      "\u001b[1m46/46\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - loss: 0.0059 - val_loss: 0.0065\n",
      "Epoch 8/30\n",
      "\u001b[1m46/46\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - loss: 0.0053 - val_loss: 0.0082\n",
      "Epoch 9/30\n",
      "\u001b[1m46/46\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - loss: 0.0049 - val_loss: 0.0035\n",
      "Epoch 10/30\n",
      "\u001b[1m46/46\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - loss: 0.0048 - val_loss: 0.0052\n",
      "Epoch 11/30\n",
      "\u001b[1m46/46\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - loss: 0.0046 - val_loss: 0.0033\n",
      "Epoch 12/30\n",
      "\u001b[1m46/46\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - loss: 0.0050 - val_loss: 0.0034\n",
      "Epoch 13/30\n",
      "\u001b[1m46/46\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 14ms/step - loss: 0.0041 - val_loss: 0.0040\n",
      "Epoch 14/30\n",
      "\u001b[1m46/46\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - loss: 0.0043 - val_loss: 0.0044\n",
      "Epoch 15/30\n",
      "\u001b[1m46/46\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - loss: 0.0043 - val_loss: 0.0035\n",
      "Epoch 16/30\n",
      "\u001b[1m46/46\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - loss: 0.0038 - val_loss: 0.0027\n",
      "Epoch 17/30\n",
      "\u001b[1m46/46\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - loss: 0.0041 - val_loss: 0.0026\n",
      "Epoch 18/30\n",
      "\u001b[1m46/46\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 15ms/step - loss: 0.0033 - val_loss: 0.0028\n",
      "Epoch 19/30\n",
      "\u001b[1m46/46\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - loss: 0.0036 - val_loss: 0.0034\n",
      "Epoch 20/30\n",
      "\u001b[1m46/46\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - loss: 0.0037 - val_loss: 0.0026\n",
      "Epoch 21/30\n",
      "\u001b[1m46/46\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - loss: 0.0030 - val_loss: 0.0024\n",
      "Epoch 22/30\n",
      "\u001b[1m46/46\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - loss: 0.0039 - val_loss: 0.0024\n",
      "Epoch 23/30\n",
      "\u001b[1m46/46\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - loss: 0.0032 - val_loss: 0.0039\n",
      "Epoch 24/30\n",
      "\u001b[1m46/46\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - loss: 0.0037 - val_loss: 0.0023\n",
      "Epoch 25/30\n",
      "\u001b[1m46/46\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - loss: 0.0025 - val_loss: 0.0027\n",
      "Epoch 26/30\n",
      "\u001b[1m46/46\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - loss: 0.0030 - val_loss: 0.0029\n",
      "Epoch 27/30\n",
      "\u001b[1m46/46\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - loss: 0.0045 - val_loss: 0.0029\n",
      "Epoch 28/30\n",
      "\u001b[1m46/46\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - loss: 0.0027 - val_loss: 0.0023\n",
      "Epoch 29/30\n",
      "\u001b[1m46/46\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - loss: 0.0032 - val_loss: 0.0021\n",
      "Epoch 30/30\n",
      "\u001b[1m46/46\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - loss: 0.0034 - val_loss: 0.0021\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:The `save_format` argument is deprecated in Keras 3. We recommend removing this argument as it can be inferred from the file path. Received: save_format=keras\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Finished: Mozambique | MAE: 0.05 | RMSE: 0.09 | R²: 0.91\n",
      "Epoch 1/30\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/dejauhnaebeadle/School/MachineLearning/machine-learning-project/code/rain-prediction/.venv/lib/python3.11/site-packages/keras/src/layers/rnn/rnn.py:200: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
      "  super().__init__(**kwargs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m46/46\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 12ms/step - loss: 0.0885 - val_loss: 0.0054\n",
      "Epoch 2/30\n",
      "\u001b[1m46/46\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - loss: 0.0079 - val_loss: 0.0062\n",
      "Epoch 3/30\n",
      "\u001b[1m46/46\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - loss: 0.0062 - val_loss: 0.0049\n",
      "Epoch 4/30\n",
      "\u001b[1m46/46\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - loss: 0.0056 - val_loss: 0.0050\n",
      "Epoch 5/30\n",
      "\u001b[1m46/46\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 0.0058 - val_loss: 0.0044\n",
      "Epoch 6/30\n",
      "\u001b[1m46/46\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - loss: 0.0059 - val_loss: 0.0039\n",
      "Epoch 7/30\n",
      "\u001b[1m46/46\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - loss: 0.0040 - val_loss: 0.0037\n",
      "Epoch 8/30\n",
      "\u001b[1m46/46\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - loss: 0.0044 - val_loss: 0.0038\n",
      "Epoch 9/30\n",
      "\u001b[1m46/46\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - loss: 0.0033 - val_loss: 0.0032\n",
      "Epoch 10/30\n",
      "\u001b[1m46/46\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - loss: 0.0038 - val_loss: 0.0025\n",
      "Epoch 11/30\n",
      "\u001b[1m46/46\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - loss: 0.0031 - val_loss: 0.0040\n",
      "Epoch 12/30\n",
      "\u001b[1m46/46\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 0.0034 - val_loss: 0.0024\n",
      "Epoch 13/30\n",
      "\u001b[1m46/46\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - loss: 0.0027 - val_loss: 0.0025\n",
      "Epoch 14/30\n",
      "\u001b[1m46/46\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - loss: 0.0029 - val_loss: 0.0023\n",
      "Epoch 15/30\n",
      "\u001b[1m46/46\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 0.0026 - val_loss: 0.0021\n",
      "Epoch 16/30\n",
      "\u001b[1m46/46\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - loss: 0.0034 - val_loss: 0.0024\n",
      "Epoch 17/30\n",
      "\u001b[1m46/46\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - loss: 0.0032 - val_loss: 0.0026\n",
      "Epoch 18/30\n",
      "\u001b[1m46/46\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - loss: 0.0026 - val_loss: 0.0025\n",
      "Epoch 19/30\n",
      "\u001b[1m46/46\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - loss: 0.0036 - val_loss: 0.0023\n",
      "Epoch 20/30\n",
      "\u001b[1m46/46\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - loss: 0.0022 - val_loss: 0.0019\n",
      "Epoch 21/30\n",
      "\u001b[1m46/46\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - loss: 0.0020 - val_loss: 0.0018\n",
      "Epoch 22/30\n",
      "\u001b[1m46/46\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - loss: 0.0030 - val_loss: 0.0019\n",
      "Epoch 23/30\n",
      "\u001b[1m46/46\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 0.0024 - val_loss: 0.0017\n",
      "Epoch 24/30\n",
      "\u001b[1m46/46\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 0.0021 - val_loss: 0.0017\n",
      "Epoch 25/30\n",
      "\u001b[1m46/46\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - loss: 0.0017 - val_loss: 0.0018\n",
      "Epoch 26/30\n",
      "\u001b[1m46/46\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - loss: 0.0020 - val_loss: 0.0038\n",
      "Epoch 27/30\n",
      "\u001b[1m46/46\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - loss: 0.0026 - val_loss: 0.0021\n",
      "Epoch 28/30\n",
      "\u001b[1m46/46\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - loss: 0.0020 - val_loss: 0.0019\n",
      "Epoch 29/30\n",
      "\u001b[1m46/46\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - loss: 0.0020 - val_loss: 0.0017\n",
      "Epoch 30/30\n",
      "\u001b[1m46/46\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 0.0021 - val_loss: 0.0018\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:The `save_format` argument is deprecated in Keras 3. We recommend removing this argument as it can be inferred from the file path. Received: save_format=keras\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Finished: Myanmar | MAE: 0.10 | RMSE: 0.14 | R²: 0.78\n",
      "Epoch 1/30\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/dejauhnaebeadle/School/MachineLearning/machine-learning-project/code/rain-prediction/.venv/lib/python3.11/site-packages/keras/src/layers/rnn/rnn.py:200: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
      "  super().__init__(**kwargs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m46/46\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 11ms/step - loss: 0.0428 - val_loss: 0.0131\n",
      "Epoch 2/30\n",
      "\u001b[1m46/46\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 0.0064 - val_loss: 0.0105\n",
      "Epoch 3/30\n",
      "\u001b[1m46/46\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - loss: 0.0053 - val_loss: 0.0106\n",
      "Epoch 4/30\n",
      "\u001b[1m46/46\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - loss: 0.0056 - val_loss: 0.0085\n",
      "Epoch 5/30\n",
      "\u001b[1m46/46\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - loss: 0.0045 - val_loss: 0.0098\n",
      "Epoch 6/30\n",
      "\u001b[1m46/46\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 0.0043 - val_loss: 0.0065\n",
      "Epoch 7/30\n",
      "\u001b[1m46/46\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - loss: 0.0038 - val_loss: 0.0073\n",
      "Epoch 8/30\n",
      "\u001b[1m46/46\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 0.0032 - val_loss: 0.0055\n",
      "Epoch 9/30\n",
      "\u001b[1m46/46\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 0.0031 - val_loss: 0.0056\n",
      "Epoch 10/30\n",
      "\u001b[1m46/46\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 0.0026 - val_loss: 0.0052\n",
      "Epoch 11/30\n",
      "\u001b[1m46/46\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 0.0031 - val_loss: 0.0052\n",
      "Epoch 12/30\n",
      "\u001b[1m46/46\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 0.0030 - val_loss: 0.0059\n",
      "Epoch 13/30\n",
      "\u001b[1m46/46\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 0.0027 - val_loss: 0.0051\n",
      "Epoch 14/30\n",
      "\u001b[1m46/46\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - loss: 0.0025 - val_loss: 0.0050\n",
      "Epoch 15/30\n",
      "\u001b[1m46/46\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 0.0023 - val_loss: 0.0048\n",
      "Epoch 16/30\n",
      "\u001b[1m46/46\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - loss: 0.0026 - val_loss: 0.0045\n",
      "Epoch 17/30\n",
      "\u001b[1m46/46\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 0.0030 - val_loss: 0.0045\n",
      "Epoch 18/30\n",
      "\u001b[1m46/46\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 0.0025 - val_loss: 0.0045\n",
      "Epoch 19/30\n",
      "\u001b[1m46/46\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 0.0024 - val_loss: 0.0044\n",
      "Epoch 20/30\n",
      "\u001b[1m46/46\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 0.0022 - val_loss: 0.0047\n",
      "Epoch 21/30\n",
      "\u001b[1m46/46\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 0.0020 - val_loss: 0.0041\n",
      "Epoch 22/30\n",
      "\u001b[1m46/46\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 0.0021 - val_loss: 0.0044\n",
      "Epoch 23/30\n",
      "\u001b[1m46/46\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - loss: 0.0019 - val_loss: 0.0047\n",
      "Epoch 24/30\n",
      "\u001b[1m46/46\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 0.0022 - val_loss: 0.0039\n",
      "Epoch 25/30\n",
      "\u001b[1m46/46\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - loss: 0.0017 - val_loss: 0.0043\n",
      "Epoch 26/30\n",
      "\u001b[1m46/46\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - loss: 0.0015 - val_loss: 0.0048\n",
      "Epoch 27/30\n",
      "\u001b[1m46/46\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 0.0023 - val_loss: 0.0039\n",
      "Epoch 28/30\n",
      "\u001b[1m46/46\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - loss: 0.0016 - val_loss: 0.0039\n",
      "Epoch 29/30\n",
      "\u001b[1m46/46\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - loss: 0.0024 - val_loss: 0.0039\n",
      "Epoch 30/30\n",
      "\u001b[1m46/46\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 0.0013 - val_loss: 0.0038\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:The `save_format` argument is deprecated in Keras 3. We recommend removing this argument as it can be inferred from the file path. Received: save_format=keras\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Finished: Namibia | MAE: 0.14 | RMSE: 0.24 | R²: 0.88\n",
      "Epoch 1/30\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/dejauhnaebeadle/School/MachineLearning/machine-learning-project/code/rain-prediction/.venv/lib/python3.11/site-packages/keras/src/layers/rnn/rnn.py:200: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
      "  super().__init__(**kwargs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m46/46\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 10ms/step - loss: 0.0783 - val_loss: 0.0038\n",
      "Epoch 2/30\n",
      "\u001b[1m46/46\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 0.0098 - val_loss: 0.0036\n",
      "Epoch 3/30\n",
      "\u001b[1m46/46\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - loss: 0.0100 - val_loss: 0.0030\n",
      "Epoch 4/30\n",
      "\u001b[1m46/46\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - loss: 0.0074 - val_loss: 0.0021\n",
      "Epoch 5/30\n",
      "\u001b[1m46/46\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - loss: 0.0076 - val_loss: 0.0027\n",
      "Epoch 6/30\n",
      "\u001b[1m46/46\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - loss: 0.0055 - val_loss: 0.0021\n",
      "Epoch 7/30\n",
      "\u001b[1m46/46\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - loss: 0.0068 - val_loss: 0.0017\n",
      "Epoch 8/30\n",
      "\u001b[1m46/46\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - loss: 0.0056 - val_loss: 0.0024\n",
      "Epoch 9/30\n",
      "\u001b[1m46/46\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 9ms/step - loss: 0.0049 - val_loss: 0.0013\n",
      "Epoch 10/30\n",
      "\u001b[1m46/46\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - loss: 0.0056 - val_loss: 0.0020\n",
      "Epoch 11/30\n",
      "\u001b[1m46/46\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - loss: 0.0042 - val_loss: 0.0021\n",
      "Epoch 12/30\n",
      "\u001b[1m46/46\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - loss: 0.0044 - val_loss: 0.0024\n",
      "Epoch 13/30\n",
      "\u001b[1m46/46\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - loss: 0.0049 - val_loss: 0.0017\n",
      "Epoch 14/30\n",
      "\u001b[1m46/46\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - loss: 0.0044 - val_loss: 0.0012\n",
      "Epoch 15/30\n",
      "\u001b[1m46/46\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - loss: 0.0039 - val_loss: 0.0013\n",
      "Epoch 16/30\n",
      "\u001b[1m46/46\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 0.0034 - val_loss: 0.0016\n",
      "Epoch 17/30\n",
      "\u001b[1m46/46\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - loss: 0.0038 - val_loss: 0.0013\n",
      "Epoch 18/30\n",
      "\u001b[1m46/46\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - loss: 0.0042 - val_loss: 9.4071e-04\n",
      "Epoch 19/30\n",
      "\u001b[1m46/46\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - loss: 0.0042 - val_loss: 0.0016\n",
      "Epoch 20/30\n",
      "\u001b[1m46/46\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - loss: 0.0033 - val_loss: 8.8679e-04\n",
      "Epoch 21/30\n",
      "\u001b[1m46/46\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - loss: 0.0048 - val_loss: 0.0012\n",
      "Epoch 22/30\n",
      "\u001b[1m46/46\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 0.0033 - val_loss: 0.0011\n",
      "Epoch 23/30\n",
      "\u001b[1m46/46\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 0.0031 - val_loss: 8.5078e-04\n",
      "Epoch 24/30\n",
      "\u001b[1m46/46\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - loss: 0.0027 - val_loss: 0.0010\n",
      "Epoch 25/30\n",
      "\u001b[1m46/46\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 0.0035 - val_loss: 9.0607e-04\n",
      "Epoch 26/30\n",
      "\u001b[1m46/46\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 0.0040 - val_loss: 0.0017\n",
      "Epoch 27/30\n",
      "\u001b[1m46/46\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 0.0035 - val_loss: 8.4787e-04\n",
      "Epoch 28/30\n",
      "\u001b[1m46/46\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 0.0028 - val_loss: 7.6250e-04\n",
      "Epoch 29/30\n",
      "\u001b[1m46/46\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 0.0038 - val_loss: 0.0015\n",
      "Epoch 30/30\n",
      "\u001b[1m46/46\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - loss: 0.0036 - val_loss: 0.0011\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:The `save_format` argument is deprecated in Keras 3. We recommend removing this argument as it can be inferred from the file path. Received: save_format=keras\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Finished: Nepal | MAE: 0.10 | RMSE: 0.14 | R²: 0.86\n",
      "Epoch 1/30\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/dejauhnaebeadle/School/MachineLearning/machine-learning-project/code/rain-prediction/.venv/lib/python3.11/site-packages/keras/src/layers/rnn/rnn.py:200: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
      "  super().__init__(**kwargs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m46/46\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 31ms/step - loss: 0.0722 - val_loss: 0.0057\n",
      "Epoch 2/30\n",
      "\u001b[1m46/46\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 10ms/step - loss: 0.0128 - val_loss: 0.0083\n",
      "Epoch 3/30\n",
      "\u001b[1m46/46\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 13ms/step - loss: 0.0107 - val_loss: 0.0041\n",
      "Epoch 4/30\n",
      "\u001b[1m46/46\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 17ms/step - loss: 0.0087 - val_loss: 0.0028\n",
      "Epoch 5/30\n",
      "\u001b[1m46/46\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 11ms/step - loss: 0.0076 - val_loss: 0.0031\n",
      "Epoch 6/30\n",
      "\u001b[1m46/46\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - loss: 0.0076 - val_loss: 0.0021\n",
      "Epoch 7/30\n",
      "\u001b[1m46/46\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - loss: 0.0079 - val_loss: 0.0025\n",
      "Epoch 8/30\n",
      "\u001b[1m46/46\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - loss: 0.0073 - val_loss: 0.0026\n",
      "Epoch 9/30\n",
      "\u001b[1m46/46\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - loss: 0.0063 - val_loss: 0.0028\n",
      "Epoch 10/30\n",
      "\u001b[1m46/46\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - loss: 0.0059 - val_loss: 0.0062\n",
      "Epoch 11/30\n",
      "\u001b[1m46/46\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - loss: 0.0067 - val_loss: 0.0016\n",
      "Epoch 12/30\n",
      "\u001b[1m46/46\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - loss: 0.0063 - val_loss: 0.0020\n",
      "Epoch 13/30\n",
      "\u001b[1m46/46\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - loss: 0.0045 - val_loss: 0.0013\n",
      "Epoch 14/30\n",
      "\u001b[1m46/46\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - loss: 0.0045 - val_loss: 0.0018\n",
      "Epoch 15/30\n",
      "\u001b[1m46/46\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - loss: 0.0056 - val_loss: 0.0016\n",
      "Epoch 16/30\n",
      "\u001b[1m46/46\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - loss: 0.0052 - val_loss: 0.0013\n",
      "Epoch 17/30\n",
      "\u001b[1m46/46\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - loss: 0.0053 - val_loss: 0.0012\n",
      "Epoch 18/30\n",
      "\u001b[1m46/46\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - loss: 0.0043 - val_loss: 0.0026\n",
      "Epoch 19/30\n",
      "\u001b[1m46/46\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - loss: 0.0059 - val_loss: 0.0015\n",
      "Epoch 20/30\n",
      "\u001b[1m46/46\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - loss: 0.0046 - val_loss: 0.0019\n",
      "Epoch 21/30\n",
      "\u001b[1m46/46\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - loss: 0.0055 - val_loss: 0.0010\n",
      "Epoch 22/30\n",
      "\u001b[1m46/46\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - loss: 0.0045 - val_loss: 0.0041\n",
      "Epoch 23/30\n",
      "\u001b[1m46/46\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - loss: 0.0051 - val_loss: 0.0012\n",
      "Epoch 24/30\n",
      "\u001b[1m46/46\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - loss: 0.0043 - val_loss: 0.0013\n",
      "Epoch 25/30\n",
      "\u001b[1m46/46\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - loss: 0.0039 - val_loss: 0.0010\n",
      "Epoch 26/30\n",
      "\u001b[1m46/46\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - loss: 0.0061 - val_loss: 0.0015\n",
      "Epoch 27/30\n",
      "\u001b[1m46/46\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - loss: 0.0047 - val_loss: 0.0011\n",
      "Epoch 28/30\n",
      "\u001b[1m46/46\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - loss: 0.0041 - val_loss: 0.0018\n",
      "Epoch 29/30\n",
      "\u001b[1m46/46\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - loss: 0.0045 - val_loss: 0.0011\n",
      "Epoch 30/30\n",
      "\u001b[1m46/46\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - loss: 0.0057 - val_loss: 9.8216e-04\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:The `save_format` argument is deprecated in Keras 3. We recommend removing this argument as it can be inferred from the file path. Received: save_format=keras\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Finished: Netherlands | MAE: 0.09 | RMSE: 0.26 | R²: 0.87\n",
      "Epoch 1/30\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/dejauhnaebeadle/School/MachineLearning/machine-learning-project/code/rain-prediction/.venv/lib/python3.11/site-packages/keras/src/layers/rnn/rnn.py:200: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
      "  super().__init__(**kwargs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m46/46\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 13ms/step - loss: 0.0414 - val_loss: 0.0035\n",
      "Epoch 2/30\n",
      "\u001b[1m46/46\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - loss: 0.0081 - val_loss: 0.0028\n",
      "Epoch 3/30\n",
      "\u001b[1m46/46\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 0.0085 - val_loss: 0.0035\n",
      "Epoch 4/30\n",
      "\u001b[1m46/46\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 0.0080 - val_loss: 0.0028\n",
      "Epoch 5/30\n",
      "\u001b[1m46/46\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 0.0059 - val_loss: 0.0032\n",
      "Epoch 6/30\n",
      "\u001b[1m46/46\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - loss: 0.0070 - val_loss: 0.0020\n",
      "Epoch 7/30\n",
      "\u001b[1m46/46\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - loss: 0.0062 - val_loss: 0.0016\n",
      "Epoch 8/30\n",
      "\u001b[1m46/46\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - loss: 0.0053 - val_loss: 0.0015\n",
      "Epoch 9/30\n",
      "\u001b[1m46/46\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - loss: 0.0045 - val_loss: 0.0016\n",
      "Epoch 10/30\n",
      "\u001b[1m46/46\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - loss: 0.0041 - val_loss: 0.0015\n",
      "Epoch 11/30\n",
      "\u001b[1m46/46\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - loss: 0.0048 - val_loss: 0.0013\n",
      "Epoch 12/30\n",
      "\u001b[1m46/46\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - loss: 0.0043 - val_loss: 0.0019\n",
      "Epoch 13/30\n",
      "\u001b[1m46/46\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - loss: 0.0036 - val_loss: 0.0017\n",
      "Epoch 14/30\n",
      "\u001b[1m46/46\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - loss: 0.0039 - val_loss: 0.0025\n",
      "Epoch 15/30\n",
      "\u001b[1m46/46\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 0.0035 - val_loss: 0.0024\n",
      "Epoch 16/30\n",
      "\u001b[1m46/46\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 0.0037 - val_loss: 0.0011\n",
      "Epoch 17/30\n",
      "\u001b[1m46/46\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 0.0031 - val_loss: 0.0019\n",
      "Epoch 18/30\n",
      "\u001b[1m46/46\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 0.0038 - val_loss: 0.0016\n",
      "Epoch 19/30\n",
      "\u001b[1m46/46\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 0.0044 - val_loss: 0.0011\n",
      "Epoch 20/30\n",
      "\u001b[1m46/46\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 0.0029 - val_loss: 0.0035\n",
      "Epoch 21/30\n",
      "\u001b[1m46/46\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 0.0032 - val_loss: 0.0022\n",
      "Epoch 22/30\n",
      "\u001b[1m46/46\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 0.0029 - val_loss: 0.0016\n",
      "Epoch 23/30\n",
      "\u001b[1m46/46\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 0.0033 - val_loss: 9.4204e-04\n",
      "Epoch 24/30\n",
      "\u001b[1m46/46\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 0.0026 - val_loss: 0.0014\n",
      "Epoch 25/30\n",
      "\u001b[1m46/46\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 0.0044 - val_loss: 9.5570e-04\n",
      "Epoch 26/30\n",
      "\u001b[1m46/46\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 0.0034 - val_loss: 9.8841e-04\n",
      "Epoch 27/30\n",
      "\u001b[1m46/46\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 0.0028 - val_loss: 9.5569e-04\n",
      "Epoch 28/30\n",
      "\u001b[1m46/46\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 0.0025 - val_loss: 0.0013\n",
      "Epoch 29/30\n",
      "\u001b[1m46/46\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - loss: 0.0026 - val_loss: 0.0018\n",
      "Epoch 30/30\n",
      "\u001b[1m46/46\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 0.0032 - val_loss: 0.0011\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:The `save_format` argument is deprecated in Keras 3. We recommend removing this argument as it can be inferred from the file path. Received: save_format=keras\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Finished: New Caledonia | MAE: 0.08 | RMSE: 0.15 | R²: 0.80\n",
      "Epoch 1/30\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/dejauhnaebeadle/School/MachineLearning/machine-learning-project/code/rain-prediction/.venv/lib/python3.11/site-packages/keras/src/layers/rnn/rnn.py:200: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
      "  super().__init__(**kwargs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m46/46\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 12ms/step - loss: 0.0887 - val_loss: 0.0128\n",
      "Epoch 2/30\n",
      "\u001b[1m46/46\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - loss: 0.0089 - val_loss: 0.0125\n",
      "Epoch 3/30\n",
      "\u001b[1m46/46\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - loss: 0.0085 - val_loss: 0.0117\n",
      "Epoch 4/30\n",
      "\u001b[1m46/46\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - loss: 0.0079 - val_loss: 0.0104\n",
      "Epoch 5/30\n",
      "\u001b[1m46/46\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - loss: 0.0063 - val_loss: 0.0095\n",
      "Epoch 6/30\n",
      "\u001b[1m46/46\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - loss: 0.0049 - val_loss: 0.0080\n",
      "Epoch 7/30\n",
      "\u001b[1m46/46\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - loss: 0.0047 - val_loss: 0.0089\n",
      "Epoch 8/30\n",
      "\u001b[1m46/46\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - loss: 0.0055 - val_loss: 0.0073\n",
      "Epoch 9/30\n",
      "\u001b[1m46/46\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - loss: 0.0041 - val_loss: 0.0068\n",
      "Epoch 10/30\n",
      "\u001b[1m46/46\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - loss: 0.0051 - val_loss: 0.0072\n",
      "Epoch 11/30\n",
      "\u001b[1m46/46\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 0.0040 - val_loss: 0.0075\n",
      "Epoch 12/30\n",
      "\u001b[1m46/46\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 0.0043 - val_loss: 0.0064\n",
      "Epoch 13/30\n",
      "\u001b[1m46/46\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 0.0035 - val_loss: 0.0070\n",
      "Epoch 14/30\n",
      "\u001b[1m46/46\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 0.0043 - val_loss: 0.0068\n",
      "Epoch 15/30\n",
      "\u001b[1m46/46\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 0.0038 - val_loss: 0.0057\n",
      "Epoch 16/30\n",
      "\u001b[1m46/46\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 0.0031 - val_loss: 0.0056\n",
      "Epoch 17/30\n",
      "\u001b[1m46/46\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 0.0037 - val_loss: 0.0056\n",
      "Epoch 18/30\n",
      "\u001b[1m46/46\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 0.0034 - val_loss: 0.0055\n",
      "Epoch 19/30\n",
      "\u001b[1m46/46\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - loss: 0.0042 - val_loss: 0.0052\n",
      "Epoch 20/30\n",
      "\u001b[1m46/46\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 0.0044 - val_loss: 0.0051\n",
      "Epoch 21/30\n",
      "\u001b[1m46/46\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 0.0033 - val_loss: 0.0050\n",
      "Epoch 22/30\n",
      "\u001b[1m46/46\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 0.0025 - val_loss: 0.0049\n",
      "Epoch 23/30\n",
      "\u001b[1m46/46\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 0.0039 - val_loss: 0.0050\n",
      "Epoch 24/30\n",
      "\u001b[1m46/46\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 0.0040 - val_loss: 0.0047\n",
      "Epoch 25/30\n",
      "\u001b[1m46/46\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 0.0027 - val_loss: 0.0046\n",
      "Epoch 26/30\n",
      "\u001b[1m46/46\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 0.0030 - val_loss: 0.0045\n",
      "Epoch 27/30\n",
      "\u001b[1m46/46\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 0.0032 - val_loss: 0.0044\n",
      "Epoch 28/30\n",
      "\u001b[1m46/46\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 0.0032 - val_loss: 0.0046\n",
      "Epoch 29/30\n",
      "\u001b[1m46/46\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 0.0027 - val_loss: 0.0043\n",
      "Epoch 30/30\n",
      "\u001b[1m46/46\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - loss: 0.0024 - val_loss: 0.0043\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:The `save_format` argument is deprecated in Keras 3. We recommend removing this argument as it can be inferred from the file path. Received: save_format=keras\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Finished: New Zealand | MAE: 0.09 | RMSE: 0.15 | R²: 0.87\n",
      "Epoch 1/30\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/dejauhnaebeadle/School/MachineLearning/machine-learning-project/code/rain-prediction/.venv/lib/python3.11/site-packages/keras/src/layers/rnn/rnn.py:200: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
      "  super().__init__(**kwargs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m46/46\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 14ms/step - loss: 0.0590 - val_loss: 0.0024\n",
      "Epoch 2/30\n",
      "\u001b[1m46/46\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - loss: 0.0080 - val_loss: 0.0058\n",
      "Epoch 3/30\n",
      "\u001b[1m46/46\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - loss: 0.0071 - val_loss: 0.0049\n",
      "Epoch 4/30\n",
      "\u001b[1m46/46\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - loss: 0.0049 - val_loss: 0.0018\n",
      "Epoch 5/30\n",
      "\u001b[1m46/46\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 0.0049 - val_loss: 0.0015\n",
      "Epoch 6/30\n",
      "\u001b[1m46/46\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - loss: 0.0053 - val_loss: 0.0020\n",
      "Epoch 7/30\n",
      "\u001b[1m46/46\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - loss: 0.0040 - val_loss: 0.0036\n",
      "Epoch 8/30\n",
      "\u001b[1m46/46\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - loss: 0.0033 - val_loss: 0.0030\n",
      "Epoch 9/30\n",
      "\u001b[1m46/46\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - loss: 0.0036 - val_loss: 0.0011\n",
      "Epoch 10/30\n",
      "\u001b[1m46/46\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - loss: 0.0035 - val_loss: 0.0031\n",
      "Epoch 11/30\n",
      "\u001b[1m46/46\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - loss: 0.0029 - val_loss: 0.0012\n",
      "Epoch 12/30\n",
      "\u001b[1m46/46\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - loss: 0.0040 - val_loss: 0.0011\n",
      "Epoch 13/30\n",
      "\u001b[1m46/46\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - loss: 0.0034 - val_loss: 0.0011\n",
      "Epoch 14/30\n",
      "\u001b[1m46/46\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - loss: 0.0024 - val_loss: 0.0011\n",
      "Epoch 15/30\n",
      "\u001b[1m46/46\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - loss: 0.0030 - val_loss: 0.0040\n",
      "Epoch 16/30\n",
      "\u001b[1m46/46\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - loss: 0.0027 - val_loss: 0.0010\n",
      "Epoch 17/30\n",
      "\u001b[1m46/46\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - loss: 0.0026 - val_loss: 0.0011\n",
      "Epoch 18/30\n",
      "\u001b[1m46/46\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - loss: 0.0029 - val_loss: 0.0016\n",
      "Epoch 19/30\n",
      "\u001b[1m46/46\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - loss: 0.0019 - val_loss: 0.0014\n",
      "Epoch 20/30\n",
      "\u001b[1m46/46\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - loss: 0.0025 - val_loss: 0.0012\n",
      "Epoch 21/30\n",
      "\u001b[1m46/46\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - loss: 0.0023 - val_loss: 0.0014\n",
      "Epoch 22/30\n",
      "\u001b[1m46/46\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - loss: 0.0023 - val_loss: 0.0027\n",
      "Epoch 23/30\n",
      "\u001b[1m46/46\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - loss: 0.0023 - val_loss: 0.0027\n",
      "Epoch 24/30\n",
      "\u001b[1m46/46\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - loss: 0.0021 - val_loss: 8.8319e-04\n",
      "Epoch 25/30\n",
      "\u001b[1m46/46\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - loss: 0.0022 - val_loss: 0.0014\n",
      "Epoch 26/30\n",
      "\u001b[1m46/46\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - loss: 0.0022 - val_loss: 0.0015\n",
      "Epoch 27/30\n",
      "\u001b[1m46/46\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - loss: 0.0020 - val_loss: 0.0020\n",
      "Epoch 28/30\n",
      "\u001b[1m46/46\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - loss: 0.0023 - val_loss: 7.5730e-04\n",
      "Epoch 29/30\n",
      "\u001b[1m46/46\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - loss: 0.0028 - val_loss: 9.4046e-04\n",
      "Epoch 30/30\n",
      "\u001b[1m46/46\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - loss: 0.0020 - val_loss: 0.0014\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:The `save_format` argument is deprecated in Keras 3. We recommend removing this argument as it can be inferred from the file path. Received: save_format=keras\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Finished: Nicaragua | MAE: 0.13 | RMSE: 0.16 | R²: 0.77\n",
      "Epoch 1/30\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/dejauhnaebeadle/School/MachineLearning/machine-learning-project/code/rain-prediction/.venv/lib/python3.11/site-packages/keras/src/layers/rnn/rnn.py:200: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
      "  super().__init__(**kwargs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m46/46\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 13ms/step - loss: 0.1141 - val_loss: 0.0082\n",
      "Epoch 2/30\n",
      "\u001b[1m46/46\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - loss: 0.0088 - val_loss: 0.0016\n",
      "Epoch 3/30\n",
      "\u001b[1m46/46\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - loss: 0.0075 - val_loss: 0.0025\n",
      "Epoch 4/30\n",
      "\u001b[1m46/46\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - loss: 0.0065 - val_loss: 0.0016\n",
      "Epoch 5/30\n",
      "\u001b[1m46/46\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - loss: 0.0070 - val_loss: 0.0013\n",
      "Epoch 6/30\n",
      "\u001b[1m46/46\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - loss: 0.0065 - val_loss: 0.0016\n",
      "Epoch 7/30\n",
      "\u001b[1m46/46\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - loss: 0.0056 - val_loss: 0.0015\n",
      "Epoch 8/30\n",
      "\u001b[1m46/46\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - loss: 0.0055 - val_loss: 9.0365e-04\n",
      "Epoch 9/30\n",
      "\u001b[1m46/46\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - loss: 0.0052 - val_loss: 9.3167e-04\n",
      "Epoch 10/30\n",
      "\u001b[1m46/46\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - loss: 0.0041 - val_loss: 0.0020\n",
      "Epoch 11/30\n",
      "\u001b[1m46/46\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 0.0037 - val_loss: 0.0026\n",
      "Epoch 12/30\n",
      "\u001b[1m46/46\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 0.0041 - val_loss: 0.0037\n",
      "Epoch 13/30\n",
      "\u001b[1m46/46\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - loss: 0.0030 - val_loss: 0.0012\n",
      "Epoch 14/30\n",
      "\u001b[1m46/46\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - loss: 0.0043 - val_loss: 0.0031\n",
      "Epoch 15/30\n",
      "\u001b[1m46/46\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - loss: 0.0039 - val_loss: 7.7600e-04\n",
      "Epoch 16/30\n",
      "\u001b[1m46/46\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - loss: 0.0032 - val_loss: 5.7910e-04\n",
      "Epoch 17/30\n",
      "\u001b[1m46/46\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - loss: 0.0037 - val_loss: 7.7278e-04\n",
      "Epoch 18/30\n",
      "\u001b[1m46/46\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - loss: 0.0033 - val_loss: 6.3158e-04\n",
      "Epoch 19/30\n",
      "\u001b[1m46/46\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - loss: 0.0035 - val_loss: 5.3568e-04\n",
      "Epoch 20/30\n",
      "\u001b[1m46/46\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - loss: 0.0029 - val_loss: 6.8141e-04\n",
      "Epoch 21/30\n",
      "\u001b[1m46/46\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - loss: 0.0027 - val_loss: 5.7106e-04\n",
      "Epoch 22/30\n",
      "\u001b[1m46/46\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - loss: 0.0029 - val_loss: 6.3878e-04\n",
      "Epoch 23/30\n",
      "\u001b[1m46/46\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - loss: 0.0029 - val_loss: 4.7430e-04\n",
      "Epoch 24/30\n",
      "\u001b[1m46/46\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - loss: 0.0028 - val_loss: 9.0743e-04\n",
      "Epoch 25/30\n",
      "\u001b[1m46/46\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - loss: 0.0025 - val_loss: 8.8078e-04\n",
      "Epoch 26/30\n",
      "\u001b[1m46/46\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - loss: 0.0028 - val_loss: 4.3433e-04\n",
      "Epoch 27/30\n",
      "\u001b[1m46/46\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - loss: 0.0021 - val_loss: 0.0013\n",
      "Epoch 28/30\n",
      "\u001b[1m46/46\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - loss: 0.0025 - val_loss: 4.9095e-04\n",
      "Epoch 29/30\n",
      "\u001b[1m46/46\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - loss: 0.0029 - val_loss: 0.0016\n",
      "Epoch 30/30\n",
      "\u001b[1m46/46\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - loss: 0.0018 - val_loss: 0.0015\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:The `save_format` argument is deprecated in Keras 3. We recommend removing this argument as it can be inferred from the file path. Received: save_format=keras\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Finished: Niger | MAE: 0.21 | RMSE: 0.26 | R²: 0.57\n",
      "Epoch 1/30\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/dejauhnaebeadle/School/MachineLearning/machine-learning-project/code/rain-prediction/.venv/lib/python3.11/site-packages/keras/src/layers/rnn/rnn.py:200: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
      "  super().__init__(**kwargs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m46/46\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 11ms/step - loss: 0.0887 - val_loss: 0.0056\n",
      "Epoch 2/30\n",
      "\u001b[1m46/46\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - loss: 0.0113 - val_loss: 0.0039\n",
      "Epoch 3/30\n",
      "\u001b[1m46/46\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 0.0094 - val_loss: 0.0065\n",
      "Epoch 4/30\n",
      "\u001b[1m46/46\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - loss: 0.0082 - val_loss: 0.0032\n",
      "Epoch 5/30\n",
      "\u001b[1m46/46\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 0.0071 - val_loss: 0.0047\n",
      "Epoch 6/30\n",
      "\u001b[1m46/46\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - loss: 0.0067 - val_loss: 0.0021\n",
      "Epoch 7/30\n",
      "\u001b[1m46/46\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 0.0051 - val_loss: 0.0042\n",
      "Epoch 8/30\n",
      "\u001b[1m46/46\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 0.0053 - val_loss: 0.0031\n",
      "Epoch 9/30\n",
      "\u001b[1m46/46\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - loss: 0.0051 - val_loss: 0.0032\n",
      "Epoch 10/30\n",
      "\u001b[1m46/46\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - loss: 0.0058 - val_loss: 0.0021\n",
      "Epoch 11/30\n",
      "\u001b[1m46/46\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - loss: 0.0049 - val_loss: 0.0048\n",
      "Epoch 12/30\n",
      "\u001b[1m46/46\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - loss: 0.0049 - val_loss: 0.0017\n",
      "Epoch 13/30\n",
      "\u001b[1m46/46\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - loss: 0.0055 - val_loss: 0.0023\n",
      "Epoch 14/30\n",
      "\u001b[1m46/46\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 0.0036 - val_loss: 0.0016\n",
      "Epoch 15/30\n",
      "\u001b[1m46/46\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 0.0035 - val_loss: 0.0042\n",
      "Epoch 16/30\n",
      "\u001b[1m46/46\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - loss: 0.0032 - val_loss: 0.0024\n",
      "Epoch 17/30\n",
      "\u001b[1m46/46\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - loss: 0.0039 - val_loss: 0.0015\n",
      "Epoch 18/30\n",
      "\u001b[1m46/46\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - loss: 0.0040 - val_loss: 0.0013\n",
      "Epoch 19/30\n",
      "\u001b[1m46/46\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - loss: 0.0038 - val_loss: 0.0031\n",
      "Epoch 20/30\n",
      "\u001b[1m46/46\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - loss: 0.0032 - val_loss: 0.0017\n",
      "Epoch 21/30\n",
      "\u001b[1m46/46\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - loss: 0.0039 - val_loss: 0.0025\n",
      "Epoch 22/30\n",
      "\u001b[1m46/46\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 0.0035 - val_loss: 0.0040\n",
      "Epoch 23/30\n",
      "\u001b[1m46/46\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - loss: 0.0042 - val_loss: 0.0015\n",
      "Epoch 24/30\n",
      "\u001b[1m46/46\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - loss: 0.0038 - val_loss: 0.0012\n",
      "Epoch 25/30\n",
      "\u001b[1m46/46\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - loss: 0.0039 - val_loss: 0.0013\n",
      "Epoch 26/30\n",
      "\u001b[1m46/46\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - loss: 0.0033 - val_loss: 0.0026\n",
      "Epoch 27/30\n",
      "\u001b[1m46/46\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - loss: 0.0023 - val_loss: 0.0048\n",
      "Epoch 28/30\n",
      "\u001b[1m46/46\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - loss: 0.0046 - val_loss: 0.0016\n",
      "Epoch 29/30\n",
      "\u001b[1m46/46\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - loss: 0.0029 - val_loss: 0.0011\n",
      "Epoch 30/30\n",
      "\u001b[1m46/46\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - loss: 0.0045 - val_loss: 0.0024\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:The `save_format` argument is deprecated in Keras 3. We recommend removing this argument as it can be inferred from the file path. Received: save_format=keras\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Finished: Nigeria | MAE: 0.11 | RMSE: 0.14 | R²: 0.69\n",
      "Epoch 1/30\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/dejauhnaebeadle/School/MachineLearning/machine-learning-project/code/rain-prediction/.venv/lib/python3.11/site-packages/keras/src/layers/rnn/rnn.py:200: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
      "  super().__init__(**kwargs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m46/46\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 14ms/step - loss: 0.0694 - val_loss: 0.0045\n",
      "Epoch 2/30\n",
      "\u001b[1m46/46\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - loss: 0.0084 - val_loss: 0.0058\n",
      "Epoch 3/30\n",
      "\u001b[1m46/46\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - loss: 0.0065 - val_loss: 0.0054\n",
      "Epoch 4/30\n",
      "\u001b[1m46/46\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - loss: 0.0068 - val_loss: 0.0040\n",
      "Epoch 5/30\n",
      "\u001b[1m46/46\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - loss: 0.0066 - val_loss: 0.0041\n",
      "Epoch 6/30\n",
      "\u001b[1m46/46\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - loss: 0.0060 - val_loss: 0.0041\n",
      "Epoch 7/30\n",
      "\u001b[1m46/46\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - loss: 0.0044 - val_loss: 0.0046\n",
      "Epoch 8/30\n",
      "\u001b[1m46/46\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - loss: 0.0038 - val_loss: 0.0042\n",
      "Epoch 9/30\n",
      "\u001b[1m46/46\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - loss: 0.0038 - val_loss: 0.0026\n",
      "Epoch 10/30\n",
      "\u001b[1m46/46\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - loss: 0.0039 - val_loss: 0.0022\n",
      "Epoch 11/30\n",
      "\u001b[1m46/46\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - loss: 0.0038 - val_loss: 0.0021\n",
      "Epoch 12/30\n",
      "\u001b[1m46/46\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - loss: 0.0044 - val_loss: 0.0021\n",
      "Epoch 13/30\n",
      "\u001b[1m46/46\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - loss: 0.0035 - val_loss: 0.0023\n",
      "Epoch 14/30\n",
      "\u001b[1m46/46\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - loss: 0.0027 - val_loss: 0.0034\n",
      "Epoch 15/30\n",
      "\u001b[1m46/46\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 0.0035 - val_loss: 0.0019\n",
      "Epoch 16/30\n",
      "\u001b[1m46/46\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 0.0036 - val_loss: 0.0020\n",
      "Epoch 17/30\n",
      "\u001b[1m46/46\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - loss: 0.0033 - val_loss: 0.0018\n",
      "Epoch 18/30\n",
      "\u001b[1m46/46\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - loss: 0.0024 - val_loss: 0.0025\n",
      "Epoch 19/30\n",
      "\u001b[1m46/46\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 0.0034 - val_loss: 0.0035\n",
      "Epoch 20/30\n",
      "\u001b[1m46/46\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - loss: 0.0026 - val_loss: 0.0017\n",
      "Epoch 21/30\n",
      "\u001b[1m46/46\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 0.0033 - val_loss: 0.0017\n",
      "Epoch 22/30\n",
      "\u001b[1m46/46\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 0.0025 - val_loss: 0.0031\n",
      "Epoch 23/30\n",
      "\u001b[1m46/46\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 0.0035 - val_loss: 0.0023\n",
      "Epoch 24/30\n",
      "\u001b[1m46/46\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 0.0027 - val_loss: 0.0015\n",
      "Epoch 25/30\n",
      "\u001b[1m46/46\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 0.0020 - val_loss: 0.0025\n",
      "Epoch 26/30\n",
      "\u001b[1m46/46\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 0.0025 - val_loss: 0.0018\n",
      "Epoch 27/30\n",
      "\u001b[1m46/46\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 0.0022 - val_loss: 0.0018\n",
      "Epoch 28/30\n",
      "\u001b[1m46/46\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 0.0026 - val_loss: 0.0016\n",
      "Epoch 29/30\n",
      "\u001b[1m46/46\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 0.0020 - val_loss: 0.0016\n",
      "Epoch 30/30\n",
      "\u001b[1m46/46\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 0.0022 - val_loss: 0.0014\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:The `save_format` argument is deprecated in Keras 3. We recommend removing this argument as it can be inferred from the file path. Received: save_format=keras\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Finished: North Korea | MAE: 0.08 | RMSE: 0.16 | R²: 0.94\n",
      "Epoch 1/30\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/dejauhnaebeadle/School/MachineLearning/machine-learning-project/code/rain-prediction/.venv/lib/python3.11/site-packages/keras/src/layers/rnn/rnn.py:200: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
      "  super().__init__(**kwargs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m46/46\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 10ms/step - loss: 0.0815 - val_loss: 0.0070\n",
      "Epoch 2/30\n",
      "\u001b[1m46/46\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 0.0078 - val_loss: 0.0067\n",
      "Epoch 3/30\n",
      "\u001b[1m46/46\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - loss: 0.0078 - val_loss: 0.0062\n",
      "Epoch 4/30\n",
      "\u001b[1m46/46\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 0.0064 - val_loss: 0.0070\n",
      "Epoch 5/30\n",
      "\u001b[1m46/46\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 0.0056 - val_loss: 0.0070\n",
      "Epoch 6/30\n",
      "\u001b[1m46/46\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 0.0047 - val_loss: 0.0044\n",
      "Epoch 7/30\n",
      "\u001b[1m46/46\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 0.0041 - val_loss: 0.0066\n",
      "Epoch 8/30\n",
      "\u001b[1m46/46\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 0.0045 - val_loss: 0.0046\n",
      "Epoch 9/30\n",
      "\u001b[1m46/46\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 0.0040 - val_loss: 0.0054\n",
      "Epoch 10/30\n",
      "\u001b[1m46/46\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 0.0041 - val_loss: 0.0059\n",
      "Epoch 11/30\n",
      "\u001b[1m46/46\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 0.0039 - val_loss: 0.0024\n",
      "Epoch 12/30\n",
      "\u001b[1m46/46\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 0.0045 - val_loss: 0.0024\n",
      "Epoch 13/30\n",
      "\u001b[1m46/46\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 0.0037 - val_loss: 0.0023\n",
      "Epoch 14/30\n",
      "\u001b[1m46/46\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 0.0046 - val_loss: 0.0026\n",
      "Epoch 15/30\n",
      "\u001b[1m46/46\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 0.0032 - val_loss: 0.0021\n",
      "Epoch 16/30\n",
      "\u001b[1m46/46\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 0.0027 - val_loss: 0.0028\n",
      "Epoch 17/30\n",
      "\u001b[1m46/46\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 0.0026 - val_loss: 0.0035\n",
      "Epoch 18/30\n",
      "\u001b[1m46/46\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 0.0038 - val_loss: 0.0025\n",
      "Epoch 19/30\n",
      "\u001b[1m46/46\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 0.0032 - val_loss: 0.0039\n",
      "Epoch 20/30\n",
      "\u001b[1m46/46\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 0.0028 - val_loss: 0.0020\n",
      "Epoch 21/30\n",
      "\u001b[1m46/46\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 0.0027 - val_loss: 0.0018\n",
      "Epoch 22/30\n",
      "\u001b[1m46/46\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - loss: 0.0023 - val_loss: 0.0020\n",
      "Epoch 23/30\n",
      "\u001b[1m46/46\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - loss: 0.0027 - val_loss: 0.0022\n",
      "Epoch 24/30\n",
      "\u001b[1m46/46\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - loss: 0.0027 - val_loss: 0.0017\n",
      "Epoch 25/30\n",
      "\u001b[1m46/46\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - loss: 0.0027 - val_loss: 0.0034\n",
      "Epoch 26/30\n",
      "\u001b[1m46/46\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 0.0022 - val_loss: 0.0024\n",
      "Epoch 27/30\n",
      "\u001b[1m46/46\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 0.0021 - val_loss: 0.0026\n",
      "Epoch 28/30\n",
      "\u001b[1m46/46\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - loss: 0.0032 - val_loss: 0.0016\n",
      "Epoch 29/30\n",
      "\u001b[1m46/46\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - loss: 0.0022 - val_loss: 0.0017\n",
      "Epoch 30/30\n",
      "\u001b[1m46/46\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - loss: 0.0031 - val_loss: 0.0020\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:The `save_format` argument is deprecated in Keras 3. We recommend removing this argument as it can be inferred from the file path. Received: save_format=keras\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Finished: North Macedonia | MAE: 0.21 | RMSE: 0.23 | R²: 0.67\n",
      "Epoch 1/30\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/dejauhnaebeadle/School/MachineLearning/machine-learning-project/code/rain-prediction/.venv/lib/python3.11/site-packages/keras/src/layers/rnn/rnn.py:200: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
      "  super().__init__(**kwargs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m46/46\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 12ms/step - loss: 0.0944 - val_loss: 0.0042\n",
      "Epoch 2/30\n",
      "\u001b[1m46/46\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - loss: 0.0113 - val_loss: 0.0034\n",
      "Epoch 3/30\n",
      "\u001b[1m46/46\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 0.0092 - val_loss: 0.0040\n",
      "Epoch 4/30\n",
      "\u001b[1m46/46\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - loss: 0.0086 - val_loss: 0.0017\n",
      "Epoch 5/30\n",
      "\u001b[1m46/46\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - loss: 0.0067 - val_loss: 0.0079\n",
      "Epoch 6/30\n",
      "\u001b[1m46/46\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - loss: 0.0075 - val_loss: 0.0052\n",
      "Epoch 7/30\n",
      "\u001b[1m46/46\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - loss: 0.0060 - val_loss: 0.0169\n",
      "Epoch 8/30\n",
      "\u001b[1m46/46\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - loss: 0.0066 - val_loss: 0.0013\n",
      "Epoch 9/30\n",
      "\u001b[1m46/46\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - loss: 0.0060 - val_loss: 0.0026\n",
      "Epoch 10/30\n",
      "\u001b[1m46/46\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - loss: 0.0048 - val_loss: 0.0017\n",
      "Epoch 11/30\n",
      "\u001b[1m46/46\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - loss: 0.0053 - val_loss: 0.0023\n",
      "Epoch 12/30\n",
      "\u001b[1m46/46\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - loss: 0.0040 - val_loss: 0.0020\n",
      "Epoch 13/30\n",
      "\u001b[1m46/46\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - loss: 0.0051 - val_loss: 0.0034\n",
      "Epoch 14/30\n",
      "\u001b[1m46/46\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - loss: 0.0056 - val_loss: 0.0025\n",
      "Epoch 15/30\n",
      "\u001b[1m46/46\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - loss: 0.0036 - val_loss: 0.0011\n",
      "Epoch 16/30\n",
      "\u001b[1m46/46\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - loss: 0.0039 - val_loss: 0.0025\n",
      "Epoch 17/30\n",
      "\u001b[1m46/46\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - loss: 0.0044 - val_loss: 9.2331e-04\n",
      "Epoch 18/30\n",
      "\u001b[1m46/46\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - loss: 0.0036 - val_loss: 0.0015\n",
      "Epoch 19/30\n",
      "\u001b[1m46/46\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 11ms/step - loss: 0.0030 - val_loss: 0.0032\n",
      "Epoch 20/30\n",
      "\u001b[1m46/46\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - loss: 0.0038 - val_loss: 7.2397e-04\n",
      "Epoch 21/30\n",
      "\u001b[1m46/46\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - loss: 0.0039 - val_loss: 0.0012\n",
      "Epoch 22/30\n",
      "\u001b[1m46/46\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - loss: 0.0036 - val_loss: 9.6294e-04\n",
      "Epoch 23/30\n",
      "\u001b[1m46/46\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - loss: 0.0036 - val_loss: 6.1607e-04\n",
      "Epoch 24/30\n",
      "\u001b[1m46/46\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - loss: 0.0038 - val_loss: 0.0018\n",
      "Epoch 25/30\n",
      "\u001b[1m46/46\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - loss: 0.0030 - val_loss: 7.0269e-04\n",
      "Epoch 26/30\n",
      "\u001b[1m46/46\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - loss: 0.0034 - val_loss: 7.4587e-04\n",
      "Epoch 27/30\n",
      "\u001b[1m46/46\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - loss: 0.0037 - val_loss: 7.9492e-04\n",
      "Epoch 28/30\n",
      "\u001b[1m46/46\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - loss: 0.0032 - val_loss: 7.3672e-04\n",
      "Epoch 29/30\n",
      "\u001b[1m46/46\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - loss: 0.0027 - val_loss: 5.5183e-04\n",
      "Epoch 30/30\n",
      "\u001b[1m46/46\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - loss: 0.0029 - val_loss: 5.5998e-04\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:The `save_format` argument is deprecated in Keras 3. We recommend removing this argument as it can be inferred from the file path. Received: save_format=keras\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Finished: Norway | MAE: 0.10 | RMSE: 0.29 | R²: 0.83\n",
      "Epoch 1/30\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/dejauhnaebeadle/School/MachineLearning/machine-learning-project/code/rain-prediction/.venv/lib/python3.11/site-packages/keras/src/layers/rnn/rnn.py:200: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
      "  super().__init__(**kwargs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m46/46\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 19ms/step - loss: 0.0565 - val_loss: 0.0030\n",
      "Epoch 2/30\n",
      "\u001b[1m46/46\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - loss: 0.0087 - val_loss: 0.0042\n",
      "Epoch 3/30\n",
      "\u001b[1m46/46\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - loss: 0.0076 - val_loss: 0.0030\n",
      "Epoch 4/30\n",
      "\u001b[1m46/46\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - loss: 0.0063 - val_loss: 0.0028\n",
      "Epoch 5/30\n",
      "\u001b[1m46/46\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - loss: 0.0060 - val_loss: 0.0039\n",
      "Epoch 6/30\n",
      "\u001b[1m46/46\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - loss: 0.0050 - val_loss: 0.0032\n",
      "Epoch 7/30\n",
      "\u001b[1m46/46\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - loss: 0.0043 - val_loss: 0.0030\n",
      "Epoch 8/30\n",
      "\u001b[1m46/46\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - loss: 0.0039 - val_loss: 0.0029\n",
      "Epoch 9/30\n",
      "\u001b[1m46/46\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - loss: 0.0042 - val_loss: 0.0025\n",
      "Epoch 10/30\n",
      "\u001b[1m46/46\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - loss: 0.0031 - val_loss: 0.0039\n",
      "Epoch 11/30\n",
      "\u001b[1m46/46\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - loss: 0.0037 - val_loss: 0.0023\n",
      "Epoch 12/30\n",
      "\u001b[1m46/46\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - loss: 0.0037 - val_loss: 0.0029\n",
      "Epoch 13/30\n",
      "\u001b[1m46/46\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - loss: 0.0031 - val_loss: 0.0019\n",
      "Epoch 14/30\n",
      "\u001b[1m46/46\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - loss: 0.0039 - val_loss: 0.0020\n",
      "Epoch 15/30\n",
      "\u001b[1m46/46\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - loss: 0.0029 - val_loss: 0.0017\n",
      "Epoch 16/30\n",
      "\u001b[1m46/46\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - loss: 0.0027 - val_loss: 0.0019\n",
      "Epoch 17/30\n",
      "\u001b[1m46/46\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 0.0026 - val_loss: 0.0020\n",
      "Epoch 18/30\n",
      "\u001b[1m46/46\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 0.0036 - val_loss: 0.0017\n",
      "Epoch 19/30\n",
      "\u001b[1m46/46\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 0.0030 - val_loss: 0.0019\n",
      "Epoch 20/30\n",
      "\u001b[1m46/46\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - loss: 0.0028 - val_loss: 0.0015\n",
      "Epoch 21/30\n",
      "\u001b[1m46/46\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - loss: 0.0028 - val_loss: 0.0015\n",
      "Epoch 22/30\n",
      "\u001b[1m46/46\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 0.0030 - val_loss: 0.0015\n",
      "Epoch 23/30\n",
      "\u001b[1m46/46\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 0.0026 - val_loss: 0.0022\n",
      "Epoch 24/30\n",
      "\u001b[1m46/46\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - loss: 0.0024 - val_loss: 0.0019\n",
      "Epoch 25/30\n",
      "\u001b[1m46/46\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 0.0026 - val_loss: 0.0015\n",
      "Epoch 26/30\n",
      "\u001b[1m46/46\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - loss: 0.0026 - val_loss: 0.0014\n",
      "Epoch 27/30\n",
      "\u001b[1m46/46\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 0.0026 - val_loss: 0.0015\n",
      "Epoch 28/30\n",
      "\u001b[1m46/46\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 0.0023 - val_loss: 0.0014\n",
      "Epoch 29/30\n",
      "\u001b[1m46/46\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 0.0017 - val_loss: 0.0014\n",
      "Epoch 30/30\n",
      "\u001b[1m46/46\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 0.0029 - val_loss: 0.0016\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:The `save_format` argument is deprecated in Keras 3. We recommend removing this argument as it can be inferred from the file path. Received: save_format=keras\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Finished: Oman | MAE: 0.07 | RMSE: 0.12 | R²: 0.87\n",
      "Epoch 1/30\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/dejauhnaebeadle/School/MachineLearning/machine-learning-project/code/rain-prediction/.venv/lib/python3.11/site-packages/keras/src/layers/rnn/rnn.py:200: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
      "  super().__init__(**kwargs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m46/46\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 15ms/step - loss: 0.1125 - val_loss: 0.0385\n",
      "Epoch 2/30\n",
      "\u001b[1m46/46\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - loss: 0.0195 - val_loss: 0.0358\n",
      "Epoch 3/30\n",
      "\u001b[1m46/46\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - loss: 0.0158 - val_loss: 0.0221\n",
      "Epoch 4/30\n",
      "\u001b[1m46/46\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - loss: 0.0134 - val_loss: 0.0270\n",
      "Epoch 5/30\n",
      "\u001b[1m46/46\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - loss: 0.0116 - val_loss: 0.0220\n",
      "Epoch 6/30\n",
      "\u001b[1m46/46\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - loss: 0.0105 - val_loss: 0.0158\n",
      "Epoch 7/30\n",
      "\u001b[1m46/46\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 0.0110 - val_loss: 0.0305\n",
      "Epoch 8/30\n",
      "\u001b[1m46/46\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 0.0107 - val_loss: 0.0156\n",
      "Epoch 9/30\n",
      "\u001b[1m46/46\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - loss: 0.0080 - val_loss: 0.0142\n",
      "Epoch 10/30\n",
      "\u001b[1m46/46\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 0.0087 - val_loss: 0.0136\n",
      "Epoch 11/30\n",
      "\u001b[1m46/46\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - loss: 0.0071 - val_loss: 0.0131\n",
      "Epoch 12/30\n",
      "\u001b[1m46/46\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - loss: 0.0073 - val_loss: 0.0134\n",
      "Epoch 13/30\n",
      "\u001b[1m46/46\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 0.0076 - val_loss: 0.0124\n",
      "Epoch 14/30\n",
      "\u001b[1m46/46\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - loss: 0.0082 - val_loss: 0.0122\n",
      "Epoch 15/30\n",
      "\u001b[1m46/46\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - loss: 0.0073 - val_loss: 0.0115\n",
      "Epoch 16/30\n",
      "\u001b[1m46/46\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - loss: 0.0091 - val_loss: 0.0143\n",
      "Epoch 17/30\n",
      "\u001b[1m46/46\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - loss: 0.0087 - val_loss: 0.0116\n",
      "Epoch 18/30\n",
      "\u001b[1m46/46\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - loss: 0.0078 - val_loss: 0.0108\n",
      "Epoch 19/30\n",
      "\u001b[1m46/46\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 0.0061 - val_loss: 0.0111\n",
      "Epoch 20/30\n",
      "\u001b[1m46/46\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - loss: 0.0075 - val_loss: 0.0104\n",
      "Epoch 21/30\n",
      "\u001b[1m46/46\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - loss: 0.0062 - val_loss: 0.0101\n",
      "Epoch 22/30\n",
      "\u001b[1m46/46\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - loss: 0.0058 - val_loss: 0.0100\n",
      "Epoch 23/30\n",
      "\u001b[1m46/46\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - loss: 0.0064 - val_loss: 0.0110\n",
      "Epoch 24/30\n",
      "\u001b[1m46/46\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - loss: 0.0071 - val_loss: 0.0100\n",
      "Epoch 25/30\n",
      "\u001b[1m46/46\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 10ms/step - loss: 0.0065 - val_loss: 0.0095\n",
      "Epoch 26/30\n",
      "\u001b[1m46/46\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - loss: 0.0067 - val_loss: 0.0101\n",
      "Epoch 27/30\n",
      "\u001b[1m46/46\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - loss: 0.0059 - val_loss: 0.0101\n",
      "Epoch 28/30\n",
      "\u001b[1m46/46\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - loss: 0.0055 - val_loss: 0.0113\n",
      "Epoch 29/30\n",
      "\u001b[1m46/46\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - loss: 0.0055 - val_loss: 0.0092\n",
      "Epoch 30/30\n",
      "\u001b[1m46/46\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - loss: 0.0058 - val_loss: 0.0092\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:The `save_format` argument is deprecated in Keras 3. We recommend removing this argument as it can be inferred from the file path. Received: save_format=keras\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Finished: Pakistan | MAE: 0.05 | RMSE: 0.13 | R²: 0.89\n",
      "Epoch 1/30\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/dejauhnaebeadle/School/MachineLearning/machine-learning-project/code/rain-prediction/.venv/lib/python3.11/site-packages/keras/src/layers/rnn/rnn.py:200: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
      "  super().__init__(**kwargs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m46/46\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 12ms/step - loss: 0.0479 - val_loss: 0.0054\n",
      "Epoch 2/30\n",
      "\u001b[1m46/46\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - loss: 0.0104 - val_loss: 0.0038\n",
      "Epoch 3/30\n",
      "\u001b[1m46/46\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 0.0078 - val_loss: 0.0025\n",
      "Epoch 4/30\n",
      "\u001b[1m46/46\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - loss: 0.0075 - val_loss: 0.0047\n",
      "Epoch 5/30\n",
      "\u001b[1m46/46\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - loss: 0.0060 - val_loss: 0.0079\n",
      "Epoch 6/30\n",
      "\u001b[1m46/46\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 0.0054 - val_loss: 0.0028\n",
      "Epoch 7/30\n",
      "\u001b[1m46/46\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 0.0055 - val_loss: 0.0051\n",
      "Epoch 8/30\n",
      "\u001b[1m46/46\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - loss: 0.0039 - val_loss: 0.0012\n",
      "Epoch 9/30\n",
      "\u001b[1m46/46\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - loss: 0.0042 - val_loss: 0.0048\n",
      "Epoch 10/30\n",
      "\u001b[1m46/46\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - loss: 0.0045 - val_loss: 0.0019\n",
      "Epoch 11/30\n",
      "\u001b[1m46/46\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - loss: 0.0048 - val_loss: 0.0022\n",
      "Epoch 12/30\n",
      "\u001b[1m46/46\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - loss: 0.0030 - val_loss: 0.0096\n",
      "Epoch 13/30\n",
      "\u001b[1m46/46\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 0.0055 - val_loss: 0.0044\n",
      "Epoch 14/30\n",
      "\u001b[1m46/46\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 0.0039 - val_loss: 0.0019\n",
      "Epoch 15/30\n",
      "\u001b[1m46/46\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 0.0036 - val_loss: 8.4488e-04\n",
      "Epoch 16/30\n",
      "\u001b[1m46/46\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 0.0031 - val_loss: 0.0021\n",
      "Epoch 17/30\n",
      "\u001b[1m46/46\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 0.0033 - val_loss: 4.7230e-04\n",
      "Epoch 18/30\n",
      "\u001b[1m46/46\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 0.0035 - val_loss: 4.9548e-04\n",
      "Epoch 19/30\n",
      "\u001b[1m46/46\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - loss: 0.0030 - val_loss: 4.5018e-04\n",
      "Epoch 20/30\n",
      "\u001b[1m46/46\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - loss: 0.0028 - val_loss: 7.5792e-04\n",
      "Epoch 21/30\n",
      "\u001b[1m46/46\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - loss: 0.0026 - val_loss: 0.0025\n",
      "Epoch 22/30\n",
      "\u001b[1m46/46\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 0.0029 - val_loss: 0.0023\n",
      "Epoch 23/30\n",
      "\u001b[1m46/46\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 0.0034 - val_loss: 0.0012\n",
      "Epoch 24/30\n",
      "\u001b[1m46/46\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 0.0033 - val_loss: 4.1415e-04\n",
      "Epoch 25/30\n",
      "\u001b[1m46/46\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - loss: 0.0028 - val_loss: 9.2534e-04\n",
      "Epoch 26/30\n",
      "\u001b[1m46/46\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - loss: 0.0031 - val_loss: 4.5443e-04\n",
      "Epoch 27/30\n",
      "\u001b[1m46/46\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - loss: 0.0025 - val_loss: 0.0019\n",
      "Epoch 28/30\n",
      "\u001b[1m46/46\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - loss: 0.0030 - val_loss: 0.0015\n",
      "Epoch 29/30\n",
      "\u001b[1m46/46\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - loss: 0.0029 - val_loss: 0.0013\n",
      "Epoch 30/30\n",
      "\u001b[1m46/46\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 12ms/step - loss: 0.0037 - val_loss: 8.3348e-04\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:The `save_format` argument is deprecated in Keras 3. We recommend removing this argument as it can be inferred from the file path. Received: save_format=keras\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Finished: Palestine | MAE: 0.16 | RMSE: 0.24 | R²: 0.74\n",
      "Epoch 1/30\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/dejauhnaebeadle/School/MachineLearning/machine-learning-project/code/rain-prediction/.venv/lib/python3.11/site-packages/keras/src/layers/rnn/rnn.py:200: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
      "  super().__init__(**kwargs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m46/46\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 16ms/step - loss: 0.0897 - val_loss: 0.0097\n",
      "Epoch 2/30\n",
      "\u001b[1m46/46\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - loss: 0.0088 - val_loss: 0.0100\n",
      "Epoch 3/30\n",
      "\u001b[1m46/46\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - loss: 0.0087 - val_loss: 0.0044\n",
      "Epoch 4/30\n",
      "\u001b[1m46/46\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - loss: 0.0063 - val_loss: 0.0047\n",
      "Epoch 5/30\n",
      "\u001b[1m46/46\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - loss: 0.0059 - val_loss: 0.0025\n",
      "Epoch 6/30\n",
      "\u001b[1m46/46\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - loss: 0.0051 - val_loss: 0.0038\n",
      "Epoch 7/30\n",
      "\u001b[1m46/46\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - loss: 0.0048 - val_loss: 0.0016\n",
      "Epoch 8/30\n",
      "\u001b[1m46/46\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - loss: 0.0056 - val_loss: 0.0037\n",
      "Epoch 9/30\n",
      "\u001b[1m46/46\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - loss: 0.0036 - val_loss: 0.0051\n",
      "Epoch 10/30\n",
      "\u001b[1m46/46\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - loss: 0.0062 - val_loss: 0.0027\n",
      "Epoch 11/30\n",
      "\u001b[1m46/46\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - loss: 0.0036 - val_loss: 0.0024\n",
      "Epoch 12/30\n",
      "\u001b[1m46/46\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - loss: 0.0048 - val_loss: 0.0027\n",
      "Epoch 13/30\n",
      "\u001b[1m46/46\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - loss: 0.0037 - val_loss: 0.0021\n",
      "Epoch 14/30\n",
      "\u001b[1m46/46\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - loss: 0.0031 - val_loss: 0.0024\n",
      "Epoch 15/30\n",
      "\u001b[1m46/46\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - loss: 0.0037 - val_loss: 0.0022\n",
      "Epoch 16/30\n",
      "\u001b[1m46/46\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - loss: 0.0031 - val_loss: 0.0020\n",
      "Epoch 17/30\n",
      "\u001b[1m46/46\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - loss: 0.0043 - val_loss: 0.0013\n",
      "Epoch 18/30\n",
      "\u001b[1m46/46\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - loss: 0.0036 - val_loss: 0.0073\n",
      "Epoch 19/30\n",
      "\u001b[1m46/46\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - loss: 0.0039 - val_loss: 0.0025\n",
      "Epoch 20/30\n",
      "\u001b[1m46/46\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - loss: 0.0031 - val_loss: 0.0016\n",
      "Epoch 21/30\n",
      "\u001b[1m46/46\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - loss: 0.0024 - val_loss: 0.0018\n",
      "Epoch 22/30\n",
      "\u001b[1m46/46\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - loss: 0.0039 - val_loss: 0.0028\n",
      "Epoch 23/30\n",
      "\u001b[1m46/46\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 0.0033 - val_loss: 0.0017\n",
      "Epoch 24/30\n",
      "\u001b[1m46/46\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 0.0024 - val_loss: 9.2974e-04\n",
      "Epoch 25/30\n",
      "\u001b[1m46/46\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - loss: 0.0034 - val_loss: 0.0010\n",
      "Epoch 26/30\n",
      "\u001b[1m46/46\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 0.0037 - val_loss: 0.0016\n",
      "Epoch 27/30\n",
      "\u001b[1m46/46\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 0.0029 - val_loss: 0.0031\n",
      "Epoch 28/30\n",
      "\u001b[1m46/46\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - loss: 0.0024 - val_loss: 0.0021\n",
      "Epoch 29/30\n",
      "\u001b[1m46/46\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - loss: 0.0021 - val_loss: 0.0016\n",
      "Epoch 30/30\n",
      "\u001b[1m46/46\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 0.0022 - val_loss: 0.0011\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:The `save_format` argument is deprecated in Keras 3. We recommend removing this argument as it can be inferred from the file path. Received: save_format=keras\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Finished: Panama | MAE: 0.11 | RMSE: 0.14 | R²: 0.78\n",
      "Epoch 1/30\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/dejauhnaebeadle/School/MachineLearning/machine-learning-project/code/rain-prediction/.venv/lib/python3.11/site-packages/keras/src/layers/rnn/rnn.py:200: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
      "  super().__init__(**kwargs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m46/46\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 20ms/step - loss: 0.0517 - val_loss: 6.2350e-04\n",
      "Epoch 2/30\n",
      "\u001b[1m46/46\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - loss: 0.0038 - val_loss: 6.1245e-04\n",
      "Epoch 3/30\n",
      "\u001b[1m46/46\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 0.0030 - val_loss: 0.0023\n",
      "Epoch 4/30\n",
      "\u001b[1m46/46\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - loss: 0.0028 - val_loss: 5.3860e-04\n",
      "Epoch 5/30\n",
      "\u001b[1m46/46\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - loss: 0.0022 - val_loss: 8.8613e-04\n",
      "Epoch 6/30\n",
      "\u001b[1m46/46\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - loss: 0.0025 - val_loss: 8.4773e-04\n",
      "Epoch 7/30\n",
      "\u001b[1m46/46\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - loss: 0.0024 - val_loss: 0.0012\n",
      "Epoch 8/30\n",
      "\u001b[1m46/46\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - loss: 0.0018 - val_loss: 0.0014\n",
      "Epoch 9/30\n",
      "\u001b[1m46/46\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - loss: 0.0021 - val_loss: 0.0015\n",
      "Epoch 10/30\n",
      "\u001b[1m46/46\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - loss: 0.0024 - val_loss: 6.6708e-04\n",
      "Epoch 11/30\n",
      "\u001b[1m46/46\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - loss: 0.0022 - val_loss: 5.9713e-04\n",
      "Epoch 12/30\n",
      "\u001b[1m46/46\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - loss: 0.0017 - val_loss: 3.7020e-04\n",
      "Epoch 13/30\n",
      "\u001b[1m46/46\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - loss: 0.0016 - val_loss: 5.4893e-04\n",
      "Epoch 14/30\n",
      "\u001b[1m46/46\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - loss: 0.0015 - val_loss: 3.4397e-04\n",
      "Epoch 15/30\n",
      "\u001b[1m46/46\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - loss: 0.0016 - val_loss: 4.0482e-04\n",
      "Epoch 16/30\n",
      "\u001b[1m46/46\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - loss: 0.0019 - val_loss: 2.9321e-04\n",
      "Epoch 17/30\n",
      "\u001b[1m46/46\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - loss: 0.0018 - val_loss: 7.1710e-04\n",
      "Epoch 18/30\n",
      "\u001b[1m46/46\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 8ms/step - loss: 0.0013 - val_loss: 4.4088e-04\n",
      "Epoch 19/30\n",
      "\u001b[1m46/46\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - loss: 0.0015 - val_loss: 8.1834e-04\n",
      "Epoch 20/30\n",
      "\u001b[1m46/46\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - loss: 0.0013 - val_loss: 2.7169e-04\n",
      "Epoch 21/30\n",
      "\u001b[1m46/46\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - loss: 0.0016 - val_loss: 2.7583e-04\n",
      "Epoch 22/30\n",
      "\u001b[1m46/46\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - loss: 0.0011 - val_loss: 0.0010\n",
      "Epoch 23/30\n",
      "\u001b[1m46/46\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - loss: 0.0011 - val_loss: 5.1283e-04\n",
      "Epoch 24/30\n",
      "\u001b[1m46/46\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - loss: 0.0012 - val_loss: 4.7102e-04\n",
      "Epoch 25/30\n",
      "\u001b[1m46/46\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 10ms/step - loss: 9.0805e-04 - val_loss: 2.6880e-04\n",
      "Epoch 26/30\n",
      "\u001b[1m46/46\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - loss: 9.4722e-04 - val_loss: 2.4577e-04\n",
      "Epoch 27/30\n",
      "\u001b[1m46/46\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - loss: 9.2342e-04 - val_loss: 5.1430e-04\n",
      "Epoch 28/30\n",
      "\u001b[1m46/46\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - loss: 0.0013 - val_loss: 2.7580e-04\n",
      "Epoch 29/30\n",
      "\u001b[1m46/46\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - loss: 8.7924e-04 - val_loss: 2.1997e-04\n",
      "Epoch 30/30\n",
      "\u001b[1m46/46\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - loss: 0.0013 - val_loss: 4.9951e-04\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:The `save_format` argument is deprecated in Keras 3. We recommend removing this argument as it can be inferred from the file path. Received: save_format=keras\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Finished: Papua New Guinea | MAE: 0.08 | RMSE: 0.11 | R²: 0.84\n",
      "Epoch 1/30\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/dejauhnaebeadle/School/MachineLearning/machine-learning-project/code/rain-prediction/.venv/lib/python3.11/site-packages/keras/src/layers/rnn/rnn.py:200: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
      "  super().__init__(**kwargs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m46/46\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 13ms/step - loss: 0.0784 - val_loss: 0.0088\n",
      "Epoch 2/30\n",
      "\u001b[1m46/46\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - loss: 0.0144 - val_loss: 0.0070\n",
      "Epoch 3/30\n",
      "\u001b[1m46/46\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - loss: 0.0135 - val_loss: 0.0075\n",
      "Epoch 4/30\n",
      "\u001b[1m46/46\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - loss: 0.0112 - val_loss: 0.0114\n",
      "Epoch 5/30\n",
      "\u001b[1m46/46\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - loss: 0.0084 - val_loss: 0.0054\n",
      "Epoch 6/30\n",
      "\u001b[1m46/46\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - loss: 0.0073 - val_loss: 0.0053\n",
      "Epoch 7/30\n",
      "\u001b[1m46/46\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - loss: 0.0067 - val_loss: 0.0044\n",
      "Epoch 8/30\n",
      "\u001b[1m46/46\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - loss: 0.0072 - val_loss: 0.0034\n",
      "Epoch 9/30\n",
      "\u001b[1m46/46\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - loss: 0.0068 - val_loss: 0.0053\n",
      "Epoch 10/30\n",
      "\u001b[1m46/46\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - loss: 0.0066 - val_loss: 0.0030\n",
      "Epoch 11/30\n",
      "\u001b[1m46/46\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - loss: 0.0064 - val_loss: 0.0046\n",
      "Epoch 12/30\n",
      "\u001b[1m46/46\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - loss: 0.0056 - val_loss: 0.0056\n",
      "Epoch 13/30\n",
      "\u001b[1m46/46\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - loss: 0.0064 - val_loss: 0.0039\n",
      "Epoch 14/30\n",
      "\u001b[1m46/46\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - loss: 0.0057 - val_loss: 0.0050\n",
      "Epoch 15/30\n",
      "\u001b[1m46/46\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - loss: 0.0060 - val_loss: 0.0033\n",
      "Epoch 16/30\n",
      "\u001b[1m46/46\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - loss: 0.0052 - val_loss: 0.0020\n",
      "Epoch 17/30\n",
      "\u001b[1m46/46\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - loss: 0.0047 - val_loss: 0.0041\n",
      "Epoch 18/30\n",
      "\u001b[1m46/46\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - loss: 0.0053 - val_loss: 0.0022\n",
      "Epoch 19/30\n",
      "\u001b[1m46/46\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - loss: 0.0054 - val_loss: 0.0027\n",
      "Epoch 20/30\n",
      "\u001b[1m46/46\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - loss: 0.0047 - val_loss: 0.0024\n",
      "Epoch 21/30\n",
      "\u001b[1m46/46\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - loss: 0.0040 - val_loss: 0.0018\n",
      "Epoch 22/30\n",
      "\u001b[1m46/46\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - loss: 0.0039 - val_loss: 0.0026\n",
      "Epoch 23/30\n",
      "\u001b[1m46/46\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - loss: 0.0045 - val_loss: 0.0051\n",
      "Epoch 24/30\n",
      "\u001b[1m46/46\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - loss: 0.0042 - val_loss: 0.0046\n",
      "Epoch 25/30\n",
      "\u001b[1m46/46\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - loss: 0.0054 - val_loss: 0.0036\n",
      "Epoch 26/30\n",
      "\u001b[1m46/46\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - loss: 0.0038 - val_loss: 0.0017\n",
      "Epoch 27/30\n",
      "\u001b[1m46/46\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - loss: 0.0047 - val_loss: 0.0054\n",
      "Epoch 28/30\n",
      "\u001b[1m46/46\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - loss: 0.0035 - val_loss: 0.0018\n",
      "Epoch 29/30\n",
      "\u001b[1m46/46\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - loss: 0.0052 - val_loss: 0.0023\n",
      "Epoch 30/30\n",
      "\u001b[1m46/46\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - loss: 0.0053 - val_loss: 0.0048\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:The `save_format` argument is deprecated in Keras 3. We recommend removing this argument as it can be inferred from the file path. Received: save_format=keras\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Finished: Paraguay | MAE: 0.26 | RMSE: 0.31 | R²: 0.71\n",
      "Epoch 1/30\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/dejauhnaebeadle/School/MachineLearning/machine-learning-project/code/rain-prediction/.venv/lib/python3.11/site-packages/keras/src/layers/rnn/rnn.py:200: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
      "  super().__init__(**kwargs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m46/46\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 13ms/step - loss: 0.0372 - val_loss: 8.2842e-04\n",
      "Epoch 2/30\n",
      "\u001b[1m46/46\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - loss: 0.0060 - val_loss: 0.0016\n",
      "Epoch 3/30\n",
      "\u001b[1m46/46\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - loss: 0.0059 - val_loss: 0.0013\n",
      "Epoch 4/30\n",
      "\u001b[1m46/46\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - loss: 0.0048 - val_loss: 0.0012\n",
      "Epoch 5/30\n",
      "\u001b[1m46/46\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - loss: 0.0047 - val_loss: 9.3268e-04\n",
      "Epoch 6/30\n",
      "\u001b[1m46/46\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - loss: 0.0035 - val_loss: 6.2967e-04\n",
      "Epoch 7/30\n",
      "\u001b[1m46/46\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - loss: 0.0040 - val_loss: 6.5243e-04\n",
      "Epoch 8/30\n",
      "\u001b[1m46/46\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 0.0032 - val_loss: 8.8762e-04\n",
      "Epoch 9/30\n",
      "\u001b[1m46/46\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 0.0033 - val_loss: 4.6571e-04\n",
      "Epoch 10/30\n",
      "\u001b[1m46/46\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 0.0026 - val_loss: 0.0014\n",
      "Epoch 11/30\n",
      "\u001b[1m46/46\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - loss: 0.0033 - val_loss: 4.4369e-04\n",
      "Epoch 12/30\n",
      "\u001b[1m46/46\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - loss: 0.0024 - val_loss: 0.0010\n",
      "Epoch 13/30\n",
      "\u001b[1m46/46\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - loss: 0.0028 - val_loss: 6.9342e-04\n",
      "Epoch 14/30\n",
      "\u001b[1m46/46\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 0.0027 - val_loss: 0.0018\n",
      "Epoch 15/30\n",
      "\u001b[1m46/46\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 0.0028 - val_loss: 5.2636e-04\n",
      "Epoch 16/30\n",
      "\u001b[1m46/46\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 0.0023 - val_loss: 4.7453e-04\n",
      "Epoch 17/30\n",
      "\u001b[1m46/46\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 0.0023 - val_loss: 4.7501e-04\n",
      "Epoch 18/30\n",
      "\u001b[1m46/46\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 0.0019 - val_loss: 0.0024\n",
      "Epoch 19/30\n",
      "\u001b[1m46/46\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - loss: 0.0023 - val_loss: 0.0019\n",
      "Epoch 20/30\n",
      "\u001b[1m46/46\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 0.0025 - val_loss: 0.0011\n",
      "Epoch 21/30\n",
      "\u001b[1m46/46\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 0.0020 - val_loss: 0.0014\n",
      "Epoch 22/30\n",
      "\u001b[1m46/46\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 0.0021 - val_loss: 9.5783e-04\n",
      "Epoch 23/30\n",
      "\u001b[1m46/46\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 0.0031 - val_loss: 3.4599e-04\n",
      "Epoch 24/30\n",
      "\u001b[1m46/46\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - loss: 0.0018 - val_loss: 0.0017\n",
      "Epoch 25/30\n",
      "\u001b[1m46/46\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 0.0019 - val_loss: 5.8745e-04\n",
      "Epoch 26/30\n",
      "\u001b[1m46/46\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 0.0017 - val_loss: 8.4075e-04\n",
      "Epoch 27/30\n",
      "\u001b[1m46/46\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 0.0023 - val_loss: 4.7867e-04\n",
      "Epoch 28/30\n",
      "\u001b[1m46/46\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - loss: 0.0022 - val_loss: 9.5928e-04\n",
      "Epoch 29/30\n",
      "\u001b[1m46/46\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 0.0021 - val_loss: 6.0856e-04\n",
      "Epoch 30/30\n",
      "\u001b[1m46/46\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 0.0019 - val_loss: 3.1556e-04\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:The `save_format` argument is deprecated in Keras 3. We recommend removing this argument as it can be inferred from the file path. Received: save_format=keras\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Finished: Peru | MAE: 0.06 | RMSE: 0.11 | R²: 0.91\n",
      "Epoch 1/30\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/dejauhnaebeadle/School/MachineLearning/machine-learning-project/code/rain-prediction/.venv/lib/python3.11/site-packages/keras/src/layers/rnn/rnn.py:200: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
      "  super().__init__(**kwargs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m46/46\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 13ms/step - loss: 0.0925 - val_loss: 4.3416e-04\n",
      "Epoch 2/30\n",
      "\u001b[1m46/46\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 0.0046 - val_loss: 0.0025\n",
      "Epoch 3/30\n",
      "\u001b[1m46/46\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 0.0036 - val_loss: 0.0022\n",
      "Epoch 4/30\n",
      "\u001b[1m46/46\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 0.0030 - val_loss: 4.7674e-04\n",
      "Epoch 5/30\n",
      "\u001b[1m46/46\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 0.0038 - val_loss: 6.8555e-04\n",
      "Epoch 6/30\n",
      "\u001b[1m46/46\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 0.0030 - val_loss: 4.3542e-04\n",
      "Epoch 7/30\n",
      "\u001b[1m46/46\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - loss: 0.0032 - val_loss: 4.9244e-04\n",
      "Epoch 8/30\n",
      "\u001b[1m46/46\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 0.0025 - val_loss: 8.6862e-04\n",
      "Epoch 9/30\n",
      "\u001b[1m46/46\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 0.0026 - val_loss: 3.8936e-04\n",
      "Epoch 10/30\n",
      "\u001b[1m46/46\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 0.0023 - val_loss: 0.0012\n",
      "Epoch 11/30\n",
      "\u001b[1m46/46\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 0.0022 - val_loss: 3.5489e-04\n",
      "Epoch 12/30\n",
      "\u001b[1m46/46\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 0.0020 - val_loss: 0.0014\n",
      "Epoch 13/30\n",
      "\u001b[1m46/46\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 0.0023 - val_loss: 6.1486e-04\n",
      "Epoch 14/30\n",
      "\u001b[1m46/46\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - loss: 0.0023 - val_loss: 4.9962e-04\n",
      "Epoch 15/30\n",
      "\u001b[1m46/46\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - loss: 0.0016 - val_loss: 3.0521e-04\n",
      "Epoch 16/30\n",
      "\u001b[1m46/46\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - loss: 0.0022 - val_loss: 8.7542e-04\n",
      "Epoch 17/30\n",
      "\u001b[1m46/46\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 0.0016 - val_loss: 0.0010\n",
      "Epoch 18/30\n",
      "\u001b[1m46/46\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 0.0017 - val_loss: 3.0748e-04\n",
      "Epoch 19/30\n",
      "\u001b[1m46/46\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - loss: 0.0016 - val_loss: 3.1937e-04\n",
      "Epoch 20/30\n",
      "\u001b[1m46/46\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - loss: 0.0013 - val_loss: 0.0015\n",
      "Epoch 21/30\n",
      "\u001b[1m46/46\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 0.0019 - val_loss: 7.8359e-04\n",
      "Epoch 22/30\n",
      "\u001b[1m46/46\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 0.0015 - val_loss: 0.0012\n",
      "Epoch 23/30\n",
      "\u001b[1m46/46\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 0.0016 - val_loss: 2.8463e-04\n",
      "Epoch 24/30\n",
      "\u001b[1m46/46\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - loss: 0.0013 - val_loss: 6.9488e-04\n",
      "Epoch 25/30\n",
      "\u001b[1m46/46\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 0.0015 - val_loss: 2.6489e-04\n",
      "Epoch 26/30\n",
      "\u001b[1m46/46\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - loss: 0.0016 - val_loss: 4.5350e-04\n",
      "Epoch 27/30\n",
      "\u001b[1m46/46\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 0.0012 - val_loss: 2.8364e-04\n",
      "Epoch 28/30\n",
      "\u001b[1m46/46\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 0.0016 - val_loss: 5.2389e-04\n",
      "Epoch 29/30\n",
      "\u001b[1m46/46\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 0.0013 - val_loss: 0.0010\n",
      "Epoch 30/30\n",
      "\u001b[1m46/46\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 0.0019 - val_loss: 4.3738e-04\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:The `save_format` argument is deprecated in Keras 3. We recommend removing this argument as it can be inferred from the file path. Received: save_format=keras\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Finished: Philippines | MAE: 0.09 | RMSE: 0.11 | R²: 0.79\n",
      "Epoch 1/30\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/dejauhnaebeadle/School/MachineLearning/machine-learning-project/code/rain-prediction/.venv/lib/python3.11/site-packages/keras/src/layers/rnn/rnn.py:200: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
      "  super().__init__(**kwargs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m46/46\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 14ms/step - loss: 0.1113 - val_loss: 0.0066\n",
      "Epoch 2/30\n",
      "\u001b[1m46/46\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 0.0105 - val_loss: 0.0114\n",
      "Epoch 3/30\n",
      "\u001b[1m46/46\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 0.0098 - val_loss: 0.0048\n",
      "Epoch 4/30\n",
      "\u001b[1m46/46\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 0.0091 - val_loss: 0.0045\n",
      "Epoch 5/30\n",
      "\u001b[1m46/46\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 0.0069 - val_loss: 0.0036\n",
      "Epoch 6/30\n",
      "\u001b[1m46/46\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - loss: 0.0062 - val_loss: 0.0020\n",
      "Epoch 7/30\n",
      "\u001b[1m46/46\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - loss: 0.0066 - val_loss: 0.0018\n",
      "Epoch 8/30\n",
      "\u001b[1m46/46\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 0.0058 - val_loss: 0.0023\n",
      "Epoch 9/30\n",
      "\u001b[1m46/46\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 0.0051 - val_loss: 0.0020\n",
      "Epoch 10/30\n",
      "\u001b[1m46/46\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 0.0049 - val_loss: 0.0079\n",
      "Epoch 11/30\n",
      "\u001b[1m46/46\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 0.0056 - val_loss: 0.0018\n",
      "Epoch 12/30\n",
      "\u001b[1m46/46\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 0.0042 - val_loss: 0.0026\n",
      "Epoch 13/30\n",
      "\u001b[1m46/46\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 0.0047 - val_loss: 0.0048\n",
      "Epoch 14/30\n",
      "\u001b[1m46/46\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 0.0040 - val_loss: 0.0041\n",
      "Epoch 15/30\n",
      "\u001b[1m46/46\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 0.0042 - val_loss: 0.0016\n",
      "Epoch 16/30\n",
      "\u001b[1m46/46\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 0.0041 - val_loss: 0.0046\n",
      "Epoch 17/30\n",
      "\u001b[1m46/46\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 0.0040 - val_loss: 0.0027\n",
      "Epoch 18/30\n",
      "\u001b[1m46/46\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - loss: 0.0032 - val_loss: 0.0023\n",
      "Epoch 19/30\n",
      "\u001b[1m46/46\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - loss: 0.0034 - val_loss: 0.0017\n",
      "Epoch 20/30\n",
      "\u001b[1m46/46\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 0.0034 - val_loss: 0.0016\n",
      "Epoch 21/30\n",
      "\u001b[1m46/46\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - loss: 0.0031 - val_loss: 0.0011\n",
      "Epoch 22/30\n",
      "\u001b[1m46/46\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - loss: 0.0034 - val_loss: 0.0011\n",
      "Epoch 23/30\n",
      "\u001b[1m46/46\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - loss: 0.0030 - val_loss: 0.0032\n",
      "Epoch 24/30\n",
      "\u001b[1m46/46\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - loss: 0.0037 - val_loss: 0.0017\n",
      "Epoch 25/30\n",
      "\u001b[1m46/46\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - loss: 0.0031 - val_loss: 0.0013\n",
      "Epoch 26/30\n",
      "\u001b[1m46/46\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - loss: 0.0026 - val_loss: 0.0013\n",
      "Epoch 27/30\n",
      "\u001b[1m46/46\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - loss: 0.0033 - val_loss: 0.0012\n",
      "Epoch 28/30\n",
      "\u001b[1m46/46\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 0.0030 - val_loss: 0.0021\n",
      "Epoch 29/30\n",
      "\u001b[1m46/46\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - loss: 0.0033 - val_loss: 0.0017\n",
      "Epoch 30/30\n",
      "\u001b[1m46/46\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - loss: 0.0030 - val_loss: 0.0023\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:The `save_format` argument is deprecated in Keras 3. We recommend removing this argument as it can be inferred from the file path. Received: save_format=keras\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Finished: Poland | MAE: 0.28 | RMSE: 0.34 | R²: 0.83\n",
      "Epoch 1/30\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/dejauhnaebeadle/School/MachineLearning/machine-learning-project/code/rain-prediction/.venv/lib/python3.11/site-packages/keras/src/layers/rnn/rnn.py:200: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
      "  super().__init__(**kwargs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m46/46\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 20ms/step - loss: 0.0848 - val_loss: 0.0035\n",
      "Epoch 2/30\n",
      "\u001b[1m46/46\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - loss: 0.0119 - val_loss: 0.0073\n",
      "Epoch 3/30\n",
      "\u001b[1m46/46\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 17ms/step - loss: 0.0112 - val_loss: 0.0041\n",
      "Epoch 4/30\n",
      "\u001b[1m46/46\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 10ms/step - loss: 0.0090 - val_loss: 0.0043\n",
      "Epoch 5/30\n",
      "\u001b[1m46/46\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - loss: 0.0094 - val_loss: 0.0026\n",
      "Epoch 6/30\n",
      "\u001b[1m46/46\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - loss: 0.0094 - val_loss: 0.0025\n",
      "Epoch 7/30\n",
      "\u001b[1m46/46\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - loss: 0.0076 - val_loss: 0.0043\n",
      "Epoch 8/30\n",
      "\u001b[1m46/46\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - loss: 0.0074 - val_loss: 0.0036\n",
      "Epoch 9/30\n",
      "\u001b[1m46/46\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - loss: 0.0059 - val_loss: 0.0017\n",
      "Epoch 10/30\n",
      "\u001b[1m46/46\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - loss: 0.0066 - val_loss: 0.0021\n",
      "Epoch 11/30\n",
      "\u001b[1m46/46\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - loss: 0.0058 - val_loss: 0.0037\n",
      "Epoch 12/30\n",
      "\u001b[1m46/46\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - loss: 0.0053 - val_loss: 0.0017\n",
      "Epoch 13/30\n",
      "\u001b[1m46/46\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - loss: 0.0048 - val_loss: 0.0030\n",
      "Epoch 14/30\n",
      "\u001b[1m46/46\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - loss: 0.0049 - val_loss: 0.0022\n",
      "Epoch 15/30\n",
      "\u001b[1m46/46\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - loss: 0.0061 - val_loss: 0.0014\n",
      "Epoch 16/30\n",
      "\u001b[1m46/46\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - loss: 0.0061 - val_loss: 0.0014\n",
      "Epoch 17/30\n",
      "\u001b[1m46/46\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - loss: 0.0040 - val_loss: 0.0019\n",
      "Epoch 18/30\n",
      "\u001b[1m46/46\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - loss: 0.0043 - val_loss: 0.0022\n",
      "Epoch 19/30\n",
      "\u001b[1m46/46\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - loss: 0.0055 - val_loss: 0.0019\n",
      "Epoch 20/30\n",
      "\u001b[1m46/46\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - loss: 0.0033 - val_loss: 0.0013\n",
      "Epoch 21/30\n",
      "\u001b[1m46/46\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - loss: 0.0041 - val_loss: 0.0020\n",
      "Epoch 22/30\n",
      "\u001b[1m46/46\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - loss: 0.0043 - val_loss: 0.0012\n",
      "Epoch 23/30\n",
      "\u001b[1m46/46\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - loss: 0.0039 - val_loss: 0.0013\n",
      "Epoch 24/30\n",
      "\u001b[1m46/46\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - loss: 0.0043 - val_loss: 0.0011\n",
      "Epoch 25/30\n",
      "\u001b[1m46/46\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 11ms/step - loss: 0.0032 - val_loss: 0.0012\n",
      "Epoch 26/30\n",
      "\u001b[1m46/46\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - loss: 0.0040 - val_loss: 0.0027\n",
      "Epoch 27/30\n",
      "\u001b[1m46/46\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - loss: 0.0027 - val_loss: 0.0011\n",
      "Epoch 28/30\n",
      "\u001b[1m46/46\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - loss: 0.0025 - val_loss: 0.0012\n",
      "Epoch 29/30\n",
      "\u001b[1m46/46\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - loss: 0.0030 - val_loss: 0.0012\n",
      "Epoch 30/30\n",
      "\u001b[1m46/46\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - loss: 0.0023 - val_loss: 0.0016\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:The `save_format` argument is deprecated in Keras 3. We recommend removing this argument as it can be inferred from the file path. Received: save_format=keras\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Finished: Portugal | MAE: 0.15 | RMSE: 0.20 | R²: 0.80\n",
      "Epoch 1/30\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/dejauhnaebeadle/School/MachineLearning/machine-learning-project/code/rain-prediction/.venv/lib/python3.11/site-packages/keras/src/layers/rnn/rnn.py:200: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
      "  super().__init__(**kwargs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m46/46\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 17ms/step - loss: 0.0415 - val_loss: 0.0034\n",
      "Epoch 2/30\n",
      "\u001b[1m46/46\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - loss: 0.0059 - val_loss: 0.0020\n",
      "Epoch 3/30\n",
      "\u001b[1m46/46\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - loss: 0.0054 - val_loss: 0.0027\n",
      "Epoch 4/30\n",
      "\u001b[1m46/46\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - loss: 0.0053 - val_loss: 0.0022\n",
      "Epoch 5/30\n",
      "\u001b[1m46/46\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - loss: 0.0044 - val_loss: 0.0015\n",
      "Epoch 6/30\n",
      "\u001b[1m46/46\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - loss: 0.0043 - val_loss: 0.0023\n",
      "Epoch 7/30\n",
      "\u001b[1m46/46\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - loss: 0.0039 - val_loss: 0.0049\n",
      "Epoch 8/30\n",
      "\u001b[1m46/46\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - loss: 0.0037 - val_loss: 0.0018\n",
      "Epoch 9/30\n",
      "\u001b[1m46/46\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - loss: 0.0030 - val_loss: 0.0013\n",
      "Epoch 10/30\n",
      "\u001b[1m46/46\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - loss: 0.0032 - val_loss: 0.0016\n",
      "Epoch 11/30\n",
      "\u001b[1m46/46\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - loss: 0.0022 - val_loss: 0.0016\n",
      "Epoch 12/30\n",
      "\u001b[1m46/46\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - loss: 0.0026 - val_loss: 0.0018\n",
      "Epoch 13/30\n",
      "\u001b[1m46/46\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - loss: 0.0031 - val_loss: 0.0013\n",
      "Epoch 14/30\n",
      "\u001b[1m46/46\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - loss: 0.0021 - val_loss: 0.0030\n",
      "Epoch 15/30\n",
      "\u001b[1m46/46\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - loss: 0.0023 - val_loss: 0.0016\n",
      "Epoch 16/30\n",
      "\u001b[1m46/46\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - loss: 0.0022 - val_loss: 0.0018\n",
      "Epoch 17/30\n",
      "\u001b[1m46/46\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - loss: 0.0022 - val_loss: 0.0037\n",
      "Epoch 18/30\n",
      "\u001b[1m46/46\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - loss: 0.0020 - val_loss: 0.0012\n",
      "Epoch 19/30\n",
      "\u001b[1m46/46\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - loss: 0.0020 - val_loss: 0.0030\n",
      "Epoch 20/30\n",
      "\u001b[1m46/46\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - loss: 0.0027 - val_loss: 0.0011\n",
      "Epoch 21/30\n",
      "\u001b[1m46/46\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 0.0019 - val_loss: 0.0045\n",
      "Epoch 22/30\n",
      "\u001b[1m46/46\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 0.0021 - val_loss: 0.0018\n",
      "Epoch 23/30\n",
      "\u001b[1m46/46\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 0.0026 - val_loss: 0.0011\n",
      "Epoch 24/30\n",
      "\u001b[1m46/46\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 0.0021 - val_loss: 0.0012\n",
      "Epoch 25/30\n",
      "\u001b[1m46/46\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 0.0017 - val_loss: 0.0011\n",
      "Epoch 26/30\n",
      "\u001b[1m46/46\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 0.0021 - val_loss: 8.7118e-04\n",
      "Epoch 27/30\n",
      "\u001b[1m46/46\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 0.0015 - val_loss: 0.0012\n",
      "Epoch 28/30\n",
      "\u001b[1m46/46\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 0.0016 - val_loss: 0.0028\n",
      "Epoch 29/30\n",
      "\u001b[1m46/46\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 0.0014 - val_loss: 7.9346e-04\n",
      "Epoch 30/30\n",
      "\u001b[1m46/46\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 0.0020 - val_loss: 0.0014\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:The `save_format` argument is deprecated in Keras 3. We recommend removing this argument as it can be inferred from the file path. Received: save_format=keras\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Finished: Puerto Rico | MAE: 0.12 | RMSE: 0.15 | R²: 0.74\n",
      "Epoch 1/30\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/dejauhnaebeadle/School/MachineLearning/machine-learning-project/code/rain-prediction/.venv/lib/python3.11/site-packages/keras/src/layers/rnn/rnn.py:200: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
      "  super().__init__(**kwargs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m46/46\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 11ms/step - loss: 0.0360 - val_loss: 0.0071\n",
      "Epoch 2/30\n",
      "\u001b[1m46/46\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 0.0088 - val_loss: 0.0061\n",
      "Epoch 3/30\n",
      "\u001b[1m46/46\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 0.0073 - val_loss: 0.0110\n",
      "Epoch 4/30\n",
      "\u001b[1m46/46\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 0.0063 - val_loss: 0.0026\n",
      "Epoch 5/30\n",
      "\u001b[1m46/46\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 0.0053 - val_loss: 0.0020\n",
      "Epoch 6/30\n",
      "\u001b[1m46/46\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 0.0047 - val_loss: 0.0015\n",
      "Epoch 7/30\n",
      "\u001b[1m46/46\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 0.0054 - val_loss: 0.0034\n",
      "Epoch 8/30\n",
      "\u001b[1m46/46\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 0.0042 - val_loss: 0.0041\n",
      "Epoch 9/30\n",
      "\u001b[1m46/46\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 0.0045 - val_loss: 0.0035\n",
      "Epoch 10/30\n",
      "\u001b[1m46/46\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 0.0053 - val_loss: 0.0015\n",
      "Epoch 11/30\n",
      "\u001b[1m46/46\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 0.0040 - val_loss: 0.0012\n",
      "Epoch 12/30\n",
      "\u001b[1m46/46\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 0.0057 - val_loss: 8.9687e-04\n",
      "Epoch 13/30\n",
      "\u001b[1m46/46\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 0.0036 - val_loss: 0.0014\n",
      "Epoch 14/30\n",
      "\u001b[1m46/46\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 0.0034 - val_loss: 0.0011\n",
      "Epoch 15/30\n",
      "\u001b[1m46/46\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 0.0031 - val_loss: 9.6756e-04\n",
      "Epoch 16/30\n",
      "\u001b[1m46/46\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 0.0034 - val_loss: 0.0012\n",
      "Epoch 17/30\n",
      "\u001b[1m46/46\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 0.0040 - val_loss: 0.0020\n",
      "Epoch 18/30\n",
      "\u001b[1m46/46\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 0.0030 - val_loss: 0.0013\n",
      "Epoch 19/30\n",
      "\u001b[1m46/46\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - loss: 0.0035 - val_loss: 0.0013\n",
      "Epoch 20/30\n",
      "\u001b[1m46/46\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - loss: 0.0034 - val_loss: 0.0012\n",
      "Epoch 21/30\n",
      "\u001b[1m46/46\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 0.0038 - val_loss: 7.6323e-04\n",
      "Epoch 22/30\n",
      "\u001b[1m46/46\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 0.0028 - val_loss: 8.8800e-04\n",
      "Epoch 23/30\n",
      "\u001b[1m46/46\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 0.0039 - val_loss: 6.4529e-04\n",
      "Epoch 24/30\n",
      "\u001b[1m46/46\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 0.0032 - val_loss: 7.2534e-04\n",
      "Epoch 25/30\n",
      "\u001b[1m46/46\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 0.0031 - val_loss: 6.7197e-04\n",
      "Epoch 26/30\n",
      "\u001b[1m46/46\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 0.0031 - val_loss: 6.4423e-04\n",
      "Epoch 27/30\n",
      "\u001b[1m46/46\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 0.0031 - val_loss: 6.2554e-04\n",
      "Epoch 28/30\n",
      "\u001b[1m46/46\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - loss: 0.0023 - val_loss: 6.4760e-04\n",
      "Epoch 29/30\n",
      "\u001b[1m46/46\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 0.0027 - val_loss: 6.0735e-04\n",
      "Epoch 30/30\n",
      "\u001b[1m46/46\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 0.0025 - val_loss: 7.2958e-04\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:The `save_format` argument is deprecated in Keras 3. We recommend removing this argument as it can be inferred from the file path. Received: save_format=keras\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Finished: Qatar | MAE: 0.05 | RMSE: 0.13 | R²: 0.91\n",
      "Epoch 1/30\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/dejauhnaebeadle/School/MachineLearning/machine-learning-project/code/rain-prediction/.venv/lib/python3.11/site-packages/keras/src/layers/rnn/rnn.py:200: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
      "  super().__init__(**kwargs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m46/46\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 11ms/step - loss: 0.0605 - val_loss: 0.0058\n",
      "Epoch 2/30\n",
      "\u001b[1m46/46\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 0.0069 - val_loss: 0.0080\n",
      "Epoch 3/30\n",
      "\u001b[1m46/46\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 0.0069 - val_loss: 0.0053\n",
      "Epoch 4/30\n",
      "\u001b[1m46/46\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 0.0062 - val_loss: 0.0050\n",
      "Epoch 5/30\n",
      "\u001b[1m46/46\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 0.0053 - val_loss: 0.0047\n",
      "Epoch 6/30\n",
      "\u001b[1m46/46\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 0.0045 - val_loss: 0.0075\n",
      "Epoch 7/30\n",
      "\u001b[1m46/46\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 0.0038 - val_loss: 0.0040\n",
      "Epoch 8/30\n",
      "\u001b[1m46/46\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 0.0033 - val_loss: 0.0037\n",
      "Epoch 9/30\n",
      "\u001b[1m46/46\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 0.0038 - val_loss: 0.0031\n",
      "Epoch 10/30\n",
      "\u001b[1m46/46\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 0.0038 - val_loss: 0.0038\n",
      "Epoch 11/30\n",
      "\u001b[1m46/46\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - loss: 0.0030 - val_loss: 0.0052\n",
      "Epoch 12/30\n",
      "\u001b[1m46/46\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - loss: 0.0030 - val_loss: 0.0038\n",
      "Epoch 13/30\n",
      "\u001b[1m46/46\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 0.0030 - val_loss: 0.0048\n",
      "Epoch 14/30\n",
      "\u001b[1m46/46\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 0.0033 - val_loss: 0.0029\n",
      "Epoch 15/30\n",
      "\u001b[1m46/46\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - loss: 0.0029 - val_loss: 0.0031\n",
      "Epoch 16/30\n",
      "\u001b[1m46/46\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 0.0027 - val_loss: 0.0022\n",
      "Epoch 17/30\n",
      "\u001b[1m46/46\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 0.0032 - val_loss: 0.0031\n",
      "Epoch 18/30\n",
      "\u001b[1m46/46\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 0.0033 - val_loss: 0.0028\n",
      "Epoch 19/30\n",
      "\u001b[1m46/46\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 0.0025 - val_loss: 0.0041\n",
      "Epoch 20/30\n",
      "\u001b[1m46/46\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - loss: 0.0035 - val_loss: 0.0020\n",
      "Epoch 21/30\n",
      "\u001b[1m46/46\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 0.0026 - val_loss: 0.0029\n",
      "Epoch 22/30\n",
      "\u001b[1m46/46\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 0.0028 - val_loss: 0.0033\n",
      "Epoch 23/30\n",
      "\u001b[1m46/46\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 0.0030 - val_loss: 0.0024\n",
      "Epoch 24/30\n",
      "\u001b[1m46/46\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - loss: 0.0025 - val_loss: 0.0021\n",
      "Epoch 25/30\n",
      "\u001b[1m46/46\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - loss: 0.0029 - val_loss: 0.0021\n",
      "Epoch 26/30\n",
      "\u001b[1m46/46\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 0.0024 - val_loss: 0.0023\n",
      "Epoch 27/30\n",
      "\u001b[1m46/46\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - loss: 0.0023 - val_loss: 0.0023\n",
      "Epoch 28/30\n",
      "\u001b[1m46/46\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 0.0026 - val_loss: 0.0019\n",
      "Epoch 29/30\n",
      "\u001b[1m46/46\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - loss: 0.0029 - val_loss: 0.0020\n",
      "Epoch 30/30\n",
      "\u001b[1m46/46\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - loss: 0.0031 - val_loss: 0.0021\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:The `save_format` argument is deprecated in Keras 3. We recommend removing this argument as it can be inferred from the file path. Received: save_format=keras\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Finished: Romania | MAE: 0.21 | RMSE: 0.25 | R²: 0.82\n",
      "Epoch 1/30\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/dejauhnaebeadle/School/MachineLearning/machine-learning-project/code/rain-prediction/.venv/lib/python3.11/site-packages/keras/src/layers/rnn/rnn.py:200: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
      "  super().__init__(**kwargs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m46/46\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 18ms/step - loss: 0.0554 - val_loss: 0.0167\n",
      "Epoch 2/30\n",
      "\u001b[1m46/46\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - loss: 0.0111 - val_loss: 0.0187\n",
      "Epoch 3/30\n",
      "\u001b[1m46/46\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - loss: 0.0104 - val_loss: 0.0153\n",
      "Epoch 4/30\n",
      "\u001b[1m46/46\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - loss: 0.0082 - val_loss: 0.0104\n",
      "Epoch 5/30\n",
      "\u001b[1m46/46\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - loss: 0.0061 - val_loss: 0.0160\n",
      "Epoch 6/30\n",
      "\u001b[1m46/46\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - loss: 0.0064 - val_loss: 0.0092\n",
      "Epoch 7/30\n",
      "\u001b[1m46/46\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - loss: 0.0058 - val_loss: 0.0090\n",
      "Epoch 8/30\n",
      "\u001b[1m46/46\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - loss: 0.0061 - val_loss: 0.0135\n",
      "Epoch 9/30\n",
      "\u001b[1m46/46\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - loss: 0.0052 - val_loss: 0.0071\n",
      "Epoch 10/30\n",
      "\u001b[1m46/46\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - loss: 0.0046 - val_loss: 0.0080\n",
      "Epoch 11/30\n",
      "\u001b[1m46/46\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - loss: 0.0050 - val_loss: 0.0104\n",
      "Epoch 12/30\n",
      "\u001b[1m46/46\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - loss: 0.0048 - val_loss: 0.0054\n",
      "Epoch 13/30\n",
      "\u001b[1m46/46\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - loss: 0.0041 - val_loss: 0.0051\n",
      "Epoch 14/30\n",
      "\u001b[1m46/46\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - loss: 0.0045 - val_loss: 0.0042\n",
      "Epoch 15/30\n",
      "\u001b[1m46/46\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - loss: 0.0035 - val_loss: 0.0040\n",
      "Epoch 16/30\n",
      "\u001b[1m46/46\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - loss: 0.0051 - val_loss: 0.0040\n",
      "Epoch 17/30\n",
      "\u001b[1m46/46\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - loss: 0.0037 - val_loss: 0.0038\n",
      "Epoch 18/30\n",
      "\u001b[1m46/46\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - loss: 0.0038 - val_loss: 0.0037\n",
      "Epoch 19/30\n",
      "\u001b[1m46/46\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - loss: 0.0037 - val_loss: 0.0042\n",
      "Epoch 20/30\n",
      "\u001b[1m46/46\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - loss: 0.0033 - val_loss: 0.0041\n",
      "Epoch 21/30\n",
      "\u001b[1m46/46\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - loss: 0.0031 - val_loss: 0.0061\n",
      "Epoch 22/30\n",
      "\u001b[1m46/46\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 0.0033 - val_loss: 0.0036\n",
      "Epoch 23/30\n",
      "\u001b[1m46/46\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - loss: 0.0029 - val_loss: 0.0044\n",
      "Epoch 24/30\n",
      "\u001b[1m46/46\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - loss: 0.0047 - val_loss: 0.0045\n",
      "Epoch 25/30\n",
      "\u001b[1m46/46\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 0.0041 - val_loss: 0.0033\n",
      "Epoch 26/30\n",
      "\u001b[1m46/46\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - loss: 0.0030 - val_loss: 0.0032\n",
      "Epoch 27/30\n",
      "\u001b[1m46/46\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 0.0037 - val_loss: 0.0038\n",
      "Epoch 28/30\n",
      "\u001b[1m46/46\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 0.0030 - val_loss: 0.0032\n",
      "Epoch 29/30\n",
      "\u001b[1m46/46\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - loss: 0.0028 - val_loss: 0.0034\n",
      "Epoch 30/30\n",
      "\u001b[1m46/46\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 0.0034 - val_loss: 0.0035\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:The `save_format` argument is deprecated in Keras 3. We recommend removing this argument as it can be inferred from the file path. Received: save_format=keras\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Finished: Russia | MAE: 0.18 | RMSE: 0.28 | R²: 0.82\n",
      "Epoch 1/30\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/dejauhnaebeadle/School/MachineLearning/machine-learning-project/code/rain-prediction/.venv/lib/python3.11/site-packages/keras/src/layers/rnn/rnn.py:200: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
      "  super().__init__(**kwargs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m46/46\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 11ms/step - loss: 0.0333 - val_loss: 0.0044\n",
      "Epoch 2/30\n",
      "\u001b[1m46/46\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 0.0051 - val_loss: 0.0036\n",
      "Epoch 3/30\n",
      "\u001b[1m46/46\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 0.0043 - val_loss: 0.0024\n",
      "Epoch 4/30\n",
      "\u001b[1m46/46\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 0.0038 - val_loss: 0.0020\n",
      "Epoch 5/30\n",
      "\u001b[1m46/46\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 0.0034 - val_loss: 0.0021\n",
      "Epoch 6/30\n",
      "\u001b[1m46/46\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 0.0037 - val_loss: 0.0019\n",
      "Epoch 7/30\n",
      "\u001b[1m46/46\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 0.0026 - val_loss: 0.0023\n",
      "Epoch 8/30\n",
      "\u001b[1m46/46\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 0.0025 - val_loss: 0.0020\n",
      "Epoch 9/30\n",
      "\u001b[1m46/46\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - loss: 0.0026 - val_loss: 0.0013\n",
      "Epoch 10/30\n",
      "\u001b[1m46/46\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 0.0021 - val_loss: 0.0027\n",
      "Epoch 11/30\n",
      "\u001b[1m46/46\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - loss: 0.0026 - val_loss: 0.0013\n",
      "Epoch 12/30\n",
      "\u001b[1m46/46\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - loss: 0.0020 - val_loss: 0.0013\n",
      "Epoch 13/30\n",
      "\u001b[1m46/46\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - loss: 0.0019 - val_loss: 0.0019\n",
      "Epoch 14/30\n",
      "\u001b[1m46/46\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - loss: 0.0019 - val_loss: 0.0011\n",
      "Epoch 15/30\n",
      "\u001b[1m46/46\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - loss: 0.0017 - val_loss: 0.0022\n",
      "Epoch 16/30\n",
      "\u001b[1m46/46\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - loss: 0.0016 - val_loss: 0.0025\n",
      "Epoch 17/30\n",
      "\u001b[1m46/46\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - loss: 0.0020 - val_loss: 0.0011\n",
      "Epoch 18/30\n",
      "\u001b[1m46/46\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - loss: 0.0016 - val_loss: 0.0015\n",
      "Epoch 19/30\n",
      "\u001b[1m46/46\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - loss: 0.0018 - val_loss: 8.9732e-04\n",
      "Epoch 20/30\n",
      "\u001b[1m46/46\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - loss: 0.0018 - val_loss: 0.0013\n",
      "Epoch 21/30\n",
      "\u001b[1m46/46\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - loss: 0.0016 - val_loss: 9.9230e-04\n",
      "Epoch 22/30\n",
      "\u001b[1m46/46\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - loss: 0.0014 - val_loss: 0.0012\n",
      "Epoch 23/30\n",
      "\u001b[1m46/46\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - loss: 0.0018 - val_loss: 7.8833e-04\n",
      "Epoch 24/30\n",
      "\u001b[1m46/46\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 0.0013 - val_loss: 0.0011\n",
      "Epoch 25/30\n",
      "\u001b[1m46/46\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - loss: 0.0016 - val_loss: 7.8369e-04\n",
      "Epoch 26/30\n",
      "\u001b[1m46/46\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - loss: 0.0016 - val_loss: 8.1897e-04\n",
      "Epoch 27/30\n",
      "\u001b[1m46/46\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - loss: 0.0014 - val_loss: 8.0507e-04\n",
      "Epoch 28/30\n",
      "\u001b[1m46/46\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - loss: 0.0010 - val_loss: 0.0019\n",
      "Epoch 29/30\n",
      "\u001b[1m46/46\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - loss: 0.0012 - val_loss: 0.0011\n",
      "Epoch 30/30\n",
      "\u001b[1m46/46\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - loss: 0.0013 - val_loss: 7.1476e-04\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:The `save_format` argument is deprecated in Keras 3. We recommend removing this argument as it can be inferred from the file path. Received: save_format=keras\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Finished: Rwanda | MAE: 0.06 | RMSE: 0.12 | R²: 0.93\n",
      "Epoch 1/30\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/dejauhnaebeadle/School/MachineLearning/machine-learning-project/code/rain-prediction/.venv/lib/python3.11/site-packages/keras/src/layers/rnn/rnn.py:200: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
      "  super().__init__(**kwargs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m46/46\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 12ms/step - loss: 0.0791 - val_loss: 0.0142\n",
      "Epoch 2/30\n",
      "\u001b[1m46/46\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - loss: 0.0116 - val_loss: 0.0147\n",
      "Epoch 3/30\n",
      "\u001b[1m46/46\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - loss: 0.0088 - val_loss: 0.0129\n",
      "Epoch 4/30\n",
      "\u001b[1m46/46\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - loss: 0.0075 - val_loss: 0.0109\n",
      "Epoch 5/30\n",
      "\u001b[1m46/46\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - loss: 0.0078 - val_loss: 0.0104\n",
      "Epoch 6/30\n",
      "\u001b[1m46/46\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - loss: 0.0065 - val_loss: 0.0088\n",
      "Epoch 7/30\n",
      "\u001b[1m46/46\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - loss: 0.0060 - val_loss: 0.0092\n",
      "Epoch 8/30\n",
      "\u001b[1m46/46\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - loss: 0.0064 - val_loss: 0.0083\n",
      "Epoch 9/30\n",
      "\u001b[1m46/46\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - loss: 0.0058 - val_loss: 0.0083\n",
      "Epoch 10/30\n",
      "\u001b[1m46/46\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - loss: 0.0054 - val_loss: 0.0080\n",
      "Epoch 11/30\n",
      "\u001b[1m46/46\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - loss: 0.0049 - val_loss: 0.0076\n",
      "Epoch 12/30\n",
      "\u001b[1m46/46\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - loss: 0.0049 - val_loss: 0.0073\n",
      "Epoch 13/30\n",
      "\u001b[1m46/46\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - loss: 0.0044 - val_loss: 0.0069\n",
      "Epoch 14/30\n",
      "\u001b[1m46/46\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - loss: 0.0051 - val_loss: 0.0067\n",
      "Epoch 15/30\n",
      "\u001b[1m46/46\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - loss: 0.0039 - val_loss: 0.0066\n",
      "Epoch 16/30\n",
      "\u001b[1m46/46\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - loss: 0.0037 - val_loss: 0.0069\n",
      "Epoch 17/30\n",
      "\u001b[1m46/46\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - loss: 0.0042 - val_loss: 0.0064\n",
      "Epoch 18/30\n",
      "\u001b[1m46/46\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - loss: 0.0041 - val_loss: 0.0064\n",
      "Epoch 19/30\n",
      "\u001b[1m46/46\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - loss: 0.0044 - val_loss: 0.0061\n",
      "Epoch 20/30\n",
      "\u001b[1m46/46\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - loss: 0.0035 - val_loss: 0.0059\n",
      "Epoch 21/30\n",
      "\u001b[1m46/46\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - loss: 0.0044 - val_loss: 0.0057\n",
      "Epoch 22/30\n",
      "\u001b[1m46/46\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - loss: 0.0034 - val_loss: 0.0058\n",
      "Epoch 23/30\n",
      "\u001b[1m46/46\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 11ms/step - loss: 0.0041 - val_loss: 0.0056\n",
      "Epoch 24/30\n",
      "\u001b[1m46/46\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - loss: 0.0035 - val_loss: 0.0054\n",
      "Epoch 25/30\n",
      "\u001b[1m46/46\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - loss: 0.0032 - val_loss: 0.0054\n",
      "Epoch 26/30\n",
      "\u001b[1m46/46\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - loss: 0.0030 - val_loss: 0.0053\n",
      "Epoch 27/30\n",
      "\u001b[1m46/46\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 13ms/step - loss: 0.0039 - val_loss: 0.0052\n",
      "Epoch 28/30\n",
      "\u001b[1m46/46\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - loss: 0.0030 - val_loss: 0.0051\n",
      "Epoch 29/30\n",
      "\u001b[1m46/46\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 11ms/step - loss: 0.0031 - val_loss: 0.0050\n",
      "Epoch 30/30\n",
      "\u001b[1m46/46\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - loss: 0.0044 - val_loss: 0.0050\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:The `save_format` argument is deprecated in Keras 3. We recommend removing this argument as it can be inferred from the file path. Received: save_format=keras\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Finished: Saint Helena | MAE: 0.04 | RMSE: 0.08 | R²: 0.89\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/dejauhnaebeadle/School/MachineLearning/machine-learning-project/code/rain-prediction/.venv/lib/python3.11/site-packages/keras/src/layers/rnn/rnn.py:200: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
      "  super().__init__(**kwargs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/30\n",
      "\u001b[1m46/46\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 19ms/step - loss: 0.0340 - val_loss: 0.0079\n",
      "Epoch 2/30\n",
      "\u001b[1m46/46\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 0.0066 - val_loss: 0.0075\n",
      "Epoch 3/30\n",
      "\u001b[1m46/46\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 0.0053 - val_loss: 0.0078\n",
      "Epoch 4/30\n",
      "\u001b[1m46/46\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 0.0048 - val_loss: 0.0048\n",
      "Epoch 5/30\n",
      "\u001b[1m46/46\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - loss: 0.0031 - val_loss: 0.0059\n",
      "Epoch 6/30\n",
      "\u001b[1m46/46\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 0.0046 - val_loss: 0.0050\n",
      "Epoch 7/30\n",
      "\u001b[1m46/46\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - loss: 0.0030 - val_loss: 0.0046\n",
      "Epoch 8/30\n",
      "\u001b[1m46/46\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - loss: 0.0036 - val_loss: 0.0022\n",
      "Epoch 9/30\n",
      "\u001b[1m46/46\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 0.0035 - val_loss: 0.0022\n",
      "Epoch 10/30\n",
      "\u001b[1m46/46\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 0.0031 - val_loss: 0.0047\n",
      "Epoch 11/30\n",
      "\u001b[1m46/46\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 0.0025 - val_loss: 0.0024\n",
      "Epoch 12/30\n",
      "\u001b[1m46/46\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 0.0029 - val_loss: 0.0021\n",
      "Epoch 13/30\n",
      "\u001b[1m46/46\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 0.0027 - val_loss: 0.0024\n",
      "Epoch 14/30\n",
      "\u001b[1m46/46\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 0.0030 - val_loss: 0.0021\n",
      "Epoch 15/30\n",
      "\u001b[1m46/46\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 0.0030 - val_loss: 0.0017\n",
      "Epoch 16/30\n",
      "\u001b[1m46/46\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 0.0026 - val_loss: 0.0023\n",
      "Epoch 17/30\n",
      "\u001b[1m46/46\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - loss: 0.0025 - val_loss: 0.0032\n",
      "Epoch 18/30\n",
      "\u001b[1m46/46\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 0.0020 - val_loss: 0.0030\n",
      "Epoch 19/30\n",
      "\u001b[1m46/46\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 0.0024 - val_loss: 0.0025\n",
      "Epoch 20/30\n",
      "\u001b[1m46/46\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 0.0029 - val_loss: 0.0024\n",
      "Epoch 21/30\n",
      "\u001b[1m46/46\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 0.0029 - val_loss: 0.0016\n",
      "Epoch 22/30\n",
      "\u001b[1m46/46\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 0.0022 - val_loss: 0.0023\n",
      "Epoch 23/30\n",
      "\u001b[1m46/46\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - loss: 0.0025 - val_loss: 0.0015\n",
      "Epoch 24/30\n",
      "\u001b[1m46/46\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - loss: 0.0022 - val_loss: 0.0013\n",
      "Epoch 25/30\n",
      "\u001b[1m46/46\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 0.0018 - val_loss: 0.0015\n",
      "Epoch 26/30\n",
      "\u001b[1m46/46\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - loss: 0.0021 - val_loss: 0.0020\n",
      "Epoch 27/30\n",
      "\u001b[1m46/46\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 0.0024 - val_loss: 0.0013\n",
      "Epoch 28/30\n",
      "\u001b[1m46/46\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - loss: 0.0016 - val_loss: 0.0016\n",
      "Epoch 29/30\n",
      "\u001b[1m46/46\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - loss: 0.0020 - val_loss: 0.0013\n",
      "Epoch 30/30\n",
      "\u001b[1m46/46\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 0.0022 - val_loss: 0.0023\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:The `save_format` argument is deprecated in Keras 3. We recommend removing this argument as it can be inferred from the file path. Received: save_format=keras\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Finished: Saint Vincent and the Grenadines | MAE: 0.08 | RMSE: 0.11 | R²: 0.84\n",
      "Epoch 1/30\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/dejauhnaebeadle/School/MachineLearning/machine-learning-project/code/rain-prediction/.venv/lib/python3.11/site-packages/keras/src/layers/rnn/rnn.py:200: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
      "  super().__init__(**kwargs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m46/46\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 12ms/step - loss: 0.0523 - val_loss: 0.0133\n",
      "Epoch 2/30\n",
      "\u001b[1m46/46\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - loss: 0.0066 - val_loss: 0.0168\n",
      "Epoch 3/30\n",
      "\u001b[1m46/46\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - loss: 0.0058 - val_loss: 0.0088\n",
      "Epoch 4/30\n",
      "\u001b[1m46/46\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 0.0052 - val_loss: 0.0080\n",
      "Epoch 5/30\n",
      "\u001b[1m46/46\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 0.0041 - val_loss: 0.0095\n",
      "Epoch 6/30\n",
      "\u001b[1m46/46\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 0.0038 - val_loss: 0.0096\n",
      "Epoch 7/30\n",
      "\u001b[1m46/46\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 0.0031 - val_loss: 0.0083\n",
      "Epoch 8/30\n",
      "\u001b[1m46/46\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - loss: 0.0032 - val_loss: 0.0075\n",
      "Epoch 9/30\n",
      "\u001b[1m46/46\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 0.0024 - val_loss: 0.0081\n",
      "Epoch 10/30\n",
      "\u001b[1m46/46\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 0.0032 - val_loss: 0.0050\n",
      "Epoch 11/30\n",
      "\u001b[1m46/46\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 0.0028 - val_loss: 0.0050\n",
      "Epoch 12/30\n",
      "\u001b[1m46/46\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - loss: 0.0030 - val_loss: 0.0047\n",
      "Epoch 13/30\n",
      "\u001b[1m46/46\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 0.0028 - val_loss: 0.0046\n",
      "Epoch 14/30\n",
      "\u001b[1m46/46\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - loss: 0.0026 - val_loss: 0.0053\n",
      "Epoch 15/30\n",
      "\u001b[1m46/46\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 11ms/step - loss: 0.0023 - val_loss: 0.0045\n",
      "Epoch 16/30\n",
      "\u001b[1m46/46\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - loss: 0.0024 - val_loss: 0.0042\n",
      "Epoch 17/30\n",
      "\u001b[1m46/46\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 0.0026 - val_loss: 0.0042\n",
      "Epoch 18/30\n",
      "\u001b[1m46/46\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - loss: 0.0019 - val_loss: 0.0045\n",
      "Epoch 19/30\n",
      "\u001b[1m46/46\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - loss: 0.0026 - val_loss: 0.0040\n",
      "Epoch 20/30\n",
      "\u001b[1m46/46\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - loss: 0.0024 - val_loss: 0.0041\n",
      "Epoch 21/30\n",
      "\u001b[1m46/46\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - loss: 0.0018 - val_loss: 0.0039\n",
      "Epoch 22/30\n",
      "\u001b[1m46/46\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - loss: 0.0025 - val_loss: 0.0049\n",
      "Epoch 23/30\n",
      "\u001b[1m46/46\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - loss: 0.0021 - val_loss: 0.0040\n",
      "Epoch 24/30\n",
      "\u001b[1m46/46\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - loss: 0.0024 - val_loss: 0.0053\n",
      "Epoch 25/30\n",
      "\u001b[1m46/46\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - loss: 0.0021 - val_loss: 0.0035\n",
      "Epoch 26/30\n",
      "\u001b[1m46/46\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - loss: 0.0018 - val_loss: 0.0036\n",
      "Epoch 27/30\n",
      "\u001b[1m46/46\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - loss: 0.0018 - val_loss: 0.0039\n",
      "Epoch 28/30\n",
      "\u001b[1m46/46\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - loss: 0.0016 - val_loss: 0.0034\n",
      "Epoch 29/30\n",
      "\u001b[1m46/46\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - loss: 0.0017 - val_loss: 0.0034\n",
      "Epoch 30/30\n",
      "\u001b[1m46/46\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - loss: 0.0016 - val_loss: 0.0036\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:The `save_format` argument is deprecated in Keras 3. We recommend removing this argument as it can be inferred from the file path. Received: save_format=keras\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Finished: Samoa | MAE: 0.05 | RMSE: 0.09 | R²: 0.88\n",
      "Epoch 1/30\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/dejauhnaebeadle/School/MachineLearning/machine-learning-project/code/rain-prediction/.venv/lib/python3.11/site-packages/keras/src/layers/rnn/rnn.py:200: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
      "  super().__init__(**kwargs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m46/46\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 13ms/step - loss: 0.0257 - val_loss: 0.0043\n",
      "Epoch 2/30\n",
      "\u001b[1m46/46\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 0.0072 - val_loss: 0.0047\n",
      "Epoch 3/30\n",
      "\u001b[1m46/46\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 0.0064 - val_loss: 0.0031\n",
      "Epoch 4/30\n",
      "\u001b[1m46/46\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 0.0062 - val_loss: 0.0044\n",
      "Epoch 5/30\n",
      "\u001b[1m46/46\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 0.0058 - val_loss: 0.0056\n",
      "Epoch 6/30\n",
      "\u001b[1m46/46\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 0.0050 - val_loss: 0.0023\n",
      "Epoch 7/30\n",
      "\u001b[1m46/46\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 0.0046 - val_loss: 0.0023\n",
      "Epoch 8/30\n",
      "\u001b[1m46/46\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 0.0042 - val_loss: 0.0021\n",
      "Epoch 9/30\n",
      "\u001b[1m46/46\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - loss: 0.0046 - val_loss: 0.0041\n",
      "Epoch 10/30\n",
      "\u001b[1m46/46\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 10ms/step - loss: 0.0039 - val_loss: 0.0021\n",
      "Epoch 11/30\n",
      "\u001b[1m46/46\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 0.0033 - val_loss: 0.0031\n",
      "Epoch 12/30\n",
      "\u001b[1m46/46\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - loss: 0.0038 - val_loss: 0.0019\n",
      "Epoch 13/30\n",
      "\u001b[1m46/46\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 0.0041 - val_loss: 0.0020\n",
      "Epoch 14/30\n",
      "\u001b[1m46/46\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - loss: 0.0036 - val_loss: 0.0022\n",
      "Epoch 15/30\n",
      "\u001b[1m46/46\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 0.0039 - val_loss: 0.0017\n",
      "Epoch 16/30\n",
      "\u001b[1m46/46\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - loss: 0.0032 - val_loss: 0.0016\n",
      "Epoch 17/30\n",
      "\u001b[1m46/46\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 0.0030 - val_loss: 0.0022\n",
      "Epoch 18/30\n",
      "\u001b[1m46/46\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - loss: 0.0034 - val_loss: 0.0018\n",
      "Epoch 19/30\n",
      "\u001b[1m46/46\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - loss: 0.0031 - val_loss: 0.0026\n",
      "Epoch 20/30\n",
      "\u001b[1m46/46\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - loss: 0.0024 - val_loss: 0.0016\n",
      "Epoch 21/30\n",
      "\u001b[1m46/46\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 0.0040 - val_loss: 0.0015\n",
      "Epoch 22/30\n",
      "\u001b[1m46/46\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 0.0029 - val_loss: 0.0016\n",
      "Epoch 23/30\n",
      "\u001b[1m46/46\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - loss: 0.0031 - val_loss: 0.0015\n",
      "Epoch 24/30\n",
      "\u001b[1m46/46\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - loss: 0.0030 - val_loss: 0.0015\n",
      "Epoch 25/30\n",
      "\u001b[1m46/46\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 0.0024 - val_loss: 0.0020\n",
      "Epoch 26/30\n",
      "\u001b[1m46/46\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 0.0031 - val_loss: 0.0016\n",
      "Epoch 27/30\n",
      "\u001b[1m46/46\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 0.0020 - val_loss: 0.0015\n",
      "Epoch 28/30\n",
      "\u001b[1m46/46\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - loss: 0.0023 - val_loss: 0.0018\n",
      "Epoch 29/30\n",
      "\u001b[1m46/46\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 0.0023 - val_loss: 0.0014\n",
      "Epoch 30/30\n",
      "\u001b[1m46/46\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 0.0018 - val_loss: 0.0014\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:The `save_format` argument is deprecated in Keras 3. We recommend removing this argument as it can be inferred from the file path. Received: save_format=keras\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Finished: Sao Tome and Principe | MAE: 0.04 | RMSE: 0.08 | R²: 0.93\n",
      "Epoch 1/30\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/dejauhnaebeadle/School/MachineLearning/machine-learning-project/code/rain-prediction/.venv/lib/python3.11/site-packages/keras/src/layers/rnn/rnn.py:200: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
      "  super().__init__(**kwargs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m46/46\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 13ms/step - loss: 0.0526 - val_loss: 8.0470e-04\n",
      "Epoch 2/30\n",
      "\u001b[1m46/46\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - loss: 0.0071 - val_loss: 0.0018\n",
      "Epoch 3/30\n",
      "\u001b[1m46/46\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - loss: 0.0062 - val_loss: 5.0616e-04\n",
      "Epoch 4/30\n",
      "\u001b[1m46/46\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - loss: 0.0050 - val_loss: 5.0305e-04\n",
      "Epoch 5/30\n",
      "\u001b[1m46/46\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - loss: 0.0048 - val_loss: 0.0011\n",
      "Epoch 6/30\n",
      "\u001b[1m46/46\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 0.0045 - val_loss: 7.3906e-04\n",
      "Epoch 7/30\n",
      "\u001b[1m46/46\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 0.0036 - val_loss: 0.0012\n",
      "Epoch 8/30\n",
      "\u001b[1m46/46\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 0.0037 - val_loss: 0.0013\n",
      "Epoch 9/30\n",
      "\u001b[1m46/46\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 0.0038 - val_loss: 0.0024\n",
      "Epoch 10/30\n",
      "\u001b[1m46/46\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - loss: 0.0035 - val_loss: 3.2628e-04\n",
      "Epoch 11/30\n",
      "\u001b[1m46/46\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - loss: 0.0033 - val_loss: 0.0011\n",
      "Epoch 12/30\n",
      "\u001b[1m46/46\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 0.0031 - val_loss: 3.0611e-04\n",
      "Epoch 13/30\n",
      "\u001b[1m46/46\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - loss: 0.0028 - val_loss: 4.2730e-04\n",
      "Epoch 14/30\n",
      "\u001b[1m46/46\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 0.0029 - val_loss: 3.8372e-04\n",
      "Epoch 15/30\n",
      "\u001b[1m46/46\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - loss: 0.0030 - val_loss: 5.1741e-04\n",
      "Epoch 16/30\n",
      "\u001b[1m46/46\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - loss: 0.0026 - val_loss: 0.0022\n",
      "Epoch 17/30\n",
      "\u001b[1m46/46\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - loss: 0.0030 - val_loss: 0.0011\n",
      "Epoch 18/30\n",
      "\u001b[1m46/46\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - loss: 0.0025 - val_loss: 7.7141e-04\n",
      "Epoch 19/30\n",
      "\u001b[1m46/46\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - loss: 0.0024 - val_loss: 8.0613e-04\n",
      "Epoch 20/30\n",
      "\u001b[1m46/46\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - loss: 0.0023 - val_loss: 2.8771e-04\n",
      "Epoch 21/30\n",
      "\u001b[1m46/46\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - loss: 0.0025 - val_loss: 3.8529e-04\n",
      "Epoch 22/30\n",
      "\u001b[1m46/46\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - loss: 0.0018 - val_loss: 2.9051e-04\n",
      "Epoch 23/30\n",
      "\u001b[1m46/46\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - loss: 0.0018 - val_loss: 3.4021e-04\n",
      "Epoch 24/30\n",
      "\u001b[1m46/46\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - loss: 0.0021 - val_loss: 3.2186e-04\n",
      "Epoch 25/30\n",
      "\u001b[1m46/46\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - loss: 0.0018 - val_loss: 7.8756e-04\n",
      "Epoch 26/30\n",
      "\u001b[1m46/46\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - loss: 0.0024 - val_loss: 0.0012\n",
      "Epoch 27/30\n",
      "\u001b[1m46/46\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - loss: 0.0020 - val_loss: 7.5028e-04\n",
      "Epoch 28/30\n",
      "\u001b[1m46/46\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - loss: 0.0020 - val_loss: 7.1581e-04\n",
      "Epoch 29/30\n",
      "\u001b[1m46/46\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - loss: 0.0019 - val_loss: 0.0011\n",
      "Epoch 30/30\n",
      "\u001b[1m46/46\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - loss: 0.0020 - val_loss: 2.3467e-04\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:The `save_format` argument is deprecated in Keras 3. We recommend removing this argument as it can be inferred from the file path. Received: save_format=keras\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Finished: Saudi Arabia | MAE: 0.06 | RMSE: 0.14 | R²: 0.89\n",
      "Epoch 1/30\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/dejauhnaebeadle/School/MachineLearning/machine-learning-project/code/rain-prediction/.venv/lib/python3.11/site-packages/keras/src/layers/rnn/rnn.py:200: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
      "  super().__init__(**kwargs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m46/46\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 13ms/step - loss: 0.1372 - val_loss: 0.0042\n",
      "Epoch 2/30\n",
      "\u001b[1m46/46\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - loss: 0.0121 - val_loss: 0.0030\n",
      "Epoch 3/30\n",
      "\u001b[1m46/46\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - loss: 0.0100 - val_loss: 0.0018\n",
      "Epoch 4/30\n",
      "\u001b[1m46/46\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 0.0092 - val_loss: 0.0013\n",
      "Epoch 5/30\n",
      "\u001b[1m46/46\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 0.0069 - val_loss: 0.0016\n",
      "Epoch 6/30\n",
      "\u001b[1m46/46\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 0.0071 - val_loss: 0.0010\n",
      "Epoch 7/30\n",
      "\u001b[1m46/46\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - loss: 0.0064 - val_loss: 0.0014\n",
      "Epoch 8/30\n",
      "\u001b[1m46/46\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - loss: 0.0055 - val_loss: 0.0014\n",
      "Epoch 9/30\n",
      "\u001b[1m46/46\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - loss: 0.0050 - val_loss: 0.0043\n",
      "Epoch 10/30\n",
      "\u001b[1m46/46\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 0.0051 - val_loss: 0.0025\n",
      "Epoch 11/30\n",
      "\u001b[1m46/46\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - loss: 0.0056 - val_loss: 0.0048\n",
      "Epoch 12/30\n",
      "\u001b[1m46/46\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - loss: 0.0049 - val_loss: 0.0012\n",
      "Epoch 13/30\n",
      "\u001b[1m46/46\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 0.0045 - val_loss: 0.0017\n",
      "Epoch 14/30\n",
      "\u001b[1m46/46\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 0.0050 - val_loss: 6.6976e-04\n",
      "Epoch 15/30\n",
      "\u001b[1m46/46\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 0.0043 - val_loss: 9.6757e-04\n",
      "Epoch 16/30\n",
      "\u001b[1m46/46\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - loss: 0.0056 - val_loss: 8.2371e-04\n",
      "Epoch 17/30\n",
      "\u001b[1m46/46\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - loss: 0.0041 - val_loss: 7.3885e-04\n",
      "Epoch 18/30\n",
      "\u001b[1m46/46\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - loss: 0.0041 - val_loss: 8.3811e-04\n",
      "Epoch 19/30\n",
      "\u001b[1m46/46\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - loss: 0.0035 - val_loss: 9.0104e-04\n",
      "Epoch 20/30\n",
      "\u001b[1m46/46\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - loss: 0.0043 - val_loss: 0.0015\n",
      "Epoch 21/30\n",
      "\u001b[1m46/46\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 0.0040 - val_loss: 6.5740e-04\n",
      "Epoch 22/30\n",
      "\u001b[1m46/46\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - loss: 0.0039 - val_loss: 5.1948e-04\n",
      "Epoch 23/30\n",
      "\u001b[1m46/46\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 0.0029 - val_loss: 6.5956e-04\n",
      "Epoch 24/30\n",
      "\u001b[1m46/46\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - loss: 0.0039 - val_loss: 4.9057e-04\n",
      "Epoch 25/30\n",
      "\u001b[1m46/46\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 0.0032 - val_loss: 9.2324e-04\n",
      "Epoch 26/30\n",
      "\u001b[1m46/46\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 0.0030 - val_loss: 0.0020\n",
      "Epoch 27/30\n",
      "\u001b[1m46/46\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 0.0040 - val_loss: 4.5863e-04\n",
      "Epoch 28/30\n",
      "\u001b[1m46/46\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - loss: 0.0028 - val_loss: 5.0667e-04\n",
      "Epoch 29/30\n",
      "\u001b[1m46/46\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - loss: 0.0028 - val_loss: 0.0012\n",
      "Epoch 30/30\n",
      "\u001b[1m46/46\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - loss: 0.0034 - val_loss: 4.5144e-04\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:The `save_format` argument is deprecated in Keras 3. We recommend removing this argument as it can be inferred from the file path. Received: save_format=keras\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Finished: Senegal | MAE: 0.05 | RMSE: 0.11 | R²: 0.85\n",
      "Epoch 1/30\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/dejauhnaebeadle/School/MachineLearning/machine-learning-project/code/rain-prediction/.venv/lib/python3.11/site-packages/keras/src/layers/rnn/rnn.py:200: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
      "  super().__init__(**kwargs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m46/46\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 11ms/step - loss: 0.0611 - val_loss: 0.0052\n",
      "Epoch 2/30\n",
      "\u001b[1m46/46\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 0.0063 - val_loss: 0.0056\n",
      "Epoch 3/30\n",
      "\u001b[1m46/46\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - loss: 0.0061 - val_loss: 0.0065\n",
      "Epoch 4/30\n",
      "\u001b[1m46/46\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 0.0058 - val_loss: 0.0068\n",
      "Epoch 5/30\n",
      "\u001b[1m46/46\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - loss: 0.0056 - val_loss: 0.0051\n",
      "Epoch 6/30\n",
      "\u001b[1m46/46\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - loss: 0.0048 - val_loss: 0.0051\n",
      "Epoch 7/30\n",
      "\u001b[1m46/46\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - loss: 0.0037 - val_loss: 0.0045\n",
      "Epoch 8/30\n",
      "\u001b[1m46/46\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 0.0037 - val_loss: 0.0031\n",
      "Epoch 9/30\n",
      "\u001b[1m46/46\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 0.0037 - val_loss: 0.0041\n",
      "Epoch 10/30\n",
      "\u001b[1m46/46\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 0.0038 - val_loss: 0.0028\n",
      "Epoch 11/30\n",
      "\u001b[1m46/46\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - loss: 0.0032 - val_loss: 0.0037\n",
      "Epoch 12/30\n",
      "\u001b[1m46/46\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - loss: 0.0035 - val_loss: 0.0029\n",
      "Epoch 13/30\n",
      "\u001b[1m46/46\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 0.0031 - val_loss: 0.0038\n",
      "Epoch 14/30\n",
      "\u001b[1m46/46\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 0.0030 - val_loss: 0.0044\n",
      "Epoch 15/30\n",
      "\u001b[1m46/46\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - loss: 0.0037 - val_loss: 0.0025\n",
      "Epoch 16/30\n",
      "\u001b[1m46/46\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - loss: 0.0024 - val_loss: 0.0025\n",
      "Epoch 17/30\n",
      "\u001b[1m46/46\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - loss: 0.0024 - val_loss: 0.0031\n",
      "Epoch 18/30\n",
      "\u001b[1m46/46\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - loss: 0.0029 - val_loss: 0.0021\n",
      "Epoch 19/30\n",
      "\u001b[1m46/46\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - loss: 0.0030 - val_loss: 0.0022\n",
      "Epoch 20/30\n",
      "\u001b[1m46/46\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - loss: 0.0026 - val_loss: 0.0023\n",
      "Epoch 21/30\n",
      "\u001b[1m46/46\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - loss: 0.0025 - val_loss: 0.0026\n",
      "Epoch 22/30\n",
      "\u001b[1m46/46\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - loss: 0.0028 - val_loss: 0.0027\n",
      "Epoch 23/30\n",
      "\u001b[1m46/46\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - loss: 0.0029 - val_loss: 0.0024\n",
      "Epoch 24/30\n",
      "\u001b[1m46/46\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - loss: 0.0028 - val_loss: 0.0023\n",
      "Epoch 25/30\n",
      "\u001b[1m46/46\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - loss: 0.0030 - val_loss: 0.0020\n",
      "Epoch 26/30\n",
      "\u001b[1m46/46\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - loss: 0.0026 - val_loss: 0.0025\n",
      "Epoch 27/30\n",
      "\u001b[1m46/46\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - loss: 0.0025 - val_loss: 0.0019\n",
      "Epoch 28/30\n",
      "\u001b[1m46/46\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - loss: 0.0021 - val_loss: 0.0020\n",
      "Epoch 29/30\n",
      "\u001b[1m46/46\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - loss: 0.0023 - val_loss: 0.0017\n",
      "Epoch 30/30\n",
      "\u001b[1m46/46\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - loss: 0.0027 - val_loss: 0.0023\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:The `save_format` argument is deprecated in Keras 3. We recommend removing this argument as it can be inferred from the file path. Received: save_format=keras\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Finished: Serbia | MAE: 0.25 | RMSE: 0.28 | R²: 0.71\n",
      "Epoch 1/30\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/dejauhnaebeadle/School/MachineLearning/machine-learning-project/code/rain-prediction/.venv/lib/python3.11/site-packages/keras/src/layers/rnn/rnn.py:200: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
      "  super().__init__(**kwargs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m46/46\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 12ms/step - loss: 0.0434 - val_loss: 0.0066\n",
      "Epoch 2/30\n",
      "\u001b[1m46/46\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 0.0102 - val_loss: 0.0091\n",
      "Epoch 3/30\n",
      "\u001b[1m46/46\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 0.0091 - val_loss: 0.0063\n",
      "Epoch 4/30\n",
      "\u001b[1m46/46\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 0.0076 - val_loss: 0.0050\n",
      "Epoch 5/30\n",
      "\u001b[1m46/46\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - loss: 0.0057 - val_loss: 0.0038\n",
      "Epoch 6/30\n",
      "\u001b[1m46/46\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 0.0068 - val_loss: 0.0043\n",
      "Epoch 7/30\n",
      "\u001b[1m46/46\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 0.0047 - val_loss: 0.0038\n",
      "Epoch 8/30\n",
      "\u001b[1m46/46\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - loss: 0.0053 - val_loss: 0.0046\n",
      "Epoch 9/30\n",
      "\u001b[1m46/46\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - loss: 0.0051 - val_loss: 0.0063\n",
      "Epoch 10/30\n",
      "\u001b[1m46/46\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 0.0056 - val_loss: 0.0035\n",
      "Epoch 11/30\n",
      "\u001b[1m46/46\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 0.0034 - val_loss: 0.0039\n",
      "Epoch 12/30\n",
      "\u001b[1m46/46\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 0.0045 - val_loss: 0.0038\n",
      "Epoch 13/30\n",
      "\u001b[1m46/46\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - loss: 0.0040 - val_loss: 0.0050\n",
      "Epoch 14/30\n",
      "\u001b[1m46/46\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - loss: 0.0037 - val_loss: 0.0037\n",
      "Epoch 15/30\n",
      "\u001b[1m46/46\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 10ms/step - loss: 0.0057 - val_loss: 0.0029\n",
      "Epoch 16/30\n",
      "\u001b[1m46/46\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - loss: 0.0039 - val_loss: 0.0030\n",
      "Epoch 17/30\n",
      "\u001b[1m46/46\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - loss: 0.0041 - val_loss: 0.0035\n",
      "Epoch 18/30\n",
      "\u001b[1m46/46\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - loss: 0.0042 - val_loss: 0.0027\n",
      "Epoch 19/30\n",
      "\u001b[1m46/46\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - loss: 0.0037 - val_loss: 0.0027\n",
      "Epoch 20/30\n",
      "\u001b[1m46/46\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - loss: 0.0032 - val_loss: 0.0034\n",
      "Epoch 21/30\n",
      "\u001b[1m46/46\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 11ms/step - loss: 0.0031 - val_loss: 0.0036\n",
      "Epoch 22/30\n",
      "\u001b[1m46/46\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 11ms/step - loss: 0.0034 - val_loss: 0.0025\n",
      "Epoch 23/30\n",
      "\u001b[1m46/46\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - loss: 0.0029 - val_loss: 0.0028\n",
      "Epoch 24/30\n",
      "\u001b[1m46/46\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - loss: 0.0031 - val_loss: 0.0025\n",
      "Epoch 25/30\n",
      "\u001b[1m46/46\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - loss: 0.0023 - val_loss: 0.0043\n",
      "Epoch 26/30\n",
      "\u001b[1m46/46\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - loss: 0.0026 - val_loss: 0.0028\n",
      "Epoch 27/30\n",
      "\u001b[1m46/46\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 11ms/step - loss: 0.0039 - val_loss: 0.0024\n",
      "Epoch 28/30\n",
      "\u001b[1m46/46\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 12ms/step - loss: 0.0027 - val_loss: 0.0034\n",
      "Epoch 29/30\n",
      "\u001b[1m46/46\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 14ms/step - loss: 0.0028 - val_loss: 0.0026\n",
      "Epoch 30/30\n",
      "\u001b[1m46/46\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 13ms/step - loss: 0.0043 - val_loss: 0.0023\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:The `save_format` argument is deprecated in Keras 3. We recommend removing this argument as it can be inferred from the file path. Received: save_format=keras\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Finished: Seychelles | MAE: 0.05 | RMSE: 0.08 | R²: 0.88\n",
      "Epoch 1/30\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/dejauhnaebeadle/School/MachineLearning/machine-learning-project/code/rain-prediction/.venv/lib/python3.11/site-packages/keras/src/layers/rnn/rnn.py:200: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
      "  super().__init__(**kwargs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m46/46\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 17ms/step - loss: 0.0217 - val_loss: 8.8727e-04\n",
      "Epoch 2/30\n",
      "\u001b[1m46/46\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - loss: 0.0036 - val_loss: 0.0017\n",
      "Epoch 3/30\n",
      "\u001b[1m46/46\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - loss: 0.0032 - val_loss: 0.0017\n",
      "Epoch 4/30\n",
      "\u001b[1m46/46\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 10ms/step - loss: 0.0037 - val_loss: 0.0015\n",
      "Epoch 5/30\n",
      "\u001b[1m46/46\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - loss: 0.0035 - val_loss: 0.0018\n",
      "Epoch 6/30\n",
      "\u001b[1m46/46\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - loss: 0.0028 - val_loss: 0.0015\n",
      "Epoch 7/30\n",
      "\u001b[1m46/46\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - loss: 0.0026 - val_loss: 0.0013\n",
      "Epoch 8/30\n",
      "\u001b[1m46/46\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - loss: 0.0026 - val_loss: 6.0879e-04\n",
      "Epoch 9/30\n",
      "\u001b[1m46/46\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - loss: 0.0028 - val_loss: 0.0012\n",
      "Epoch 10/30\n",
      "\u001b[1m46/46\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - loss: 0.0023 - val_loss: 8.3652e-04\n",
      "Epoch 11/30\n",
      "\u001b[1m46/46\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - loss: 0.0020 - val_loss: 5.2007e-04\n",
      "Epoch 12/30\n",
      "\u001b[1m46/46\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - loss: 0.0023 - val_loss: 5.4246e-04\n",
      "Epoch 13/30\n",
      "\u001b[1m46/46\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - loss: 0.0026 - val_loss: 5.0135e-04\n",
      "Epoch 14/30\n",
      "\u001b[1m46/46\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - loss: 0.0019 - val_loss: 6.4775e-04\n",
      "Epoch 15/30\n",
      "\u001b[1m46/46\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - loss: 0.0024 - val_loss: 6.3511e-04\n",
      "Epoch 16/30\n",
      "\u001b[1m46/46\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - loss: 0.0017 - val_loss: 0.0010\n",
      "Epoch 17/30\n",
      "\u001b[1m46/46\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - loss: 0.0015 - val_loss: 5.7070e-04\n",
      "Epoch 18/30\n",
      "\u001b[1m46/46\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - loss: 0.0014 - val_loss: 0.0014\n",
      "Epoch 19/30\n",
      "\u001b[1m46/46\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - loss: 0.0019 - val_loss: 4.9655e-04\n",
      "Epoch 20/30\n",
      "\u001b[1m46/46\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - loss: 0.0018 - val_loss: 4.4113e-04\n",
      "Epoch 21/30\n",
      "\u001b[1m46/46\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - loss: 0.0020 - val_loss: 4.3412e-04\n",
      "Epoch 22/30\n",
      "\u001b[1m46/46\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - loss: 0.0016 - val_loss: 4.9650e-04\n",
      "Epoch 23/30\n",
      "\u001b[1m46/46\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - loss: 0.0020 - val_loss: 0.0011\n",
      "Epoch 24/30\n",
      "\u001b[1m46/46\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - loss: 0.0018 - val_loss: 6.3629e-04\n",
      "Epoch 25/30\n",
      "\u001b[1m46/46\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - loss: 0.0012 - val_loss: 8.1273e-04\n",
      "Epoch 26/30\n",
      "\u001b[1m46/46\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - loss: 0.0013 - val_loss: 0.0011\n",
      "Epoch 27/30\n",
      "\u001b[1m46/46\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - loss: 0.0017 - val_loss: 5.7622e-04\n",
      "Epoch 28/30\n",
      "\u001b[1m46/46\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - loss: 0.0011 - val_loss: 4.6946e-04\n",
      "Epoch 29/30\n",
      "\u001b[1m46/46\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 14ms/step - loss: 0.0018 - val_loss: 3.9690e-04\n",
      "Epoch 30/30\n",
      "\u001b[1m46/46\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 17ms/step - loss: 0.0014 - val_loss: 4.3761e-04\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:The `save_format` argument is deprecated in Keras 3. We recommend removing this argument as it can be inferred from the file path. Received: save_format=keras\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Finished: Sierra Leone | MAE: 0.05 | RMSE: 0.09 | R²: 0.95\n",
      "Epoch 1/30\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/dejauhnaebeadle/School/MachineLearning/machine-learning-project/code/rain-prediction/.venv/lib/python3.11/site-packages/keras/src/layers/rnn/rnn.py:200: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
      "  super().__init__(**kwargs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m46/46\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 18ms/step - loss: 0.0570 - val_loss: 0.0040\n",
      "Epoch 2/30\n",
      "\u001b[1m46/46\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - loss: 0.0060 - val_loss: 0.0088\n",
      "Epoch 3/30\n",
      "\u001b[1m46/46\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - loss: 0.0052 - val_loss: 0.0059\n",
      "Epoch 4/30\n",
      "\u001b[1m46/46\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - loss: 0.0050 - val_loss: 0.0033\n",
      "Epoch 5/30\n",
      "\u001b[1m46/46\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - loss: 0.0049 - val_loss: 0.0040\n",
      "Epoch 6/30\n",
      "\u001b[1m46/46\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - loss: 0.0044 - val_loss: 0.0054\n",
      "Epoch 7/30\n",
      "\u001b[1m46/46\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - loss: 0.0036 - val_loss: 0.0024\n",
      "Epoch 8/30\n",
      "\u001b[1m46/46\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - loss: 0.0038 - val_loss: 0.0031\n",
      "Epoch 9/30\n",
      "\u001b[1m46/46\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - loss: 0.0033 - val_loss: 0.0039\n",
      "Epoch 10/30\n",
      "\u001b[1m46/46\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 0.0030 - val_loss: 0.0048\n",
      "Epoch 11/30\n",
      "\u001b[1m46/46\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - loss: 0.0033 - val_loss: 0.0021\n",
      "Epoch 12/30\n",
      "\u001b[1m46/46\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - loss: 0.0028 - val_loss: 0.0016\n",
      "Epoch 13/30\n",
      "\u001b[1m46/46\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - loss: 0.0035 - val_loss: 0.0021\n",
      "Epoch 14/30\n",
      "\u001b[1m46/46\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - loss: 0.0022 - val_loss: 0.0019\n",
      "Epoch 15/30\n",
      "\u001b[1m46/46\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - loss: 0.0025 - val_loss: 0.0017\n",
      "Epoch 16/30\n",
      "\u001b[1m46/46\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - loss: 0.0026 - val_loss: 0.0030\n",
      "Epoch 17/30\n",
      "\u001b[1m46/46\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - loss: 0.0028 - val_loss: 0.0021\n",
      "Epoch 18/30\n",
      "\u001b[1m46/46\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - loss: 0.0027 - val_loss: 0.0020\n",
      "Epoch 19/30\n",
      "\u001b[1m46/46\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - loss: 0.0025 - val_loss: 0.0022\n",
      "Epoch 20/30\n",
      "\u001b[1m46/46\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - loss: 0.0020 - val_loss: 0.0045\n",
      "Epoch 21/30\n",
      "\u001b[1m46/46\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - loss: 0.0028 - val_loss: 0.0014\n",
      "Epoch 22/30\n",
      "\u001b[1m46/46\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - loss: 0.0020 - val_loss: 0.0015\n",
      "Epoch 23/30\n",
      "\u001b[1m46/46\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - loss: 0.0024 - val_loss: 0.0013\n",
      "Epoch 24/30\n",
      "\u001b[1m46/46\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - loss: 0.0018 - val_loss: 0.0021\n",
      "Epoch 25/30\n",
      "\u001b[1m46/46\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - loss: 0.0020 - val_loss: 0.0013\n",
      "Epoch 26/30\n",
      "\u001b[1m46/46\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - loss: 0.0021 - val_loss: 0.0016\n",
      "Epoch 27/30\n",
      "\u001b[1m46/46\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - loss: 0.0019 - val_loss: 0.0015\n",
      "Epoch 28/30\n",
      "\u001b[1m46/46\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - loss: 0.0024 - val_loss: 0.0011\n",
      "Epoch 29/30\n",
      "\u001b[1m46/46\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - loss: 0.0021 - val_loss: 0.0010\n",
      "Epoch 30/30\n",
      "\u001b[1m46/46\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - loss: 0.0022 - val_loss: 0.0014\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:The `save_format` argument is deprecated in Keras 3. We recommend removing this argument as it can be inferred from the file path. Received: save_format=keras\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Finished: Slovakia | MAE: 0.18 | RMSE: 0.26 | R²: 0.85\n",
      "Epoch 1/30\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/dejauhnaebeadle/School/MachineLearning/machine-learning-project/code/rain-prediction/.venv/lib/python3.11/site-packages/keras/src/layers/rnn/rnn.py:200: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
      "  super().__init__(**kwargs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m46/46\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 13ms/step - loss: 0.1125 - val_loss: 0.0122\n",
      "Epoch 2/30\n",
      "\u001b[1m46/46\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - loss: 0.0074 - val_loss: 0.0068\n",
      "Epoch 3/30\n",
      "\u001b[1m46/46\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - loss: 0.0066 - val_loss: 0.0069\n",
      "Epoch 4/30\n",
      "\u001b[1m46/46\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - loss: 0.0068 - val_loss: 0.0045\n",
      "Epoch 5/30\n",
      "\u001b[1m46/46\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - loss: 0.0066 - val_loss: 0.0046\n",
      "Epoch 6/30\n",
      "\u001b[1m46/46\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - loss: 0.0053 - val_loss: 0.0054\n",
      "Epoch 7/30\n",
      "\u001b[1m46/46\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 0.0046 - val_loss: 0.0067\n",
      "Epoch 8/30\n",
      "\u001b[1m46/46\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 0.0052 - val_loss: 0.0045\n",
      "Epoch 9/30\n",
      "\u001b[1m46/46\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 0.0042 - val_loss: 0.0043\n",
      "Epoch 10/30\n",
      "\u001b[1m46/46\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 0.0040 - val_loss: 0.0034\n",
      "Epoch 11/30\n",
      "\u001b[1m46/46\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - loss: 0.0035 - val_loss: 0.0046\n",
      "Epoch 12/30\n",
      "\u001b[1m46/46\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 0.0035 - val_loss: 0.0029\n",
      "Epoch 13/30\n",
      "\u001b[1m46/46\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 0.0033 - val_loss: 0.0058\n",
      "Epoch 14/30\n",
      "\u001b[1m46/46\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - loss: 0.0032 - val_loss: 0.0032\n",
      "Epoch 15/30\n",
      "\u001b[1m46/46\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - loss: 0.0024 - val_loss: 0.0022\n",
      "Epoch 16/30\n",
      "\u001b[1m46/46\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - loss: 0.0040 - val_loss: 0.0034\n",
      "Epoch 17/30\n",
      "\u001b[1m46/46\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - loss: 0.0036 - val_loss: 0.0041\n",
      "Epoch 18/30\n",
      "\u001b[1m46/46\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - loss: 0.0029 - val_loss: 0.0033\n",
      "Epoch 19/30\n",
      "\u001b[1m46/46\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - loss: 0.0026 - val_loss: 0.0018\n",
      "Epoch 20/30\n",
      "\u001b[1m46/46\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 0.0030 - val_loss: 0.0041\n",
      "Epoch 21/30\n",
      "\u001b[1m46/46\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 0.0029 - val_loss: 0.0019\n",
      "Epoch 22/30\n",
      "\u001b[1m46/46\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 0.0022 - val_loss: 0.0058\n",
      "Epoch 23/30\n",
      "\u001b[1m46/46\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 0.0022 - val_loss: 0.0017\n",
      "Epoch 24/30\n",
      "\u001b[1m46/46\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 0.0020 - val_loss: 0.0032\n",
      "Epoch 25/30\n",
      "\u001b[1m46/46\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 0.0020 - val_loss: 0.0016\n",
      "Epoch 26/30\n",
      "\u001b[1m46/46\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - loss: 0.0024 - val_loss: 0.0017\n",
      "Epoch 27/30\n",
      "\u001b[1m46/46\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 0.0024 - val_loss: 0.0015\n",
      "Epoch 28/30\n",
      "\u001b[1m46/46\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - loss: 0.0026 - val_loss: 0.0016\n",
      "Epoch 29/30\n",
      "\u001b[1m46/46\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - loss: 0.0021 - val_loss: 0.0015\n",
      "Epoch 30/30\n",
      "\u001b[1m46/46\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - loss: 0.0020 - val_loss: 0.0028\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:The `save_format` argument is deprecated in Keras 3. We recommend removing this argument as it can be inferred from the file path. Received: save_format=keras\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Finished: Slovenia | MAE: 0.28 | RMSE: 0.32 | R²: 0.64\n",
      "Epoch 1/30\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/dejauhnaebeadle/School/MachineLearning/machine-learning-project/code/rain-prediction/.venv/lib/python3.11/site-packages/keras/src/layers/rnn/rnn.py:200: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
      "  super().__init__(**kwargs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m46/46\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 14ms/step - loss: 0.0268 - val_loss: 0.0032\n",
      "Epoch 2/30\n",
      "\u001b[1m46/46\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - loss: 0.0034 - val_loss: 0.0039\n",
      "Epoch 3/30\n",
      "\u001b[1m46/46\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - loss: 0.0027 - val_loss: 0.0029\n",
      "Epoch 4/30\n",
      "\u001b[1m46/46\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 0.0024 - val_loss: 0.0029\n",
      "Epoch 5/30\n",
      "\u001b[1m46/46\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - loss: 0.0024 - val_loss: 0.0021\n",
      "Epoch 6/30\n",
      "\u001b[1m46/46\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - loss: 0.0027 - val_loss: 0.0023\n",
      "Epoch 7/30\n",
      "\u001b[1m46/46\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - loss: 0.0014 - val_loss: 0.0026\n",
      "Epoch 8/30\n",
      "\u001b[1m46/46\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - loss: 0.0021 - val_loss: 0.0035\n",
      "Epoch 9/30\n",
      "\u001b[1m46/46\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 0.0019 - val_loss: 0.0016\n",
      "Epoch 10/30\n",
      "\u001b[1m46/46\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - loss: 0.0014 - val_loss: 0.0027\n",
      "Epoch 11/30\n",
      "\u001b[1m46/46\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - loss: 0.0013 - val_loss: 0.0029\n",
      "Epoch 12/30\n",
      "\u001b[1m46/46\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - loss: 0.0013 - val_loss: 0.0016\n",
      "Epoch 13/30\n",
      "\u001b[1m46/46\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - loss: 0.0016 - val_loss: 0.0030\n",
      "Epoch 14/30\n",
      "\u001b[1m46/46\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - loss: 0.0017 - val_loss: 0.0016\n",
      "Epoch 15/30\n",
      "\u001b[1m46/46\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - loss: 0.0013 - val_loss: 0.0015\n",
      "Epoch 16/30\n",
      "\u001b[1m46/46\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - loss: 0.0012 - val_loss: 0.0018\n",
      "Epoch 17/30\n",
      "\u001b[1m46/46\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - loss: 0.0014 - val_loss: 0.0015\n",
      "Epoch 18/30\n",
      "\u001b[1m46/46\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - loss: 0.0014 - val_loss: 0.0014\n",
      "Epoch 19/30\n",
      "\u001b[1m46/46\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - loss: 0.0012 - val_loss: 0.0013\n",
      "Epoch 20/30\n",
      "\u001b[1m46/46\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - loss: 0.0013 - val_loss: 0.0014\n",
      "Epoch 21/30\n",
      "\u001b[1m46/46\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - loss: 0.0012 - val_loss: 0.0018\n",
      "Epoch 22/30\n",
      "\u001b[1m46/46\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - loss: 0.0012 - val_loss: 0.0023\n",
      "Epoch 23/30\n",
      "\u001b[1m46/46\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - loss: 0.0012 - val_loss: 0.0013\n",
      "Epoch 24/30\n",
      "\u001b[1m46/46\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - loss: 0.0011 - val_loss: 0.0014\n",
      "Epoch 25/30\n",
      "\u001b[1m46/46\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - loss: 0.0012 - val_loss: 0.0018\n",
      "Epoch 26/30\n",
      "\u001b[1m46/46\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - loss: 0.0011 - val_loss: 0.0012\n",
      "Epoch 27/30\n",
      "\u001b[1m46/46\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - loss: 7.5823e-04 - val_loss: 0.0012\n",
      "Epoch 28/30\n",
      "\u001b[1m46/46\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - loss: 9.0605e-04 - val_loss: 0.0011\n",
      "Epoch 29/30\n",
      "\u001b[1m46/46\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - loss: 0.0010 - val_loss: 0.0018\n",
      "Epoch 30/30\n",
      "\u001b[1m46/46\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - loss: 0.0012 - val_loss: 0.0014\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:The `save_format` argument is deprecated in Keras 3. We recommend removing this argument as it can be inferred from the file path. Received: save_format=keras\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Finished: Solomon Islands | MAE: 0.09 | RMSE: 0.10 | R²: 0.77\n",
      "Epoch 1/30\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/dejauhnaebeadle/School/MachineLearning/machine-learning-project/code/rain-prediction/.venv/lib/python3.11/site-packages/keras/src/layers/rnn/rnn.py:200: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
      "  super().__init__(**kwargs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m46/46\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 13ms/step - loss: 0.0463 - val_loss: 0.0040\n",
      "Epoch 2/30\n",
      "\u001b[1m46/46\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 6ms/step - loss: 0.0062 - val_loss: 0.0033\n",
      "Epoch 3/30\n",
      "\u001b[1m46/46\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - loss: 0.0052 - val_loss: 0.0025\n",
      "Epoch 4/30\n",
      "\u001b[1m46/46\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 0.0043 - val_loss: 0.0039\n",
      "Epoch 5/30\n",
      "\u001b[1m46/46\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - loss: 0.0043 - val_loss: 0.0029\n",
      "Epoch 6/30\n",
      "\u001b[1m46/46\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 0.0036 - val_loss: 0.0017\n",
      "Epoch 7/30\n",
      "\u001b[1m46/46\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 0.0038 - val_loss: 0.0020\n",
      "Epoch 8/30\n",
      "\u001b[1m46/46\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - loss: 0.0029 - val_loss: 0.0036\n",
      "Epoch 9/30\n",
      "\u001b[1m46/46\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 0.0032 - val_loss: 0.0017\n",
      "Epoch 10/30\n",
      "\u001b[1m46/46\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - loss: 0.0033 - val_loss: 0.0013\n",
      "Epoch 11/30\n",
      "\u001b[1m46/46\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - loss: 0.0032 - val_loss: 0.0020\n",
      "Epoch 12/30\n",
      "\u001b[1m46/46\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - loss: 0.0030 - val_loss: 0.0012\n",
      "Epoch 13/30\n",
      "\u001b[1m46/46\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - loss: 0.0031 - val_loss: 0.0026\n",
      "Epoch 14/30\n",
      "\u001b[1m46/46\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - loss: 0.0024 - val_loss: 0.0016\n",
      "Epoch 15/30\n",
      "\u001b[1m46/46\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - loss: 0.0027 - val_loss: 0.0017\n",
      "Epoch 16/30\n",
      "\u001b[1m46/46\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 0.0026 - val_loss: 0.0014\n",
      "Epoch 17/30\n",
      "\u001b[1m46/46\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 0.0020 - val_loss: 0.0016\n",
      "Epoch 18/30\n",
      "\u001b[1m46/46\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - loss: 0.0023 - val_loss: 0.0011\n",
      "Epoch 19/30\n",
      "\u001b[1m46/46\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - loss: 0.0025 - val_loss: 0.0011\n",
      "Epoch 20/30\n",
      "\u001b[1m46/46\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - loss: 0.0027 - val_loss: 0.0016\n",
      "Epoch 21/30\n",
      "\u001b[1m46/46\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - loss: 0.0022 - val_loss: 0.0011\n",
      "Epoch 22/30\n",
      "\u001b[1m46/46\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - loss: 0.0025 - val_loss: 0.0012\n",
      "Epoch 23/30\n",
      "\u001b[1m46/46\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - loss: 0.0021 - val_loss: 0.0010\n",
      "Epoch 24/30\n",
      "\u001b[1m46/46\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - loss: 0.0016 - val_loss: 0.0016\n",
      "Epoch 25/30\n",
      "\u001b[1m46/46\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - loss: 0.0018 - val_loss: 0.0031\n",
      "Epoch 26/30\n",
      "\u001b[1m46/46\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - loss: 0.0023 - val_loss: 0.0011\n",
      "Epoch 27/30\n",
      "\u001b[1m46/46\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - loss: 0.0018 - val_loss: 9.3464e-04\n",
      "Epoch 28/30\n",
      "\u001b[1m46/46\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - loss: 0.0019 - val_loss: 0.0011\n",
      "Epoch 29/30\n",
      "\u001b[1m46/46\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - loss: 0.0019 - val_loss: 0.0013\n",
      "Epoch 30/30\n",
      "\u001b[1m46/46\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - loss: 0.0017 - val_loss: 9.4506e-04\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:The `save_format` argument is deprecated in Keras 3. We recommend removing this argument as it can be inferred from the file path. Received: save_format=keras\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Finished: Somalia | MAE: 0.06 | RMSE: 0.10 | R²: 0.88\n",
      "Epoch 1/30\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/dejauhnaebeadle/School/MachineLearning/machine-learning-project/code/rain-prediction/.venv/lib/python3.11/site-packages/keras/src/layers/rnn/rnn.py:200: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
      "  super().__init__(**kwargs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m46/46\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 15ms/step - loss: 0.0335 - val_loss: 0.0051\n",
      "Epoch 2/30\n",
      "\u001b[1m46/46\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - loss: 0.0073 - val_loss: 0.0037\n",
      "Epoch 3/30\n",
      "\u001b[1m46/46\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 13ms/step - loss: 0.0057 - val_loss: 0.0055\n",
      "Epoch 4/30\n",
      "\u001b[1m46/46\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - loss: 0.0066 - val_loss: 0.0031\n",
      "Epoch 5/30\n",
      "\u001b[1m46/46\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - loss: 0.0058 - val_loss: 0.0028\n",
      "Epoch 6/30\n",
      "\u001b[1m46/46\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - loss: 0.0045 - val_loss: 0.0027\n",
      "Epoch 7/30\n",
      "\u001b[1m46/46\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - loss: 0.0039 - val_loss: 0.0053\n",
      "Epoch 8/30\n",
      "\u001b[1m46/46\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - loss: 0.0042 - val_loss: 0.0022\n",
      "Epoch 9/30\n",
      "\u001b[1m46/46\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - loss: 0.0048 - val_loss: 0.0025\n",
      "Epoch 10/30\n",
      "\u001b[1m46/46\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - loss: 0.0045 - val_loss: 0.0019\n",
      "Epoch 11/30\n",
      "\u001b[1m46/46\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - loss: 0.0034 - val_loss: 0.0018\n",
      "Epoch 12/30\n",
      "\u001b[1m46/46\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - loss: 0.0035 - val_loss: 0.0030\n",
      "Epoch 13/30\n",
      "\u001b[1m46/46\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - loss: 0.0033 - val_loss: 0.0022\n",
      "Epoch 14/30\n",
      "\u001b[1m46/46\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - loss: 0.0036 - val_loss: 0.0018\n",
      "Epoch 15/30\n",
      "\u001b[1m46/46\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - loss: 0.0034 - val_loss: 0.0032\n",
      "Epoch 16/30\n",
      "\u001b[1m46/46\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - loss: 0.0026 - val_loss: 0.0017\n",
      "Epoch 17/30\n",
      "\u001b[1m46/46\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - loss: 0.0028 - val_loss: 0.0024\n",
      "Epoch 18/30\n",
      "\u001b[1m46/46\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - loss: 0.0028 - val_loss: 0.0041\n",
      "Epoch 19/30\n",
      "\u001b[1m46/46\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - loss: 0.0034 - val_loss: 0.0023\n",
      "Epoch 20/30\n",
      "\u001b[1m46/46\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - loss: 0.0038 - val_loss: 0.0021\n",
      "Epoch 21/30\n",
      "\u001b[1m46/46\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - loss: 0.0024 - val_loss: 0.0014\n",
      "Epoch 22/30\n",
      "\u001b[1m46/46\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - loss: 0.0027 - val_loss: 0.0014\n",
      "Epoch 23/30\n",
      "\u001b[1m46/46\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - loss: 0.0031 - val_loss: 0.0015\n",
      "Epoch 24/30\n",
      "\u001b[1m46/46\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - loss: 0.0028 - val_loss: 0.0018\n",
      "Epoch 25/30\n",
      "\u001b[1m46/46\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - loss: 0.0028 - val_loss: 0.0022\n",
      "Epoch 26/30\n",
      "\u001b[1m46/46\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - loss: 0.0026 - val_loss: 0.0014\n",
      "Epoch 27/30\n",
      "\u001b[1m46/46\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - loss: 0.0025 - val_loss: 0.0014\n",
      "Epoch 28/30\n",
      "\u001b[1m46/46\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - loss: 0.0024 - val_loss: 0.0014\n",
      "Epoch 29/30\n",
      "\u001b[1m46/46\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - loss: 0.0025 - val_loss: 0.0013\n",
      "Epoch 30/30\n",
      "\u001b[1m46/46\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - loss: 0.0024 - val_loss: 0.0013\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:The `save_format` argument is deprecated in Keras 3. We recommend removing this argument as it can be inferred from the file path. Received: save_format=keras\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Finished: South Africa | MAE: 0.05 | RMSE: 0.15 | R²: 0.90\n",
      "Epoch 1/30\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/dejauhnaebeadle/School/MachineLearning/machine-learning-project/code/rain-prediction/.venv/lib/python3.11/site-packages/keras/src/layers/rnn/rnn.py:200: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
      "  super().__init__(**kwargs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m46/46\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 13ms/step - loss: 0.0930 - val_loss: 0.0131\n",
      "Epoch 2/30\n",
      "\u001b[1m46/46\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 0.0121 - val_loss: 0.0123\n",
      "Epoch 3/30\n",
      "\u001b[1m46/46\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 0.0107 - val_loss: 0.0113\n",
      "Epoch 4/30\n",
      "\u001b[1m46/46\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 0.0081 - val_loss: 0.0115\n",
      "Epoch 5/30\n",
      "\u001b[1m46/46\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 0.0079 - val_loss: 0.0092\n",
      "Epoch 6/30\n",
      "\u001b[1m46/46\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 0.0070 - val_loss: 0.0076\n",
      "Epoch 7/30\n",
      "\u001b[1m46/46\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 0.0069 - val_loss: 0.0080\n",
      "Epoch 8/30\n",
      "\u001b[1m46/46\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 0.0070 - val_loss: 0.0068\n",
      "Epoch 9/30\n",
      "\u001b[1m46/46\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 0.0044 - val_loss: 0.0072\n",
      "Epoch 10/30\n",
      "\u001b[1m46/46\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 0.0050 - val_loss: 0.0065\n",
      "Epoch 11/30\n",
      "\u001b[1m46/46\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 0.0055 - val_loss: 0.0060\n",
      "Epoch 12/30\n",
      "\u001b[1m46/46\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 0.0046 - val_loss: 0.0059\n",
      "Epoch 13/30\n",
      "\u001b[1m46/46\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 0.0048 - val_loss: 0.0058\n",
      "Epoch 14/30\n",
      "\u001b[1m46/46\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 0.0045 - val_loss: 0.0057\n",
      "Epoch 15/30\n",
      "\u001b[1m46/46\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 0.0042 - val_loss: 0.0052\n",
      "Epoch 16/30\n",
      "\u001b[1m46/46\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 0.0045 - val_loss: 0.0053\n",
      "Epoch 17/30\n",
      "\u001b[1m46/46\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 0.0042 - val_loss: 0.0051\n",
      "Epoch 18/30\n",
      "\u001b[1m46/46\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 0.0035 - val_loss: 0.0052\n",
      "Epoch 19/30\n",
      "\u001b[1m46/46\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 0.0036 - val_loss: 0.0047\n",
      "Epoch 20/30\n",
      "\u001b[1m46/46\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 0.0039 - val_loss: 0.0047\n",
      "Epoch 21/30\n",
      "\u001b[1m46/46\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 0.0035 - val_loss: 0.0047\n",
      "Epoch 22/30\n",
      "\u001b[1m46/46\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 0.0033 - val_loss: 0.0045\n",
      "Epoch 23/30\n",
      "\u001b[1m46/46\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 0.0032 - val_loss: 0.0048\n",
      "Epoch 24/30\n",
      "\u001b[1m46/46\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - loss: 0.0027 - val_loss: 0.0043\n",
      "Epoch 25/30\n",
      "\u001b[1m46/46\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - loss: 0.0036 - val_loss: 0.0042\n",
      "Epoch 26/30\n",
      "\u001b[1m46/46\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 0.0039 - val_loss: 0.0045\n",
      "Epoch 27/30\n",
      "\u001b[1m46/46\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - loss: 0.0033 - val_loss: 0.0042\n",
      "Epoch 28/30\n",
      "\u001b[1m46/46\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - loss: 0.0030 - val_loss: 0.0046\n",
      "Epoch 29/30\n",
      "\u001b[1m46/46\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 0.0037 - val_loss: 0.0041\n",
      "Epoch 30/30\n",
      "\u001b[1m46/46\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 0.0034 - val_loss: 0.0040\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:The `save_format` argument is deprecated in Keras 3. We recommend removing this argument as it can be inferred from the file path. Received: save_format=keras\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Finished: South Georgia and the South Sandwich Islands | MAE: 0.07 | RMSE: 0.16 | R²: 0.85\n",
      "Epoch 1/30\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/dejauhnaebeadle/School/MachineLearning/machine-learning-project/code/rain-prediction/.venv/lib/python3.11/site-packages/keras/src/layers/rnn/rnn.py:200: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
      "  super().__init__(**kwargs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m46/46\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 13ms/step - loss: 0.0491 - val_loss: 0.0046\n",
      "Epoch 2/30\n",
      "\u001b[1m46/46\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - loss: 0.0071 - val_loss: 0.0045\n",
      "Epoch 3/30\n",
      "\u001b[1m46/46\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - loss: 0.0067 - val_loss: 0.0102\n",
      "Epoch 4/30\n",
      "\u001b[1m46/46\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 0.0071 - val_loss: 0.0058\n",
      "Epoch 5/30\n",
      "\u001b[1m46/46\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - loss: 0.0054 - val_loss: 0.0033\n",
      "Epoch 6/30\n",
      "\u001b[1m46/46\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 0.0052 - val_loss: 0.0027\n",
      "Epoch 7/30\n",
      "\u001b[1m46/46\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 0.0045 - val_loss: 0.0025\n",
      "Epoch 8/30\n",
      "\u001b[1m46/46\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - loss: 0.0051 - val_loss: 0.0036\n",
      "Epoch 9/30\n",
      "\u001b[1m46/46\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - loss: 0.0036 - val_loss: 0.0029\n",
      "Epoch 10/30\n",
      "\u001b[1m46/46\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - loss: 0.0038 - val_loss: 0.0041\n",
      "Epoch 11/30\n",
      "\u001b[1m46/46\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - loss: 0.0041 - val_loss: 0.0033\n",
      "Epoch 12/30\n",
      "\u001b[1m46/46\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - loss: 0.0044 - val_loss: 0.0029\n",
      "Epoch 13/30\n",
      "\u001b[1m46/46\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - loss: 0.0038 - val_loss: 0.0024\n",
      "Epoch 14/30\n",
      "\u001b[1m46/46\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - loss: 0.0036 - val_loss: 0.0021\n",
      "Epoch 15/30\n",
      "\u001b[1m46/46\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - loss: 0.0027 - val_loss: 0.0022\n",
      "Epoch 16/30\n",
      "\u001b[1m46/46\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - loss: 0.0039 - val_loss: 0.0019\n",
      "Epoch 17/30\n",
      "\u001b[1m46/46\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - loss: 0.0029 - val_loss: 0.0019\n",
      "Epoch 18/30\n",
      "\u001b[1m46/46\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - loss: 0.0043 - val_loss: 0.0017\n",
      "Epoch 19/30\n",
      "\u001b[1m46/46\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - loss: 0.0026 - val_loss: 0.0017\n",
      "Epoch 20/30\n",
      "\u001b[1m46/46\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - loss: 0.0032 - val_loss: 0.0016\n",
      "Epoch 21/30\n",
      "\u001b[1m46/46\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - loss: 0.0027 - val_loss: 0.0016\n",
      "Epoch 22/30\n",
      "\u001b[1m46/46\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - loss: 0.0028 - val_loss: 0.0015\n",
      "Epoch 23/30\n",
      "\u001b[1m46/46\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - loss: 0.0029 - val_loss: 0.0021\n",
      "Epoch 24/30\n",
      "\u001b[1m46/46\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - loss: 0.0025 - val_loss: 0.0025\n",
      "Epoch 25/30\n",
      "\u001b[1m46/46\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - loss: 0.0025 - val_loss: 0.0016\n",
      "Epoch 26/30\n",
      "\u001b[1m46/46\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - loss: 0.0019 - val_loss: 0.0018\n",
      "Epoch 27/30\n",
      "\u001b[1m46/46\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 0.0020 - val_loss: 0.0015\n",
      "Epoch 28/30\n",
      "\u001b[1m46/46\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 0.0027 - val_loss: 0.0014\n",
      "Epoch 29/30\n",
      "\u001b[1m46/46\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 0.0022 - val_loss: 0.0019\n",
      "Epoch 30/30\n",
      "\u001b[1m46/46\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - loss: 0.0023 - val_loss: 0.0015\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:The `save_format` argument is deprecated in Keras 3. We recommend removing this argument as it can be inferred from the file path. Received: save_format=keras\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Finished: South Korea | MAE: 0.09 | RMSE: 0.14 | R²: 0.94\n",
      "Epoch 1/30\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/dejauhnaebeadle/School/MachineLearning/machine-learning-project/code/rain-prediction/.venv/lib/python3.11/site-packages/keras/src/layers/rnn/rnn.py:200: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
      "  super().__init__(**kwargs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m46/46\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 16ms/step - loss: 0.0597 - val_loss: 0.0055\n",
      "Epoch 2/30\n",
      "\u001b[1m46/46\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - loss: 0.0053 - val_loss: 0.0044\n",
      "Epoch 3/30\n",
      "\u001b[1m46/46\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - loss: 0.0044 - val_loss: 0.0025\n",
      "Epoch 4/30\n",
      "\u001b[1m46/46\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - loss: 0.0039 - val_loss: 0.0024\n",
      "Epoch 5/30\n",
      "\u001b[1m46/46\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - loss: 0.0031 - val_loss: 0.0021\n",
      "Epoch 6/30\n",
      "\u001b[1m46/46\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - loss: 0.0036 - val_loss: 0.0023\n",
      "Epoch 7/30\n",
      "\u001b[1m46/46\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - loss: 0.0025 - val_loss: 0.0018\n",
      "Epoch 8/30\n",
      "\u001b[1m46/46\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - loss: 0.0022 - val_loss: 0.0037\n",
      "Epoch 9/30\n",
      "\u001b[1m46/46\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - loss: 0.0026 - val_loss: 0.0045\n",
      "Epoch 10/30\n",
      "\u001b[1m46/46\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - loss: 0.0025 - val_loss: 0.0025\n",
      "Epoch 11/30\n",
      "\u001b[1m46/46\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - loss: 0.0022 - val_loss: 0.0024\n",
      "Epoch 12/30\n",
      "\u001b[1m46/46\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - loss: 0.0026 - val_loss: 0.0016\n",
      "Epoch 13/30\n",
      "\u001b[1m46/46\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - loss: 0.0022 - val_loss: 0.0020\n",
      "Epoch 14/30\n",
      "\u001b[1m46/46\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - loss: 0.0020 - val_loss: 0.0010\n",
      "Epoch 15/30\n",
      "\u001b[1m46/46\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - loss: 0.0021 - val_loss: 0.0020\n",
      "Epoch 16/30\n",
      "\u001b[1m46/46\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - loss: 0.0022 - val_loss: 0.0026\n",
      "Epoch 17/30\n",
      "\u001b[1m46/46\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - loss: 0.0019 - val_loss: 0.0015\n",
      "Epoch 18/30\n",
      "\u001b[1m46/46\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - loss: 0.0018 - val_loss: 0.0020\n",
      "Epoch 19/30\n",
      "\u001b[1m46/46\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - loss: 0.0018 - val_loss: 0.0014\n",
      "Epoch 20/30\n",
      "\u001b[1m46/46\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - loss: 0.0015 - val_loss: 7.6139e-04\n",
      "Epoch 21/30\n",
      "\u001b[1m46/46\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - loss: 0.0020 - val_loss: 0.0027\n",
      "Epoch 22/30\n",
      "\u001b[1m46/46\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - loss: 0.0017 - val_loss: 8.5933e-04\n",
      "Epoch 23/30\n",
      "\u001b[1m46/46\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - loss: 0.0018 - val_loss: 0.0014\n",
      "Epoch 24/30\n",
      "\u001b[1m46/46\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - loss: 0.0017 - val_loss: 0.0013\n",
      "Epoch 25/30\n",
      "\u001b[1m46/46\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - loss: 0.0013 - val_loss: 0.0038\n",
      "Epoch 26/30\n",
      "\u001b[1m46/46\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - loss: 0.0024 - val_loss: 9.6724e-04\n",
      "Epoch 27/30\n",
      "\u001b[1m46/46\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - loss: 0.0015 - val_loss: 9.0166e-04\n",
      "Epoch 28/30\n",
      "\u001b[1m46/46\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - loss: 0.0014 - val_loss: 6.8185e-04\n",
      "Epoch 29/30\n",
      "\u001b[1m46/46\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - loss: 0.0013 - val_loss: 9.8374e-04\n",
      "Epoch 30/30\n",
      "\u001b[1m46/46\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - loss: 0.0015 - val_loss: 0.0013\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:The `save_format` argument is deprecated in Keras 3. We recommend removing this argument as it can be inferred from the file path. Received: save_format=keras\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Finished: South Sudan | MAE: 0.18 | RMSE: 0.22 | R²: 0.81\n",
      "Epoch 1/30\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/dejauhnaebeadle/School/MachineLearning/machine-learning-project/code/rain-prediction/.venv/lib/python3.11/site-packages/keras/src/layers/rnn/rnn.py:200: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
      "  super().__init__(**kwargs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m46/46\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 20ms/step - loss: 0.0490 - val_loss: 0.0074\n",
      "Epoch 2/30\n",
      "\u001b[1m46/46\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - loss: 0.0092 - val_loss: 0.0074\n",
      "Epoch 3/30\n",
      "\u001b[1m46/46\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - loss: 0.0073 - val_loss: 0.0048\n",
      "Epoch 4/30\n",
      "\u001b[1m46/46\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - loss: 0.0065 - val_loss: 0.0042\n",
      "Epoch 5/30\n",
      "\u001b[1m46/46\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 10ms/step - loss: 0.0057 - val_loss: 0.0073\n",
      "Epoch 6/30\n",
      "\u001b[1m46/46\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - loss: 0.0049 - val_loss: 0.0055\n",
      "Epoch 7/30\n",
      "\u001b[1m46/46\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - loss: 0.0056 - val_loss: 0.0044\n",
      "Epoch 8/30\n",
      "\u001b[1m46/46\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - loss: 0.0054 - val_loss: 0.0032\n",
      "Epoch 9/30\n",
      "\u001b[1m46/46\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - loss: 0.0044 - val_loss: 0.0044\n",
      "Epoch 10/30\n",
      "\u001b[1m46/46\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - loss: 0.0034 - val_loss: 0.0036\n",
      "Epoch 11/30\n",
      "\u001b[1m46/46\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - loss: 0.0037 - val_loss: 0.0032\n",
      "Epoch 12/30\n",
      "\u001b[1m46/46\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - loss: 0.0044 - val_loss: 0.0030\n",
      "Epoch 13/30\n",
      "\u001b[1m46/46\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - loss: 0.0034 - val_loss: 0.0037\n",
      "Epoch 14/30\n",
      "\u001b[1m46/46\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - loss: 0.0037 - val_loss: 0.0025\n",
      "Epoch 15/30\n",
      "\u001b[1m46/46\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - loss: 0.0027 - val_loss: 0.0046\n",
      "Epoch 16/30\n",
      "\u001b[1m46/46\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - loss: 0.0041 - val_loss: 0.0023\n",
      "Epoch 17/30\n",
      "\u001b[1m46/46\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - loss: 0.0029 - val_loss: 0.0027\n",
      "Epoch 18/30\n",
      "\u001b[1m46/46\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - loss: 0.0037 - val_loss: 0.0039\n",
      "Epoch 19/30\n",
      "\u001b[1m46/46\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - loss: 0.0029 - val_loss: 0.0035\n",
      "Epoch 20/30\n",
      "\u001b[1m46/46\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - loss: 0.0027 - val_loss: 0.0028\n",
      "Epoch 21/30\n",
      "\u001b[1m46/46\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - loss: 0.0030 - val_loss: 0.0022\n",
      "Epoch 22/30\n",
      "\u001b[1m46/46\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - loss: 0.0039 - val_loss: 0.0022\n",
      "Epoch 23/30\n",
      "\u001b[1m46/46\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - loss: 0.0037 - val_loss: 0.0023\n",
      "Epoch 24/30\n",
      "\u001b[1m46/46\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - loss: 0.0035 - val_loss: 0.0020\n",
      "Epoch 25/30\n",
      "\u001b[1m46/46\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - loss: 0.0028 - val_loss: 0.0021\n",
      "Epoch 26/30\n",
      "\u001b[1m46/46\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - loss: 0.0028 - val_loss: 0.0027\n",
      "Epoch 27/30\n",
      "\u001b[1m46/46\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - loss: 0.0029 - val_loss: 0.0022\n",
      "Epoch 28/30\n",
      "\u001b[1m46/46\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - loss: 0.0021 - val_loss: 0.0019\n",
      "Epoch 29/30\n",
      "\u001b[1m46/46\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - loss: 0.0028 - val_loss: 0.0020\n",
      "Epoch 30/30\n",
      "\u001b[1m46/46\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - loss: 0.0026 - val_loss: 0.0024\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:The `save_format` argument is deprecated in Keras 3. We recommend removing this argument as it can be inferred from the file path. Received: save_format=keras\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Finished: Spain | MAE: 0.13 | RMSE: 0.21 | R²: 0.83\n",
      "Epoch 1/30\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/dejauhnaebeadle/School/MachineLearning/machine-learning-project/code/rain-prediction/.venv/lib/python3.11/site-packages/keras/src/layers/rnn/rnn.py:200: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
      "  super().__init__(**kwargs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m46/46\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 13ms/step - loss: 0.1326 - val_loss: 0.0078\n",
      "Epoch 2/30\n",
      "\u001b[1m46/46\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 0.0097 - val_loss: 0.0032\n",
      "Epoch 3/30\n",
      "\u001b[1m46/46\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 0.0076 - val_loss: 0.0016\n",
      "Epoch 4/30\n",
      "\u001b[1m46/46\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 0.0076 - val_loss: 0.0013\n",
      "Epoch 5/30\n",
      "\u001b[1m46/46\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 0.0067 - val_loss: 0.0012\n",
      "Epoch 6/30\n",
      "\u001b[1m46/46\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 0.0055 - val_loss: 9.8067e-04\n",
      "Epoch 7/30\n",
      "\u001b[1m46/46\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - loss: 0.0057 - val_loss: 0.0013\n",
      "Epoch 8/30\n",
      "\u001b[1m46/46\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - loss: 0.0046 - val_loss: 7.5222e-04\n",
      "Epoch 9/30\n",
      "\u001b[1m46/46\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 0.0050 - val_loss: 0.0018\n",
      "Epoch 10/30\n",
      "\u001b[1m46/46\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 0.0042 - val_loss: 0.0011\n",
      "Epoch 11/30\n",
      "\u001b[1m46/46\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 0.0039 - val_loss: 0.0013\n",
      "Epoch 12/30\n",
      "\u001b[1m46/46\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 0.0041 - val_loss: 7.4195e-04\n",
      "Epoch 13/30\n",
      "\u001b[1m46/46\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 0.0038 - val_loss: 8.8828e-04\n",
      "Epoch 14/30\n",
      "\u001b[1m46/46\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 0.0042 - val_loss: 0.0023\n",
      "Epoch 15/30\n",
      "\u001b[1m46/46\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 0.0043 - val_loss: 0.0012\n",
      "Epoch 16/30\n",
      "\u001b[1m46/46\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 0.0037 - val_loss: 5.4114e-04\n",
      "Epoch 17/30\n",
      "\u001b[1m46/46\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 0.0027 - val_loss: 0.0032\n",
      "Epoch 18/30\n",
      "\u001b[1m46/46\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 0.0035 - val_loss: 0.0014\n",
      "Epoch 19/30\n",
      "\u001b[1m46/46\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 0.0032 - val_loss: 6.2059e-04\n",
      "Epoch 20/30\n",
      "\u001b[1m46/46\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 0.0033 - val_loss: 4.8213e-04\n",
      "Epoch 21/30\n",
      "\u001b[1m46/46\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 0.0032 - val_loss: 4.6295e-04\n",
      "Epoch 22/30\n",
      "\u001b[1m46/46\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - loss: 0.0028 - val_loss: 4.4903e-04\n",
      "Epoch 23/30\n",
      "\u001b[1m46/46\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - loss: 0.0031 - val_loss: 0.0017\n",
      "Epoch 24/30\n",
      "\u001b[1m46/46\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 0.0031 - val_loss: 5.3589e-04\n",
      "Epoch 25/30\n",
      "\u001b[1m46/46\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 0.0030 - val_loss: 0.0015\n",
      "Epoch 26/30\n",
      "\u001b[1m46/46\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - loss: 0.0029 - val_loss: 4.8121e-04\n",
      "Epoch 27/30\n",
      "\u001b[1m46/46\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - loss: 0.0023 - val_loss: 0.0012\n",
      "Epoch 28/30\n",
      "\u001b[1m46/46\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - loss: 0.0035 - val_loss: 4.0562e-04\n",
      "Epoch 29/30\n",
      "\u001b[1m46/46\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - loss: 0.0025 - val_loss: 8.0795e-04\n",
      "Epoch 30/30\n",
      "\u001b[1m46/46\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - loss: 0.0029 - val_loss: 0.0017\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:The `save_format` argument is deprecated in Keras 3. We recommend removing this argument as it can be inferred from the file path. Received: save_format=keras\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Finished: Sri Lanka | MAE: 0.13 | RMSE: 0.15 | R²: 0.63\n",
      "Epoch 1/30\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/dejauhnaebeadle/School/MachineLearning/machine-learning-project/code/rain-prediction/.venv/lib/python3.11/site-packages/keras/src/layers/rnn/rnn.py:200: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
      "  super().__init__(**kwargs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m46/46\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 12ms/step - loss: 0.0747 - val_loss: 0.0044\n",
      "Epoch 2/30\n",
      "\u001b[1m46/46\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 0.0076 - val_loss: 0.0025\n",
      "Epoch 3/30\n",
      "\u001b[1m46/46\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 0.0071 - val_loss: 0.0011\n",
      "Epoch 4/30\n",
      "\u001b[1m46/46\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - loss: 0.0071 - val_loss: 5.9098e-04\n",
      "Epoch 5/30\n",
      "\u001b[1m46/46\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - loss: 0.0062 - val_loss: 7.1431e-04\n",
      "Epoch 6/30\n",
      "\u001b[1m46/46\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 0.0040 - val_loss: 0.0042\n",
      "Epoch 7/30\n",
      "\u001b[1m46/46\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 0.0046 - val_loss: 0.0029\n",
      "Epoch 8/30\n",
      "\u001b[1m46/46\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 0.0043 - val_loss: 0.0044\n",
      "Epoch 9/30\n",
      "\u001b[1m46/46\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 0.0037 - val_loss: 8.8839e-04\n",
      "Epoch 10/30\n",
      "\u001b[1m46/46\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 0.0043 - val_loss: 0.0017\n",
      "Epoch 11/30\n",
      "\u001b[1m46/46\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 0.0035 - val_loss: 0.0014\n",
      "Epoch 12/30\n",
      "\u001b[1m46/46\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 0.0035 - val_loss: 4.6553e-04\n",
      "Epoch 13/30\n",
      "\u001b[1m46/46\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 0.0033 - val_loss: 0.0045\n",
      "Epoch 14/30\n",
      "\u001b[1m46/46\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 0.0038 - val_loss: 6.7407e-04\n",
      "Epoch 15/30\n",
      "\u001b[1m46/46\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 0.0035 - val_loss: 3.9875e-04\n",
      "Epoch 16/30\n",
      "\u001b[1m46/46\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 0.0038 - val_loss: 7.6640e-04\n",
      "Epoch 17/30\n",
      "\u001b[1m46/46\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 0.0035 - val_loss: 0.0024\n",
      "Epoch 18/30\n",
      "\u001b[1m46/46\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 0.0032 - val_loss: 9.6059e-04\n",
      "Epoch 19/30\n",
      "\u001b[1m46/46\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 0.0029 - val_loss: 3.6318e-04\n",
      "Epoch 20/30\n",
      "\u001b[1m46/46\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 0.0026 - val_loss: 5.6781e-04\n",
      "Epoch 21/30\n",
      "\u001b[1m46/46\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 0.0024 - val_loss: 4.0489e-04\n",
      "Epoch 22/30\n",
      "\u001b[1m46/46\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 0.0025 - val_loss: 2.6776e-04\n",
      "Epoch 23/30\n",
      "\u001b[1m46/46\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 0.0023 - val_loss: 0.0031\n",
      "Epoch 24/30\n",
      "\u001b[1m46/46\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 0.0031 - val_loss: 3.0182e-04\n",
      "Epoch 25/30\n",
      "\u001b[1m46/46\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 0.0027 - val_loss: 5.9007e-04\n",
      "Epoch 26/30\n",
      "\u001b[1m46/46\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - loss: 0.0028 - val_loss: 0.0014\n",
      "Epoch 27/30\n",
      "\u001b[1m46/46\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 0.0022 - val_loss: 0.0015\n",
      "Epoch 28/30\n",
      "\u001b[1m46/46\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - loss: 0.0025 - val_loss: 0.0010\n",
      "Epoch 29/30\n",
      "\u001b[1m46/46\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 0.0020 - val_loss: 7.6013e-04\n",
      "Epoch 30/30\n",
      "\u001b[1m46/46\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 0.0023 - val_loss: 0.0011\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:The `save_format` argument is deprecated in Keras 3. We recommend removing this argument as it can be inferred from the file path. Received: save_format=keras\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Finished: Sudan | MAE: 0.18 | RMSE: 0.22 | R²: 0.59\n",
      "Epoch 1/30\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/dejauhnaebeadle/School/MachineLearning/machine-learning-project/code/rain-prediction/.venv/lib/python3.11/site-packages/keras/src/layers/rnn/rnn.py:200: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
      "  super().__init__(**kwargs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m46/46\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 13ms/step - loss: 0.0341 - val_loss: 0.0026\n",
      "Epoch 2/30\n",
      "\u001b[1m46/46\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 0.0104 - val_loss: 0.0017\n",
      "Epoch 3/30\n",
      "\u001b[1m46/46\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 0.0096 - val_loss: 0.0018\n",
      "Epoch 4/30\n",
      "\u001b[1m46/46\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 0.0073 - val_loss: 0.0024\n",
      "Epoch 5/30\n",
      "\u001b[1m46/46\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 0.0052 - val_loss: 0.0018\n",
      "Epoch 6/30\n",
      "\u001b[1m46/46\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 0.0058 - val_loss: 0.0028\n",
      "Epoch 7/30\n",
      "\u001b[1m46/46\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 0.0045 - val_loss: 0.0025\n",
      "Epoch 8/30\n",
      "\u001b[1m46/46\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 0.0050 - val_loss: 0.0028\n",
      "Epoch 9/30\n",
      "\u001b[1m46/46\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 0.0046 - val_loss: 0.0015\n",
      "Epoch 10/30\n",
      "\u001b[1m46/46\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 0.0050 - val_loss: 8.9098e-04\n",
      "Epoch 11/30\n",
      "\u001b[1m46/46\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 0.0036 - val_loss: 8.1101e-04\n",
      "Epoch 12/30\n",
      "\u001b[1m46/46\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - loss: 0.0037 - val_loss: 0.0013\n",
      "Epoch 13/30\n",
      "\u001b[1m46/46\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 0.0042 - val_loss: 8.0833e-04\n",
      "Epoch 14/30\n",
      "\u001b[1m46/46\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 0.0035 - val_loss: 0.0036\n",
      "Epoch 15/30\n",
      "\u001b[1m46/46\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 0.0032 - val_loss: 0.0012\n",
      "Epoch 16/30\n",
      "\u001b[1m46/46\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 0.0045 - val_loss: 8.9121e-04\n",
      "Epoch 17/30\n",
      "\u001b[1m46/46\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 0.0036 - val_loss: 0.0012\n",
      "Epoch 18/30\n",
      "\u001b[1m46/46\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 0.0031 - val_loss: 7.2537e-04\n",
      "Epoch 19/30\n",
      "\u001b[1m46/46\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 0.0038 - val_loss: 0.0021\n",
      "Epoch 20/30\n",
      "\u001b[1m46/46\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 0.0027 - val_loss: 6.9792e-04\n",
      "Epoch 21/30\n",
      "\u001b[1m46/46\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 0.0021 - val_loss: 6.2196e-04\n",
      "Epoch 22/30\n",
      "\u001b[1m46/46\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 0.0042 - val_loss: 0.0011\n",
      "Epoch 23/30\n",
      "\u001b[1m46/46\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 0.0033 - val_loss: 8.0577e-04\n",
      "Epoch 24/30\n",
      "\u001b[1m46/46\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 0.0036 - val_loss: 0.0012\n",
      "Epoch 25/30\n",
      "\u001b[1m46/46\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 0.0029 - val_loss: 8.9037e-04\n",
      "Epoch 26/30\n",
      "\u001b[1m46/46\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 0.0031 - val_loss: 6.2644e-04\n",
      "Epoch 27/30\n",
      "\u001b[1m46/46\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 0.0051 - val_loss: 7.1589e-04\n",
      "Epoch 28/30\n",
      "\u001b[1m46/46\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 0.0042 - val_loss: 8.6220e-04\n",
      "Epoch 29/30\n",
      "\u001b[1m46/46\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - loss: 0.0040 - val_loss: 6.4395e-04\n",
      "Epoch 30/30\n",
      "\u001b[1m46/46\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 0.0035 - val_loss: 0.0012\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:The `save_format` argument is deprecated in Keras 3. We recommend removing this argument as it can be inferred from the file path. Received: save_format=keras\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Finished: Suriname | MAE: 0.10 | RMSE: 0.15 | R²: 0.85\n",
      "Epoch 1/30\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/dejauhnaebeadle/School/MachineLearning/machine-learning-project/code/rain-prediction/.venv/lib/python3.11/site-packages/keras/src/layers/rnn/rnn.py:200: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
      "  super().__init__(**kwargs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m46/46\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 13ms/step - loss: 0.0795 - val_loss: 0.0028\n",
      "Epoch 2/30\n",
      "\u001b[1m46/46\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 0.0174 - val_loss: 0.0026\n",
      "Epoch 3/30\n",
      "\u001b[1m46/46\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 0.0159 - val_loss: 0.0033\n",
      "Epoch 4/30\n",
      "\u001b[1m46/46\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 0.0142 - val_loss: 0.0036\n",
      "Epoch 5/30\n",
      "\u001b[1m46/46\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 0.0129 - val_loss: 0.0047\n",
      "Epoch 6/30\n",
      "\u001b[1m46/46\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 0.0091 - val_loss: 0.0035\n",
      "Epoch 7/30\n",
      "\u001b[1m46/46\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 0.0077 - val_loss: 0.0063\n",
      "Epoch 8/30\n",
      "\u001b[1m46/46\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 0.0073 - val_loss: 0.0022\n",
      "Epoch 9/30\n",
      "\u001b[1m46/46\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 0.0083 - val_loss: 0.0059\n",
      "Epoch 10/30\n",
      "\u001b[1m46/46\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 0.0080 - val_loss: 8.4554e-04\n",
      "Epoch 11/30\n",
      "\u001b[1m46/46\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 0.0083 - val_loss: 0.0035\n",
      "Epoch 12/30\n",
      "\u001b[1m46/46\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 0.0075 - val_loss: 7.2364e-04\n",
      "Epoch 13/30\n",
      "\u001b[1m46/46\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 0.0076 - val_loss: 0.0033\n",
      "Epoch 14/30\n",
      "\u001b[1m46/46\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 0.0064 - val_loss: 0.0020\n",
      "Epoch 15/30\n",
      "\u001b[1m46/46\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 0.0056 - val_loss: 0.0018\n",
      "Epoch 16/30\n",
      "\u001b[1m46/46\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 0.0077 - val_loss: 0.0046\n",
      "Epoch 17/30\n",
      "\u001b[1m46/46\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 0.0062 - val_loss: 6.3537e-04\n",
      "Epoch 18/30\n",
      "\u001b[1m46/46\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 0.0063 - val_loss: 0.0014\n",
      "Epoch 19/30\n",
      "\u001b[1m46/46\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 0.0058 - val_loss: 5.7946e-04\n",
      "Epoch 20/30\n",
      "\u001b[1m46/46\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 0.0064 - val_loss: 0.0016\n",
      "Epoch 21/30\n",
      "\u001b[1m46/46\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 0.0044 - val_loss: 0.0014\n",
      "Epoch 22/30\n",
      "\u001b[1m46/46\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 0.0054 - val_loss: 6.1739e-04\n",
      "Epoch 23/30\n",
      "\u001b[1m46/46\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 0.0063 - val_loss: 9.1122e-04\n",
      "Epoch 24/30\n",
      "\u001b[1m46/46\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - loss: 0.0056 - val_loss: 7.6866e-04\n",
      "Epoch 25/30\n",
      "\u001b[1m46/46\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - loss: 0.0066 - val_loss: 0.0020\n",
      "Epoch 26/30\n",
      "\u001b[1m46/46\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 0.0069 - val_loss: 5.9152e-04\n",
      "Epoch 27/30\n",
      "\u001b[1m46/46\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 0.0063 - val_loss: 0.0012\n",
      "Epoch 28/30\n",
      "\u001b[1m46/46\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 0.0051 - val_loss: 6.0472e-04\n",
      "Epoch 29/30\n",
      "\u001b[1m46/46\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 0.0058 - val_loss: 8.3260e-04\n",
      "Epoch 30/30\n",
      "\u001b[1m46/46\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 0.0039 - val_loss: 5.2028e-04\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:The `save_format` argument is deprecated in Keras 3. We recommend removing this argument as it can be inferred from the file path. Received: save_format=keras\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Finished: Sweden | MAE: 0.12 | RMSE: 0.35 | R²: 0.82\n",
      "Epoch 1/30\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/dejauhnaebeadle/School/MachineLearning/machine-learning-project/code/rain-prediction/.venv/lib/python3.11/site-packages/keras/src/layers/rnn/rnn.py:200: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
      "  super().__init__(**kwargs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m46/46\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 12ms/step - loss: 0.0423 - val_loss: 0.0056\n",
      "Epoch 2/30\n",
      "\u001b[1m46/46\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 0.0065 - val_loss: 0.0045\n",
      "Epoch 3/30\n",
      "\u001b[1m46/46\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 0.0060 - val_loss: 0.0059\n",
      "Epoch 4/30\n",
      "\u001b[1m46/46\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 0.0062 - val_loss: 0.0040\n",
      "Epoch 5/30\n",
      "\u001b[1m46/46\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 0.0046 - val_loss: 0.0028\n",
      "Epoch 6/30\n",
      "\u001b[1m46/46\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 0.0054 - val_loss: 0.0065\n",
      "Epoch 7/30\n",
      "\u001b[1m46/46\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 0.0037 - val_loss: 0.0043\n",
      "Epoch 8/30\n",
      "\u001b[1m46/46\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 0.0045 - val_loss: 0.0040\n",
      "Epoch 9/30\n",
      "\u001b[1m46/46\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 0.0034 - val_loss: 0.0035\n",
      "Epoch 10/30\n",
      "\u001b[1m46/46\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 0.0037 - val_loss: 0.0021\n",
      "Epoch 11/30\n",
      "\u001b[1m46/46\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 0.0033 - val_loss: 0.0021\n",
      "Epoch 12/30\n",
      "\u001b[1m46/46\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 0.0038 - val_loss: 0.0018\n",
      "Epoch 13/30\n",
      "\u001b[1m46/46\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 0.0033 - val_loss: 0.0038\n",
      "Epoch 14/30\n",
      "\u001b[1m46/46\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 0.0022 - val_loss: 0.0017\n",
      "Epoch 15/30\n",
      "\u001b[1m46/46\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 0.0031 - val_loss: 0.0027\n",
      "Epoch 16/30\n",
      "\u001b[1m46/46\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 0.0038 - val_loss: 0.0041\n",
      "Epoch 17/30\n",
      "\u001b[1m46/46\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 0.0027 - val_loss: 0.0014\n",
      "Epoch 18/30\n",
      "\u001b[1m46/46\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - loss: 0.0026 - val_loss: 0.0014\n",
      "Epoch 19/30\n",
      "\u001b[1m46/46\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 0.0024 - val_loss: 0.0013\n",
      "Epoch 20/30\n",
      "\u001b[1m46/46\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 0.0023 - val_loss: 0.0020\n",
      "Epoch 21/30\n",
      "\u001b[1m46/46\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 0.0030 - val_loss: 0.0019\n",
      "Epoch 22/30\n",
      "\u001b[1m46/46\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 0.0027 - val_loss: 0.0015\n",
      "Epoch 23/30\n",
      "\u001b[1m46/46\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 0.0026 - val_loss: 0.0017\n",
      "Epoch 24/30\n",
      "\u001b[1m46/46\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 0.0025 - val_loss: 0.0011\n",
      "Epoch 25/30\n",
      "\u001b[1m46/46\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - loss: 0.0024 - val_loss: 0.0019\n",
      "Epoch 26/30\n",
      "\u001b[1m46/46\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - loss: 0.0023 - val_loss: 0.0030\n",
      "Epoch 27/30\n",
      "\u001b[1m46/46\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 0.0018 - val_loss: 0.0016\n",
      "Epoch 28/30\n",
      "\u001b[1m46/46\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - loss: 0.0037 - val_loss: 0.0013\n",
      "Epoch 29/30\n",
      "\u001b[1m46/46\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - loss: 0.0030 - val_loss: 0.0018\n",
      "Epoch 30/30\n",
      "\u001b[1m46/46\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - loss: 0.0018 - val_loss: 0.0011\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:The `save_format` argument is deprecated in Keras 3. We recommend removing this argument as it can be inferred from the file path. Received: save_format=keras\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Finished: Switzerland | MAE: 0.14 | RMSE: 0.26 | R²: 0.86\n",
      "Epoch 1/30\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/dejauhnaebeadle/School/MachineLearning/machine-learning-project/code/rain-prediction/.venv/lib/python3.11/site-packages/keras/src/layers/rnn/rnn.py:200: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
      "  super().__init__(**kwargs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m46/46\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 13ms/step - loss: 0.0498 - val_loss: 0.0018\n",
      "Epoch 2/30\n",
      "\u001b[1m46/46\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - loss: 0.0130 - val_loss: 0.0032\n",
      "Epoch 3/30\n",
      "\u001b[1m46/46\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 0.0112 - val_loss: 0.0028\n",
      "Epoch 4/30\n",
      "\u001b[1m46/46\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 0.0078 - val_loss: 0.0039\n",
      "Epoch 5/30\n",
      "\u001b[1m46/46\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - loss: 0.0067 - val_loss: 0.0077\n",
      "Epoch 6/30\n",
      "\u001b[1m46/46\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - loss: 0.0063 - val_loss: 5.7962e-04\n",
      "Epoch 7/30\n",
      "\u001b[1m46/46\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 0.0065 - val_loss: 0.0069\n",
      "Epoch 8/30\n",
      "\u001b[1m46/46\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 0.0066 - val_loss: 5.3258e-04\n",
      "Epoch 9/30\n",
      "\u001b[1m46/46\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - loss: 0.0064 - val_loss: 0.0015\n",
      "Epoch 10/30\n",
      "\u001b[1m46/46\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - loss: 0.0063 - val_loss: 0.0015\n",
      "Epoch 11/30\n",
      "\u001b[1m46/46\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - loss: 0.0048 - val_loss: 0.0030\n",
      "Epoch 12/30\n",
      "\u001b[1m46/46\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - loss: 0.0049 - val_loss: 7.2281e-04\n",
      "Epoch 13/30\n",
      "\u001b[1m46/46\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 0.0070 - val_loss: 0.0012\n",
      "Epoch 14/30\n",
      "\u001b[1m46/46\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - loss: 0.0053 - val_loss: 0.0017\n",
      "Epoch 15/30\n",
      "\u001b[1m46/46\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - loss: 0.0036 - val_loss: 9.4031e-04\n",
      "Epoch 16/30\n",
      "\u001b[1m46/46\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - loss: 0.0051 - val_loss: 4.6158e-04\n",
      "Epoch 17/30\n",
      "\u001b[1m46/46\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 0.0056 - val_loss: 8.3413e-04\n",
      "Epoch 18/30\n",
      "\u001b[1m46/46\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 0.0045 - val_loss: 5.1844e-04\n",
      "Epoch 19/30\n",
      "\u001b[1m46/46\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 0.0037 - val_loss: 0.0032\n",
      "Epoch 20/30\n",
      "\u001b[1m46/46\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - loss: 0.0041 - val_loss: 5.1737e-04\n",
      "Epoch 21/30\n",
      "\u001b[1m46/46\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - loss: 0.0040 - val_loss: 4.0509e-04\n",
      "Epoch 22/30\n",
      "\u001b[1m46/46\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 0.0032 - val_loss: 9.6725e-04\n",
      "Epoch 23/30\n",
      "\u001b[1m46/46\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - loss: 0.0028 - val_loss: 9.9815e-04\n",
      "Epoch 24/30\n",
      "\u001b[1m46/46\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - loss: 0.0048 - val_loss: 9.4242e-04\n",
      "Epoch 25/30\n",
      "\u001b[1m46/46\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - loss: 0.0037 - val_loss: 0.0021\n",
      "Epoch 26/30\n",
      "\u001b[1m46/46\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - loss: 0.0033 - val_loss: 0.0016\n",
      "Epoch 27/30\n",
      "\u001b[1m46/46\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - loss: 0.0044 - val_loss: 0.0021\n",
      "Epoch 28/30\n",
      "\u001b[1m46/46\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - loss: 0.0037 - val_loss: 0.0023\n",
      "Epoch 29/30\n",
      "\u001b[1m46/46\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - loss: 0.0044 - val_loss: 4.0877e-04\n",
      "Epoch 30/30\n",
      "\u001b[1m46/46\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - loss: 0.0038 - val_loss: 9.0792e-04\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:The `save_format` argument is deprecated in Keras 3. We recommend removing this argument as it can be inferred from the file path. Received: save_format=keras\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Finished: Syria | MAE: 0.23 | RMSE: 0.31 | R²: 0.74\n",
      "Epoch 1/30\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/dejauhnaebeadle/School/MachineLearning/machine-learning-project/code/rain-prediction/.venv/lib/python3.11/site-packages/keras/src/layers/rnn/rnn.py:200: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
      "  super().__init__(**kwargs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m46/46\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 11ms/step - loss: 0.0734 - val_loss: 0.0099\n",
      "Epoch 2/30\n",
      "\u001b[1m46/46\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - loss: 0.0170 - val_loss: 0.0082\n",
      "Epoch 3/30\n",
      "\u001b[1m46/46\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 0.0138 - val_loss: 0.0124\n",
      "Epoch 4/30\n",
      "\u001b[1m46/46\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 0.0123 - val_loss: 0.0056\n",
      "Epoch 5/30\n",
      "\u001b[1m46/46\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 0.0117 - val_loss: 0.0078\n",
      "Epoch 6/30\n",
      "\u001b[1m46/46\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - loss: 0.0103 - val_loss: 0.0052\n",
      "Epoch 7/30\n",
      "\u001b[1m46/46\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - loss: 0.0099 - val_loss: 0.0051\n",
      "Epoch 8/30\n",
      "\u001b[1m46/46\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 0.0094 - val_loss: 0.0097\n",
      "Epoch 9/30\n",
      "\u001b[1m46/46\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 0.0077 - val_loss: 0.0047\n",
      "Epoch 10/30\n",
      "\u001b[1m46/46\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 0.0061 - val_loss: 0.0043\n",
      "Epoch 11/30\n",
      "\u001b[1m46/46\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - loss: 0.0063 - val_loss: 0.0075\n",
      "Epoch 12/30\n",
      "\u001b[1m46/46\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - loss: 0.0093 - val_loss: 0.0041\n",
      "Epoch 13/30\n",
      "\u001b[1m46/46\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - loss: 0.0092 - val_loss: 0.0039\n",
      "Epoch 14/30\n",
      "\u001b[1m46/46\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - loss: 0.0089 - val_loss: 0.0061\n",
      "Epoch 15/30\n",
      "\u001b[1m46/46\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - loss: 0.0058 - val_loss: 0.0033\n",
      "Epoch 16/30\n",
      "\u001b[1m46/46\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - loss: 0.0098 - val_loss: 0.0046\n",
      "Epoch 17/30\n",
      "\u001b[1m46/46\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - loss: 0.0063 - val_loss: 0.0056\n",
      "Epoch 18/30\n",
      "\u001b[1m46/46\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - loss: 0.0078 - val_loss: 0.0032\n",
      "Epoch 19/30\n",
      "\u001b[1m46/46\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - loss: 0.0052 - val_loss: 0.0036\n",
      "Epoch 20/30\n",
      "\u001b[1m46/46\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - loss: 0.0065 - val_loss: 0.0034\n",
      "Epoch 21/30\n",
      "\u001b[1m46/46\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - loss: 0.0053 - val_loss: 0.0038\n",
      "Epoch 22/30\n",
      "\u001b[1m46/46\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - loss: 0.0048 - val_loss: 0.0029\n",
      "Epoch 23/30\n",
      "\u001b[1m46/46\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - loss: 0.0045 - val_loss: 0.0034\n",
      "Epoch 24/30\n",
      "\u001b[1m46/46\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - loss: 0.0047 - val_loss: 0.0039\n",
      "Epoch 25/30\n",
      "\u001b[1m46/46\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - loss: 0.0058 - val_loss: 0.0033\n",
      "Epoch 26/30\n",
      "\u001b[1m46/46\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - loss: 0.0051 - val_loss: 0.0029\n",
      "Epoch 27/30\n",
      "\u001b[1m46/46\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - loss: 0.0059 - val_loss: 0.0027\n",
      "Epoch 28/30\n",
      "\u001b[1m46/46\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - loss: 0.0057 - val_loss: 0.0036\n",
      "Epoch 29/30\n",
      "\u001b[1m46/46\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 10ms/step - loss: 0.0046 - val_loss: 0.0043\n",
      "Epoch 30/30\n",
      "\u001b[1m46/46\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - loss: 0.0058 - val_loss: 0.0036\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:The `save_format` argument is deprecated in Keras 3. We recommend removing this argument as it can be inferred from the file path. Received: save_format=keras\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Finished: Tajikistan | MAE: 0.16 | RMSE: 0.24 | R²: 0.86\n",
      "Epoch 1/30\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/dejauhnaebeadle/School/MachineLearning/machine-learning-project/code/rain-prediction/.venv/lib/python3.11/site-packages/keras/src/layers/rnn/rnn.py:200: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
      "  super().__init__(**kwargs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m46/46\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 14ms/step - loss: 0.0625 - val_loss: 0.0138\n",
      "Epoch 2/30\n",
      "\u001b[1m46/46\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - loss: 0.0107 - val_loss: 0.0174\n",
      "Epoch 3/30\n",
      "\u001b[1m46/46\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - loss: 0.0095 - val_loss: 0.0105\n",
      "Epoch 4/30\n",
      "\u001b[1m46/46\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - loss: 0.0080 - val_loss: 0.0086\n",
      "Epoch 5/30\n",
      "\u001b[1m46/46\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - loss: 0.0070 - val_loss: 0.0135\n",
      "Epoch 6/30\n",
      "\u001b[1m46/46\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - loss: 0.0069 - val_loss: 0.0071\n",
      "Epoch 7/30\n",
      "\u001b[1m46/46\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - loss: 0.0070 - val_loss: 0.0110\n",
      "Epoch 8/30\n",
      "\u001b[1m46/46\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - loss: 0.0061 - val_loss: 0.0106\n",
      "Epoch 9/30\n",
      "\u001b[1m46/46\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - loss: 0.0057 - val_loss: 0.0094\n",
      "Epoch 10/30\n",
      "\u001b[1m46/46\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - loss: 0.0046 - val_loss: 0.0056\n",
      "Epoch 11/30\n",
      "\u001b[1m46/46\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - loss: 0.0054 - val_loss: 0.0056\n",
      "Epoch 12/30\n",
      "\u001b[1m46/46\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - loss: 0.0049 - val_loss: 0.0059\n",
      "Epoch 13/30\n",
      "\u001b[1m46/46\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - loss: 0.0060 - val_loss: 0.0053\n",
      "Epoch 14/30\n",
      "\u001b[1m46/46\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - loss: 0.0047 - val_loss: 0.0052\n",
      "Epoch 15/30\n",
      "\u001b[1m46/46\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - loss: 0.0038 - val_loss: 0.0049\n",
      "Epoch 16/30\n",
      "\u001b[1m46/46\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - loss: 0.0036 - val_loss: 0.0052\n",
      "Epoch 17/30\n",
      "\u001b[1m46/46\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - loss: 0.0041 - val_loss: 0.0049\n",
      "Epoch 18/30\n",
      "\u001b[1m46/46\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - loss: 0.0031 - val_loss: 0.0043\n",
      "Epoch 19/30\n",
      "\u001b[1m46/46\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - loss: 0.0032 - val_loss: 0.0046\n",
      "Epoch 20/30\n",
      "\u001b[1m46/46\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - loss: 0.0048 - val_loss: 0.0056\n",
      "Epoch 21/30\n",
      "\u001b[1m46/46\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 0.0040 - val_loss: 0.0064\n",
      "Epoch 22/30\n",
      "\u001b[1m46/46\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - loss: 0.0036 - val_loss: 0.0039\n",
      "Epoch 23/30\n",
      "\u001b[1m46/46\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - loss: 0.0037 - val_loss: 0.0052\n",
      "Epoch 24/30\n",
      "\u001b[1m46/46\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - loss: 0.0038 - val_loss: 0.0044\n",
      "Epoch 25/30\n",
      "\u001b[1m46/46\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - loss: 0.0041 - val_loss: 0.0046\n",
      "Epoch 26/30\n",
      "\u001b[1m46/46\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - loss: 0.0034 - val_loss: 0.0048\n",
      "Epoch 27/30\n",
      "\u001b[1m46/46\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - loss: 0.0034 - val_loss: 0.0036\n",
      "Epoch 28/30\n",
      "\u001b[1m46/46\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - loss: 0.0032 - val_loss: 0.0036\n",
      "Epoch 29/30\n",
      "\u001b[1m46/46\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - loss: 0.0030 - val_loss: 0.0045\n",
      "Epoch 30/30\n",
      "\u001b[1m46/46\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - loss: 0.0018 - val_loss: 0.0045\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:The `save_format` argument is deprecated in Keras 3. We recommend removing this argument as it can be inferred from the file path. Received: save_format=keras\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Finished: Tanzania | MAE: 0.09 | RMSE: 0.11 | R²: 0.72\n",
      "Epoch 1/30\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/dejauhnaebeadle/School/MachineLearning/machine-learning-project/code/rain-prediction/.venv/lib/python3.11/site-packages/keras/src/layers/rnn/rnn.py:200: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
      "  super().__init__(**kwargs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m46/46\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 14ms/step - loss: 0.0592 - val_loss: 0.0038\n",
      "Epoch 2/30\n",
      "\u001b[1m46/46\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - loss: 0.0053 - val_loss: 0.0043\n",
      "Epoch 3/30\n",
      "\u001b[1m46/46\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - loss: 0.0050 - val_loss: 0.0026\n",
      "Epoch 4/30\n",
      "\u001b[1m46/46\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - loss: 0.0044 - val_loss: 0.0030\n",
      "Epoch 5/30\n",
      "\u001b[1m46/46\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - loss: 0.0048 - val_loss: 0.0018\n",
      "Epoch 6/30\n",
      "\u001b[1m46/46\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - loss: 0.0042 - val_loss: 0.0014\n",
      "Epoch 7/30\n",
      "\u001b[1m46/46\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - loss: 0.0038 - val_loss: 0.0014\n",
      "Epoch 8/30\n",
      "\u001b[1m46/46\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - loss: 0.0032 - val_loss: 0.0028\n",
      "Epoch 9/30\n",
      "\u001b[1m46/46\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - loss: 0.0031 - val_loss: 0.0012\n",
      "Epoch 10/30\n",
      "\u001b[1m46/46\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - loss: 0.0027 - val_loss: 0.0011\n",
      "Epoch 11/30\n",
      "\u001b[1m46/46\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - loss: 0.0028 - val_loss: 0.0032\n",
      "Epoch 12/30\n",
      "\u001b[1m46/46\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - loss: 0.0032 - val_loss: 0.0016\n",
      "Epoch 13/30\n",
      "\u001b[1m46/46\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 0.0031 - val_loss: 0.0011\n",
      "Epoch 14/30\n",
      "\u001b[1m46/46\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - loss: 0.0030 - val_loss: 0.0014\n",
      "Epoch 15/30\n",
      "\u001b[1m46/46\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - loss: 0.0021 - val_loss: 0.0016\n",
      "Epoch 16/30\n",
      "\u001b[1m46/46\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - loss: 0.0028 - val_loss: 0.0011\n",
      "Epoch 17/30\n",
      "\u001b[1m46/46\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - loss: 0.0022 - val_loss: 9.7510e-04\n",
      "Epoch 18/30\n",
      "\u001b[1m46/46\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 0.0024 - val_loss: 0.0010\n",
      "Epoch 19/30\n",
      "\u001b[1m46/46\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 0.0018 - val_loss: 9.7817e-04\n",
      "Epoch 20/30\n",
      "\u001b[1m46/46\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - loss: 0.0018 - val_loss: 0.0025\n",
      "Epoch 21/30\n",
      "\u001b[1m46/46\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - loss: 0.0030 - val_loss: 9.5684e-04\n",
      "Epoch 22/30\n",
      "\u001b[1m46/46\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 0.0028 - val_loss: 9.2391e-04\n",
      "Epoch 23/30\n",
      "\u001b[1m46/46\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 0.0018 - val_loss: 0.0013\n",
      "Epoch 24/30\n",
      "\u001b[1m46/46\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - loss: 0.0018 - val_loss: 0.0011\n",
      "Epoch 25/30\n",
      "\u001b[1m46/46\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 0.0023 - val_loss: 8.7120e-04\n",
      "Epoch 26/30\n",
      "\u001b[1m46/46\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - loss: 0.0021 - val_loss: 8.4153e-04\n",
      "Epoch 27/30\n",
      "\u001b[1m46/46\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - loss: 0.0020 - val_loss: 8.2782e-04\n",
      "Epoch 28/30\n",
      "\u001b[1m46/46\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - loss: 0.0021 - val_loss: 8.3773e-04\n",
      "Epoch 29/30\n",
      "\u001b[1m46/46\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - loss: 0.0017 - val_loss: 0.0011\n",
      "Epoch 30/30\n",
      "\u001b[1m46/46\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 0.0018 - val_loss: 9.0619e-04\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:The `save_format` argument is deprecated in Keras 3. We recommend removing this argument as it can be inferred from the file path. Received: save_format=keras\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Finished: Thailand | MAE: 0.09 | RMSE: 0.17 | R²: 0.83\n",
      "Epoch 1/30\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/dejauhnaebeadle/School/MachineLearning/machine-learning-project/code/rain-prediction/.venv/lib/python3.11/site-packages/keras/src/layers/rnn/rnn.py:200: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
      "  super().__init__(**kwargs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m46/46\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 10ms/step - loss: 0.0490 - val_loss: 0.0012\n",
      "Epoch 2/30\n",
      "\u001b[1m46/46\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 0.0070 - val_loss: 9.2426e-04\n",
      "Epoch 3/30\n",
      "\u001b[1m46/46\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 0.0066 - val_loss: 0.0013\n",
      "Epoch 4/30\n",
      "\u001b[1m46/46\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 0.0056 - val_loss: 4.8332e-04\n",
      "Epoch 5/30\n",
      "\u001b[1m46/46\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 0.0048 - val_loss: 0.0015\n",
      "Epoch 6/30\n",
      "\u001b[1m46/46\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 0.0049 - val_loss: 0.0012\n",
      "Epoch 7/30\n",
      "\u001b[1m46/46\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 0.0041 - val_loss: 4.4212e-04\n",
      "Epoch 8/30\n",
      "\u001b[1m46/46\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 0.0040 - val_loss: 0.0036\n",
      "Epoch 9/30\n",
      "\u001b[1m46/46\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 0.0043 - val_loss: 3.0882e-04\n",
      "Epoch 10/30\n",
      "\u001b[1m46/46\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - loss: 0.0032 - val_loss: 5.5550e-04\n",
      "Epoch 11/30\n",
      "\u001b[1m46/46\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - loss: 0.0031 - val_loss: 0.0015\n",
      "Epoch 12/30\n",
      "\u001b[1m46/46\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 0.0030 - val_loss: 2.6388e-04\n",
      "Epoch 13/30\n",
      "\u001b[1m46/46\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 0.0031 - val_loss: 0.0011\n",
      "Epoch 14/30\n",
      "\u001b[1m46/46\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 0.0022 - val_loss: 6.2557e-04\n",
      "Epoch 15/30\n",
      "\u001b[1m46/46\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 0.0032 - val_loss: 5.0495e-04\n",
      "Epoch 16/30\n",
      "\u001b[1m46/46\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 0.0028 - val_loss: 2.8394e-04\n",
      "Epoch 17/30\n",
      "\u001b[1m46/46\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 0.0024 - val_loss: 2.3461e-04\n",
      "Epoch 18/30\n",
      "\u001b[1m46/46\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - loss: 0.0027 - val_loss: 4.6822e-04\n",
      "Epoch 19/30\n",
      "\u001b[1m46/46\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 0.0028 - val_loss: 2.6806e-04\n",
      "Epoch 20/30\n",
      "\u001b[1m46/46\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 0.0021 - val_loss: 8.4515e-04\n",
      "Epoch 21/30\n",
      "\u001b[1m46/46\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 0.0025 - val_loss: 9.3417e-04\n",
      "Epoch 22/30\n",
      "\u001b[1m46/46\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 0.0019 - val_loss: 1.9767e-04\n",
      "Epoch 23/30\n",
      "\u001b[1m46/46\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 0.0021 - val_loss: 2.9936e-04\n",
      "Epoch 24/30\n",
      "\u001b[1m46/46\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 0.0026 - val_loss: 0.0018\n",
      "Epoch 25/30\n",
      "\u001b[1m46/46\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 0.0021 - val_loss: 2.4241e-04\n",
      "Epoch 26/30\n",
      "\u001b[1m46/46\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - loss: 0.0018 - val_loss: 4.4553e-04\n",
      "Epoch 27/30\n",
      "\u001b[1m46/46\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - loss: 0.0021 - val_loss: 0.0014\n",
      "Epoch 28/30\n",
      "\u001b[1m46/46\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 0.0021 - val_loss: 3.5864e-04\n",
      "Epoch 29/30\n",
      "\u001b[1m46/46\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 0.0017 - val_loss: 1.8893e-04\n",
      "Epoch 30/30\n",
      "\u001b[1m46/46\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - loss: 0.0028 - val_loss: 3.5243e-04\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:The `save_format` argument is deprecated in Keras 3. We recommend removing this argument as it can be inferred from the file path. Received: save_format=keras\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Finished: Togo | MAE: 0.07 | RMSE: 0.11 | R²: 0.85\n",
      "Epoch 1/30\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/dejauhnaebeadle/School/MachineLearning/machine-learning-project/code/rain-prediction/.venv/lib/python3.11/site-packages/keras/src/layers/rnn/rnn.py:200: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
      "  super().__init__(**kwargs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m46/46\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 12ms/step - loss: 0.0340 - val_loss: 0.0045\n",
      "Epoch 2/30\n",
      "\u001b[1m46/46\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - loss: 0.0062 - val_loss: 0.0070\n",
      "Epoch 3/30\n",
      "\u001b[1m46/46\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - loss: 0.0059 - val_loss: 0.0037\n",
      "Epoch 4/30\n",
      "\u001b[1m46/46\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 0.0049 - val_loss: 0.0045\n",
      "Epoch 5/30\n",
      "\u001b[1m46/46\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 0.0036 - val_loss: 0.0016\n",
      "Epoch 6/30\n",
      "\u001b[1m46/46\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - loss: 0.0037 - val_loss: 0.0043\n",
      "Epoch 7/30\n",
      "\u001b[1m46/46\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - loss: 0.0030 - val_loss: 0.0032\n",
      "Epoch 8/30\n",
      "\u001b[1m46/46\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - loss: 0.0030 - val_loss: 0.0017\n",
      "Epoch 9/30\n",
      "\u001b[1m46/46\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - loss: 0.0028 - val_loss: 0.0048\n",
      "Epoch 10/30\n",
      "\u001b[1m46/46\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - loss: 0.0028 - val_loss: 0.0034\n",
      "Epoch 11/30\n",
      "\u001b[1m46/46\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - loss: 0.0026 - val_loss: 0.0017\n",
      "Epoch 12/30\n",
      "\u001b[1m46/46\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - loss: 0.0026 - val_loss: 0.0016\n",
      "Epoch 13/30\n",
      "\u001b[1m46/46\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - loss: 0.0027 - val_loss: 0.0019\n",
      "Epoch 14/30\n",
      "\u001b[1m46/46\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - loss: 0.0026 - val_loss: 0.0017\n",
      "Epoch 15/30\n",
      "\u001b[1m46/46\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - loss: 0.0029 - val_loss: 0.0017\n",
      "Epoch 16/30\n",
      "\u001b[1m46/46\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - loss: 0.0018 - val_loss: 0.0020\n",
      "Epoch 17/30\n",
      "\u001b[1m46/46\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - loss: 0.0023 - val_loss: 9.3624e-04\n",
      "Epoch 18/30\n",
      "\u001b[1m46/46\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - loss: 0.0024 - val_loss: 0.0016\n",
      "Epoch 19/30\n",
      "\u001b[1m46/46\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - loss: 0.0019 - val_loss: 0.0014\n",
      "Epoch 20/30\n",
      "\u001b[1m46/46\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - loss: 0.0023 - val_loss: 0.0021\n",
      "Epoch 21/30\n",
      "\u001b[1m46/46\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - loss: 0.0021 - val_loss: 0.0014\n",
      "Epoch 22/30\n",
      "\u001b[1m46/46\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - loss: 0.0017 - val_loss: 0.0026\n",
      "Epoch 23/30\n",
      "\u001b[1m46/46\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - loss: 0.0018 - val_loss: 8.3938e-04\n",
      "Epoch 24/30\n",
      "\u001b[1m46/46\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - loss: 0.0018 - val_loss: 0.0012\n",
      "Epoch 25/30\n",
      "\u001b[1m46/46\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - loss: 0.0018 - val_loss: 8.2460e-04\n",
      "Epoch 26/30\n",
      "\u001b[1m46/46\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - loss: 0.0018 - val_loss: 8.1575e-04\n",
      "Epoch 27/30\n",
      "\u001b[1m46/46\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - loss: 0.0019 - val_loss: 7.8619e-04\n",
      "Epoch 28/30\n",
      "\u001b[1m46/46\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - loss: 0.0028 - val_loss: 9.5448e-04\n",
      "Epoch 29/30\n",
      "\u001b[1m46/46\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - loss: 0.0016 - val_loss: 0.0016\n",
      "Epoch 30/30\n",
      "\u001b[1m46/46\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - loss: 0.0024 - val_loss: 0.0018\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:The `save_format` argument is deprecated in Keras 3. We recommend removing this argument as it can be inferred from the file path. Received: save_format=keras\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Finished: Trinidad and Tobago | MAE: 0.10 | RMSE: 0.13 | R²: 0.79\n",
      "Epoch 1/30\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/dejauhnaebeadle/School/MachineLearning/machine-learning-project/code/rain-prediction/.venv/lib/python3.11/site-packages/keras/src/layers/rnn/rnn.py:200: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
      "  super().__init__(**kwargs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m46/46\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 12ms/step - loss: 0.0624 - val_loss: 0.0026\n",
      "Epoch 2/30\n",
      "\u001b[1m46/46\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - loss: 0.0084 - val_loss: 0.0019\n",
      "Epoch 3/30\n",
      "\u001b[1m46/46\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - loss: 0.0070 - val_loss: 0.0015\n",
      "Epoch 4/30\n",
      "\u001b[1m46/46\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - loss: 0.0060 - val_loss: 0.0014\n",
      "Epoch 5/30\n",
      "\u001b[1m46/46\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - loss: 0.0052 - val_loss: 0.0015\n",
      "Epoch 6/30\n",
      "\u001b[1m46/46\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - loss: 0.0043 - val_loss: 0.0015\n",
      "Epoch 7/30\n",
      "\u001b[1m46/46\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - loss: 0.0047 - val_loss: 0.0027\n",
      "Epoch 8/30\n",
      "\u001b[1m46/46\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - loss: 0.0043 - val_loss: 0.0012\n",
      "Epoch 9/30\n",
      "\u001b[1m46/46\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - loss: 0.0036 - val_loss: 0.0016\n",
      "Epoch 10/30\n",
      "\u001b[1m46/46\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - loss: 0.0038 - val_loss: 8.7052e-04\n",
      "Epoch 11/30\n",
      "\u001b[1m46/46\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - loss: 0.0036 - val_loss: 7.6946e-04\n",
      "Epoch 12/30\n",
      "\u001b[1m46/46\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - loss: 0.0031 - val_loss: 8.9896e-04\n",
      "Epoch 13/30\n",
      "\u001b[1m46/46\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - loss: 0.0031 - val_loss: 7.8628e-04\n",
      "Epoch 14/30\n",
      "\u001b[1m46/46\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - loss: 0.0030 - val_loss: 7.2792e-04\n",
      "Epoch 15/30\n",
      "\u001b[1m46/46\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - loss: 0.0030 - val_loss: 0.0011\n",
      "Epoch 16/30\n",
      "\u001b[1m46/46\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - loss: 0.0028 - val_loss: 7.6247e-04\n",
      "Epoch 17/30\n",
      "\u001b[1m46/46\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - loss: 0.0026 - val_loss: 0.0014\n",
      "Epoch 18/30\n",
      "\u001b[1m46/46\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - loss: 0.0030 - val_loss: 6.6025e-04\n",
      "Epoch 19/30\n",
      "\u001b[1m46/46\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - loss: 0.0024 - val_loss: 9.4284e-04\n",
      "Epoch 20/30\n",
      "\u001b[1m46/46\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - loss: 0.0027 - val_loss: 9.3655e-04\n",
      "Epoch 21/30\n",
      "\u001b[1m46/46\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - loss: 0.0031 - val_loss: 5.3182e-04\n",
      "Epoch 22/30\n",
      "\u001b[1m46/46\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 0.0022 - val_loss: 6.8460e-04\n",
      "Epoch 23/30\n",
      "\u001b[1m46/46\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - loss: 0.0023 - val_loss: 5.9908e-04\n",
      "Epoch 24/30\n",
      "\u001b[1m46/46\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - loss: 0.0024 - val_loss: 8.2452e-04\n",
      "Epoch 25/30\n",
      "\u001b[1m46/46\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - loss: 0.0022 - val_loss: 5.0073e-04\n",
      "Epoch 26/30\n",
      "\u001b[1m46/46\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - loss: 0.0022 - val_loss: 9.8203e-04\n",
      "Epoch 27/30\n",
      "\u001b[1m46/46\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - loss: 0.0018 - val_loss: 6.5137e-04\n",
      "Epoch 28/30\n",
      "\u001b[1m46/46\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 0.0031 - val_loss: 5.2383e-04\n",
      "Epoch 29/30\n",
      "\u001b[1m46/46\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 0.0018 - val_loss: 6.3746e-04\n",
      "Epoch 30/30\n",
      "\u001b[1m46/46\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 0.0019 - val_loss: 8.2817e-04\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:The `save_format` argument is deprecated in Keras 3. We recommend removing this argument as it can be inferred from the file path. Received: save_format=keras\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Finished: Tunisia | MAE: 0.12 | RMSE: 0.17 | R²: 0.87\n",
      "Epoch 1/30\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/dejauhnaebeadle/School/MachineLearning/machine-learning-project/code/rain-prediction/.venv/lib/python3.11/site-packages/keras/src/layers/rnn/rnn.py:200: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
      "  super().__init__(**kwargs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m46/46\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 15ms/step - loss: 0.0817 - val_loss: 0.0049\n",
      "Epoch 2/30\n",
      "\u001b[1m46/46\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 0.0166 - val_loss: 0.0032\n",
      "Epoch 3/30\n",
      "\u001b[1m46/46\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 0.0136 - val_loss: 0.0029\n",
      "Epoch 4/30\n",
      "\u001b[1m46/46\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 0.0097 - val_loss: 0.0029\n",
      "Epoch 5/30\n",
      "\u001b[1m46/46\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - loss: 0.0083 - val_loss: 0.0013\n",
      "Epoch 6/30\n",
      "\u001b[1m46/46\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 0.0071 - val_loss: 0.0014\n",
      "Epoch 7/30\n",
      "\u001b[1m46/46\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 0.0076 - val_loss: 0.0033\n",
      "Epoch 8/30\n",
      "\u001b[1m46/46\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 0.0079 - val_loss: 0.0022\n",
      "Epoch 9/30\n",
      "\u001b[1m46/46\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 0.0074 - val_loss: 0.0037\n",
      "Epoch 10/30\n",
      "\u001b[1m46/46\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 0.0055 - val_loss: 0.0027\n",
      "Epoch 11/30\n",
      "\u001b[1m46/46\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 0.0062 - val_loss: 0.0022\n",
      "Epoch 12/30\n",
      "\u001b[1m46/46\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 0.0075 - val_loss: 0.0017\n",
      "Epoch 13/30\n",
      "\u001b[1m46/46\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - loss: 0.0062 - val_loss: 0.0013\n",
      "Epoch 14/30\n",
      "\u001b[1m46/46\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - loss: 0.0069 - val_loss: 0.0012\n",
      "Epoch 15/30\n",
      "\u001b[1m46/46\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 0.0064 - val_loss: 0.0034\n",
      "Epoch 16/30\n",
      "\u001b[1m46/46\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 0.0051 - val_loss: 0.0027\n",
      "Epoch 17/30\n",
      "\u001b[1m46/46\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 0.0061 - val_loss: 0.0011\n",
      "Epoch 18/30\n",
      "\u001b[1m46/46\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - loss: 0.0059 - val_loss: 0.0020\n",
      "Epoch 19/30\n",
      "\u001b[1m46/46\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 0.0043 - val_loss: 0.0011\n",
      "Epoch 20/30\n",
      "\u001b[1m46/46\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 0.0054 - val_loss: 9.0744e-04\n",
      "Epoch 21/30\n",
      "\u001b[1m46/46\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 0.0050 - val_loss: 0.0027\n",
      "Epoch 22/30\n",
      "\u001b[1m46/46\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 0.0038 - val_loss: 0.0019\n",
      "Epoch 23/30\n",
      "\u001b[1m46/46\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - loss: 0.0056 - val_loss: 0.0010\n",
      "Epoch 24/30\n",
      "\u001b[1m46/46\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 0.0050 - val_loss: 0.0026\n",
      "Epoch 25/30\n",
      "\u001b[1m46/46\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 0.0037 - val_loss: 0.0017\n",
      "Epoch 26/30\n",
      "\u001b[1m46/46\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 0.0051 - val_loss: 0.0039\n",
      "Epoch 27/30\n",
      "\u001b[1m46/46\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 0.0046 - val_loss: 0.0017\n",
      "Epoch 28/30\n",
      "\u001b[1m46/46\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 0.0052 - val_loss: 0.0024\n",
      "Epoch 29/30\n",
      "\u001b[1m46/46\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 0.0045 - val_loss: 0.0013\n",
      "Epoch 30/30\n",
      "\u001b[1m46/46\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 0.0034 - val_loss: 8.5807e-04\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:The `save_format` argument is deprecated in Keras 3. We recommend removing this argument as it can be inferred from the file path. Received: save_format=keras\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Finished: Turkey | MAE: 0.23 | RMSE: 0.33 | R²: 0.77\n",
      "Epoch 1/30\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/dejauhnaebeadle/School/MachineLearning/machine-learning-project/code/rain-prediction/.venv/lib/python3.11/site-packages/keras/src/layers/rnn/rnn.py:200: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
      "  super().__init__(**kwargs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m46/46\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 12ms/step - loss: 0.0771 - val_loss: 0.0034\n",
      "Epoch 2/30\n",
      "\u001b[1m46/46\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - loss: 0.0136 - val_loss: 0.0037\n",
      "Epoch 3/30\n",
      "\u001b[1m46/46\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 0.0144 - val_loss: 0.0035\n",
      "Epoch 4/30\n",
      "\u001b[1m46/46\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 0.0118 - val_loss: 0.0030\n",
      "Epoch 5/30\n",
      "\u001b[1m46/46\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 0.0090 - val_loss: 0.0025\n",
      "Epoch 6/30\n",
      "\u001b[1m46/46\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 0.0080 - val_loss: 0.0077\n",
      "Epoch 7/30\n",
      "\u001b[1m46/46\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 0.0079 - val_loss: 0.0066\n",
      "Epoch 8/30\n",
      "\u001b[1m46/46\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 0.0078 - val_loss: 0.0017\n",
      "Epoch 9/30\n",
      "\u001b[1m46/46\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 0.0060 - val_loss: 0.0017\n",
      "Epoch 10/30\n",
      "\u001b[1m46/46\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 0.0072 - val_loss: 0.0015\n",
      "Epoch 11/30\n",
      "\u001b[1m46/46\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 0.0081 - val_loss: 0.0027\n",
      "Epoch 12/30\n",
      "\u001b[1m46/46\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 0.0056 - val_loss: 0.0016\n",
      "Epoch 13/30\n",
      "\u001b[1m46/46\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 0.0060 - val_loss: 0.0048\n",
      "Epoch 14/30\n",
      "\u001b[1m46/46\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 0.0058 - val_loss: 0.0016\n",
      "Epoch 15/30\n",
      "\u001b[1m46/46\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 0.0066 - val_loss: 0.0020\n",
      "Epoch 16/30\n",
      "\u001b[1m46/46\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 0.0049 - val_loss: 0.0050\n",
      "Epoch 17/30\n",
      "\u001b[1m46/46\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 0.0057 - val_loss: 0.0020\n",
      "Epoch 18/30\n",
      "\u001b[1m46/46\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 0.0054 - val_loss: 0.0011\n",
      "Epoch 19/30\n",
      "\u001b[1m46/46\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 0.0063 - val_loss: 0.0011\n",
      "Epoch 20/30\n",
      "\u001b[1m46/46\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 0.0042 - val_loss: 0.0016\n",
      "Epoch 21/30\n",
      "\u001b[1m46/46\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 0.0051 - val_loss: 0.0015\n",
      "Epoch 22/30\n",
      "\u001b[1m46/46\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 0.0050 - val_loss: 0.0026\n",
      "Epoch 23/30\n",
      "\u001b[1m46/46\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 0.0044 - val_loss: 0.0013\n",
      "Epoch 24/30\n",
      "\u001b[1m46/46\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 0.0044 - val_loss: 0.0018\n",
      "Epoch 25/30\n",
      "\u001b[1m46/46\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 0.0048 - val_loss: 0.0010\n",
      "Epoch 26/30\n",
      "\u001b[1m46/46\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 0.0051 - val_loss: 0.0016\n",
      "Epoch 27/30\n",
      "\u001b[1m46/46\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 0.0037 - val_loss: 0.0020\n",
      "Epoch 28/30\n",
      "\u001b[1m46/46\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 0.0041 - val_loss: 0.0011\n",
      "Epoch 29/30\n",
      "\u001b[1m46/46\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 0.0040 - val_loss: 0.0011\n",
      "Epoch 30/30\n",
      "\u001b[1m46/46\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 0.0057 - val_loss: 0.0011\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:The `save_format` argument is deprecated in Keras 3. We recommend removing this argument as it can be inferred from the file path. Received: save_format=keras\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Finished: Turkmenistan | MAE: 0.12 | RMSE: 0.23 | R²: 0.85\n",
      "Epoch 1/30\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/dejauhnaebeadle/School/MachineLearning/machine-learning-project/code/rain-prediction/.venv/lib/python3.11/site-packages/keras/src/layers/rnn/rnn.py:200: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
      "  super().__init__(**kwargs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m46/46\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 11ms/step - loss: 0.0505 - val_loss: 0.0038\n",
      "Epoch 2/30\n",
      "\u001b[1m46/46\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 0.0051 - val_loss: 0.0055\n",
      "Epoch 3/30\n",
      "\u001b[1m46/46\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 0.0046 - val_loss: 0.0032\n",
      "Epoch 4/30\n",
      "\u001b[1m46/46\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 0.0037 - val_loss: 0.0029\n",
      "Epoch 5/30\n",
      "\u001b[1m46/46\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 0.0033 - val_loss: 0.0026\n",
      "Epoch 6/30\n",
      "\u001b[1m46/46\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 0.0032 - val_loss: 0.0026\n",
      "Epoch 7/30\n",
      "\u001b[1m46/46\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 0.0034 - val_loss: 0.0020\n",
      "Epoch 8/30\n",
      "\u001b[1m46/46\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 0.0029 - val_loss: 0.0033\n",
      "Epoch 9/30\n",
      "\u001b[1m46/46\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 0.0031 - val_loss: 0.0019\n",
      "Epoch 10/30\n",
      "\u001b[1m46/46\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 0.0029 - val_loss: 0.0020\n",
      "Epoch 11/30\n",
      "\u001b[1m46/46\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 0.0032 - val_loss: 0.0016\n",
      "Epoch 12/30\n",
      "\u001b[1m46/46\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 0.0022 - val_loss: 0.0019\n",
      "Epoch 13/30\n",
      "\u001b[1m46/46\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 0.0026 - val_loss: 0.0015\n",
      "Epoch 14/30\n",
      "\u001b[1m46/46\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 0.0023 - val_loss: 0.0021\n",
      "Epoch 15/30\n",
      "\u001b[1m46/46\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 0.0025 - val_loss: 0.0023\n",
      "Epoch 16/30\n",
      "\u001b[1m46/46\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 0.0017 - val_loss: 0.0022\n",
      "Epoch 17/30\n",
      "\u001b[1m46/46\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 0.0016 - val_loss: 0.0018\n",
      "Epoch 18/30\n",
      "\u001b[1m46/46\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 0.0021 - val_loss: 0.0014\n",
      "Epoch 19/30\n",
      "\u001b[1m46/46\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 0.0015 - val_loss: 0.0038\n",
      "Epoch 20/30\n",
      "\u001b[1m46/46\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 0.0022 - val_loss: 0.0014\n",
      "Epoch 21/30\n",
      "\u001b[1m46/46\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 0.0020 - val_loss: 0.0012\n",
      "Epoch 22/30\n",
      "\u001b[1m46/46\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 0.0019 - val_loss: 0.0012\n",
      "Epoch 23/30\n",
      "\u001b[1m46/46\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 0.0014 - val_loss: 0.0028\n",
      "Epoch 24/30\n",
      "\u001b[1m46/46\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 0.0018 - val_loss: 0.0014\n",
      "Epoch 25/30\n",
      "\u001b[1m46/46\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 0.0011 - val_loss: 0.0011\n",
      "Epoch 26/30\n",
      "\u001b[1m46/46\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 0.0015 - val_loss: 0.0017\n",
      "Epoch 27/30\n",
      "\u001b[1m46/46\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 0.0015 - val_loss: 0.0011\n",
      "Epoch 28/30\n",
      "\u001b[1m46/46\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 0.0015 - val_loss: 0.0010\n",
      "Epoch 29/30\n",
      "\u001b[1m46/46\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 0.0012 - val_loss: 0.0011\n",
      "Epoch 30/30\n",
      "\u001b[1m46/46\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 0.0012 - val_loss: 0.0010\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:The `save_format` argument is deprecated in Keras 3. We recommend removing this argument as it can be inferred from the file path. Received: save_format=keras\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Finished: Uganda | MAE: 0.05 | RMSE: 0.10 | R²: 0.92\n",
      "Epoch 1/30\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/dejauhnaebeadle/School/MachineLearning/machine-learning-project/code/rain-prediction/.venv/lib/python3.11/site-packages/keras/src/layers/rnn/rnn.py:200: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
      "  super().__init__(**kwargs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m46/46\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 10ms/step - loss: 0.0548 - val_loss: 0.0125\n",
      "Epoch 2/30\n",
      "\u001b[1m46/46\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - loss: 0.0114 - val_loss: 0.0080\n",
      "Epoch 3/30\n",
      "\u001b[1m46/46\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 0.0108 - val_loss: 0.0098\n",
      "Epoch 4/30\n",
      "\u001b[1m46/46\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - loss: 0.0087 - val_loss: 0.0087\n",
      "Epoch 5/30\n",
      "\u001b[1m46/46\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 0.0093 - val_loss: 0.0071\n",
      "Epoch 6/30\n",
      "\u001b[1m46/46\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 0.0077 - val_loss: 0.0038\n",
      "Epoch 7/30\n",
      "\u001b[1m46/46\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - loss: 0.0058 - val_loss: 0.0037\n",
      "Epoch 8/30\n",
      "\u001b[1m46/46\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 0.0056 - val_loss: 0.0075\n",
      "Epoch 9/30\n",
      "\u001b[1m46/46\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 0.0057 - val_loss: 0.0074\n",
      "Epoch 10/30\n",
      "\u001b[1m46/46\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 0.0053 - val_loss: 0.0061\n",
      "Epoch 11/30\n",
      "\u001b[1m46/46\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 0.0054 - val_loss: 0.0039\n",
      "Epoch 12/30\n",
      "\u001b[1m46/46\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 0.0051 - val_loss: 0.0047\n",
      "Epoch 13/30\n",
      "\u001b[1m46/46\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - loss: 0.0047 - val_loss: 0.0035\n",
      "Epoch 14/30\n",
      "\u001b[1m46/46\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 0.0047 - val_loss: 0.0035\n",
      "Epoch 15/30\n",
      "\u001b[1m46/46\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 0.0033 - val_loss: 0.0030\n",
      "Epoch 16/30\n",
      "\u001b[1m46/46\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 0.0047 - val_loss: 0.0051\n",
      "Epoch 17/30\n",
      "\u001b[1m46/46\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - loss: 0.0042 - val_loss: 0.0027\n",
      "Epoch 18/30\n",
      "\u001b[1m46/46\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - loss: 0.0038 - val_loss: 0.0042\n",
      "Epoch 19/30\n",
      "\u001b[1m46/46\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 0.0041 - val_loss: 0.0044\n",
      "Epoch 20/30\n",
      "\u001b[1m46/46\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 0.0050 - val_loss: 0.0036\n",
      "Epoch 21/30\n",
      "\u001b[1m46/46\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 0.0045 - val_loss: 0.0030\n",
      "Epoch 22/30\n",
      "\u001b[1m46/46\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 0.0050 - val_loss: 0.0024\n",
      "Epoch 23/30\n",
      "\u001b[1m46/46\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - loss: 0.0036 - val_loss: 0.0032\n",
      "Epoch 24/30\n",
      "\u001b[1m46/46\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 0.0034 - val_loss: 0.0028\n",
      "Epoch 25/30\n",
      "\u001b[1m46/46\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 0.0031 - val_loss: 0.0025\n",
      "Epoch 26/30\n",
      "\u001b[1m46/46\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 0.0038 - val_loss: 0.0023\n",
      "Epoch 27/30\n",
      "\u001b[1m46/46\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 0.0025 - val_loss: 0.0022\n",
      "Epoch 28/30\n",
      "\u001b[1m46/46\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 0.0042 - val_loss: 0.0023\n",
      "Epoch 29/30\n",
      "\u001b[1m46/46\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 0.0030 - val_loss: 0.0028\n",
      "Epoch 30/30\n",
      "\u001b[1m46/46\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 0.0032 - val_loss: 0.0022\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:The `save_format` argument is deprecated in Keras 3. We recommend removing this argument as it can be inferred from the file path. Received: save_format=keras\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Finished: Ukraine | MAE: 0.10 | RMSE: 0.19 | R²: 0.91\n",
      "Epoch 1/30\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/dejauhnaebeadle/School/MachineLearning/machine-learning-project/code/rain-prediction/.venv/lib/python3.11/site-packages/keras/src/layers/rnn/rnn.py:200: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
      "  super().__init__(**kwargs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m46/46\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 10ms/step - loss: 0.0620 - val_loss: 0.0216\n",
      "Epoch 2/30\n",
      "\u001b[1m46/46\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 0.0108 - val_loss: 0.0016\n",
      "Epoch 3/30\n",
      "\u001b[1m46/46\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 0.0082 - val_loss: 0.0028\n",
      "Epoch 4/30\n",
      "\u001b[1m46/46\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 0.0092 - val_loss: 0.0083\n",
      "Epoch 5/30\n",
      "\u001b[1m46/46\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 0.0056 - val_loss: 0.0019\n",
      "Epoch 6/30\n",
      "\u001b[1m46/46\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 0.0053 - val_loss: 0.0229\n",
      "Epoch 7/30\n",
      "\u001b[1m46/46\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 0.0054 - val_loss: 8.5627e-04\n",
      "Epoch 8/30\n",
      "\u001b[1m46/46\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 0.0055 - val_loss: 7.2701e-04\n",
      "Epoch 9/30\n",
      "\u001b[1m46/46\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 0.0056 - val_loss: 0.0028\n",
      "Epoch 10/30\n",
      "\u001b[1m46/46\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 0.0046 - val_loss: 0.0016\n",
      "Epoch 11/30\n",
      "\u001b[1m46/46\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 0.0043 - val_loss: 0.0013\n",
      "Epoch 12/30\n",
      "\u001b[1m46/46\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 0.0051 - val_loss: 7.5453e-04\n",
      "Epoch 13/30\n",
      "\u001b[1m46/46\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 0.0033 - val_loss: 9.5258e-04\n",
      "Epoch 14/30\n",
      "\u001b[1m46/46\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 0.0050 - val_loss: 6.5427e-04\n",
      "Epoch 15/30\n",
      "\u001b[1m46/46\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 0.0042 - val_loss: 7.9993e-04\n",
      "Epoch 16/30\n",
      "\u001b[1m46/46\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 0.0034 - val_loss: 0.0012\n",
      "Epoch 17/30\n",
      "\u001b[1m46/46\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 0.0034 - val_loss: 7.6099e-04\n",
      "Epoch 18/30\n",
      "\u001b[1m46/46\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 0.0031 - val_loss: 5.5171e-04\n",
      "Epoch 19/30\n",
      "\u001b[1m46/46\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 0.0036 - val_loss: 8.8517e-04\n",
      "Epoch 20/30\n",
      "\u001b[1m46/46\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 0.0047 - val_loss: 6.2573e-04\n",
      "Epoch 21/30\n",
      "\u001b[1m46/46\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 0.0029 - val_loss: 6.2322e-04\n",
      "Epoch 22/30\n",
      "\u001b[1m46/46\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 0.0036 - val_loss: 7.6183e-04\n",
      "Epoch 23/30\n",
      "\u001b[1m46/46\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 0.0028 - val_loss: 0.0029\n",
      "Epoch 24/30\n",
      "\u001b[1m46/46\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 0.0037 - val_loss: 7.7042e-04\n",
      "Epoch 25/30\n",
      "\u001b[1m46/46\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 0.0026 - val_loss: 4.5015e-04\n",
      "Epoch 26/30\n",
      "\u001b[1m46/46\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 0.0042 - val_loss: 4.7995e-04\n",
      "Epoch 27/30\n",
      "\u001b[1m46/46\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 0.0025 - val_loss: 5.1263e-04\n",
      "Epoch 28/30\n",
      "\u001b[1m46/46\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 0.0028 - val_loss: 9.7018e-04\n",
      "Epoch 29/30\n",
      "\u001b[1m46/46\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 0.0034 - val_loss: 0.0025\n",
      "Epoch 30/30\n",
      "\u001b[1m46/46\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 0.0029 - val_loss: 6.4977e-04\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:The `save_format` argument is deprecated in Keras 3. We recommend removing this argument as it can be inferred from the file path. Received: save_format=keras\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Finished: United Arab Emirates | MAE: 0.10 | RMSE: 0.16 | R²: 0.84\n",
      "Epoch 1/30\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/dejauhnaebeadle/School/MachineLearning/machine-learning-project/code/rain-prediction/.venv/lib/python3.11/site-packages/keras/src/layers/rnn/rnn.py:200: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
      "  super().__init__(**kwargs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m46/46\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 10ms/step - loss: 0.1253 - val_loss: 0.0164\n",
      "Epoch 2/30\n",
      "\u001b[1m46/46\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 0.0121 - val_loss: 0.0108\n",
      "Epoch 3/30\n",
      "\u001b[1m46/46\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 0.0099 - val_loss: 0.0055\n",
      "Epoch 4/30\n",
      "\u001b[1m46/46\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 0.0095 - val_loss: 0.0028\n",
      "Epoch 5/30\n",
      "\u001b[1m46/46\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 0.0078 - val_loss: 0.0077\n",
      "Epoch 6/30\n",
      "\u001b[1m46/46\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 0.0081 - val_loss: 0.0055\n",
      "Epoch 7/30\n",
      "\u001b[1m46/46\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 0.0078 - val_loss: 0.0052\n",
      "Epoch 8/30\n",
      "\u001b[1m46/46\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 0.0065 - val_loss: 0.0121\n",
      "Epoch 9/30\n",
      "\u001b[1m46/46\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 0.0066 - val_loss: 0.0040\n",
      "Epoch 10/30\n",
      "\u001b[1m46/46\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 0.0048 - val_loss: 0.0060\n",
      "Epoch 11/30\n",
      "\u001b[1m46/46\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 0.0060 - val_loss: 0.0021\n",
      "Epoch 12/30\n",
      "\u001b[1m46/46\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 0.0061 - val_loss: 0.0044\n",
      "Epoch 13/30\n",
      "\u001b[1m46/46\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 0.0050 - val_loss: 0.0047\n",
      "Epoch 14/30\n",
      "\u001b[1m46/46\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 0.0050 - val_loss: 0.0021\n",
      "Epoch 15/30\n",
      "\u001b[1m46/46\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 0.0046 - val_loss: 0.0041\n",
      "Epoch 16/30\n",
      "\u001b[1m46/46\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 0.0053 - val_loss: 0.0062\n",
      "Epoch 17/30\n",
      "\u001b[1m46/46\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 0.0050 - val_loss: 0.0033\n",
      "Epoch 18/30\n",
      "\u001b[1m46/46\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 0.0052 - val_loss: 0.0043\n",
      "Epoch 19/30\n",
      "\u001b[1m46/46\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 0.0046 - val_loss: 0.0014\n",
      "Epoch 20/30\n",
      "\u001b[1m46/46\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 0.0037 - val_loss: 0.0024\n",
      "Epoch 21/30\n",
      "\u001b[1m46/46\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 0.0049 - val_loss: 0.0014\n",
      "Epoch 22/30\n",
      "\u001b[1m46/46\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 0.0046 - val_loss: 0.0031\n",
      "Epoch 23/30\n",
      "\u001b[1m46/46\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 0.0037 - val_loss: 0.0012\n",
      "Epoch 24/30\n",
      "\u001b[1m46/46\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 0.0041 - val_loss: 0.0030\n",
      "Epoch 25/30\n",
      "\u001b[1m46/46\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 0.0043 - val_loss: 0.0018\n",
      "Epoch 26/30\n",
      "\u001b[1m46/46\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 0.0038 - val_loss: 0.0012\n",
      "Epoch 27/30\n",
      "\u001b[1m46/46\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 0.0042 - val_loss: 0.0013\n",
      "Epoch 28/30\n",
      "\u001b[1m46/46\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 0.0033 - val_loss: 0.0016\n",
      "Epoch 29/30\n",
      "\u001b[1m46/46\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 0.0045 - val_loss: 0.0014\n",
      "Epoch 30/30\n",
      "\u001b[1m46/46\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 0.0038 - val_loss: 0.0014\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:The `save_format` argument is deprecated in Keras 3. We recommend removing this argument as it can be inferred from the file path. Received: save_format=keras\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Finished: United Kingdom | MAE: 0.10 | RMSE: 0.21 | R²: 0.83\n"
     ]
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 1000x500 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/30\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/dejauhnaebeadle/School/MachineLearning/machine-learning-project/code/rain-prediction/.venv/lib/python3.11/site-packages/keras/src/layers/rnn/rnn.py:200: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
      "  super().__init__(**kwargs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m46/46\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 9ms/step - loss: 0.0289 - val_loss: 0.0047\n",
      "Epoch 2/30\n",
      "\u001b[1m46/46\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 0.0056 - val_loss: 0.0044\n",
      "Epoch 3/30\n",
      "\u001b[1m46/46\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 0.0046 - val_loss: 0.0052\n",
      "Epoch 4/30\n",
      "\u001b[1m46/46\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 0.0056 - val_loss: 0.0029\n",
      "Epoch 5/30\n",
      "\u001b[1m46/46\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 0.0041 - val_loss: 0.0028\n",
      "Epoch 6/30\n",
      "\u001b[1m46/46\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 0.0034 - val_loss: 0.0027\n",
      "Epoch 7/30\n",
      "\u001b[1m46/46\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 0.0035 - val_loss: 0.0020\n",
      "Epoch 8/30\n",
      "\u001b[1m46/46\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 0.0033 - val_loss: 0.0038\n",
      "Epoch 9/30\n",
      "\u001b[1m46/46\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 0.0036 - val_loss: 0.0022\n",
      "Epoch 10/30\n",
      "\u001b[1m46/46\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 0.0031 - val_loss: 0.0033\n",
      "Epoch 11/30\n",
      "\u001b[1m46/46\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 0.0028 - val_loss: 0.0023\n",
      "Epoch 12/30\n",
      "\u001b[1m46/46\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 0.0027 - val_loss: 0.0027\n",
      "Epoch 13/30\n",
      "\u001b[1m46/46\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 0.0021 - val_loss: 0.0027\n",
      "Epoch 14/30\n",
      "\u001b[1m46/46\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 0.0028 - val_loss: 0.0016\n",
      "Epoch 15/30\n",
      "\u001b[1m46/46\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 0.0021 - val_loss: 0.0018\n",
      "Epoch 16/30\n",
      "\u001b[1m46/46\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 0.0022 - val_loss: 0.0015\n",
      "Epoch 17/30\n",
      "\u001b[1m46/46\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 0.0026 - val_loss: 0.0020\n",
      "Epoch 18/30\n",
      "\u001b[1m46/46\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 0.0023 - val_loss: 0.0019\n",
      "Epoch 19/30\n",
      "\u001b[1m46/46\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - loss: 0.0025 - val_loss: 0.0016\n",
      "Epoch 20/30\n",
      "\u001b[1m46/46\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - loss: 0.0026 - val_loss: 0.0029\n",
      "Epoch 21/30\n",
      "\u001b[1m46/46\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 0.0020 - val_loss: 0.0015\n",
      "Epoch 22/30\n",
      "\u001b[1m46/46\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - loss: 0.0031 - val_loss: 0.0014\n",
      "Epoch 23/30\n",
      "\u001b[1m46/46\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 0.0017 - val_loss: 0.0015\n",
      "Epoch 24/30\n",
      "\u001b[1m46/46\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 0.0020 - val_loss: 0.0022\n",
      "Epoch 25/30\n",
      "\u001b[1m46/46\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 0.0018 - val_loss: 0.0013\n",
      "Epoch 26/30\n",
      "\u001b[1m46/46\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 0.0018 - val_loss: 0.0013\n",
      "Epoch 27/30\n",
      "\u001b[1m46/46\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 0.0015 - val_loss: 0.0017\n",
      "Epoch 28/30\n",
      "\u001b[1m46/46\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 0.0024 - val_loss: 0.0013\n",
      "Epoch 29/30\n",
      "\u001b[1m46/46\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 0.0024 - val_loss: 0.0028\n",
      "Epoch 30/30\n",
      "\u001b[1m46/46\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 0.0021 - val_loss: 0.0013\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:The `save_format` argument is deprecated in Keras 3. We recommend removing this argument as it can be inferred from the file path. Received: save_format=keras\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Finished: United States | MAE: 0.08 | RMSE: 0.16 | R²: 0.92\n"
     ]
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 1000x500 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/30\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/dejauhnaebeadle/School/MachineLearning/machine-learning-project/code/rain-prediction/.venv/lib/python3.11/site-packages/keras/src/layers/rnn/rnn.py:200: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
      "  super().__init__(**kwargs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m46/46\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 10ms/step - loss: 0.0259 - val_loss: 0.0037\n",
      "Epoch 2/30\n",
      "\u001b[1m46/46\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 0.0067 - val_loss: 0.0055\n",
      "Epoch 3/30\n",
      "\u001b[1m46/46\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 0.0052 - val_loss: 0.0033\n",
      "Epoch 4/30\n",
      "\u001b[1m46/46\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 0.0046 - val_loss: 0.0034\n",
      "Epoch 5/30\n",
      "\u001b[1m46/46\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 0.0040 - val_loss: 0.0024\n",
      "Epoch 6/30\n",
      "\u001b[1m46/46\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 0.0039 - val_loss: 0.0028\n",
      "Epoch 7/30\n",
      "\u001b[1m46/46\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 0.0035 - val_loss: 0.0021\n",
      "Epoch 8/30\n",
      "\u001b[1m46/46\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 0.0033 - val_loss: 0.0025\n",
      "Epoch 9/30\n",
      "\u001b[1m46/46\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 0.0031 - val_loss: 0.0026\n",
      "Epoch 10/30\n",
      "\u001b[1m46/46\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 0.0030 - val_loss: 0.0028\n",
      "Epoch 11/30\n",
      "\u001b[1m46/46\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 0.0030 - val_loss: 0.0023\n",
      "Epoch 12/30\n",
      "\u001b[1m46/46\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 0.0032 - val_loss: 0.0029\n",
      "Epoch 13/30\n",
      "\u001b[1m46/46\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 0.0030 - val_loss: 0.0025\n",
      "Epoch 14/30\n",
      "\u001b[1m46/46\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 0.0026 - val_loss: 0.0018\n",
      "Epoch 15/30\n",
      "\u001b[1m46/46\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 0.0025 - val_loss: 0.0029\n",
      "Epoch 16/30\n",
      "\u001b[1m46/46\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 0.0027 - val_loss: 0.0039\n",
      "Epoch 17/30\n",
      "\u001b[1m46/46\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 0.0026 - val_loss: 0.0019\n",
      "Epoch 18/30\n",
      "\u001b[1m46/46\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 0.0021 - val_loss: 0.0034\n",
      "Epoch 19/30\n",
      "\u001b[1m46/46\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 0.0038 - val_loss: 0.0021\n",
      "Epoch 20/30\n",
      "\u001b[1m46/46\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 0.0024 - val_loss: 0.0025\n",
      "Epoch 21/30\n",
      "\u001b[1m46/46\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 0.0019 - val_loss: 0.0015\n",
      "Epoch 22/30\n",
      "\u001b[1m46/46\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 0.0019 - val_loss: 0.0027\n",
      "Epoch 23/30\n",
      "\u001b[1m46/46\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 0.0026 - val_loss: 0.0019\n",
      "Epoch 24/30\n",
      "\u001b[1m46/46\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 0.0023 - val_loss: 0.0015\n",
      "Epoch 25/30\n",
      "\u001b[1m46/46\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 0.0022 - val_loss: 0.0019\n",
      "Epoch 26/30\n",
      "\u001b[1m46/46\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 0.0021 - val_loss: 0.0017\n",
      "Epoch 27/30\n",
      "\u001b[1m46/46\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 0.0025 - val_loss: 0.0018\n",
      "Epoch 28/30\n",
      "\u001b[1m46/46\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 0.0021 - val_loss: 0.0014\n",
      "Epoch 29/30\n",
      "\u001b[1m46/46\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 0.0017 - val_loss: 0.0015\n",
      "Epoch 30/30\n",
      "\u001b[1m46/46\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 0.0023 - val_loss: 0.0024\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:The `save_format` argument is deprecated in Keras 3. We recommend removing this argument as it can be inferred from the file path. Received: save_format=keras\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Finished: United States Virgin Islands | MAE: 0.09 | RMSE: 0.12 | R²: 0.83\n",
      "Epoch 1/30\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/dejauhnaebeadle/School/MachineLearning/machine-learning-project/code/rain-prediction/.venv/lib/python3.11/site-packages/keras/src/layers/rnn/rnn.py:200: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
      "  super().__init__(**kwargs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m46/46\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 11ms/step - loss: 0.0660 - val_loss: 0.0117\n",
      "Epoch 2/30\n",
      "\u001b[1m46/46\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 0.0151 - val_loss: 0.0113\n",
      "Epoch 3/30\n",
      "\u001b[1m46/46\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 0.0120 - val_loss: 0.0084\n",
      "Epoch 4/30\n",
      "\u001b[1m46/46\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 0.0105 - val_loss: 0.0070\n",
      "Epoch 5/30\n",
      "\u001b[1m46/46\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 0.0069 - val_loss: 0.0069\n",
      "Epoch 6/30\n",
      "\u001b[1m46/46\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 0.0082 - val_loss: 0.0062\n",
      "Epoch 7/30\n",
      "\u001b[1m46/46\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 0.0080 - val_loss: 0.0060\n",
      "Epoch 8/30\n",
      "\u001b[1m46/46\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 0.0082 - val_loss: 0.0059\n",
      "Epoch 9/30\n",
      "\u001b[1m46/46\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - loss: 0.0077 - val_loss: 0.0100\n",
      "Epoch 10/30\n",
      "\u001b[1m46/46\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 0.0078 - val_loss: 0.0063\n",
      "Epoch 11/30\n",
      "\u001b[1m46/46\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 0.0052 - val_loss: 0.0054\n",
      "Epoch 12/30\n",
      "\u001b[1m46/46\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 0.0062 - val_loss: 0.0061\n",
      "Epoch 13/30\n",
      "\u001b[1m46/46\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 0.0063 - val_loss: 0.0052\n",
      "Epoch 14/30\n",
      "\u001b[1m46/46\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 0.0066 - val_loss: 0.0069\n",
      "Epoch 15/30\n",
      "\u001b[1m46/46\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 0.0069 - val_loss: 0.0050\n",
      "Epoch 16/30\n",
      "\u001b[1m46/46\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 0.0054 - val_loss: 0.0057\n",
      "Epoch 17/30\n",
      "\u001b[1m46/46\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 0.0056 - val_loss: 0.0051\n",
      "Epoch 18/30\n",
      "\u001b[1m46/46\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 0.0042 - val_loss: 0.0046\n",
      "Epoch 19/30\n",
      "\u001b[1m46/46\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 0.0041 - val_loss: 0.0060\n",
      "Epoch 20/30\n",
      "\u001b[1m46/46\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 0.0052 - val_loss: 0.0047\n",
      "Epoch 21/30\n",
      "\u001b[1m46/46\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 0.0053 - val_loss: 0.0043\n",
      "Epoch 22/30\n",
      "\u001b[1m46/46\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 0.0061 - val_loss: 0.0043\n",
      "Epoch 23/30\n",
      "\u001b[1m46/46\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 0.0038 - val_loss: 0.0046\n",
      "Epoch 24/30\n",
      "\u001b[1m46/46\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 0.0064 - val_loss: 0.0045\n",
      "Epoch 25/30\n",
      "\u001b[1m46/46\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 0.0047 - val_loss: 0.0042\n",
      "Epoch 26/30\n",
      "\u001b[1m46/46\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 0.0032 - val_loss: 0.0051\n",
      "Epoch 27/30\n",
      "\u001b[1m46/46\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 0.0070 - val_loss: 0.0042\n",
      "Epoch 28/30\n",
      "\u001b[1m46/46\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 0.0042 - val_loss: 0.0043\n",
      "Epoch 29/30\n",
      "\u001b[1m46/46\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 0.0047 - val_loss: 0.0040\n",
      "Epoch 30/30\n",
      "\u001b[1m46/46\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 0.0058 - val_loss: 0.0042\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:The `save_format` argument is deprecated in Keras 3. We recommend removing this argument as it can be inferred from the file path. Received: save_format=keras\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Finished: Uruguay | MAE: 0.09 | RMSE: 0.17 | R²: 0.76\n",
      "Epoch 1/30\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/dejauhnaebeadle/School/MachineLearning/machine-learning-project/code/rain-prediction/.venv/lib/python3.11/site-packages/keras/src/layers/rnn/rnn.py:200: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
      "  super().__init__(**kwargs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m46/46\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 9ms/step - loss: 0.0526 - val_loss: 0.0072\n",
      "Epoch 2/30\n",
      "\u001b[1m46/46\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 0.0144 - val_loss: 0.0093\n",
      "Epoch 3/30\n",
      "\u001b[1m46/46\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 0.0133 - val_loss: 0.0127\n",
      "Epoch 4/30\n",
      "\u001b[1m46/46\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 0.0111 - val_loss: 0.0034\n",
      "Epoch 5/30\n",
      "\u001b[1m46/46\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 0.0095 - val_loss: 0.0113\n",
      "Epoch 6/30\n",
      "\u001b[1m46/46\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 0.0109 - val_loss: 0.0031\n",
      "Epoch 7/30\n",
      "\u001b[1m46/46\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 0.0095 - val_loss: 0.0045\n",
      "Epoch 8/30\n",
      "\u001b[1m46/46\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 0.0078 - val_loss: 0.0033\n",
      "Epoch 9/30\n",
      "\u001b[1m46/46\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 0.0094 - val_loss: 0.0031\n",
      "Epoch 10/30\n",
      "\u001b[1m46/46\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 0.0066 - val_loss: 0.0053\n",
      "Epoch 11/30\n",
      "\u001b[1m46/46\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 0.0068 - val_loss: 0.0038\n",
      "Epoch 12/30\n",
      "\u001b[1m46/46\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 0.0087 - val_loss: 0.0034\n",
      "Epoch 13/30\n",
      "\u001b[1m46/46\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 0.0066 - val_loss: 0.0030\n",
      "Epoch 14/30\n",
      "\u001b[1m46/46\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 0.0065 - val_loss: 0.0073\n",
      "Epoch 15/30\n",
      "\u001b[1m46/46\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 0.0056 - val_loss: 0.0031\n",
      "Epoch 16/30\n",
      "\u001b[1m46/46\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 0.0074 - val_loss: 0.0024\n",
      "Epoch 17/30\n",
      "\u001b[1m46/46\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 0.0061 - val_loss: 0.0051\n",
      "Epoch 18/30\n",
      "\u001b[1m46/46\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 0.0059 - val_loss: 0.0022\n",
      "Epoch 19/30\n",
      "\u001b[1m46/46\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 0.0053 - val_loss: 0.0024\n",
      "Epoch 20/30\n",
      "\u001b[1m46/46\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 0.0052 - val_loss: 0.0021\n",
      "Epoch 21/30\n",
      "\u001b[1m46/46\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 0.0054 - val_loss: 0.0022\n",
      "Epoch 22/30\n",
      "\u001b[1m46/46\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 0.0062 - val_loss: 0.0039\n",
      "Epoch 23/30\n",
      "\u001b[1m46/46\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 0.0056 - val_loss: 0.0031\n",
      "Epoch 24/30\n",
      "\u001b[1m46/46\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 0.0056 - val_loss: 0.0037\n",
      "Epoch 25/30\n",
      "\u001b[1m46/46\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 0.0049 - val_loss: 0.0027\n",
      "Epoch 26/30\n",
      "\u001b[1m46/46\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 0.0050 - val_loss: 0.0046\n",
      "Epoch 27/30\n",
      "\u001b[1m46/46\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 0.0065 - val_loss: 0.0027\n",
      "Epoch 28/30\n",
      "\u001b[1m46/46\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 0.0067 - val_loss: 0.0026\n",
      "Epoch 29/30\n",
      "\u001b[1m46/46\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 0.0058 - val_loss: 0.0020\n",
      "Epoch 30/30\n",
      "\u001b[1m46/46\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 0.0044 - val_loss: 0.0037\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:The `save_format` argument is deprecated in Keras 3. We recommend removing this argument as it can be inferred from the file path. Received: save_format=keras\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Finished: Uzbekistan | MAE: 0.27 | RMSE: 0.34 | R²: 0.74\n",
      "Epoch 1/30\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/dejauhnaebeadle/School/MachineLearning/machine-learning-project/code/rain-prediction/.venv/lib/python3.11/site-packages/keras/src/layers/rnn/rnn.py:200: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
      "  super().__init__(**kwargs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m46/46\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 9ms/step - loss: 0.0616 - val_loss: 0.0083\n",
      "Epoch 2/30\n",
      "\u001b[1m46/46\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 0.0117 - val_loss: 0.0073\n",
      "Epoch 3/30\n",
      "\u001b[1m46/46\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 0.0082 - val_loss: 0.0070\n",
      "Epoch 4/30\n",
      "\u001b[1m46/46\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - loss: 0.0082 - val_loss: 0.0079\n",
      "Epoch 5/30\n",
      "\u001b[1m46/46\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 0.0068 - val_loss: 0.0038\n",
      "Epoch 6/30\n",
      "\u001b[1m46/46\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 0.0062 - val_loss: 0.0040\n",
      "Epoch 7/30\n",
      "\u001b[1m46/46\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 0.0057 - val_loss: 0.0037\n",
      "Epoch 8/30\n",
      "\u001b[1m46/46\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 0.0062 - val_loss: 0.0035\n",
      "Epoch 9/30\n",
      "\u001b[1m46/46\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 0.0056 - val_loss: 0.0037\n",
      "Epoch 10/30\n",
      "\u001b[1m46/46\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 0.0045 - val_loss: 0.0032\n",
      "Epoch 11/30\n",
      "\u001b[1m46/46\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 0.0041 - val_loss: 0.0033\n",
      "Epoch 12/30\n",
      "\u001b[1m46/46\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 0.0052 - val_loss: 0.0031\n",
      "Epoch 13/30\n",
      "\u001b[1m46/46\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 0.0051 - val_loss: 0.0028\n",
      "Epoch 14/30\n",
      "\u001b[1m46/46\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 0.0049 - val_loss: 0.0027\n",
      "Epoch 15/30\n",
      "\u001b[1m46/46\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 0.0052 - val_loss: 0.0035\n",
      "Epoch 16/30\n",
      "\u001b[1m46/46\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 0.0042 - val_loss: 0.0030\n",
      "Epoch 17/30\n",
      "\u001b[1m46/46\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 0.0042 - val_loss: 0.0032\n",
      "Epoch 18/30\n",
      "\u001b[1m46/46\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 0.0048 - val_loss: 0.0027\n",
      "Epoch 19/30\n",
      "\u001b[1m46/46\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 0.0038 - val_loss: 0.0024\n",
      "Epoch 20/30\n",
      "\u001b[1m46/46\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 0.0034 - val_loss: 0.0023\n",
      "Epoch 21/30\n",
      "\u001b[1m46/46\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 0.0040 - val_loss: 0.0031\n",
      "Epoch 22/30\n",
      "\u001b[1m46/46\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 0.0037 - val_loss: 0.0022\n",
      "Epoch 23/30\n",
      "\u001b[1m46/46\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 0.0038 - val_loss: 0.0021\n",
      "Epoch 24/30\n",
      "\u001b[1m46/46\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - loss: 0.0046 - val_loss: 0.0021\n",
      "Epoch 25/30\n",
      "\u001b[1m46/46\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - loss: 0.0029 - val_loss: 0.0022\n",
      "Epoch 26/30\n",
      "\u001b[1m46/46\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - loss: 0.0026 - val_loss: 0.0031\n",
      "Epoch 27/30\n",
      "\u001b[1m46/46\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - loss: 0.0036 - val_loss: 0.0025\n",
      "Epoch 28/30\n",
      "\u001b[1m46/46\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 0.0033 - val_loss: 0.0025\n",
      "Epoch 29/30\n",
      "\u001b[1m46/46\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - loss: 0.0030 - val_loss: 0.0020\n",
      "Epoch 30/30\n",
      "\u001b[1m46/46\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 0.0031 - val_loss: 0.0021\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:The `save_format` argument is deprecated in Keras 3. We recommend removing this argument as it can be inferred from the file path. Received: save_format=keras\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Finished: Vanuatu | MAE: 0.05 | RMSE: 0.09 | R²: 0.85\n",
      "Epoch 1/30\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/dejauhnaebeadle/School/MachineLearning/machine-learning-project/code/rain-prediction/.venv/lib/python3.11/site-packages/keras/src/layers/rnn/rnn.py:200: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
      "  super().__init__(**kwargs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m46/46\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 12ms/step - loss: 0.0703 - val_loss: 0.0026\n",
      "Epoch 2/30\n",
      "\u001b[1m46/46\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 0.0056 - val_loss: 0.0046\n",
      "Epoch 3/30\n",
      "\u001b[1m46/46\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 0.0046 - val_loss: 0.0022\n",
      "Epoch 4/30\n",
      "\u001b[1m46/46\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 0.0042 - val_loss: 0.0021\n",
      "Epoch 5/30\n",
      "\u001b[1m46/46\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - loss: 0.0039 - val_loss: 0.0015\n",
      "Epoch 6/30\n",
      "\u001b[1m46/46\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - loss: 0.0038 - val_loss: 0.0014\n",
      "Epoch 7/30\n",
      "\u001b[1m46/46\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - loss: 0.0035 - val_loss: 0.0013\n",
      "Epoch 8/30\n",
      "\u001b[1m46/46\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - loss: 0.0033 - val_loss: 0.0022\n",
      "Epoch 9/30\n",
      "\u001b[1m46/46\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 0.0035 - val_loss: 0.0013\n",
      "Epoch 10/30\n",
      "\u001b[1m46/46\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 0.0026 - val_loss: 9.3666e-04\n",
      "Epoch 11/30\n",
      "\u001b[1m46/46\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 0.0025 - val_loss: 0.0013\n",
      "Epoch 12/30\n",
      "\u001b[1m46/46\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 0.0023 - val_loss: 0.0017\n",
      "Epoch 13/30\n",
      "\u001b[1m46/46\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - loss: 0.0021 - val_loss: 0.0013\n",
      "Epoch 14/30\n",
      "\u001b[1m46/46\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 0.0023 - val_loss: 6.2535e-04\n",
      "Epoch 15/30\n",
      "\u001b[1m46/46\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 0.0024 - val_loss: 6.5072e-04\n",
      "Epoch 16/30\n",
      "\u001b[1m46/46\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 0.0022 - val_loss: 0.0013\n",
      "Epoch 17/30\n",
      "\u001b[1m46/46\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 0.0027 - val_loss: 0.0020\n",
      "Epoch 18/30\n",
      "\u001b[1m46/46\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 0.0018 - val_loss: 0.0025\n",
      "Epoch 19/30\n",
      "\u001b[1m46/46\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 0.0020 - val_loss: 6.0394e-04\n",
      "Epoch 20/30\n",
      "\u001b[1m46/46\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - loss: 0.0024 - val_loss: 9.7859e-04\n",
      "Epoch 21/30\n",
      "\u001b[1m46/46\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 0.0019 - val_loss: 8.5768e-04\n",
      "Epoch 22/30\n",
      "\u001b[1m46/46\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 0.0018 - val_loss: 0.0011\n",
      "Epoch 23/30\n",
      "\u001b[1m46/46\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 0.0018 - val_loss: 6.2276e-04\n",
      "Epoch 24/30\n",
      "\u001b[1m46/46\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 0.0017 - val_loss: 7.5885e-04\n",
      "Epoch 25/30\n",
      "\u001b[1m46/46\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 0.0019 - val_loss: 5.6733e-04\n",
      "Epoch 26/30\n",
      "\u001b[1m46/46\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 0.0018 - val_loss: 4.7496e-04\n",
      "Epoch 27/30\n",
      "\u001b[1m46/46\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - loss: 0.0021 - val_loss: 0.0012\n",
      "Epoch 28/30\n",
      "\u001b[1m46/46\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - loss: 0.0014 - val_loss: 8.2230e-04\n",
      "Epoch 29/30\n",
      "\u001b[1m46/46\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 0.0015 - val_loss: 9.8432e-04\n",
      "Epoch 30/30\n",
      "\u001b[1m46/46\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 0.0016 - val_loss: 0.0018\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:The `save_format` argument is deprecated in Keras 3. We recommend removing this argument as it can be inferred from the file path. Received: save_format=keras\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Finished: Venezuela | MAE: 0.18 | RMSE: 0.22 | R²: 0.68\n",
      "Epoch 1/30\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/dejauhnaebeadle/School/MachineLearning/machine-learning-project/code/rain-prediction/.venv/lib/python3.11/site-packages/keras/src/layers/rnn/rnn.py:200: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
      "  super().__init__(**kwargs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m46/46\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 10ms/step - loss: 0.0636 - val_loss: 0.0037\n",
      "Epoch 2/30\n",
      "\u001b[1m46/46\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 0.0056 - val_loss: 0.0037\n",
      "Epoch 3/30\n",
      "\u001b[1m46/46\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 0.0059 - val_loss: 0.0036\n",
      "Epoch 4/30\n",
      "\u001b[1m46/46\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 0.0048 - val_loss: 0.0026\n",
      "Epoch 5/30\n",
      "\u001b[1m46/46\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 0.0044 - val_loss: 0.0036\n",
      "Epoch 6/30\n",
      "\u001b[1m46/46\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 0.0039 - val_loss: 0.0022\n",
      "Epoch 7/30\n",
      "\u001b[1m46/46\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 0.0037 - val_loss: 0.0021\n",
      "Epoch 8/30\n",
      "\u001b[1m46/46\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 0.0030 - val_loss: 0.0025\n",
      "Epoch 9/30\n",
      "\u001b[1m46/46\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 0.0029 - val_loss: 0.0019\n",
      "Epoch 10/30\n",
      "\u001b[1m46/46\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 0.0036 - val_loss: 0.0033\n",
      "Epoch 11/30\n",
      "\u001b[1m46/46\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 0.0029 - val_loss: 0.0020\n",
      "Epoch 12/30\n",
      "\u001b[1m46/46\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 0.0023 - val_loss: 0.0018\n",
      "Epoch 13/30\n",
      "\u001b[1m46/46\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 0.0031 - val_loss: 0.0017\n",
      "Epoch 14/30\n",
      "\u001b[1m46/46\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 0.0025 - val_loss: 0.0017\n",
      "Epoch 15/30\n",
      "\u001b[1m46/46\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 0.0025 - val_loss: 0.0023\n",
      "Epoch 16/30\n",
      "\u001b[1m46/46\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 0.0023 - val_loss: 0.0033\n",
      "Epoch 17/30\n",
      "\u001b[1m46/46\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 0.0022 - val_loss: 0.0023\n",
      "Epoch 18/30\n",
      "\u001b[1m46/46\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 0.0023 - val_loss: 0.0015\n",
      "Epoch 19/30\n",
      "\u001b[1m46/46\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 0.0023 - val_loss: 0.0015\n",
      "Epoch 20/30\n",
      "\u001b[1m46/46\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 0.0018 - val_loss: 0.0015\n",
      "Epoch 21/30\n",
      "\u001b[1m46/46\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 0.0025 - val_loss: 0.0016\n",
      "Epoch 22/30\n",
      "\u001b[1m46/46\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 0.0025 - val_loss: 0.0019\n",
      "Epoch 23/30\n",
      "\u001b[1m46/46\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 0.0019 - val_loss: 0.0016\n",
      "Epoch 24/30\n",
      "\u001b[1m46/46\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 0.0025 - val_loss: 0.0014\n",
      "Epoch 25/30\n",
      "\u001b[1m46/46\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 0.0024 - val_loss: 0.0021\n",
      "Epoch 26/30\n",
      "\u001b[1m46/46\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 0.0020 - val_loss: 0.0015\n",
      "Epoch 27/30\n",
      "\u001b[1m46/46\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 0.0023 - val_loss: 0.0016\n",
      "Epoch 28/30\n",
      "\u001b[1m46/46\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 0.0018 - val_loss: 0.0020\n",
      "Epoch 29/30\n",
      "\u001b[1m46/46\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 0.0021 - val_loss: 0.0014\n",
      "Epoch 30/30\n",
      "\u001b[1m46/46\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 0.0018 - val_loss: 0.0013\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:The `save_format` argument is deprecated in Keras 3. We recommend removing this argument as it can be inferred from the file path. Received: save_format=keras\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Finished: Vietnam | MAE: 0.09 | RMSE: 0.17 | R²: 0.86\n",
      "Epoch 1/30\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/dejauhnaebeadle/School/MachineLearning/machine-learning-project/code/rain-prediction/.venv/lib/python3.11/site-packages/keras/src/layers/rnn/rnn.py:200: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
      "  super().__init__(**kwargs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m46/46\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 11ms/step - loss: 0.0154 - val_loss: 0.0011\n",
      "Epoch 2/30\n",
      "\u001b[1m46/46\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 0.0020 - val_loss: 9.6925e-04\n",
      "Epoch 3/30\n",
      "\u001b[1m46/46\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 0.0018 - val_loss: 8.2197e-04\n",
      "Epoch 4/30\n",
      "\u001b[1m46/46\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 0.0019 - val_loss: 8.9917e-04\n",
      "Epoch 5/30\n",
      "\u001b[1m46/46\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 0.0016 - val_loss: 6.7535e-04\n",
      "Epoch 6/30\n",
      "\u001b[1m46/46\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 0.0018 - val_loss: 0.0012\n",
      "Epoch 7/30\n",
      "\u001b[1m46/46\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 0.0012 - val_loss: 5.7625e-04\n",
      "Epoch 8/30\n",
      "\u001b[1m46/46\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 0.0013 - val_loss: 9.1294e-04\n",
      "Epoch 9/30\n",
      "\u001b[1m46/46\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 0.0013 - val_loss: 6.6082e-04\n",
      "Epoch 10/30\n",
      "\u001b[1m46/46\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 9.6056e-04 - val_loss: 7.9438e-04\n",
      "Epoch 11/30\n",
      "\u001b[1m46/46\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 9.9033e-04 - val_loss: 5.2129e-04\n",
      "Epoch 12/30\n",
      "\u001b[1m46/46\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 0.0011 - val_loss: 4.8102e-04\n",
      "Epoch 13/30\n",
      "\u001b[1m46/46\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 0.0011 - val_loss: 0.0014\n",
      "Epoch 14/30\n",
      "\u001b[1m46/46\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 9.3085e-04 - val_loss: 7.3561e-04\n",
      "Epoch 15/30\n",
      "\u001b[1m46/46\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 0.0010 - val_loss: 4.7748e-04\n",
      "Epoch 16/30\n",
      "\u001b[1m46/46\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 8.5951e-04 - val_loss: 4.6473e-04\n",
      "Epoch 17/30\n",
      "\u001b[1m46/46\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 8.2422e-04 - val_loss: 4.6212e-04\n",
      "Epoch 18/30\n",
      "\u001b[1m46/46\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - loss: 0.0012 - val_loss: 4.3404e-04\n",
      "Epoch 19/30\n",
      "\u001b[1m46/46\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - loss: 8.8204e-04 - val_loss: 0.0011\n",
      "Epoch 20/30\n",
      "\u001b[1m46/46\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - loss: 8.3921e-04 - val_loss: 4.0263e-04\n",
      "Epoch 21/30\n",
      "\u001b[1m46/46\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 6.4457e-04 - val_loss: 5.1840e-04\n",
      "Epoch 22/30\n",
      "\u001b[1m46/46\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 0.0011 - val_loss: 4.2187e-04\n",
      "Epoch 23/30\n",
      "\u001b[1m46/46\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - loss: 9.3671e-04 - val_loss: 3.9005e-04\n",
      "Epoch 24/30\n",
      "\u001b[1m46/46\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - loss: 7.8774e-04 - val_loss: 3.7793e-04\n",
      "Epoch 25/30\n",
      "\u001b[1m46/46\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - loss: 6.0599e-04 - val_loss: 0.0010\n",
      "Epoch 26/30\n",
      "\u001b[1m46/46\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 0.0010 - val_loss: 3.9028e-04\n",
      "Epoch 27/30\n",
      "\u001b[1m46/46\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 8.0249e-04 - val_loss: 5.0227e-04\n",
      "Epoch 28/30\n",
      "\u001b[1m46/46\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 0.0010 - val_loss: 5.5094e-04\n",
      "Epoch 29/30\n",
      "\u001b[1m46/46\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - loss: 7.4624e-04 - val_loss: 3.4652e-04\n",
      "Epoch 30/30\n",
      "\u001b[1m46/46\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - loss: 7.7017e-04 - val_loss: 9.8203e-04\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:The `save_format` argument is deprecated in Keras 3. We recommend removing this argument as it can be inferred from the file path. Received: save_format=keras\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Finished: World | MAE: 0.06 | RMSE: 0.07 | R²: 0.90\n",
      "Epoch 1/30\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/dejauhnaebeadle/School/MachineLearning/machine-learning-project/code/rain-prediction/.venv/lib/python3.11/site-packages/keras/src/layers/rnn/rnn.py:200: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
      "  super().__init__(**kwargs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m46/46\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 15ms/step - loss: 0.0383 - val_loss: 0.0025\n",
      "Epoch 2/30\n",
      "\u001b[1m46/46\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 0.0042 - val_loss: 8.1700e-04\n",
      "Epoch 3/30\n",
      "\u001b[1m46/46\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 0.0033 - val_loss: 7.8787e-04\n",
      "Epoch 4/30\n",
      "\u001b[1m46/46\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 0.0031 - val_loss: 7.9218e-04\n",
      "Epoch 5/30\n",
      "\u001b[1m46/46\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 0.0028 - val_loss: 0.0010\n",
      "Epoch 6/30\n",
      "\u001b[1m46/46\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 0.0028 - val_loss: 7.3528e-04\n",
      "Epoch 7/30\n",
      "\u001b[1m46/46\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 0.0024 - val_loss: 6.8514e-04\n",
      "Epoch 8/30\n",
      "\u001b[1m46/46\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 0.0022 - val_loss: 0.0014\n",
      "Epoch 9/30\n",
      "\u001b[1m46/46\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 0.0030 - val_loss: 7.9443e-04\n",
      "Epoch 10/30\n",
      "\u001b[1m46/46\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 0.0025 - val_loss: 8.4060e-04\n",
      "Epoch 11/30\n",
      "\u001b[1m46/46\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 0.0024 - val_loss: 0.0011\n",
      "Epoch 12/30\n",
      "\u001b[1m46/46\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 0.0022 - val_loss: 0.0016\n",
      "Epoch 13/30\n",
      "\u001b[1m46/46\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - loss: 0.0017 - val_loss: 7.7601e-04\n",
      "Epoch 14/30\n",
      "\u001b[1m46/46\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - loss: 0.0019 - val_loss: 0.0011\n",
      "Epoch 15/30\n",
      "\u001b[1m46/46\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - loss: 0.0019 - val_loss: 7.1566e-04\n",
      "Epoch 16/30\n",
      "\u001b[1m46/46\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - loss: 0.0018 - val_loss: 0.0013\n",
      "Epoch 17/30\n",
      "\u001b[1m46/46\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 0.0016 - val_loss: 5.7562e-04\n",
      "Epoch 18/30\n",
      "\u001b[1m46/46\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 0.0017 - val_loss: 7.7513e-04\n",
      "Epoch 19/30\n",
      "\u001b[1m46/46\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 0.0017 - val_loss: 0.0017\n",
      "Epoch 20/30\n",
      "\u001b[1m46/46\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - loss: 0.0016 - val_loss: 6.0659e-04\n",
      "Epoch 21/30\n",
      "\u001b[1m46/46\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - loss: 0.0013 - val_loss: 9.6394e-04\n",
      "Epoch 22/30\n",
      "\u001b[1m46/46\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - loss: 0.0016 - val_loss: 9.8400e-04\n",
      "Epoch 23/30\n",
      "\u001b[1m46/46\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - loss: 0.0014 - val_loss: 5.6890e-04\n",
      "Epoch 24/30\n",
      "\u001b[1m46/46\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - loss: 0.0013 - val_loss: 6.5448e-04\n",
      "Epoch 25/30\n",
      "\u001b[1m46/46\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - loss: 0.0017 - val_loss: 6.7332e-04\n",
      "Epoch 26/30\n",
      "\u001b[1m46/46\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - loss: 0.0013 - val_loss: 5.1239e-04\n",
      "Epoch 27/30\n",
      "\u001b[1m46/46\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - loss: 0.0017 - val_loss: 5.7160e-04\n",
      "Epoch 28/30\n",
      "\u001b[1m46/46\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - loss: 0.0013 - val_loss: 4.8664e-04\n",
      "Epoch 29/30\n",
      "\u001b[1m46/46\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 11ms/step - loss: 0.0011 - val_loss: 5.5653e-04\n",
      "Epoch 30/30\n",
      "\u001b[1m46/46\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - loss: 0.0016 - val_loss: 4.8749e-04\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:The `save_format` argument is deprecated in Keras 3. We recommend removing this argument as it can be inferred from the file path. Received: save_format=keras\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Finished: Yemen | MAE: 0.06 | RMSE: 0.12 | R²: 0.89\n",
      "Epoch 1/30\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/dejauhnaebeadle/School/MachineLearning/machine-learning-project/code/rain-prediction/.venv/lib/python3.11/site-packages/keras/src/layers/rnn/rnn.py:200: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
      "  super().__init__(**kwargs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m46/46\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 17ms/step - loss: 0.0524 - val_loss: 0.0170\n",
      "Epoch 2/30\n",
      "\u001b[1m46/46\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - loss: 0.0179 - val_loss: 0.0145\n",
      "Epoch 3/30\n",
      "\u001b[1m46/46\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - loss: 0.0142 - val_loss: 0.0136\n",
      "Epoch 4/30\n",
      "\u001b[1m46/46\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 10ms/step - loss: 0.0111 - val_loss: 0.0095\n",
      "Epoch 5/30\n",
      "\u001b[1m46/46\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - loss: 0.0088 - val_loss: 0.0095\n",
      "Epoch 6/30\n",
      "\u001b[1m46/46\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - loss: 0.0078 - val_loss: 0.0092\n",
      "Epoch 7/30\n",
      "\u001b[1m46/46\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - loss: 0.0068 - val_loss: 0.0091\n",
      "Epoch 8/30\n",
      "\u001b[1m46/46\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 11ms/step - loss: 0.0102 - val_loss: 0.0081\n",
      "Epoch 9/30\n",
      "\u001b[1m46/46\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 11ms/step - loss: 0.0089 - val_loss: 0.0081\n",
      "Epoch 10/30\n",
      "\u001b[1m46/46\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 10ms/step - loss: 0.0060 - val_loss: 0.0093\n",
      "Epoch 11/30\n",
      "\u001b[1m46/46\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - loss: 0.0091 - val_loss: 0.0074\n",
      "Epoch 12/30\n",
      "\u001b[1m46/46\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - loss: 0.0068 - val_loss: 0.0074\n",
      "Epoch 13/30\n",
      "\u001b[1m46/46\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - loss: 0.0053 - val_loss: 0.0082\n",
      "Epoch 14/30\n",
      "\u001b[1m46/46\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - loss: 0.0067 - val_loss: 0.0064\n",
      "Epoch 15/30\n",
      "\u001b[1m46/46\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 10ms/step - loss: 0.0085 - val_loss: 0.0071\n",
      "Epoch 16/30\n",
      "\u001b[1m46/46\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - loss: 0.0055 - val_loss: 0.0087\n",
      "Epoch 17/30\n",
      "\u001b[1m46/46\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - loss: 0.0092 - val_loss: 0.0060\n",
      "Epoch 18/30\n",
      "\u001b[1m46/46\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - loss: 0.0064 - val_loss: 0.0069\n",
      "Epoch 19/30\n",
      "\u001b[1m46/46\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - loss: 0.0044 - val_loss: 0.0063\n",
      "Epoch 20/30\n",
      "\u001b[1m46/46\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - loss: 0.0069 - val_loss: 0.0057\n",
      "Epoch 21/30\n",
      "\u001b[1m46/46\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - loss: 0.0042 - val_loss: 0.0057\n",
      "Epoch 22/30\n",
      "\u001b[1m46/46\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - loss: 0.0058 - val_loss: 0.0055\n",
      "Epoch 23/30\n",
      "\u001b[1m46/46\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - loss: 0.0055 - val_loss: 0.0054\n",
      "Epoch 24/30\n",
      "\u001b[1m46/46\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - loss: 0.0037 - val_loss: 0.0081\n",
      "Epoch 25/30\n",
      "\u001b[1m46/46\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - loss: 0.0041 - val_loss: 0.0068\n",
      "Epoch 26/30\n",
      "\u001b[1m46/46\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - loss: 0.0065 - val_loss: 0.0069\n",
      "Epoch 27/30\n",
      "\u001b[1m46/46\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - loss: 0.0067 - val_loss: 0.0060\n",
      "Epoch 28/30\n",
      "\u001b[1m46/46\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - loss: 0.0049 - val_loss: 0.0053\n",
      "Epoch 29/30\n",
      "\u001b[1m46/46\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - loss: 0.0062 - val_loss: 0.0053\n",
      "Epoch 30/30\n",
      "\u001b[1m46/46\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - loss: 0.0037 - val_loss: 0.0063\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:The `save_format` argument is deprecated in Keras 3. We recommend removing this argument as it can be inferred from the file path. Received: save_format=keras\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Finished: Zambia | MAE: 0.11 | RMSE: 0.13 | R²: 0.85\n",
      "Epoch 1/30\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/dejauhnaebeadle/School/MachineLearning/machine-learning-project/code/rain-prediction/.venv/lib/python3.11/site-packages/keras/src/layers/rnn/rnn.py:200: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
      "  super().__init__(**kwargs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m46/46\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 14ms/step - loss: 0.0308 - val_loss: 0.0144\n",
      "Epoch 2/30\n",
      "\u001b[1m46/46\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - loss: 0.0140 - val_loss: 0.0128\n",
      "Epoch 3/30\n",
      "\u001b[1m46/46\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - loss: 0.0112 - val_loss: 0.0098\n",
      "Epoch 4/30\n",
      "\u001b[1m46/46\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - loss: 0.0096 - val_loss: 0.0109\n",
      "Epoch 5/30\n",
      "\u001b[1m46/46\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - loss: 0.0076 - val_loss: 0.0061\n",
      "Epoch 6/30\n",
      "\u001b[1m46/46\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 0.0074 - val_loss: 0.0050\n",
      "Epoch 7/30\n",
      "\u001b[1m46/46\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - loss: 0.0070 - val_loss: 0.0055\n",
      "Epoch 8/30\n",
      "\u001b[1m46/46\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - loss: 0.0060 - val_loss: 0.0048\n",
      "Epoch 9/30\n",
      "\u001b[1m46/46\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - loss: 0.0055 - val_loss: 0.0046\n",
      "Epoch 10/30\n",
      "\u001b[1m46/46\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - loss: 0.0057 - val_loss: 0.0049\n",
      "Epoch 11/30\n",
      "\u001b[1m46/46\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - loss: 0.0062 - val_loss: 0.0048\n",
      "Epoch 12/30\n",
      "\u001b[1m46/46\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - loss: 0.0062 - val_loss: 0.0057\n",
      "Epoch 13/30\n",
      "\u001b[1m46/46\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - loss: 0.0049 - val_loss: 0.0053\n",
      "Epoch 14/30\n",
      "\u001b[1m46/46\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - loss: 0.0050 - val_loss: 0.0042\n",
      "Epoch 15/30\n",
      "\u001b[1m46/46\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - loss: 0.0070 - val_loss: 0.0046\n",
      "Epoch 16/30\n",
      "\u001b[1m46/46\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 13ms/step - loss: 0.0056 - val_loss: 0.0045\n",
      "Epoch 17/30\n",
      "\u001b[1m46/46\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - loss: 0.0043 - val_loss: 0.0037\n",
      "Epoch 18/30\n",
      "\u001b[1m46/46\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - loss: 0.0065 - val_loss: 0.0041\n",
      "Epoch 19/30\n",
      "\u001b[1m46/46\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - loss: 0.0057 - val_loss: 0.0037\n",
      "Epoch 20/30\n",
      "\u001b[1m46/46\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - loss: 0.0050 - val_loss: 0.0037\n",
      "Epoch 21/30\n",
      "\u001b[1m46/46\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - loss: 0.0042 - val_loss: 0.0037\n",
      "Epoch 22/30\n",
      "\u001b[1m46/46\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - loss: 0.0038 - val_loss: 0.0040\n",
      "Epoch 23/30\n",
      "\u001b[1m46/46\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - loss: 0.0042 - val_loss: 0.0046\n",
      "Epoch 24/30\n",
      "\u001b[1m46/46\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - loss: 0.0043 - val_loss: 0.0036\n",
      "Epoch 25/30\n",
      "\u001b[1m46/46\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - loss: 0.0046 - val_loss: 0.0034\n",
      "Epoch 26/30\n",
      "\u001b[1m46/46\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - loss: 0.0049 - val_loss: 0.0034\n",
      "Epoch 27/30\n",
      "\u001b[1m46/46\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - loss: 0.0049 - val_loss: 0.0034\n",
      "Epoch 28/30\n",
      "\u001b[1m46/46\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - loss: 0.0034 - val_loss: 0.0036\n",
      "Epoch 29/30\n",
      "\u001b[1m46/46\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - loss: 0.0043 - val_loss: 0.0051\n",
      "Epoch 30/30\n",
      "\u001b[1m46/46\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - loss: 0.0038 - val_loss: 0.0033\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:The `save_format` argument is deprecated in Keras 3. We recommend removing this argument as it can be inferred from the file path. Received: save_format=keras\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Finished: Zimbabwe | MAE: 0.08 | RMSE: 0.16 | R²: 0.89\n"
     ]
    }
   ],
   "source": [
    "countries = df[\"Entity\"].unique()\n",
    "results = run_LSTM(countries, {\"United States\", \"United Kingdom\", \"Australia\"})\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Country</th>\n",
       "      <th>MAE</th>\n",
       "      <th>RMSE</th>\n",
       "      <th>R2</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Afghanistan</td>\n",
       "      <td>0.131918</td>\n",
       "      <td>0.238527</td>\n",
       "      <td>0.867284</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Albania</td>\n",
       "      <td>0.174953</td>\n",
       "      <td>0.199016</td>\n",
       "      <td>0.793006</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Algeria</td>\n",
       "      <td>0.133811</td>\n",
       "      <td>0.208095</td>\n",
       "      <td>0.857535</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>American Samoa</td>\n",
       "      <td>0.058580</td>\n",
       "      <td>0.094957</td>\n",
       "      <td>0.861911</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Andorra</td>\n",
       "      <td>0.092880</td>\n",
       "      <td>0.278759</td>\n",
       "      <td>0.864998</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>190</th>\n",
       "      <td>Vietnam</td>\n",
       "      <td>0.088229</td>\n",
       "      <td>0.167282</td>\n",
       "      <td>0.856512</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>191</th>\n",
       "      <td>World</td>\n",
       "      <td>0.057530</td>\n",
       "      <td>0.067534</td>\n",
       "      <td>0.900673</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>192</th>\n",
       "      <td>Yemen</td>\n",
       "      <td>0.055030</td>\n",
       "      <td>0.122180</td>\n",
       "      <td>0.889659</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>193</th>\n",
       "      <td>Zambia</td>\n",
       "      <td>0.106504</td>\n",
       "      <td>0.134918</td>\n",
       "      <td>0.847727</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>194</th>\n",
       "      <td>Zimbabwe</td>\n",
       "      <td>0.076338</td>\n",
       "      <td>0.161162</td>\n",
       "      <td>0.888968</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>195 rows × 4 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "            Country       MAE      RMSE        R2\n",
       "0       Afghanistan  0.131918  0.238527  0.867284\n",
       "1           Albania  0.174953  0.199016  0.793006\n",
       "2           Algeria  0.133811  0.208095  0.857535\n",
       "3    American Samoa  0.058580  0.094957  0.861911\n",
       "4           Andorra  0.092880  0.278759  0.864998\n",
       "..              ...       ...       ...       ...\n",
       "190         Vietnam  0.088229  0.167282  0.856512\n",
       "191           World  0.057530  0.067534  0.900673\n",
       "192           Yemen  0.055030  0.122180  0.889659\n",
       "193          Zambia  0.106504  0.134918  0.847727\n",
       "194        Zimbabwe  0.076338  0.161162  0.888968\n",
       "\n",
       "[195 rows x 4 columns]"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "results.to_csv('../metrics/LSTM/LSTM-epochs=30-batch_size=16-validation_split=0.1.csv', index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## LSTM: Hypertuning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "import itertools\n",
    "from sklearn.metrics import mean_absolute_error, root_mean_squared_error, r2_score, mean_squared_error\n",
    "from tensorflow.keras.models import Sequential, load_model\n",
    "from tensorflow.keras.layers import LSTM, Dense, Input \n",
    "from tensorflow.keras.callbacks import EarlyStopping\n",
    "from tensorflow.keras.optimizers import Adam, RMSprop\n",
    "\n",
    "\n",
    "def hypertune_lstm(raw_data, param_grid, seq_len=12, verbose=False):\n",
    "    best_score = float('inf')\n",
    "    best_params = None\n",
    "    best_model = None\n",
    "    scores = None\n",
    "\n",
    "    all_keys = list(param_grid.keys())\n",
    "    all_combinations = list(itertools.product(*param_grid.values()))\n",
    "\n",
    "    for combo in all_combinations:\n",
    "        params = dict(zip(all_keys, combo))\n",
    "        if verbose:\n",
    "            print(f\"Testing: {params}\")\n",
    "\n",
    "        try:\n",
    "            # Build pipeline\n",
    "            pipeline = LSTMPipeline(seq_len=params.get('seq_len', seq_len))\n",
    "\n",
    "            # Scale and sequence data\n",
    "            data_scaled = pipeline.scaler.fit_transform(raw_data.reshape(-1, 1))\n",
    "            X, y = pipeline.create_sequences(data_scaled)\n",
    "            split = int(len(X) * 0.8)\n",
    "            X_train, y_train = X[:split], y[:split]\n",
    "            X_val, y_val = X[split:], y[split:]\n",
    "\n",
    "            # Reshape to 3D for LSTM\n",
    "            X_train = X_train.reshape((-1, params['seq_len'], 1))\n",
    "            X_val = X_val.reshape((-1, params['seq_len'], 1))\n",
    "\n",
    "            model = Sequential()\n",
    "            model.add(Input(shape=(params['seq_len'], 1)))\n",
    "\n",
    "            for i in range(params.get('num_lstm_layers', 1)):\n",
    "                return_sequences = (i < params['num_lstm_layers'] - 1)  # True for all but last layer\n",
    "                model.add(LSTM(params['lstm_units'], return_sequences=return_sequences))\n",
    "\n",
    "            model.add(Dense(1))\n",
    "\n",
    "\n",
    "            optimizer = {\n",
    "                'adam': Adam,\n",
    "                'rmsprop': RMSprop\n",
    "            }[params['optimizer']](learning_rate=params['learning_rate'])\n",
    "\n",
    "            model.compile(loss='mse', optimizer=optimizer)\n",
    "\n",
    "            callbacks = []\n",
    "            if params.get(\"use_early_stopping\", False):\n",
    "                callbacks.append(EarlyStopping(patience=params.get(\"patience\", 5), restore_best_weights=True))\n",
    "\n",
    "            model.fit(\n",
    "                X_train, y_train,\n",
    "                epochs=params['epochs'],\n",
    "                batch_size=params['batch_size'],\n",
    "                validation_data=(X_val, y_val),\n",
    "                callbacks=callbacks,\n",
    "                verbose=0\n",
    "            )\n",
    "\n",
    "            y_pred = model.predict(X_val)\n",
    "            y_val_inv = pipeline.scaler.inverse_transform(y_val.reshape(-1, 1))\n",
    "            y_pred_inv = pipeline.scaler.inverse_transform(y_pred)\n",
    "\n",
    "            mae = mean_absolute_error(y_val_inv, y_pred_inv)\n",
    "            rmse = root_mean_squared_error(y_val_inv, y_pred_inv)\n",
    "            mse = mean_squared_error(y_val_inv, y_pred_inv)\n",
    "            r2 = r2_score(y_val_inv, y_pred_inv)\n",
    "\n",
    "            if verbose:\n",
    "                print(f\"MAE: {mae:.4f}\")\n",
    "\n",
    "            if mae < best_score:\n",
    "                best_score = mae\n",
    "                scores = {'MAE': mae, 'RMSE': rmse, 'R2': r2, 'MSE' : mse}\n",
    "                best_params = params\n",
    "                best_model = model\n",
    "\n",
    "        except Exception as e:\n",
    "            print(f\"Error with parameters {params}: {e}\")\n",
    "\n",
    "    return best_model, best_params, best_score, scores"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "def hypertune_all_countries(df, countries, param_grid):\n",
    "    results = []\n",
    "\n",
    "    for country in countries:\n",
    "        print(f\"\\nHypertuning for {country}...\")\n",
    "        country_df = df[df[\"Entity\"] == country].copy()\n",
    "        country_df = country_df.sort_values(by=\"Day\")\n",
    "        temps = country_df[\"Monthly Average Temp\"].values\n",
    "\n",
    "        try:\n",
    "            best_model, best_params, best_score, scores = hypertune_lstm(temps, param_grid)\n",
    "            results.append({\n",
    "                \"Country\": country,\n",
    "                \"Best_MAE\": best_score,\n",
    "                \"Best_Params\": best_params,\n",
    "                \"Scores\" : scores\n",
    "            })\n",
    "            print(f\"Done: {country} | MAE: {scores['MAE']:.4f} | RMSE: {scores['RMSE']:.4f} | R2: {scores['R2']:.4f} | MSE: {scores['MSE']:.4f}\")\n",
    "        except Exception as e:\n",
    "            print(f\"Error with {country}: {e}\")\n",
    "            results.append({\n",
    "                \"Country\": country,\n",
    "                \"Best_MAE\": None,\n",
    "                \"Best_Params\": None,\n",
    "                \"Scores\" : None,\n",
    "                \"Error\": str(e)\n",
    "            })\n",
    "\n",
    "    return pd.DataFrame(results)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['Afghanistan' 'Albania' 'Algeria' 'American Samoa' 'Andorra' 'Angola'\n",
      " 'Anguilla' 'Antigua and Barbuda' 'Argentina' 'Armenia' 'Australia'\n",
      " 'Austria' 'Azerbaijan' 'Bahamas' 'Bahrain' 'Bangladesh' 'Belarus'\n",
      " 'Belgium' 'Belize' 'Benin' 'Bhutan' 'Bolivia' 'Bosnia and Herzegovina'\n",
      " 'Botswana' 'Brazil' 'Brunei' 'Bulgaria' 'Burkina Faso' 'Burundi'\n",
      " 'Cambodia' 'Cameroon' 'Canada' 'Cape Verde' 'Cayman Islands'\n",
      " 'Central African Republic' 'Chad' 'Chile' 'China' 'Colombia' 'Comoros'\n",
      " 'Congo' 'Cook Islands' 'Costa Rica' \"Cote d'Ivoire\" 'Croatia' 'Cuba'\n",
      " 'Cyprus' 'Czechia' 'Democratic Republic of Congo' 'Denmark' 'Djibouti'\n",
      " 'Dominican Republic' 'East Timor' 'Ecuador' 'Egypt' 'El Salvador'\n",
      " 'Equatorial Guinea' 'Eritrea' 'Estonia' 'Eswatini' 'Ethiopia'\n",
      " 'Falkland Islands' 'Faroe Islands' 'Fiji' 'Finland' 'France'\n",
      " 'French Polynesia' 'Gabon' 'Gambia' 'Georgia' 'Germany' 'Ghana' 'Greece'\n",
      " 'Greenland' 'Guatemala' 'Guinea' 'Guinea-Bissau' 'Guyana' 'Haiti'\n",
      " 'Heard Island and McDonald Islands' 'Honduras' 'Hong Kong' 'Hungary'\n",
      " 'Iceland' 'India' 'Indonesia' 'Iran' 'Iraq' 'Ireland' 'Isle of Man'\n",
      " 'Israel' 'Italy' 'Jamaica' 'Japan' 'Jordan' 'Kazakhstan' 'Kenya'\n",
      " 'Kiribati' 'Kosovo' 'Kuwait' 'Kyrgyzstan' 'Laos' 'Latvia' 'Lebanon'\n",
      " 'Lesotho' 'Liberia' 'Libya' 'Lithuania' 'Luxembourg' 'Madagascar'\n",
      " 'Malawi' 'Malaysia' 'Mali' 'Mauritania' 'Mauritius' 'Mexico' 'Moldova'\n",
      " 'Mongolia' 'Montenegro' 'Morocco' 'Mozambique' 'Myanmar' 'Namibia'\n",
      " 'Nepal' 'Netherlands' 'New Caledonia' 'New Zealand' 'Nicaragua' 'Niger'\n",
      " 'Nigeria' 'North Korea' 'North Macedonia' 'Norway' 'Oman' 'Pakistan'\n",
      " 'Palestine' 'Panama' 'Papua New Guinea' 'Paraguay' 'Peru' 'Philippines'\n",
      " 'Poland' 'Portugal' 'Puerto Rico' 'Qatar' 'Romania' 'Russia' 'Rwanda'\n",
      " 'Saint Helena' 'Saint Vincent and the Grenadines' 'Samoa'\n",
      " 'Sao Tome and Principe' 'Saudi Arabia' 'Senegal' 'Serbia' 'Seychelles'\n",
      " 'Sierra Leone' 'Slovakia' 'Slovenia' 'Solomon Islands' 'Somalia'\n",
      " 'South Africa' 'South Georgia and the South Sandwich Islands'\n",
      " 'South Korea' 'South Sudan' 'Spain' 'Sri Lanka' 'Sudan' 'Suriname'\n",
      " 'Sweden' 'Switzerland' 'Syria' 'Tajikistan' 'Tanzania' 'Thailand' 'Togo'\n",
      " 'Trinidad and Tobago' 'Tunisia' 'Turkey' 'Turkmenistan' 'Uganda'\n",
      " 'Ukraine' 'United Arab Emirates' 'United Kingdom' 'United States'\n",
      " 'United States Virgin Islands' 'Uruguay' 'Uzbekistan' 'Vanuatu'\n",
      " 'Venezuela' 'Vietnam' 'World' 'Yemen' 'Zambia' 'Zimbabwe']\n",
      "\n",
      "Hypertuning for Afghanistan...\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 30ms/step\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 27ms/step\n",
      "Done: Afghanistan | MAE: 0.3073 | RMSE: 0.4177 | R2: 0.5929 | MSE: 0.1745\n",
      "\n",
      "Hypertuning for Albania...\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 29ms/step\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 37ms/step\n",
      "Done: Albania | MAE: 0.1376 | RMSE: 0.2126 | R2: 0.7639 | MSE: 0.0452\n",
      "\n",
      "Hypertuning for Algeria...\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 27ms/step\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 28ms/step\n",
      "Done: Algeria | MAE: 0.1673 | RMSE: 0.2808 | R2: 0.7406 | MSE: 0.0788\n",
      "\n",
      "Hypertuning for American Samoa...\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 28ms/step\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 31ms/step\n",
      "Done: American Samoa | MAE: 0.0717 | RMSE: 0.1141 | R2: 0.8006 | MSE: 0.0130\n",
      "\n",
      "Hypertuning for Andorra...\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 27ms/step\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 28ms/step\n",
      "Done: Andorra | MAE: 0.2784 | RMSE: 0.4239 | R2: 0.6879 | MSE: 0.1797\n",
      "\n",
      "Hypertuning for Angola...\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 28ms/step\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 27ms/step\n",
      "Done: Angola | MAE: 0.1782 | RMSE: 0.2295 | R2: 0.5909 | MSE: 0.0527\n",
      "\n",
      "Hypertuning for Anguilla...\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 28ms/step\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 27ms/step\n",
      "Done: Anguilla | MAE: 0.1112 | RMSE: 0.1604 | R2: 0.7096 | MSE: 0.0257\n",
      "\n",
      "Hypertuning for Antigua and Barbuda...\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 27ms/step\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 28ms/step\n",
      "Done: Antigua and Barbuda | MAE: 0.0987 | RMSE: 0.1597 | R2: 0.7263 | MSE: 0.0255\n",
      "\n",
      "Hypertuning for Argentina...\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 28ms/step\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 27ms/step\n",
      "Done: Argentina | MAE: 0.1708 | RMSE: 0.2178 | R2: 0.3441 | MSE: 0.0474\n",
      "\n",
      "Hypertuning for Armenia...\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 31ms/step\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 28ms/step\n",
      "Done: Armenia | MAE: 0.4078 | RMSE: 0.6013 | R2: 0.3161 | MSE: 0.3615\n",
      "\n",
      "Hypertuning for Australia...\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 29ms/step\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 28ms/step\n",
      "Done: Australia | MAE: 0.1613 | RMSE: 0.2256 | R2: 0.7582 | MSE: 0.0509\n",
      "\n",
      "Hypertuning for Austria...\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 28ms/step\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 28ms/step\n",
      "Done: Austria | MAE: 0.3319 | RMSE: 0.4103 | R2: 0.6070 | MSE: 0.1684\n",
      "\n",
      "Hypertuning for Azerbaijan...\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 28ms/step\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 34ms/step\n",
      "Done: Azerbaijan | MAE: 0.2675 | RMSE: 0.4195 | R2: 0.4500 | MSE: 0.1760\n",
      "\n",
      "Hypertuning for Bahamas...\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 28ms/step\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 27ms/step\n",
      "Done: Bahamas | MAE: 0.1494 | RMSE: 0.1900 | R2: 0.7235 | MSE: 0.0361\n",
      "\n",
      "Hypertuning for Bahrain...\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 28ms/step\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 29ms/step\n",
      "Done: Bahrain | MAE: 0.0970 | RMSE: 0.1766 | R2: 0.8347 | MSE: 0.0312\n",
      "\n",
      "Hypertuning for Bangladesh...\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 27ms/step\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 27ms/step\n",
      "Done: Bangladesh | MAE: 0.0930 | RMSE: 0.1396 | R2: 0.7610 | MSE: 0.0195\n",
      "\n",
      "Hypertuning for Belarus...\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 28ms/step\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 28ms/step\n",
      "Done: Belarus | MAE: 0.1990 | RMSE: 0.3150 | R2: 0.8223 | MSE: 0.0993\n",
      "\n",
      "Hypertuning for Belgium...\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 28ms/step\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 28ms/step\n",
      "Done: Belgium | MAE: 0.1954 | RMSE: 0.3487 | R2: 0.7713 | MSE: 0.1216\n",
      "\n",
      "Hypertuning for Belize...\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 28ms/step\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 29ms/step\n",
      "Done: Belize | MAE: 0.0888 | RMSE: 0.1439 | R2: 0.8427 | MSE: 0.0207\n",
      "\n",
      "Hypertuning for Benin...\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 28ms/step\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 28ms/step\n",
      "Done: Benin | MAE: 0.1353 | RMSE: 0.1793 | R2: 0.5373 | MSE: 0.0322\n",
      "\n",
      "Hypertuning for Bhutan...\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 28ms/step\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 38ms/step\n",
      "Done: Bhutan | MAE: 0.1512 | RMSE: 0.1999 | R2: 0.6210 | MSE: 0.0400\n",
      "\n",
      "Hypertuning for Bolivia...\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 28ms/step\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 28ms/step\n",
      "Done: Bolivia | MAE: 0.0803 | RMSE: 0.1592 | R2: 0.8369 | MSE: 0.0253\n",
      "\n",
      "Hypertuning for Bosnia and Herzegovina...\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 28ms/step\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 29ms/step\n",
      "Done: Bosnia and Herzegovina | MAE: 0.1620 | RMSE: 0.2374 | R2: 0.8327 | MSE: 0.0563\n",
      "\n",
      "Hypertuning for Botswana...\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 28ms/step\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 29ms/step\n",
      "Done: Botswana | MAE: 0.2407 | RMSE: 0.3503 | R2: 0.7408 | MSE: 0.1227\n",
      "\n",
      "Hypertuning for Brazil...\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 29ms/step\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 28ms/step\n",
      "Done: Brazil | MAE: 0.1143 | RMSE: 0.1557 | R2: 0.7256 | MSE: 0.0242\n",
      "\n",
      "Hypertuning for Brunei...\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 28ms/step\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 28ms/step\n",
      "Done: Brunei | MAE: 0.1341 | RMSE: 0.1725 | R2: 0.6750 | MSE: 0.0297\n",
      "\n",
      "Hypertuning for Bulgaria...\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 28ms/step\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 27ms/step\n",
      "Done: Bulgaria | MAE: 0.2618 | RMSE: 0.3220 | R2: 0.6227 | MSE: 0.1037\n",
      "\n",
      "Hypertuning for Burkina Faso...\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 28ms/step\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 28ms/step\n",
      "Done: Burkina Faso | MAE: 0.1274 | RMSE: 0.1933 | R2: 0.4539 | MSE: 0.0374\n",
      "\n",
      "Hypertuning for Burundi...\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 32ms/step\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 28ms/step\n",
      "Done: Burundi | MAE: 0.0833 | RMSE: 0.1400 | R2: 0.8554 | MSE: 0.0196\n",
      "\n",
      "Hypertuning for Cambodia...\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 28ms/step\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 30ms/step\n",
      "Done: Cambodia | MAE: 0.1168 | RMSE: 0.2106 | R2: 0.6989 | MSE: 0.0444\n",
      "\n",
      "Hypertuning for Cameroon...\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 27ms/step\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 28ms/step\n",
      "Done: Cameroon | MAE: 0.0986 | RMSE: 0.1447 | R2: 0.7337 | MSE: 0.0209\n",
      "\n",
      "Hypertuning for Canada...\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 28ms/step\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 29ms/step\n",
      "Done: Canada | MAE: 0.2431 | RMSE: 0.4060 | R2: 0.7540 | MSE: 0.1649\n",
      "\n",
      "Hypertuning for Cape Verde...\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 27ms/step\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 32ms/step\n",
      "Done: Cape Verde | MAE: 0.0957 | RMSE: 0.1833 | R2: 0.8379 | MSE: 0.0336\n",
      "\n",
      "Hypertuning for Cayman Islands...\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 27ms/step\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 29ms/step\n",
      "Done: Cayman Islands | MAE: 0.1230 | RMSE: 0.1664 | R2: 0.7024 | MSE: 0.0277\n",
      "\n",
      "Hypertuning for Central African Republic...\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 35ms/step\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 47ms/step\n",
      "Done: Central African Republic | MAE: 0.0972 | RMSE: 0.1397 | R2: 0.8943 | MSE: 0.0195\n",
      "\n",
      "Hypertuning for Chad...\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 54ms/step\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 32ms/step\n",
      "Done: Chad | MAE: 0.2141 | RMSE: 0.2963 | R2: 0.2804 | MSE: 0.0878\n",
      "\n",
      "Hypertuning for Chile...\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 29ms/step\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 29ms/step\n",
      "Done: Chile | MAE: 0.1585 | RMSE: 0.2084 | R2: 0.4454 | MSE: 0.0434\n",
      "\n",
      "Hypertuning for China...\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 31ms/step\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 29ms/step\n",
      "Done: China | MAE: 0.0672 | RMSE: 0.1213 | R2: 0.9064 | MSE: 0.0147\n",
      "\n",
      "Hypertuning for Colombia...\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 28ms/step\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 28ms/step\n",
      "Done: Colombia | MAE: 0.1036 | RMSE: 0.1471 | R2: 0.7919 | MSE: 0.0216\n",
      "\n",
      "Hypertuning for Comoros...\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 79ms/step\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 31ms/step\n",
      "Done: Comoros | MAE: 0.1035 | RMSE: 0.1524 | R2: 0.6382 | MSE: 0.0232\n",
      "\n",
      "Hypertuning for Congo...\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 28ms/step\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 28ms/step\n",
      "Done: Congo | MAE: 0.0716 | RMSE: 0.1110 | R2: 0.8504 | MSE: 0.0123\n",
      "\n",
      "Hypertuning for Cook Islands...\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 28ms/step\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 28ms/step\n",
      "Done: Cook Islands | MAE: 0.1074 | RMSE: 0.1515 | R2: 0.6570 | MSE: 0.0229\n",
      "\n",
      "Hypertuning for Costa Rica...\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 29ms/step\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 28ms/step\n",
      "Done: Costa Rica | MAE: 0.1521 | RMSE: 0.1998 | R2: 0.4807 | MSE: 0.0399\n",
      "\n",
      "Hypertuning for Cote d'Ivoire...\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 28ms/step\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 29ms/step\n",
      "Done: Cote d'Ivoire | MAE: 0.0534 | RMSE: 0.1009 | R2: 0.8096 | MSE: 0.0102\n",
      "\n",
      "Hypertuning for Croatia...\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 35ms/step\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 28ms/step\n",
      "Done: Croatia | MAE: 0.3018 | RMSE: 0.3704 | R2: 0.5877 | MSE: 0.1372\n",
      "\n",
      "Hypertuning for Cuba...\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 31ms/step\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 29ms/step\n",
      "Done: Cuba | MAE: 0.1236 | RMSE: 0.1572 | R2: 0.8033 | MSE: 0.0247\n",
      "\n",
      "Hypertuning for Cyprus...\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 29ms/step\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 29ms/step\n",
      "Done: Cyprus | MAE: 0.1151 | RMSE: 0.2150 | R2: 0.7028 | MSE: 0.0462\n",
      "\n",
      "Hypertuning for Czechia...\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 28ms/step\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 28ms/step\n",
      "Done: Czechia | MAE: 0.3909 | RMSE: 0.5172 | R2: 0.5595 | MSE: 0.2675\n",
      "\n",
      "Hypertuning for Democratic Republic of Congo...\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 28ms/step\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 28ms/step\n",
      "Done: Democratic Republic of Congo | MAE: 0.0732 | RMSE: 0.1113 | R2: 0.9111 | MSE: 0.0124\n",
      "\n",
      "Hypertuning for Denmark...\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 27ms/step\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 32ms/step\n",
      "Done: Denmark | MAE: 0.1659 | RMSE: 0.3456 | R2: 0.7787 | MSE: 0.1194\n",
      "\n",
      "Hypertuning for Djibouti...\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 28ms/step\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 28ms/step\n",
      "Done: Djibouti | MAE: 0.1145 | RMSE: 0.1845 | R2: 0.8489 | MSE: 0.0340\n",
      "\n",
      "Hypertuning for Dominican Republic...\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 28ms/step\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 29ms/step\n",
      "Done: Dominican Republic | MAE: 0.0812 | RMSE: 0.1270 | R2: 0.8601 | MSE: 0.0161\n",
      "\n",
      "Hypertuning for East Timor...\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 35ms/step\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 36ms/step\n",
      "Done: East Timor | MAE: 0.1300 | RMSE: 0.1936 | R2: 0.5718 | MSE: 0.0375\n",
      "\n",
      "Hypertuning for Ecuador...\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 60ms/step\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 26ms/step\n",
      "Done: Ecuador | MAE: 0.1428 | RMSE: 0.2069 | R2: 0.6235 | MSE: 0.0428\n",
      "\n",
      "Hypertuning for Egypt...\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 48ms/step\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 31ms/step\n",
      "Done: Egypt | MAE: 0.3124 | RMSE: 0.4462 | R2: 0.1295 | MSE: 0.1991\n",
      "\n",
      "Hypertuning for El Salvador...\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 34ms/step\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 49ms/step\n",
      "Done: El Salvador | MAE: 0.1792 | RMSE: 0.2412 | R2: 0.7247 | MSE: 0.0582\n",
      "\n",
      "Hypertuning for Equatorial Guinea...\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 30ms/step\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 29ms/step\n",
      "Done: Equatorial Guinea | MAE: 0.0481 | RMSE: 0.0819 | R2: 0.9275 | MSE: 0.0067\n",
      "\n",
      "Hypertuning for Eritrea...\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 31ms/step\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 27ms/step\n",
      "Done: Eritrea | MAE: 0.2062 | RMSE: 0.2495 | R2: 0.4211 | MSE: 0.0623\n",
      "\n",
      "Hypertuning for Estonia...\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 42ms/step\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 26ms/step\n",
      "Done: Estonia | MAE: 0.3057 | RMSE: 0.4272 | R2: 0.7328 | MSE: 0.1825\n",
      "\n",
      "Hypertuning for Eswatini...\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 27ms/step\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 28ms/step\n",
      "Done: Eswatini | MAE: 0.1969 | RMSE: 0.2626 | R2: 0.5430 | MSE: 0.0689\n",
      "\n",
      "Hypertuning for Ethiopia...\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 27ms/step\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 27ms/step\n",
      "Done: Ethiopia | MAE: 0.1336 | RMSE: 0.1711 | R2: 0.6553 | MSE: 0.0293\n",
      "\n",
      "Hypertuning for Falkland Islands...\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 28ms/step\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 27ms/step\n",
      "Done: Falkland Islands | MAE: 0.1047 | RMSE: 0.1626 | R2: 0.7728 | MSE: 0.0264\n",
      "\n",
      "Hypertuning for Faroe Islands...\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 27ms/step\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 27ms/step\n",
      "Done: Faroe Islands | MAE: 0.1134 | RMSE: 0.2100 | R2: 0.5571 | MSE: 0.0441\n",
      "\n",
      "Hypertuning for Fiji...\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 26ms/step\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 28ms/step\n",
      "Done: Fiji | MAE: 0.1073 | RMSE: 0.1725 | R2: 0.7554 | MSE: 0.0297\n",
      "\n",
      "Hypertuning for Finland...\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 27ms/step\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 27ms/step\n",
      "Done: Finland | MAE: 0.2795 | RMSE: 0.4440 | R2: 0.6913 | MSE: 0.1971\n",
      "\n",
      "Hypertuning for France...\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 27ms/step\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 37ms/step\n",
      "Done: France | MAE: 0.2541 | RMSE: 0.3951 | R2: 0.5517 | MSE: 0.1561\n",
      "\n",
      "Hypertuning for French Polynesia...\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 29ms/step\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 30ms/step\n",
      "Done: French Polynesia | MAE: 0.0745 | RMSE: 0.1290 | R2: 0.7816 | MSE: 0.0166\n",
      "\n",
      "Hypertuning for Gabon...\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 30ms/step\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 28ms/step\n",
      "Done: Gabon | MAE: 0.0400 | RMSE: 0.0720 | R2: 0.9255 | MSE: 0.0052\n",
      "\n",
      "Hypertuning for Gambia...\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 37ms/step\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 27ms/step\n",
      "Done: Gambia | MAE: 0.1421 | RMSE: 0.2057 | R2: 0.4132 | MSE: 0.0423\n",
      "\n",
      "Hypertuning for Georgia...\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 27ms/step\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 31ms/step\n",
      "Done: Georgia | MAE: 0.3506 | RMSE: 0.5701 | R2: 0.2321 | MSE: 0.3250\n",
      "\n",
      "Hypertuning for Germany...\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 27ms/step\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 28ms/step\n",
      "Done: Germany | MAE: 0.4446 | RMSE: 0.5719 | R2: 0.4396 | MSE: 0.3271\n",
      "\n",
      "Hypertuning for Ghana...\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 27ms/step\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 28ms/step\n",
      "Done: Ghana | MAE: 0.1135 | RMSE: 0.1656 | R2: 0.6294 | MSE: 0.0274\n",
      "\n",
      "Hypertuning for Greece...\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 27ms/step\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 28ms/step\n",
      "Done: Greece | MAE: 0.2634 | RMSE: 0.3542 | R2: 0.2806 | MSE: 0.1255\n",
      "\n",
      "Hypertuning for Greenland...\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 29ms/step\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 30ms/step\n",
      "Done: Greenland | MAE: 0.4682 | RMSE: 0.7561 | R2: 0.3588 | MSE: 0.5718\n",
      "\n",
      "Hypertuning for Guatemala...\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 27ms/step\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 28ms/step\n",
      "Done: Guatemala | MAE: 0.0948 | RMSE: 0.1697 | R2: 0.8174 | MSE: 0.0288\n",
      "\n",
      "Hypertuning for Guinea...\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 28ms/step\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 28ms/step\n",
      "Done: Guinea | MAE: 0.0911 | RMSE: 0.1257 | R2: 0.8567 | MSE: 0.0158\n",
      "\n",
      "Hypertuning for Guinea-Bissau...\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 37ms/step\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 27ms/step\n",
      "Done: Guinea-Bissau | MAE: 0.0682 | RMSE: 0.1166 | R2: 0.8355 | MSE: 0.0136\n",
      "\n",
      "Hypertuning for Guyana...\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 28ms/step\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 27ms/step\n",
      "Done: Guyana | MAE: 0.1300 | RMSE: 0.1994 | R2: 0.6998 | MSE: 0.0398\n",
      "\n",
      "Hypertuning for Haiti...\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 27ms/step\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 27ms/step\n",
      "Done: Haiti | MAE: 0.1473 | RMSE: 0.1941 | R2: 0.6527 | MSE: 0.0377\n",
      "\n",
      "Hypertuning for Heard Island and McDonald Islands...\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 27ms/step\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 28ms/step\n",
      "Done: Heard Island and McDonald Islands | MAE: 0.0798 | RMSE: 0.1266 | R2: 0.7987 | MSE: 0.0160\n",
      "\n",
      "Hypertuning for Honduras...\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 27ms/step\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 27ms/step\n",
      "Done: Honduras | MAE: 0.1261 | RMSE: 0.1991 | R2: 0.7870 | MSE: 0.0396\n",
      "\n",
      "Hypertuning for Hong Kong...\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 26ms/step\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 27ms/step\n",
      "Done: Hong Kong | MAE: 0.1918 | RMSE: 0.2368 | R2: 0.6429 | MSE: 0.0561\n",
      "\n",
      "Hypertuning for Hungary...\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 27ms/step\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 27ms/step\n",
      "Done: Hungary | MAE: 0.2451 | RMSE: 0.3337 | R2: 0.6975 | MSE: 0.1114\n",
      "\n",
      "Hypertuning for Iceland...\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 27ms/step\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 27ms/step\n",
      "Done: Iceland | MAE: 0.1870 | RMSE: 0.3342 | R2: 0.5710 | MSE: 0.1117\n",
      "\n",
      "Hypertuning for India...\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 30ms/step\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 28ms/step\n",
      "Done: India | MAE: 0.1354 | RMSE: 0.1846 | R2: 0.5472 | MSE: 0.0341\n",
      "\n",
      "Hypertuning for Indonesia...\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 27ms/step\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 27ms/step\n",
      "Done: Indonesia | MAE: 0.0717 | RMSE: 0.1072 | R2: 0.8132 | MSE: 0.0115\n",
      "\n",
      "Hypertuning for Iran...\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 27ms/step\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 27ms/step\n",
      "Done: Iran | MAE: 0.2215 | RMSE: 0.3339 | R2: 0.5945 | MSE: 0.1115\n",
      "\n",
      "Hypertuning for Iraq...\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 27ms/step\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 27ms/step\n",
      "Done: Iraq | MAE: 0.2722 | RMSE: 0.4213 | R2: 0.4698 | MSE: 0.1775\n",
      "\n",
      "Hypertuning for Ireland...\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 27ms/step\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 26ms/step\n",
      "Done: Ireland | MAE: 0.1196 | RMSE: 0.2029 | R2: 0.8016 | MSE: 0.0412\n",
      "\n",
      "Hypertuning for Isle of Man...\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 27ms/step\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 27ms/step\n",
      "Done: Isle of Man | MAE: 0.1208 | RMSE: 0.2106 | R2: 0.7933 | MSE: 0.0444\n",
      "\n",
      "Hypertuning for Israel...\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 27ms/step\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 27ms/step\n",
      "Done: Israel | MAE: 0.1891 | RMSE: 0.3289 | R2: 0.5441 | MSE: 0.1081\n",
      "\n",
      "Hypertuning for Italy...\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 27ms/step\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 27ms/step\n",
      "Done: Italy | MAE: 0.1463 | RMSE: 0.2186 | R2: 0.7773 | MSE: 0.0478\n",
      "\n",
      "Hypertuning for Jamaica...\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 28ms/step\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 37ms/step\n",
      "Done: Jamaica | MAE: 0.0583 | RMSE: 0.1056 | R2: 0.9323 | MSE: 0.0112\n",
      "\n",
      "Hypertuning for Japan...\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 27ms/step\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 27ms/step\n",
      "Done: Japan | MAE: 0.1749 | RMSE: 0.2391 | R2: 0.7766 | MSE: 0.0572\n",
      "\n",
      "Hypertuning for Jordan...\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 28ms/step\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 28ms/step\n",
      "Done: Jordan | MAE: 0.4103 | RMSE: 0.5640 | R2: 0.0232 | MSE: 0.3181\n",
      "\n",
      "Hypertuning for Kazakhstan...\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 27ms/step\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 27ms/step\n",
      "Done: Kazakhstan | MAE: 0.2991 | RMSE: 0.4185 | R2: 0.6417 | MSE: 0.1751\n",
      "\n",
      "Hypertuning for Kenya...\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 27ms/step\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 28ms/step\n",
      "Done: Kenya | MAE: 0.0829 | RMSE: 0.1522 | R2: 0.6245 | MSE: 0.0232\n",
      "\n",
      "Hypertuning for Kiribati...\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 27ms/step\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 27ms/step\n",
      "Done: Kiribati | MAE: 0.1148 | RMSE: 0.1970 | R2: 0.8267 | MSE: 0.0388\n",
      "\n",
      "Hypertuning for Kosovo...\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 34ms/step\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 51ms/step\n",
      "Done: Kosovo | MAE: 0.1881 | RMSE: 0.2541 | R2: 0.5920 | MSE: 0.0646\n",
      "\n",
      "Hypertuning for Kuwait...\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 88ms/step\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 36ms/step\n",
      "Done: Kuwait | MAE: 0.2560 | RMSE: 0.3888 | R2: 0.4603 | MSE: 0.1511\n",
      "\n",
      "Hypertuning for Kyrgyzstan...\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 28ms/step\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 27ms/step\n",
      "Done: Kyrgyzstan | MAE: 0.2622 | RMSE: 0.3308 | R2: 0.5836 | MSE: 0.1094\n",
      "\n",
      "Hypertuning for Laos...\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 26ms/step\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 26ms/step\n",
      "Done: Laos | MAE: 0.1103 | RMSE: 0.2056 | R2: 0.8146 | MSE: 0.0423\n",
      "\n",
      "Hypertuning for Latvia...\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 28ms/step\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 47ms/step\n",
      "Done: Latvia | MAE: 0.3003 | RMSE: 0.4120 | R2: 0.7386 | MSE: 0.1698\n",
      "\n",
      "Hypertuning for Lebanon...\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 28ms/step\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 28ms/step\n",
      "Done: Lebanon | MAE: 0.3349 | RMSE: 0.4495 | R2: 0.4111 | MSE: 0.2020\n",
      "\n",
      "Hypertuning for Lesotho...\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 28ms/step\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 29ms/step\n",
      "Done: Lesotho | MAE: 0.2870 | RMSE: 0.4076 | R2: 0.4825 | MSE: 0.1661\n",
      "\n",
      "Hypertuning for Liberia...\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 27ms/step\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 31ms/step\n",
      "Done: Liberia | MAE: 0.0857 | RMSE: 0.1252 | R2: 0.8875 | MSE: 0.0157\n",
      "\n",
      "Hypertuning for Libya...\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 30ms/step\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 27ms/step\n",
      "Done: Libya | MAE: 0.2446 | RMSE: 0.4165 | R2: 0.5349 | MSE: 0.1735\n",
      "\n",
      "Hypertuning for Lithuania...\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 27ms/step\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 27ms/step\n",
      "Done: Lithuania | MAE: 0.2877 | RMSE: 0.3938 | R2: 0.7658 | MSE: 0.1551\n",
      "\n",
      "Hypertuning for Luxembourg...\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 27ms/step\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 47ms/step\n",
      "Done: Luxembourg | MAE: 0.2075 | RMSE: 0.3616 | R2: 0.7635 | MSE: 0.1307\n",
      "\n",
      "Hypertuning for Madagascar...\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 43ms/step\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 35ms/step\n",
      "Done: Madagascar | MAE: 0.0781 | RMSE: 0.1317 | R2: 0.6934 | MSE: 0.0173\n",
      "\n",
      "Hypertuning for Malawi...\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 29ms/step\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 28ms/step\n",
      "Done: Malawi | MAE: 0.0868 | RMSE: 0.1320 | R2: 0.7920 | MSE: 0.0174\n",
      "\n",
      "Hypertuning for Malaysia...\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 37ms/step\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 93ms/step\n",
      "Done: Malaysia | MAE: 0.0693 | RMSE: 0.1169 | R2: 0.8523 | MSE: 0.0137\n",
      "\n",
      "Hypertuning for Mali...\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 34ms/step\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 31ms/step\n",
      "Done: Mali | MAE: 0.2230 | RMSE: 0.2923 | R2: 0.5239 | MSE: 0.0854\n",
      "\n",
      "Hypertuning for Mauritania...\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 52ms/step\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 40ms/step\n",
      "Done: Mauritania | MAE: 0.1566 | RMSE: 0.2387 | R2: 0.7646 | MSE: 0.0570\n",
      "\n",
      "Hypertuning for Mauritius...\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 48ms/step\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 34ms/step\n",
      "Done: Mauritius | MAE: 0.0685 | RMSE: 0.1245 | R2: 0.7256 | MSE: 0.0155\n",
      "\n",
      "Hypertuning for Mexico...\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 36ms/step\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 33ms/step\n",
      "Done: Mexico | MAE: 0.1839 | RMSE: 0.2424 | R2: 0.5192 | MSE: 0.0587\n",
      "\n",
      "Hypertuning for Moldova...\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 28ms/step\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 31ms/step\n",
      "Done: Moldova | MAE: 0.3303 | RMSE: 0.4583 | R2: 0.5643 | MSE: 0.2100\n",
      "\n",
      "Hypertuning for Mongolia...\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 28ms/step\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 26ms/step\n",
      "Done: Mongolia | MAE: 0.2141 | RMSE: 0.2953 | R2: 0.7844 | MSE: 0.0872\n",
      "\n",
      "Hypertuning for Montenegro...\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 28ms/step\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 29ms/step\n",
      "Done: Montenegro | MAE: 0.2157 | RMSE: 0.2666 | R2: 0.6161 | MSE: 0.0711\n",
      "\n",
      "Hypertuning for Morocco...\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m899s\u001b[0m 150s/step\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 37ms/step\n",
      "Done: Morocco | MAE: 0.2625 | RMSE: 0.3514 | R2: 0.6272 | MSE: 0.1235\n",
      "\n",
      "Hypertuning for Mozambique...\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 30ms/step\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 254ms/step\n",
      "Done: Mozambique | MAE: 0.1413 | RMSE: 0.1867 | R2: 0.6550 | MSE: 0.0348\n",
      "\n",
      "Hypertuning for Myanmar...\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 229ms/step\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 26ms/step\n",
      "Done: Myanmar | MAE: 0.1448 | RMSE: 0.1911 | R2: 0.5655 | MSE: 0.0365\n",
      "\n",
      "Hypertuning for Namibia...\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 26ms/step\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 290ms/step\n",
      "Done: Namibia | MAE: 0.2246 | RMSE: 0.3116 | R2: 0.7958 | MSE: 0.0971\n",
      "\n",
      "Hypertuning for Nepal...\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 307ms/step\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 50ms/step\n",
      "Done: Nepal | MAE: 0.0917 | RMSE: 0.1706 | R2: 0.8008 | MSE: 0.0291\n",
      "\n",
      "Hypertuning for Netherlands...\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 35ms/step\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 273ms/step\n",
      "Done: Netherlands | MAE: 0.1719 | RMSE: 0.3614 | R2: 0.7526 | MSE: 0.1306\n",
      "\n",
      "Hypertuning for New Caledonia...\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 33ms/step\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 34ms/step\n",
      "Done: New Caledonia | MAE: 0.1049 | RMSE: 0.1906 | R2: 0.6923 | MSE: 0.0363\n",
      "\n",
      "Hypertuning for New Zealand...\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 304ms/step\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 185ms/step\n",
      "Done: New Zealand | MAE: 0.1195 | RMSE: 0.1811 | R2: 0.8051 | MSE: 0.0328\n",
      "\n",
      "Hypertuning for Nicaragua...\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 89ms/step\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m14s\u001b[0m 2s/step \n",
      "Done: Nicaragua | MAE: 0.1301 | RMSE: 0.1792 | R2: 0.7078 | MSE: 0.0321\n",
      "\n",
      "Hypertuning for Niger...\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 47ms/step\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 29ms/step\n",
      "Done: Niger | MAE: 0.2533 | RMSE: 0.3368 | R2: 0.2848 | MSE: 0.1135\n",
      "\n",
      "Hypertuning for Nigeria...\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 26ms/step\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 26ms/step\n",
      "Done: Nigeria | MAE: 0.1376 | RMSE: 0.1836 | R2: 0.4717 | MSE: 0.0337\n",
      "\n",
      "Hypertuning for North Korea...\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 262ms/step\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 123ms/step\n",
      "Done: North Korea | MAE: 0.1427 | RMSE: 0.2386 | R2: 0.8601 | MSE: 0.0569\n",
      "\n",
      "Hypertuning for North Macedonia...\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 44ms/step\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 42ms/step\n",
      "Done: North Macedonia | MAE: 0.1783 | RMSE: 0.2281 | R2: 0.6650 | MSE: 0.0520\n",
      "\n",
      "Hypertuning for Norway...\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 82ms/step\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 50ms/step\n",
      "Done: Norway | MAE: 0.2187 | RMSE: 0.4122 | R2: 0.6542 | MSE: 0.1699\n",
      "\n",
      "Hypertuning for Oman...\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 40ms/step\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 32ms/step\n",
      "Done: Oman | MAE: 0.0978 | RMSE: 0.1540 | R2: 0.7660 | MSE: 0.0237\n",
      "\n",
      "Hypertuning for Pakistan...\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 54ms/step\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 39ms/step\n",
      "Done: Pakistan | MAE: 0.1870 | RMSE: 0.2505 | R2: 0.6119 | MSE: 0.0627\n",
      "\n",
      "Hypertuning for Palestine...\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 54ms/step\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 75ms/step\n",
      "Done: Palestine | MAE: 0.1995 | RMSE: 0.3129 | R2: 0.5711 | MSE: 0.0979\n",
      "\n",
      "Hypertuning for Panama...\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 57ms/step\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 65ms/step\n",
      "Done: Panama | MAE: 0.1515 | RMSE: 0.1940 | R2: 0.5726 | MSE: 0.0376\n",
      "\n",
      "Hypertuning for Papua New Guinea...\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 68ms/step\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 49ms/step\n",
      "Done: Papua New Guinea | MAE: 0.1042 | RMSE: 0.1550 | R2: 0.6851 | MSE: 0.0240\n",
      "\n",
      "Hypertuning for Paraguay...\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 36ms/step\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 36ms/step\n",
      "Done: Paraguay | MAE: 0.3412 | RMSE: 0.4233 | R2: 0.4394 | MSE: 0.1792\n",
      "\n",
      "Hypertuning for Peru...\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 36ms/step\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 30ms/step\n",
      "Done: Peru | MAE: 0.1228 | RMSE: 0.1780 | R2: 0.7584 | MSE: 0.0317\n",
      "\n",
      "Hypertuning for Philippines...\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 30ms/step\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 28ms/step\n",
      "Done: Philippines | MAE: 0.1366 | RMSE: 0.1809 | R2: 0.4676 | MSE: 0.0327\n",
      "\n",
      "Hypertuning for Poland...\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 34ms/step\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 57ms/step\n",
      "Done: Poland | MAE: 0.3593 | RMSE: 0.4466 | R2: 0.7011 | MSE: 0.1994\n",
      "\n",
      "Hypertuning for Portugal...\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 95ms/step\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 55ms/step\n",
      "Done: Portugal | MAE: 0.2627 | RMSE: 0.3311 | R2: 0.4471 | MSE: 0.1096\n",
      "\n",
      "Hypertuning for Puerto Rico...\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 64ms/step\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 66ms/step\n",
      "Done: Puerto Rico | MAE: 0.0886 | RMSE: 0.1429 | R2: 0.7749 | MSE: 0.0204\n",
      "\n",
      "Hypertuning for Qatar...\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 54ms/step\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 55ms/step\n",
      "Done: Qatar | MAE: 0.1305 | RMSE: 0.2066 | R2: 0.7704 | MSE: 0.0427\n",
      "\n",
      "Hypertuning for Romania...\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 85ms/step\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 38ms/step\n",
      "Done: Romania | MAE: 0.2447 | RMSE: 0.3142 | R2: 0.7139 | MSE: 0.0987\n",
      "\n",
      "Hypertuning for Russia...\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 37ms/step\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 33ms/step\n",
      "Done: Russia | MAE: 0.2895 | RMSE: 0.4046 | R2: 0.6383 | MSE: 0.1637\n",
      "\n",
      "Hypertuning for Rwanda...\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 43ms/step\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 34ms/step\n",
      "Done: Rwanda | MAE: 0.1154 | RMSE: 0.1808 | R2: 0.8303 | MSE: 0.0327\n",
      "\n",
      "Hypertuning for Saint Helena...\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 30ms/step\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 86ms/step\n",
      "Done: Saint Helena | MAE: 0.1217 | RMSE: 0.1727 | R2: 0.5471 | MSE: 0.0298\n",
      "\n",
      "Hypertuning for Saint Vincent and the Grenadines...\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 74ms/step\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 43ms/step\n",
      "Done: Saint Vincent and the Grenadines | MAE: 0.0727 | RMSE: 0.1297 | R2: 0.7877 | MSE: 0.0168\n",
      "\n",
      "Hypertuning for Samoa...\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 70ms/step\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 39ms/step\n",
      "Done: Samoa | MAE: 0.1242 | RMSE: 0.1637 | R2: 0.5888 | MSE: 0.0268\n",
      "\n",
      "Hypertuning for Sao Tome and Principe...\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 44ms/step\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 45ms/step\n",
      "Done: Sao Tome and Principe | MAE: 0.0623 | RMSE: 0.1021 | R2: 0.8759 | MSE: 0.0104\n",
      "\n",
      "Hypertuning for Saudi Arabia...\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 46ms/step\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 35ms/step\n",
      "Done: Saudi Arabia | MAE: 0.1659 | RMSE: 0.2558 | R2: 0.6480 | MSE: 0.0654\n",
      "\n",
      "Hypertuning for Senegal...\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 85ms/step\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 98ms/step\n",
      "Done: Senegal | MAE: 0.0688 | RMSE: 0.1445 | R2: 0.7601 | MSE: 0.0209\n",
      "\n",
      "Hypertuning for Serbia...\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 35ms/step\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 36ms/step\n",
      "Done: Serbia | MAE: 0.2042 | RMSE: 0.2748 | R2: 0.7159 | MSE: 0.0755\n",
      "\n",
      "Hypertuning for Seychelles...\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 46ms/step\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 63ms/step\n",
      "Done: Seychelles | MAE: 0.1016 | RMSE: 0.1474 | R2: 0.5931 | MSE: 0.0217\n",
      "\n",
      "Hypertuning for Sierra Leone...\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 53ms/step\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 54ms/step\n",
      "Done: Sierra Leone | MAE: 0.0877 | RMSE: 0.1266 | R2: 0.8865 | MSE: 0.0160\n",
      "\n",
      "Hypertuning for Slovakia...\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 40ms/step\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 36ms/step\n",
      "Done: Slovakia | MAE: 0.3181 | RMSE: 0.3919 | R2: 0.6486 | MSE: 0.1536\n",
      "\n",
      "Hypertuning for Slovenia...\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 50ms/step\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 66ms/step\n",
      "Done: Slovenia | MAE: 0.2642 | RMSE: 0.3385 | R2: 0.5830 | MSE: 0.1146\n",
      "\n",
      "Hypertuning for Solomon Islands...\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 48ms/step\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 46ms/step\n",
      "Done: Solomon Islands | MAE: 0.0482 | RMSE: 0.0822 | R2: 0.8492 | MSE: 0.0068\n",
      "\n",
      "Hypertuning for Somalia...\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 71ms/step\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 68ms/step\n",
      "Done: Somalia | MAE: 0.1341 | RMSE: 0.1872 | R2: 0.6046 | MSE: 0.0350\n",
      "\n",
      "Hypertuning for South Africa...\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 50ms/step\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 44ms/step\n",
      "Done: South Africa | MAE: 0.1235 | RMSE: 0.2142 | R2: 0.7984 | MSE: 0.0459\n",
      "\n",
      "Hypertuning for South Georgia and the South Sandwich Islands...\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 40ms/step\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 70ms/step\n",
      "Done: South Georgia and the South Sandwich Islands | MAE: 0.1061 | RMSE: 0.1941 | R2: 0.7661 | MSE: 0.0377\n",
      "\n",
      "Hypertuning for South Korea...\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 51ms/step\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 54ms/step\n",
      "Done: South Korea | MAE: 0.2083 | RMSE: 0.2746 | R2: 0.7541 | MSE: 0.0754\n",
      "\n",
      "Hypertuning for South Sudan...\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 32ms/step\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 37ms/step\n",
      "Done: South Sudan | MAE: 0.1650 | RMSE: 0.2398 | R2: 0.7662 | MSE: 0.0575\n",
      "\n",
      "Hypertuning for Spain...\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 46ms/step\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 64ms/step\n",
      "Done: Spain | MAE: 0.1403 | RMSE: 0.2405 | R2: 0.7766 | MSE: 0.0579\n",
      "\n",
      "Hypertuning for Sri Lanka...\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 60ms/step\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 135ms/step\n",
      "Done: Sri Lanka | MAE: 0.1192 | RMSE: 0.1743 | R2: 0.5289 | MSE: 0.0304\n",
      "\n",
      "Hypertuning for Sudan...\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 58ms/step\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 73ms/step\n",
      "Done: Sudan | MAE: 0.1975 | RMSE: 0.2906 | R2: 0.3133 | MSE: 0.0845\n",
      "\n",
      "Hypertuning for Suriname...\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 92ms/step\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 69ms/step\n",
      "Done: Suriname | MAE: 0.1402 | RMSE: 0.2173 | R2: 0.6722 | MSE: 0.0472\n",
      "\n",
      "Hypertuning for Sweden...\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 78ms/step\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 83ms/step\n",
      "Done: Sweden | MAE: 0.2432 | RMSE: 0.4396 | R2: 0.7100 | MSE: 0.1933\n",
      "\n",
      "Hypertuning for Switzerland...\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 121ms/step\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 81ms/step\n",
      "Done: Switzerland | MAE: 0.3662 | RMSE: 0.4852 | R2: 0.5249 | MSE: 0.2354\n",
      "\n",
      "Hypertuning for Syria...\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 45ms/step\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 39ms/step\n",
      "Done: Syria | MAE: 0.3874 | RMSE: 0.5209 | R2: 0.2414 | MSE: 0.2713\n",
      "\n",
      "Hypertuning for Tajikistan...\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 39ms/step\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 32ms/step\n",
      "Done: Tajikistan | MAE: 0.2841 | RMSE: 0.3695 | R2: 0.6584 | MSE: 0.1365\n",
      "\n",
      "Hypertuning for Tanzania...\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 33ms/step\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 34ms/step\n",
      "Done: Tanzania | MAE: 0.1156 | RMSE: 0.1615 | R2: 0.3937 | MSE: 0.0261\n",
      "\n",
      "Hypertuning for Thailand...\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 38ms/step\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 27ms/step\n",
      "Done: Thailand | MAE: 0.1811 | RMSE: 0.2828 | R2: 0.5519 | MSE: 0.0800\n",
      "\n",
      "Hypertuning for Togo...\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 27ms/step\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 27ms/step\n",
      "Done: Togo | MAE: 0.0973 | RMSE: 0.1506 | R2: 0.7149 | MSE: 0.0227\n",
      "\n",
      "Hypertuning for Trinidad and Tobago...\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 27ms/step\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 30ms/step\n",
      "Done: Trinidad and Tobago | MAE: 0.0803 | RMSE: 0.1316 | R2: 0.7852 | MSE: 0.0173\n",
      "\n",
      "Hypertuning for Tunisia...\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 27ms/step\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 28ms/step\n",
      "Done: Tunisia | MAE: 0.1495 | RMSE: 0.2389 | R2: 0.7460 | MSE: 0.0571\n",
      "\n",
      "Hypertuning for Turkey...\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 27ms/step\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 27ms/step\n",
      "Done: Turkey | MAE: 0.3959 | RMSE: 0.5753 | R2: 0.3138 | MSE: 0.3310\n",
      "\n",
      "Hypertuning for Turkmenistan...\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 27ms/step\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 27ms/step\n",
      "Done: Turkmenistan | MAE: 0.3340 | RMSE: 0.4255 | R2: 0.4732 | MSE: 0.1811\n",
      "\n",
      "Hypertuning for Uganda...\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 26ms/step\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 26ms/step\n",
      "Done: Uganda | MAE: 0.1326 | RMSE: 0.1886 | R2: 0.7506 | MSE: 0.0356\n",
      "\n",
      "Hypertuning for Ukraine...\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 27ms/step\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 27ms/step\n",
      "Done: Ukraine | MAE: 0.2682 | RMSE: 0.3461 | R2: 0.7129 | MSE: 0.1198\n",
      "\n",
      "Hypertuning for United Arab Emirates...\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 27ms/step\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 27ms/step\n",
      "Done: United Arab Emirates | MAE: 0.1265 | RMSE: 0.2060 | R2: 0.7467 | MSE: 0.0424\n",
      "\n",
      "Hypertuning for United Kingdom...\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 27ms/step\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 27ms/step\n",
      "Done: United Kingdom | MAE: 0.1374 | RMSE: 0.2702 | R2: 0.7311 | MSE: 0.0730\n",
      "\n",
      "Hypertuning for United States...\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 27ms/step\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 27ms/step\n",
      "Done: United States | MAE: 0.1220 | RMSE: 0.2046 | R2: 0.8580 | MSE: 0.0419\n",
      "\n",
      "Hypertuning for United States Virgin Islands...\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 27ms/step\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 27ms/step\n",
      "Done: United States Virgin Islands | MAE: 0.1408 | RMSE: 0.1843 | R2: 0.6188 | MSE: 0.0340\n",
      "\n",
      "Hypertuning for Uruguay...\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 27ms/step\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 30ms/step\n",
      "Done: Uruguay | MAE: 0.1255 | RMSE: 0.2194 | R2: 0.5897 | MSE: 0.0481\n",
      "\n",
      "Hypertuning for Uzbekistan...\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 29ms/step\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 28ms/step\n",
      "Done: Uzbekistan | MAE: 0.1940 | RMSE: 0.3281 | R2: 0.7630 | MSE: 0.1077\n",
      "\n",
      "Hypertuning for Vanuatu...\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 31ms/step\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 30ms/step\n",
      "Done: Vanuatu | MAE: 0.1128 | RMSE: 0.1624 | R2: 0.5582 | MSE: 0.0264\n",
      "\n",
      "Hypertuning for Venezuela...\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 29ms/step\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 27ms/step\n",
      "Done: Venezuela | MAE: 0.1682 | RMSE: 0.2326 | R2: 0.6259 | MSE: 0.0541\n",
      "\n",
      "Hypertuning for Vietnam...\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 27ms/step\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 34ms/step\n",
      "Done: Vietnam | MAE: 0.1323 | RMSE: 0.2161 | R2: 0.7605 | MSE: 0.0467\n",
      "\n",
      "Hypertuning for World...\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 27ms/step\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 28ms/step\n",
      "Done: World | MAE: 0.0329 | RMSE: 0.0550 | R2: 0.9341 | MSE: 0.0030\n",
      "\n",
      "Hypertuning for Yemen...\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 27ms/step\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 27ms/step\n",
      "Done: Yemen | MAE: 0.0941 | RMSE: 0.1682 | R2: 0.7908 | MSE: 0.0283\n",
      "\n",
      "Hypertuning for Zambia...\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 27ms/step\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 28ms/step\n",
      "Done: Zambia | MAE: 0.1115 | RMSE: 0.1632 | R2: 0.7773 | MSE: 0.0266\n",
      "\n",
      "Hypertuning for Zimbabwe...\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 28ms/step\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 27ms/step\n",
      "Done: Zimbabwe | MAE: 0.1145 | RMSE: 0.2016 | R2: 0.8262 | MSE: 0.0406\n"
     ]
    }
   ],
   "source": [
    "param_grid = {\n",
    "    'seq_len': [12],  # Different sequence lengths to try\n",
    "    'lstm_units': [32],  # Number of neurons in LSTM layer\n",
    "    'num_lstm_layers': [1],    # Number of LSTM layers\n",
    "    'dropout': [0.2],     # Dropout rate\n",
    "    'batch_size': [32],   # Batch size\n",
    "    'epochs': [10, 20],      # Number of epochs\n",
    "    'optimizer': ['adam'],  # Optimizer\n",
    "    'learning_rate': [0.001],  # Learning rate\n",
    "    'use_early_stopping': [True],  # Whether to use early stopping\n",
    "    'patience': [3],              # Early stopping patience\n",
    "}\n",
    "\n",
    "countries = df[\"Entity\"].unique()\n",
    "#countries = countries[:2]\n",
    "print(countries)\n",
    "results_df = hypertune_all_countries(df, countries, param_grid)\n",
    "results_df.to_csv(\"../metrics/LSTM/hypertuning_results.csv\", index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Country</th>\n",
       "      <th>Best_MAE</th>\n",
       "      <th>Best_Params</th>\n",
       "      <th>Scores</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Afghanistan</td>\n",
       "      <td>0.307281</td>\n",
       "      <td>{'seq_len': 12, 'lstm_units': 32, 'num_lstm_la...</td>\n",
       "      <td>{'MAE': 0.3072811635576003, 'RMSE': 0.41773376...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Albania</td>\n",
       "      <td>0.137561</td>\n",
       "      <td>{'seq_len': 12, 'lstm_units': 32, 'num_lstm_la...</td>\n",
       "      <td>{'MAE': 0.13756118522810246, 'RMSE': 0.2125583...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Algeria</td>\n",
       "      <td>0.167318</td>\n",
       "      <td>{'seq_len': 12, 'lstm_units': 32, 'num_lstm_la...</td>\n",
       "      <td>{'MAE': 0.1673180034904856, 'RMSE': 0.28078965...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>American Samoa</td>\n",
       "      <td>0.071735</td>\n",
       "      <td>{'seq_len': 12, 'lstm_units': 32, 'num_lstm_la...</td>\n",
       "      <td>{'MAE': 0.07173501669341742, 'RMSE': 0.1141096...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Andorra</td>\n",
       "      <td>0.278389</td>\n",
       "      <td>{'seq_len': 12, 'lstm_units': 32, 'num_lstm_la...</td>\n",
       "      <td>{'MAE': 0.278389467012039, 'RMSE': 0.423862968...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>190</th>\n",
       "      <td>Vietnam</td>\n",
       "      <td>0.132274</td>\n",
       "      <td>{'seq_len': 12, 'lstm_units': 32, 'num_lstm_la...</td>\n",
       "      <td>{'MAE': 0.132273926493126, 'RMSE': 0.216114541...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>191</th>\n",
       "      <td>World</td>\n",
       "      <td>0.032919</td>\n",
       "      <td>{'seq_len': 12, 'lstm_units': 32, 'num_lstm_la...</td>\n",
       "      <td>{'MAE': 0.0329188817591905, 'RMSE': 0.05499239...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>192</th>\n",
       "      <td>Yemen</td>\n",
       "      <td>0.094082</td>\n",
       "      <td>{'seq_len': 12, 'lstm_units': 32, 'num_lstm_la...</td>\n",
       "      <td>{'MAE': 0.0940824105587192, 'RMSE': 0.16823765...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>193</th>\n",
       "      <td>Zambia</td>\n",
       "      <td>0.111544</td>\n",
       "      <td>{'seq_len': 12, 'lstm_units': 32, 'num_lstm_la...</td>\n",
       "      <td>{'MAE': 0.11154400956439037, 'RMSE': 0.1631756...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>194</th>\n",
       "      <td>Zimbabwe</td>\n",
       "      <td>0.114521</td>\n",
       "      <td>{'seq_len': 12, 'lstm_units': 32, 'num_lstm_la...</td>\n",
       "      <td>{'MAE': 0.11452095756727172, 'RMSE': 0.2016071...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>195 rows × 4 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "            Country  Best_MAE  \\\n",
       "0       Afghanistan  0.307281   \n",
       "1           Albania  0.137561   \n",
       "2           Algeria  0.167318   \n",
       "3    American Samoa  0.071735   \n",
       "4           Andorra  0.278389   \n",
       "..              ...       ...   \n",
       "190         Vietnam  0.132274   \n",
       "191           World  0.032919   \n",
       "192           Yemen  0.094082   \n",
       "193          Zambia  0.111544   \n",
       "194        Zimbabwe  0.114521   \n",
       "\n",
       "                                           Best_Params  \\\n",
       "0    {'seq_len': 12, 'lstm_units': 32, 'num_lstm_la...   \n",
       "1    {'seq_len': 12, 'lstm_units': 32, 'num_lstm_la...   \n",
       "2    {'seq_len': 12, 'lstm_units': 32, 'num_lstm_la...   \n",
       "3    {'seq_len': 12, 'lstm_units': 32, 'num_lstm_la...   \n",
       "4    {'seq_len': 12, 'lstm_units': 32, 'num_lstm_la...   \n",
       "..                                                 ...   \n",
       "190  {'seq_len': 12, 'lstm_units': 32, 'num_lstm_la...   \n",
       "191  {'seq_len': 12, 'lstm_units': 32, 'num_lstm_la...   \n",
       "192  {'seq_len': 12, 'lstm_units': 32, 'num_lstm_la...   \n",
       "193  {'seq_len': 12, 'lstm_units': 32, 'num_lstm_la...   \n",
       "194  {'seq_len': 12, 'lstm_units': 32, 'num_lstm_la...   \n",
       "\n",
       "                                                Scores  \n",
       "0    {'MAE': 0.3072811635576003, 'RMSE': 0.41773376...  \n",
       "1    {'MAE': 0.13756118522810246, 'RMSE': 0.2125583...  \n",
       "2    {'MAE': 0.1673180034904856, 'RMSE': 0.28078965...  \n",
       "3    {'MAE': 0.07173501669341742, 'RMSE': 0.1141096...  \n",
       "4    {'MAE': 0.278389467012039, 'RMSE': 0.423862968...  \n",
       "..                                                 ...  \n",
       "190  {'MAE': 0.132273926493126, 'RMSE': 0.216114541...  \n",
       "191  {'MAE': 0.0329188817591905, 'RMSE': 0.05499239...  \n",
       "192  {'MAE': 0.0940824105587192, 'RMSE': 0.16823765...  \n",
       "193  {'MAE': 0.11154400956439037, 'RMSE': 0.1631756...  \n",
       "194  {'MAE': 0.11452095756727172, 'RMSE': 0.2016071...  \n",
       "\n",
       "[195 rows x 4 columns]"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "results_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_results = pd.DataFrame(results)\n",
    "df_results.to_csv(\"saved_results/comparison.csv\", index=False)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
